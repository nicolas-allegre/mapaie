# ::snt First of all, how can existing regulations or new ones facilitate algorithmic accountability  or fairness?
# File 167

(p / possible-01
      :ARG1 (f / facilitate-01
            :ARG0 (o / or
                  :op1 (r / regulate-01
                        :ARG1-of (e / exist-01))
                  :op2 (r2 / regulate-01
                        :ARG1-of (n / new-01)))
            :ARG1 (o2 / or
                  :op1 (a / accountable-02
                        :mod (a2 / algorithm))
                  :op2 (f2 / fair-01))
            :manner (a3 / amr-unknown))
      :mod (f3 / first-of-all))

# ::snt The prohibition of discrimination (see subsection 3.7)   The Council of Europe could shed light on how algorithmic accountability or fairness can be  facilitated and how the developers of algorithms can be enabled to devise automated decisions that  respect human rights and will not (unintentionally) discriminate  against individuals .
# File 167

(p / possible-01
      :ARG1 (s / shed-light-10
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "Council"
                        :op2 "of"
                        :op3 "Europe"))
            :ARG1 (a / and
                  :op1 (p2 / possible-01
                        :ARG1 (f / facilitate-01
                              :ARG1 (o2 / or
                                    :op1 (a2 / accountable-02
                                          :ARG1 (a3 / algorithm))
                                    :op2 (f2 / fairness
                                          :mod (a4 / algorithm)))))
                  :op2 (e / enable-01
                        :ARG1 (d / devise-01
                              :ARG0 (p3 / person
                                    :ARG0-of (d2 / develop-02
                                          :ARG1 (a5 / algorithm)))
                              :ARG1 (d3 / decide-01
                                    :ARG1-of (a6 / automate-01)
                                    :ARG0-of (r / respect-01
                                          :ARG1 (r2 / right-05
                                                :ARG1 (h / human)))
                                    :ARG0-of (d4 / discriminate-02
                                          :polarity -
                                          :ARG1 (ii / individual)
                                          :ARG1-of (ii2 / intend-01
                                                :polarity -))))
                        :ARG2 p3)))
      :ARG1-of (c / cause-01
            :ARG0 (p4 / prohibit-01
                  :ARG1 (d5 / discriminate-02)
                  :ARG1-of (d6 / describe-01
                        :ARG0 (s2 / section
                              :mod 3.7)))))

# ::snt 20 4.3.3 AI Initiatives in Swiss Enterprises: Governance Mechanisms to Increase Transparency and Fairness .
# File 150

(m / multi-sentence
      :snt1 (ii / initiate-01
            :li 20
            :ARG1 (p / program
                  :name (n / name
                        :op1 "AI"))
            :location (e / enterprise
                  :mod (c / country
                        :name (n2 / name
                              :op1 "Switzerland"))))
      :snt2 (m2 / mechanism
            :mod (g / govern-01)
            :ARG0-of (ii2 / increase-01
                  :ARG1 (a / and
                        :op1 (t / transparency)
                        :op2 (f / fairness))))
      :li 3)

# ::snt A commonly used principle is fairness, which is, at rst glance, simple.
# File 150

(p / principle
      :ARG1-of (u / use-01
            :mod (c / common))
      :domain (f / fairness
            :ARG1-of (s / simple-02
                  :manner (g / glance-01
                        :ord (o / ordinal-entity
                              :value 1)))))

# ::snt But as can be seen in Dr. Weinberger's example of gender discrimination, there are many ways to dene fairness.
# File 150

(c / contrast-01
      :ARG2 (w / way
            :quant (m / many)
            :manner-of (d / discriminate-02
                  :mod (g / gender))
            :manner-of (f / fair-01)
            :ARG1-of (s / see-01
                  :ARG1-of (p / possible-01)
                  :location (e / example
                        :poss (p2 / person
                              :name (n / name
                                    :op1 "Dr."
                                    :op2 "Wineberger"))
                        :topic d))))

# ::snt The dierent denitions, such as equal opportunity, gender-blindness, or demographic fairness, give rise to very dierent recommended outcomes.
# File 150

(r / rise-01
      :ARG0 (d / diverse
            :example (o / or
                  :op1 (o2 / opportunity
                        :ARG1-of (e / equal-01))
                  :op2 (b / blind-02
                        :ARG2 (g / gender))
                  :op3 (f / fairness
                        :mod (d2 / demography)))
            :mod (d3 / diverse))
      :ARG1 (o3 / outcome
            :ARG1-of (r2 / recommend-01)
            :mod (d4 / distinctive
                  :degree (v / very))))

# ::snt The conclusion is that fairness is not simple, and we need to include everyone in the discussion on what it means.
# File 150

(c / conclude-01
      :ARG1 (a / and
            :op1 (s / simple-02
                  :polarity -
                  :ARG1 (f / fairness))
            :op2 (n / need-01
                  :ARG0 (w / we)
                  :ARG1 (ii / include-01
                        :ARG0 w
                        :ARG1 (e / everyone)
                        :ARG2 (d / discuss-01
                              :ARG1 (t / thing
                                    :ARG2-of (m / mean-01
                                          :ARG1 f)))))))

# ::snt Privacy, fairness, and trustworthiness are increasingly being discussed and gaining importance beyond the EU, in countries such as Brazil, USA, and China.
# File 150

(a / and
      :op1 (d / discuss-01
            :ARG1 (a2 / and
                  :op1 (p / privacy)
                  :op2 (f / fairness)
                  :op3 (d2 / deserve-01
                        :ARG1 (t / trust-01)))
            :ARG1-of (ii / increase-01))
      :op2 (g / gain-02
            :ARG1 a2
            :ARG2 (ii2 / important-01
                  :ARG1 a2)
            :location (b / beyond
                  :op1 (o / organization
                        :name (n / name
                              :op1 "EU"))
                  :location (c / country
                        :example (a3 / and
                              :op1 (c2 / country
                                    :name (n2 / name
                                          :op1 "Brazil"))
                              :op2 (c3 / country
                                    :name (n3 / name
                                          :op1 "USA"))
                              :op3 (c4 / country
                                    :name (n4 / name
                                          :op1 "China")))))))

# ::snt Another advantage of a physiciancentered approach is that medical professionals already have considerable experience with many critical issues, including bias, data privacy, fairness, and security of sensitive data.
# File 150

(a / advantage-01
      :ARG1 (a2 / approach-02
            :ARG1-of (c / center-01
                  :ARG2 (p / physician)))
      :ARG2 (e / experience-01
            :ARG0 (p2 / professional
                  :mod (m / medicine))
            :ARG1 (ii / issue-02
                  :ARG0-of (c2 / critical-02)
                  :quant (m2 / many)
                  :ARG2-of (ii2 / include-01
                        :ARG1 (a3 / and
                              :op1 (b / bias-01)
                              :op2 (p3 / private-02
                                    :ARG1 (d / data))
                              :op3 (f / fair-01)
                              :op4 (s / security
                                    :poss (d2 / data
                                          :ARG0-of (s2 / sensitive-03))))))
            :degree (c3 / considerable)
            :time (a4 / already))
      :mod (a5 / another))

# ::snt icting results regarding productivity and perceived fairness in human-robot teams.
# File 150

(t / thing
      :ARG2-of (r / result-01)
      :ARG0-of (r2 / regard-01
            :ARG1 (a / and
                  :op1 (p / productive-03
                        :ARG0 (t2 / team
                              :mod (r3 / robot
                                    :mod (h / human))))
                  :op2 (f / fair-01
                        :ARG1 t2
                        :ARG1-of (p2 / perceive-01)))))

# ::snt Some papers present an increase in perceived fairness of employees when given robotic managers, while there is also counter-evidence on how humans see the machine's competence as insucient to justify its superior position.
# File 150

(c / contrast-01
      :ARG1 (p / present-01
            :ARG0 (p2 / paper
                  :quant (s / some))
            :ARG1 (ii / increase-01
                  :ARG1 (f / fair-01
                        :ARG1 (p3 / person
                              :ARG1-of (e / employ-01))
                        :ARG1-of (p4 / perceive-01))
                  :condition (g / give-01
                        :ARG1 (p5 / person
                              :ARG0-of (m / manage-01)
                              :mod (r / robot))
                        :ARG2 p3)))
      :ARG2 (e2 / evidence-01
            :ARG1 (s2 / see-01
                  :ARG0 (h / human)
                  :ARG1 (c2 / competent-01
                        :ARG1 (m2 / machine))
                  :ARG2 (ii2 / insucient
                        :ARG0-of (j / justify-01
                              :ARG1 (p6 / position-02
                                    :ARG0 m2
                                    :ARG1-of (s3 / superior-01)))))
            :ARG0-of (c3 / counter-01)
            :mod (a / also)))

# ::snt The author underlined that the accuracy bounding should always be context-specic. The use of accuracy bounding could have other benecial impacts, such as drawing attention to the inherent trade-os when using metrics in fairness applications.
# File 150

(m / multi-sentence
      :snt1 (u / underline-01
            :ARG0 (p / person
                  :ARG0-of (a / author-01))
            :ARG1 (r / recommend-01
                  :ARG1 (c / context
                        :domain (b / bind-01
                              :ARG1 (a2 / accurate)))
                  :time (a3 / always)))
      :snt2 (p2 / possible-01
            :ARG1 (ii / impact-01
                  :ARG0 (u2 / use-01
                        :ARG1 (b2 / bind-01
                              :ARG1 (a4 / accurate)))
                  :mod (b3 / benevolence)
                  :example (d / draw-02
                        :ARG1 (a5 / attend-02
                              :ARG1 (o / object-01
                                    :ARG1 (t / trade-01)
                                    :mod (ii2 / inherent)))
                        :time (u3 / use-01
                              :ARG1 (m2 / metric)
                              :ARG2 (a6 / apply-02
                                    :ARG1 (f / fairness))))
                  :mod (o2 / other))))

# ::snt 4.3.3 AI Initiatives in Swiss Enterprises: Governance Mechanisms to Increase Transparency and Fairness Michael Weiser, Mael Schnegg, Patrick Lanter As AI becomes widely used in corporations, it is imperative to explore the ethical risks of employing strategies from algorithms that perform tasks without human involvement and control.
# File 150

(m / multi-sentence
      :snt2 imperative
      :li 3
      :domain (e / explore-01
            :ARG1 (r / risk-01
                  :ARG1 (e2 / employ-02
                        :ARG1 (s / strategy)
                        :source (a / algorithm
                              :ARG0-of (p / perform-02
                                    :ARG1 (t / task)
                                    :manner (ii / involve-01
                                          :polarity -
                                          :ARG1 (h / human))
                                    :manner (c / control-01
                                          :polarity -
                                          :ARG0 (h2 / human)))))
                  :mod (e3 / ethics)))
      :time (b / become-01
            :ARG1 (ii2 / intelligent-01
                  :mod (a2 / artificial))
            :ARG2 (u / use-01
                  :ARG1 ii2
                  :ARG2 (c2 / corporation)
                  :ARG1-of (w / wide-02)))
      :snt1 (ii3 / initiate-01
            :li 3
            :ARG1 (m2 / mechanism
                  :mod (g / govern-01)
                  :purpose (ii4 / increase-01
                        :ARG1 (a3 / and
                              :op1 (t2 / transparency)
                              :op2 (f / fairness))))
            :location (e4 / enterprise
                  :mod (c3 / country
                        :name (n / name
                              :op1 "Switzerland"))))
      :snt3 (a4 / and
            :op1 (p2 / person
                  :name (n2 / name
                        :op1 "Michael"
                        :op2 "Weiser"))
            :op2 (p3 / person
                  :name (n3 / name
                        :op1 "Mael"
                        :op2 "Schnegg"))
            :op3 (p4 / person
                  :name (n4 / name
                        :op1 "Patrick"
                        :op2 "Lanter"))))

# ::snt examined four large Swiss corporations to determine the current state of AI governance initiatives for increasing fairness and transparency in their algorithms.
# File 150

(e / examine-01
      :ARG1 (c / corporation
            :quant 4
            :mod (l / large)
            :mod (c2 / country
                  :name (n / name
                        :op1 "Switzerland")))
      :purpose (d / determine-01
            :ARG1 (s / state
                  :time (c3 / current)
                  :poss (ii / initiative
                        :topic (g / govern-01
                              :manner (ii2 / intelligent-01
                                    :mod (a / artificial)))
                        :ARG0-of (ii3 / increase-01
                              :ARG1 (a2 / and
                                    :op1 (f / fairness)
                                    :op2 (t / transparency)
                                    :location (a3 / algorithm
                                          :poss c)))))))

# ::snt 4.4 Technical Aspects of AI 4.4.1 A Parallel Evolutionary Multiple-try Metropolis Markov Chain Monte Carlo Algorithm for Sampling Spatial Partitions Wendy K. Tam Cho, Yan Liu Current methods for determining districts for rst-past-the-post voting systems present many challenges and questions regarding how partisanship can aect the fairness of the electoral maps drawn.
# File 150

(m / multi-sentence
      :snt2 (a / and
            :op1 (p / person
                  :name (n / name
                        :op1 "Wendy"
                        :op2 "K."
                        :op3 "Cho"))
            :op2 (p2 / person
                  :name (n2 / name
                        :op1 "Yan"
                        :op2 "Liu")))
      :snt3 (p3 / present-01
            :ARG0 (m2 / method
                  :time (c / current)
                  :instrument-of (d / determine-01
                        :ARG1 (d2 / district)
                        :ARG3 (s / system
                              :mod (v / vote-01
                                    :manner (t / thing
                                          :name (n3 / name
                                                :op1 "past"
                                                :op2 "the"
                                                :op3 "post"))
                                    :ord (o / ordinal-entity
                                          :value 1)))))
            :ARG1 (a2 / and
                  :op1 (c2 / challenge-01)
                  :op2 (q / question-01
                        :ARG1 (t2 / thing
                              :manner-of (p4 / possible-01
                                    :ARG1 (a3 / affect-01
                                          :ARG0 (p5 / partisanship)
                                          :ARG1 (f / fair-01
                                                :ARG1 (m3 / map
                                                      :mod (e / elect-01)
                                                      :ARG1-of (d3 / draw-01)))))))
                  :quant (m4 / many)))
      :snt1 (a4 / aspect
            :topic (ii / intelligent-01
                  :mod (a5 / artificial)
                  :ord (o2 / ordinal-entity
                        :value "4.4.1"))
            :mod (t3 / technical)
            :example (a6 / algorithm
                  :name (n4 / name
                        :op1 "Metropolis"
                        :op2 "Markov"
                        :op3 "Chain"
                        :op4 "Monte"
                        :op5 "Carlo"
                        :op6 "Algorithm")
                  :mod (e2 / evolution
                        :ARG1-of (p6 / parallel-01))
                  :mod (t4 / try-01
                        :quant (m5 / multiple))
                  :purpose (s2 / sample-01
                        :ARG1 (p7 / partition-01
                              :mod (s3 / space))))))

# ::snt Troncoso et al argued that this approach, with its focus on algorithmic fairness, is insucient to address the issue of harmful AI adequately.
# File 150

(a / argue-01
      :ARG0 (a2 / and
            :op1 (p / person
                  :name (n / name
                        :op1 "Troncoso"))
            :op2 (p2 / person
                  :mod (o / other)))
      :ARG1 (ii / insucient
            :domain (a3 / address-02
                  :ARG0 (a4 / approach-02
                        :mod (t / this)
                        :ARG0-of (f / focus-01
                              :ARG2 (f2 / fair-01
                                    :mod (a5 / algorithm))))
                  :ARG1 (ii2 / issue-02
                        :ARG0 (ii3 / intelligent-01
                              :mod (a6 / artificial)
                              :ARG0-of (h / harmful-02)))
                  :manner (a7 / adequate))))

# ::snt Hence, commonly used frameworks of fairness are too narrow to capture the full range of harmful AI risks.
# File 150

(c / cause-01
      :ARG1 (h / have-degree-91
            :ARG1 (f / framework
                  :ARG1-of (u / use-01
                        :mod (c2 / common))
                  :topic (f2 / fair-01))
            :ARG2 (n / narrow-02
                  :ARG1 f)
            :ARG3 (t / too)
            :ARG6 (c3 / capture-01
                  :ARG0 f
                  :ARG1 (r / range-01
                        :ARG1 (r2 / risk-01
                              :ARG1 (ii / intelligent-01
                                    :mod (a / artificial))
                              :ARG0-of (h2 / harmful-02))
                        :ARG1-of (f3 / full-09)))))

# ::snt However, POTs are more suited to address the issue of harmful AI than current notions of algorithmic fairness and AI governance.
# File 150

(c / contrast-01
      :ARG2 (s / suit-01
            :ARG1 (t / thing
                  :name (n / name
                        :op1 "POT"))
            :ARG2 (a / address-02
                  :ARG0 t
                  :ARG1 (ii / issue-02
                        :ARG0 (ii2 / intelligent-01
                              :mod (a2 / artificial)
                              :ARG0-of (h / harmful-02))))
            :ARG2-of (h2 / have-degree-91
                  :ARG1 t
                  :ARG3 (m / more)
                  :ARG4 (n2 / notion
                        :time (c2 / current)
                        :topic (a3 / and
                              :op1 (f / fairness
                                    :mod (a4 / algorithmic))
                              :op2 (g / govern-01
                                    :ARG1 ii2))))))

# ::snt At the same time, big data amplifies risks to privacy, fairness,  equality, and due process.
# File 105

(a / amplify-01
      :ARG0 (d / data
            :mod (b / big))
      :ARG1 (r / risk-01
            :ARG2 (a2 / and
                  :op1 (p / privacy)
                  :op2 (f / fairness)
                  :op3 (e / equal-01)
                  :op4 (d2 / due-process)))
      :time (t / time
            :ARG1-of (s / same-01)))

# ::snt Depending on the projects, its role will also consist of arbitrating between any tensions (between performance and ethical and security issues), establishing thresholds and other limits, specifying the criteria of fairness and explainability which will be referred to and examining critical cases.
# File 132

(c / consist-01
      :ARG1 (r / role
            :poss (ii / it))
      :ARG2 (a / and
            :op1 (a2 / arbitrate-01
                  :ARG0 ii
                  :ARG1 (t / tension
                        :mod (a3 / any)
                        :location (b / between
                              :op1 (p / perform-02)
                              :op2 (ii2 / issue-02
                                    :ARG0 (a4 / and
                                          :op1 (e / ethics)
                                          :op2 (s / security))))))
            :op2 (e2 / establish-01
                  :ARG0 ii
                  :ARG1 (a5 / and
                        :op1 (t2 / threshold)
                        :op2 (l / limit-01
                              :mod (o / other))))
            :op3 (s2 / specify-01
                  :ARG0 ii
                  :ARG1 (c2 / criteria
                        :topic (a6 / and
                              :op1 (f / fairness)
                              :op2 (e3 / explain-01
                                    :ARG1-of (p2 / possible-01)))
                        :ARG1-of (r2 / refer-03)))
            :op4 (e4 / examine-01
                  :ARG0 ii
                  :ARG1 (c3 / case-04
                        :ARG1-of (c4 / critical-02))))
      :ARG0-of (d / depend-01
            :ARG1 (p3 / project))
      :mod (a7 / also))

# ::snt PRACTICAL RECOMMENDATIONS 21 PART 3 PART 1 PART 2 PART 2 TABLE OF CONTENTSEthical subjects to consider specifically Data protection No bias Transparency Fairness Control Reliability System purpose and  implementation framework Applies  to the  project Confidentiality of personal data Controlled and  measured use of personal data  Prevention of risks of  discrimination Diversity of the  project team Accessibility of the  solution Explainability of the  model and the results Traceability of data  and processes Reliability of results Disclosure of the AI Operation under  human control Robustness and  resilience of the solution The business needThe system automates a decision, or helps to make a decision concerning physical persons Yes/No The system automates the performance of tasks for the userYes/No The system is destined to deployed on a very large scale- cf.
# File 132

(m / multi-sentence
      :snt1 (r / recommend-01
            :ARG0 (p / publication
                  :ARG1-of (c / cite-01
                        :ARG2 (a / and
                              :op1 (p2 / part
                                    :mod 3)
                              :op2 (p3 / part
                                    :mod 1)
                              :op3 (p4 / part
                                    :mod 2)
                              :op4 (t / table
                                    :mod 2
                                    :consist-of (s / subject
                                          :mod (c2 / contingency))
                                    :purpose (c3 / consider-02
                                          :ARG1 (p5 / protect-01
                                                :ARG1 (d / data)
                                                :ARG1-of (s2 / specific-02)))))))
            :ARG1 (a2 / and
                  :op1 (b / bias-01
                        :polarity -)
                  :op2 (t2 / transparency)
                  :op3 (o / organization
                        :name (n / name
                              :op1 "Fairness"
                              :op2 "Control"
                              :op3 "Reliability"
                              :op4 "System"))
                  :op4 (f / framework
                        :mod (ii / implement-01))))
      :snt2 (a3 / apply-02
            :ARG1 (s3 / system)
            :ARG2 (a4 / and
                  :op1 (c4 / confidential
                        :domain (d2 / data
                              :ARG1-of (p6 / personal-02)))
                  :op2 (a5 / and
                        :op1 (c5 / control-01
                              :ARG1 d2)
                        :op2 (u / use-01
                              :ARG1 d2
                              :ARG1-of (m2 / measure-01)))
                  :op3 (p7 / prevent-01
                        :ARG1 (r2 / risk-01
                              :ARG2 (d3 / discriminate-02)))
                  :op4 (d4 / diversity
                        :domain (t3 / team
                              :mod (p8 / project)))
                  :op5 (p9 / possible-01
                        :ARG1 (e / explain-01
                              :ARG1 (a6 / and
                                    :op1 (m3 / model-01)
                                    :op2 (r3 / result))))
                  :op6 (p10 / possible-01
                        :ARG1 (r4 / rely-01
                              :ARG1 (a7 / and
                                    :op1 (d5 / data)
                                    :op2 (p11 / process-01))))
                  :op7 (r5 / rely-01
                        :ARG1 (r6 / result))
                  :op8 (d6 / disclose-01
                        :ARG1 (o2 / operate-01
                              :mod (a8 / artificial))
                        :condition (c6 / control-01
                              :ARG0 (h / human)))
                  :op9 (a9 / and
                        :op1 (r7 / robust
                              :domain (s4 / solution))
                        :op2 (r8 / resilience
                              :poss s4))
                  :op10 (n2 / need-01
                        :ARG0 (b2 / business))))
      :ARG1 (d7 / deploy-01
            :ARG1 s3
            :ARG2 (l / large-scale
                  :degree (v / very))
            :example (a10 / and
                  :op1 (y / yes)
                  :op2 (n3 / no))))

# ::snt PRACTICAL RECOMMENDATIONS 22 PART 3 PART 1 PART 2 PART 2 TABLE OF CONTENTSEthical subjects to consider specifically Data protection No bias Transparency Fairness Control Reliability System purpose and  implementation framework  Applies to  the project Confidentiality of personal data Controlled and  measured use of personal data  Prevention of risks  of discrimination Diversity of the  project team Accessibility of the  solution Explainability of  the model and the results Traceability of data  and processes Reliability of results Disclosure of the AI Operation under  human control Robustness and  resilience of the solutionThe technical AI solutionThe system is embedded in a larger system Yes/No Training the system requires a large volume of data Yes/No Training the system requires the use of sensitive  and/or personal data Yes/No The system requires machine learning datasets from public databasesYes/No The  system draws on a single source to build its machine learning datasetsYes/No The machine learning dataset is built from different heterogeneous databases (in terms of quality, quantity, etc.
# File 132

(m / multi-sentence
      :snt1 (r / recommend-01
            :ARG0 (p / publication
                  :ARG1-of (ii / include-91
                        :ARG2 (a / and
                              :op1 (p2 / part
                                    :mod 3)
                              :op2 (p3 / part
                                    :mod 1)
                              :op3 (p4 / part
                                    :mod 2))))
            :ARG1 (t / table
                  :consist-of (s / subject
                        :mod (c / contingency))
                  :purpose (c2 / consider-02
                        :ARG1 (p5 / protect-01
                              :ARG1 (d / data)
                              :ARG1-of (s2 / specific-02)))))
      :snt2 (a2 / and
            :op1 (b / bias-01
                  :polarity -)
            :op2 (t2 / transparency)
            :op3 (h / have-purpose-91
                  :ARG1 (s3 / system)
                  :ARG2 (a3 / and
                        :op1 (p6 / purpose)
                        :op2 (f / framework
                              :topic (ii2 / implement-01)))))
      :snt3 (a4 / apply-02
            :ARG2 (p7 / project))
      :snt4 (r2 / require-01
            :ARG0 (s4 / system)
            :ARG1 (u / use-01
                  :ARG1 (d2 / data
                        :ARG1-of (p8 / personal-02))
                  :ARG1-of (c3 / control-01
                        :ARG0 (h2 / human))
                  :ARG1-of (m2 / measure-01)))
      :snt5 (a5 / and
            :op1 (p9 / prevent-01
                  :ARG1 (r3 / risk-01))
            :op2 (d3 / discriminate-02)
            :op3 (d4 / diverse
                  :domain (t3 / team
                        :mod p7)))
      :snt6 (r4 / rely-01
            :ARG1 (a6 / and
                  :op1 (d5 / data)
                  :op2 (p10 / process-01))
            :ARG1-of (p11 / possible-01))
      :snt7 (a7 / and
            :op1 (e / embed-01
                  :ARG1 (s5 / system
                        :ARG1-of (h3 / have-degree-91
                              :ARG2 (l / large)
                              :ARG3 (m3 / more)))
                  :ARG2 s5)
            :op2 (t4 / train-01
                  :ARG2 s5))
      :snt8 (r5 / require-01
            :ARG0 (s6 / system)
            :ARG1 (d6 / dataset
                  :mod (l2 / learn-01
                        :ARG1 (m4 / machine)))
            :source (d7 / database
                  :ARG1-of (p12 / public-02))))

# ::snt PRACTICAL RECOMMENDATIONS 23 PART 3 PART 1 PART 2 PART 2 TABLE OF CONTENTSEthical subjects to consider specifically Data protection No bias Transparency Fairness Control Reliability System purpose and  implementation framework  Applies  to the  project Confidentiality of personal data Controlled and  measured use of personal data  Prevention of risks of  discrimination Diversity of the  project team Accessibility of the  solution Explainability of the  model and the results Traceability of data  and processes Reliability of results Disclosure of the AI Operation under  human control Robustness and  resilience of the solutionProject governanceThe project team can refer to an in-house body in charge of ethics and AI-related subjectsYes/No The project team can refer to a set of AI project governance rulesYes/No The project team lacks diversity (gender, origin, culture, business, etc.
# File 132

(m / multi-sentence
      :snt1 (r / recommend-01
            :ARG1 (a / and
                  :op1 (p / part
                        :mod 3)
                  :op2 (p2 / part
                        :mod 1)
                  :op3 (p3 / part
                        :mod 2)
                  :op4 (t / table
                        :consist-of (s / subject
                              :mod (c / contingency)))
                  :purpose (c2 / consider-02
                        :ARG1 (p4 / protect-01
                              :ARG1 (d / data)
                              :ARG1-of (s2 / specific-02)))))
      :snt2 (a2 / and
            :op1 (b / bias-01
                  :polarity -)
            :op2 (t2 / transparency)
            :op3 (o / organization
                  :name (n / name
                        :op1 "Fairness"
                        :op2 "Control"
                        :op3 "Reliability"
                        :op4 "System"))
            :op4 (f / framework
                  :mod (ii / implement-01)))
      :snt3 (a3 / apply-02
            :ARG1 (p5 / possible-01
                  :ARG1 (r2 / refer-03
                        :ARG0 (t3 / team
                              :mod (p6 / project))
                        :ARG1 (b2 / body
                              :mod (ii2 / in-house)
                              :ARG0-of (c3 / charge-08
                                    :ARG1 s
                                    :ARG1-of (r3 / relate-01
                                          :ARG2 (a4 / and
                                                :op1 (e / ethics)
                                                :op2 (ii3 / intelligent-01
                                                      :mod (a5 / artificial)))))))))
      :ARG2 (c4 / confidential
            :mod p6)
      :snt4 (s3 / slash
            :op1 (y / yes)
            :op2 (n2 / no))
      :snt5 (l / lack-01
            :ARG0 t3
            :ARG1 (d2 / diversity
                  :example (a6 / and
                        :op1 (g / gender)
                        :op2 (o2 / origin)
                        :op3 (c5 / culture)
                        :op4 (b3 / business)
                        :op5 (e2 / et-cetera))))
      :snt6 (a7 / and
            :op1 (p7 / possible-01
                  :ARG1 (a8 / access-01
                        :ARG1 (s4 / solution)))
            :op2 (p8 / possible-01
                  :ARG1 (e3 / explain-01
                        :ARG1 (a9 / and
                              :op1 (m2 / model)
                              :op2 (r4 / result))))
            :op3 (p9 / possible-01
                  :ARG1 (r5 / rely-01
                        :ARG1 (a10 / and
                              :op1 (d3 / data)
                              :op2 (p10 / process)))))
      :op4 (r6 / rely-01
            :ARG1 (r7 / result))
      :snt7 (d4 / disclose-01
            :ARG0 (o3 / operate-01
                  :mod ii3)
            :condition (c6 / control-01
                  :ARG0 (h / human))))

# ::snt →   An approach defended by the Institut Montaigne in its white paper Algorithmes, contrôle des biais SVP ,  which  it calls «active fairness», consists of using datasets containing protected variables (the approach requires submitting an impact assessment to the CNIL).
# File 132

(m / multi-sentence
      :snt1 (c / consist-01
            :ARG1 (a / approach-02
                  :ARG1-of (d / defend-01
                        :ARG0 (r / research-institute
                              :name (n / name
                                    :op1 "Institut"
                                    :op2 "Montaigne"))
                        :medium (p / paper
                              :name (n2 / name
                                    :op1 "Algorithmes")
                              :ARG1-of (w / white-03)
                              :poss r)))
            :ARG2 (u / use-01
                  :ARG1 (d2 / dataset
                        :ARG0-of (c2 / contain-01
                              :ARG1 (v / variable
                                    :ARG1-of (p2 / protect-01))))))
      :snt2 (r2 / require-01
            :ARG0 a
            :ARG1 (s / submit-01
                  :ARG1 (a2 / assess-01
                        :ARG1 (ii / impact-01))
                  :ARG2 (g / government-organization
                        :name (n3 / name
                              :op1 "CNIL")))))

# ::snt ▶ A tutorial on fairness   in machine learning, atechnical post by Ziyuan Zhong (Towards Data Science, 2018).EXPLORE THE SUBJECT FURTHER 40 PARTIE 3 SOMMAIRE PARTIE 1 PARTIE 2
# File 132

(m / multi-sentence
      :snt1 (p / post-01
            :ARG0 (p2 / person
                  :name (n / name
                        :op1 "Ziyuan"
                        :op2 "Zhong"))
            :ARG1 (p3 / publication-91
                  :ARG1 (p4 / publication
                        :name (n2 / name
                              :op1 "Towards"
                              :op2 "Data"
                              :op3 "Science"))
                  :time (d / date-entity
                        :year 2018))
            :ARG3 (t / tutorial
                  :topic (f / fairness
                        :topic (l / learn-01
                              :ARG1 (m2 / machine))))
            :mod (c / culinary))
      :snt2 (e / explore-01
            :mode imperative
            :ARG0 (y / you)
            :ARG1 (s / subject)
            :degree (f2 / further))
      :snt3 (a / and
            :op1 (p5 / party
                  :quant 40)
            :op2 (p6 / party
                  :quant 3)
            :op3 (p7 / party
                  :mod 1)
            :op4 (p8 / party
                  :mod 2)))

# ::snt USE CASES AND EXAMPLES 65 PART 3 PART 1 PART 2 PART 3 TABLE OF CONTENTSSubjects to address   (according to the ethical sensitivity matrix)Ideas for solutions identified   (for each subject to be addressed) ETHICAL SUBJECTS TO CONSIDER SPECIFICALL Y RespectConfidentiality of personal data Controlled and measured use of personal data UnbiasedPrevention of risks of discrimination Diversity of the project team Accessibility of the solution TransparencyExplainability of the model and the results Traceability of data and processes FairnessReliability of results Disclosure of the AI Control Operation under human control Reliability Robustness and resilience of the solutionACTION(S)/PHASE(S) OF THE PROJECT/ACTOR(S) Design: pseudonymisation of personal data, setting up of secure access to data, list of features that  are inputs for the algorithms, work from customer identifier, non-integration of data considered as «sensitive» within the meaning of the GDPR Design: two separate data processing operations: learning and use of the model  Development: validation of data relevant to operation, final minimisation Design: introduction of random data for deliberate diversity in the recommendation Development: diversity in the test team or test roles Design: design for accessibility to all audiences from the outset Design: need for transparency for the tester and the customer Deployment: propose different parameter settings to the user: relevance, dates, etc.
# File 132

(m / multi-sentence
      :snt1 (a / and
            :op1 (c / case
                  :mod 65)
            :op2 (e / exemplify-01))
      :snt2 (a2 / and
            :op1 (ii / include-91
                  :ARG1 (p / part
                        :mod 1)
                  :ARG2 (p2 / part
                        :mod 2))
            :op2 (ii2 / include-91
                  :ARG1 (t / table
                        :mod 3
                        :consist-of (c2 / contingency
                              :ARG1-of (a3 / address-02
                                    :ARG0 (m2 / matrix
                                          :mod (s / sensitive-03
                                                :mod (e2 / ethics))))))
                  :ARG2 (d / design-01
                        :ARG1 (a4 / and
                              :op1 (a5 / and
                                    :op1 (v / validate-01
                                          :ARG1 (d2 / data
                                                :ARG1-of (r / relevant-01
                                                      :ARG2 (o / operation))))
                                    :op2 (m3 / minimize-01
                                          :ARG1 d2
                                          :mod (f / final)))
                              :op2 (ii3 / introduce-02
                                    :ARG1 (d3 / data
                                          :mod (r2 / random))
                                    :ARG2 (d4 / diversity
                                          :topic (o2 / or
                                                :op1 (t2 / team
                                                      :ARG0-of (t3 / test-01))
                                                :op2 (r3 / role
                                                      :mod t3))))
                              :op3 (d5 / design-01
                                    :ARG1 (a6 / accessibility
                                          :beneficiary (a7 / audience
                                                :mod (a8 / all))
                                          :time (f2 / from
                                                :op1 (o3 / outset))))
                              :op4 (a9 / and
                                    :op1 (p3 / prevent-01
                                          :ARG1 (r4 / risk-01
                                                :ARG2 (d6 / discriminate-02)))
                                    :op2 (u / use-01
                                          :ARG1 (d7 / data
                                                :ARG1-of (p4 / personal-02))
                                          :ARG1-of (m4 / measure-01))
                                    :op3 (w / work-01
                                          :ARG3 (t4 / thing
                                                :ARG2-of (ii4 / identify-01
                                                      :ARG1 (c3 / customer))))
                                    :op4 (ii5 / integrate-01
                                          :polarity -
                                          :ARG1 d7
                                          :ARG1-of (c4 / consider-01
                                                :ARG0 (l / law
                                                      :name (n / name
                                                            :op1 "GDPR")))))))
                  :snt3 (a10 / and
                        :op1 (p5 / possible-01
                              :ARG1 (e3 / explain-01
                                    :ARG1 (a11 / and
                                          :op1 (d8 / data)
                                          :op2 (p6 / process-01)))))
                  :op2 (p7 / possible-01
                        :ARG1 (r5 / rely-01
                              :ARG1 a11)))
            :snt4 (a12 / and
                  :op1 (p8 / possible-01
                        :ARG1 (r6 / rely-01
                              :ARG1 a11))
                  :op2 (r7 / resilience))
            :snt5 (a13 / and
                  :op1 (p9 / possible-01
                        :ARG1 e3))
            :op2 (p10 / possible-01
                  :ARG1 (r8 / rely-01))
            :snt6 (e4 / et-cetera)))

# ::snt  Policies and regulations that promote explainability, transparency and fairness,  as well as human -centricity, as clear baseline requirements can build consumer  trust in AI deployments.
# File 26

(p / possible-01
      :ARG1 (b / build-01
            :ARG0 (a / and
                  :op1 (p2 / policy-01)
                  :op2 (r / regulate-01)
                  :ARG0-of (p3 / promote-02
                        :ARG1 (a2 / and
                              :op1 p
                              :ARG1 (e / explain-01))
                        :op2 (t / transparency)
                        :op3 (f / fairness)
                        :op4 (c / center-01
                              :ARG1 (h / human))))
            :prep-as (r2 / require-01
                  :mod (b2 / baseline)
                  :ARG1-of (c2 / clear-06)))
      :ARG1 (t2 / trust-02
            :ARG0 (p4 / person
                  :ARG0-of (c3 / consume-01))
            :ARG1 (d / deploy-01
                  :ARG1 (ii / intelligent-01
                        :mod (a3 / artificial)))))

# ::snt  Fair:  AI algorithms and models embedded in decision -making systems should  incorporate fairness at their  core.
# File 26

(m / multi-sentence
      :snt1 (f / fair-01)
      :snt2 (r / recommend-01
            :ARG1 (ii / incorporate-01
                  :ARG0 (a / and
                        :op1 (a2 / algorithm
                              :mod (a3 / artificial))
                        :op2 (m2 / model
                              :mod a3)
                        :ARG1-of (e / embed-01
                              :ARG2 (s / system
                                    :ARG0-of (m3 / make-01
                                          :ARG1 (d / decide-01)))))
                  :ARG1 (f2 / fairness)
                  :ARG2 (c / core
                        :poss a))))

# ::snt Ensuring fairness of AI results depends upon how the algorithms were developed, and in the case of AI-based machine learning, also upon the data that was utilized for their training.
# File 11

(d / depend-01
      :ARG0 (e / ensure-01
            :ARG1 (f / fair-01
                  :ARG1 (r / result
                        :mod (ii / intelligent-01
                              :mod (a / artificial)))))
      :ARG1 (a2 / and
            :op1 (t / thing
                  :manner-of (d2 / develop-02
                        :ARG1 (a3 / algorithm)))
            :op2 (d3 / data
                  :ARG1-of (u / utilize-01
                        :purpose (t2 / train-01
                              :ARG2 a3))
                  :mod (a4 / also)
                  :condition (l / learn-01
                        :mod (m / machine)
                        :ARG1-of (b / base-02
                              :ARG2 (ii2 / intelligent-01
                                    :mod a))))))

# ::snt Means to mitigate bias include using algorithms and data models that account for bias, well-curated training sets, extensive verification and validation of AI systems, and alertness to possible ethical or fairness implications from AI-based decisions.
# File 11

(m / mean-01
      :ARG2 (ii / include-01
            :ARG1 (a / and
                  :op1 (u / use-01
                        :ARG1 (a2 / and
                              :op1 (a3 / algorithm)
                              :op2 (m2 / model
                                    :mod (d / data))
                              :ARG0-of (a4 / account-01
                                    :ARG1 (b / bias-01))))
                  :op2 (s / set
                        :purpose (t / train-01)
                        :ARG1-of (c / curate-01
                              :ARG1-of (w / well-09)))
                  :op3 (a5 / and
                        :op1 (v / verify-01
                              :ARG1 (s2 / system
                                    :mod (ii2 / intelligent-01
                                          :mod (a6 / artificial)))
                              :ARG1-of (e / extensive-03))
                        :op2 (v2 / validate-01
                              :ARG1 s2
                              :ARG1-of e))
                  :op4 (a7 / alert-01
                        :ARG2 (ii3 / implicate-01
                              :ARG0 (d2 / decide-01
                                    :ARG1-of (b2 / base-02
                                          :ARG2 ii2))
                              :ARG1 (o / or
                                    :op1 (e2 / ethics)
                                    :op2 (f / fairness)
                                    :ARG1-of (p / possible-01))))))
      :ARG3 (m3 / mitigate-01
            :ARG1 (b3 / bias-01)))

# ::snt The National Science Foundation  program on algorithmic fairness, for instance, calls for interdisciplinary perspectives while stating that “this program supports the conduct of fundamental computer science research” and requiring the PI to “bring computer science expertise to the research.” 8 But producing  fairness-aware algorithms or just understanding the concept of fairness requires knowledge and expertise outside the computer science field to incorporate the social and legal contexts in which AI systems will be deployed.
# File 184

(m / multi-sentence
      :snt1 (c / contrast-01
            :ARG1 (c2 / call-03
                  :ARG0 (p / program
                        :mod (o / organization
                              :name (n / name
                                    :op1 "National"
                                    :op2 "Science"
                                    :op3 "Foundation"))
                        :topic (f / fairness
                              :mod (a / algorithmic))
                        :ARG0-of (e / exemplify-01))
                  :ARG1 (p2 / perspective
                        :mod (ii / interdisciplinary)))
            :ARG2 (s / state-01
                  :ARG0 p
                  :ARG1 (a2 / and
                        :op1 (s2 / support-01
                              :ARG0 p
                              :ARG1 (c3 / conduct-01
                                    :ARG1 (r / research-01
                                          :ARG1 (s3 / science
                                                :mod (c4 / computer))
                                          :mod (f2 / fundamental))))
                        :op2 (r2 / require-01
                              :ARG0 p
                              :ARG1 (b / bring-01
                                    :ARG0 (p3 / person
                                          :ARG0-of (h / have-org-role-91
                                                :ARG2 (d / director
                                                      :mod (s4 / science
                                                            :mod (c5 / computer))))
                                          :ARG1 (e2 / expertise
                                                :topic s3))
                                    :ARG2 (r3 / research-01))))))
      :snt2 c
      :ARG2 (r4 / require-01
            :ARG0 (o2 / or
                  :op1 (p4 / produce-01
                        :ARG1 (a3 / algorithm
                              :ARG0-of (r5 / realize-01
                                    :ARG1 (f3 / fairness))))
                  :op2 (u / understand-01
                        :ARG1 (c6 / concept
                              :topic f3)
                        :mod (j / just)))
            :ARG1 (a4 / and
                  :op1 (k / know-01)
                  :op2 (e3 / expertise)
                  :location (o3 / outside
                        :op1 (f4 / field
                              :mod (c7 / computer))))
            :purpose (ii2 / incorporate-02
                  :ARG0 o2
                  :ARG1 (a5 / and
                        :op1 (c8 / context
                              :mod (s5 / society))
                        :op2 (c9 / context
                              :ARG1-of (l / legal-02))
                        :location-of (d2 / deploy-01
                              :ARG1 (s6 / system
                                    :mod (ii3 / intelligent-01
                                          :mod (a6 / artificial)))))))
      :li 8)

# ::snt 9 Andrew D. Selbst et al., “Fairness and Abstraction in Sociotechnical Systems,” Proceedings of the Conference on Fairness, Accountability, and  Transparency (January 2019): 59-68, https://doi.org/10.1145/3287560.3287598 .
# File 184

(p / publication-91
      :li 9
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Andrew"
                        :op2 "D."
                        :op3 "Selbst"))
            :op2 (p3 / person
                  :mod (o / other)))
      :ARG1 (p4 / publication
            :name (n2 / name
                  :op1 "Fairness"
                  :op2 "and"
                  :op3 "Abstraction"
                  :op4 "in"
                  :op5 "Sociotechnical"
                  :op6 "Systems"))
      :ARG4 p4
      :name (n3 / name
            :op1 "Proceeds"
            :op2 "of"
            :op3 "the"
            :op4 "Conference"
            :op5 "on"
            :op6 "Fairness,"
            :op7 "Accountability"
            :op8 "and"
            :op9 "Transparency")
      :ARG7 (v / value-interval
            :op1 59
            :op2 68)
      :ARG4 (u / url-entity
            :value "https://doi.org/10.1145/3287560.3287598")
      :time (d / date-entity
            :month 1
            :year 2019))

# ::snt 8 “NSF Program on Fairness in Artificial Intelligence in Collaboration with Amazon (FAI),” The National Science Foundation, 2021,  https://www.nsf.gov/pubs/2021/nsf21585/nsf21585.htm .
# File 184

(p / publication-91
      :li 8
      :ARG1 (p2 / program
            :name (n / name
                  :op1 "NSF"
                  :op2 "Program"
                  :op3 "on"
                  :op4 "Fairness"
                  :op5 "in"
                  :op6 "Artificial"
                  :op7 "Intelligence"
                  :op8 "in"
                  :op9 "Collaboration"
                  :op10 "with"
                  :op11 "Amazon"))
      :ARG4 (p3 / publication
            :name (n2 / name
                  :op1 "The"
                  :op2 "National"
                  :op3 "Science"
                  :op4 "Foundation"))
      :time (d / date-entity
            :year 2021)
      :medium (u / url-entity
            :value "https://www.nsf.gov/pubs/2021/nsf21585/nsf21585.htm"))

# ::snt 12 But such protections  can obscure certain information about the inputs their tools use and how the tools operate behind trade secrecy claims, which in turn prevents appropriate analysis, audit, and testing to ensure the fairness of their use.
# File 184

(c / contrast-01
      :li 12
      :ARG2 (p / possible-01
            :ARG1 (o / obscure-01
                  :ARG0 (p2 / protect-01
                        :mod (s / such))
                  :ARG1 (ii / information
                        :mod (c2 / certain)
                        :topic (a / and
                              :op1 (ii2 / input
                                    :ARG1-of (u / use-01
                                          :ARG0 (t / tool
                                                :poss (t2 / they))))
                              :op2 (t3 / thing
                                    :manner-of (o2 / operate-01
                                          :ARG1 t
                                          :location (b / behind
                                                :op1 (c3 / claim-01
                                                      :ARG1 (s2 / secrecy
                                                            :mod (t4 / trade-01)))))))
                        :ARG0-of (p3 / prevent-01
                              :ARG1 (a2 / and
                                    :op1 (a3 / analyze-01
                                          :ARG1-of (a4 / appropriate-02))
                                    :op2 (a5 / audit-01)
                                    :op3 (t5 / test-01)
                                    :purpose (e / ensure-01
                                          :ARG1 (f / fair-01
                                                :ARG1 (u2 / use-01
                                                      :ARG1 t))))
                              :mod (ii3 / in-turn))))))

# ::snt 19 In doing so, the  federal government should weigh considerations such as privacy , security , and fairness, and it  should begin to develop its own frameworks for evaluating such datasets and their applications in tandem, informed by important developments under the Foundations for Evidence-Based Policymaking Act of 2018 and the National Secure Data Service.
# File 184

(a / and
      :li 19
      :op1 (r / recommend-01
            :ARG1 (w / weigh-01
                  :ARG0 (g / government-organization
                        :ARG0-of (g2 / govern-01)
                        :mod (f / federal))
                  :ARG1 (c / consideration
                        :example (a2 / and
                              :op1 (p / privacy)
                              :op2 (s / security)
                              :op3 (f2 / fairness)))))
      :op2 (r2 / recommend-01
            :ARG1 (b / begin-01
                  :ARG0 g
                  :ARG1 (d / develop-02
                        :ARG0 g
                        :ARG1 (f3 / framework
                              :poss g
                              :purpose (e / evaluate-01
                                    :ARG0 g
                                    :ARG1 (a3 / and
                                          :op1 (d2 / dataset
                                                :mod (s2 / such))
                                          :op2 (a4 / application
                                                :mod d2))
                                    :manner (t / tandem)
                                    :ARG1-of (ii / inform-01
                                          :ARG0 (d3 / develop-01
                                                :ARG1-of (ii2 / important-01)
                                                :prep-under (a5 / and
                                                      :op1 (l / law
                                                            :name (n / name
                                                                  :op1 "Foundations"
                                                                  :op2 "for"
                                                                  :op3 "Evidence-Based"
                                                                  :op4 "Policymaking"
                                                                  :op5 "Act"
                                                                  :op6 "of"
                                                                  :op7 "2018"))
                                                      :op2 (l2 / law
                                                            :name (n2 / name
                                                                  :op1 "National"
                                                                  :op2 "Secure"
                                                                  :op3 "Data"
                                                                  :op4 "Service"))))))))))
      :manner (d4 / do-02
            :ARG0 g
            :ARG1 (s3 / so)))

# ::snt AI tightly developed under human oversight and control), embed the principles of fairness and justice  in algorithms, applied in all phases of AI systems’ design, implementation  and testing, while following  through bias complaints and other undesired effects reporting.
# File 90

(m / multi-sentence
      :snt1 (d / develop-02
            :ARG1 (ii / intelligent-01
                  :mod (a / artificial))
            :ARG1-of (t / tight-05)
            :prep-under (a2 / and
                  :op1 (o / oversee-01
                        :ARG0 (h / human))
                  :op2 (c / control-01
                        :ARG0 h)))
      :snt2 (e / embed-01
            :ARG1 (p / principle
                  :topic (a3 / and
                        :op1 (f / fairness)
                        :op2 (j / justice))
                  :ARG1-of (a4 / apply-02
                        :ARG2 (p2 / phase
                              :mod (a5 / all)
                              :subevent-of (a6 / and
                                    :op1 (d2 / design-01
                                          :ARG1 (s / system
                                                :mod (ii2 / intelligent-01)))
                                    :op2 (ii3 / implement-01
                                          :ARG1 s)
                                    :op3 (t2 / test-01
                                          :ARG1 s)))
                        :time (f2 / follow-01
                              :ARG1 p
                              :path (a7 / and
                                    :op1 (c2 / complain-01
                                          :ARG1 (b / bias-01))
                                    :op2 (r / report-01
                                          :ARG1 (a8 / affect-01
                                                :ARG1-of (d3 / desire-01
                                                      :polarity -)
                                                :mod (o2 / other)))))))
            :ARG2 (a9 / algorithm)))

# ::snt This guidance will have a broad er scope of existing AI  ethics guidance  (Box 6), and will embrace social inclusion, algorithm transparency, safety, fairness and  the future of work.
# File 90

(a / and
      :op1 (h / have-03
            :ARG0 (g / guide-01
                  :mod (t / this))
            :ARG1 (s / scope
                  :ARG1-of (b / broad-02)
                  :poss (g2 / guide-01
                        :ARG1 (e / ethics)
                        :mod (ii / intelligent-01
                              :mod (a2 / artificial))
                        :ARG1-of (e2 / exist-01)))
            :ARG1-of (d / describe-01
                  :ARG0 (p / publication
                        :name (n / name
                              :op1 "Box"
                              :op2 6))))
      :op2 (e3 / embrace-01
            :ARG0 g
            :ARG1 (a3 / and
                  :op1 (ii2 / include-01
                        :ARG2 (s2 / society))
                  :op2 (t2 / transparency
                        :mod (a4 / algorithm))
                  :op3 (s3 / safe-01)
                  :op4 (f / fairness)
                  :op5 (f2 / future
                        :poss (w / work-01)))))

# ::snt • AI should operate on principles of intelligibility and fairness.
# File 90

(r / recommend-01
      :ARG1 (o / operate-01
            :ARG0 (a / artificial-intelligence)
            :ARG1 (p / principle
                  :domain (a2 / and
                        :op1 (ii / intelligibility)
                        :op2 (f / fairness)))))

# ::snt Data  workers of the future will need to improve their knowledge of mathematics and statistics, along with  the ability to identify and collect data sets for machine learning, to track the sources of data biases, and  to foster fairness, non- discrimination and diversity .
# File 90

(n / need-01
      :ARG0 (p / person
            :ARG0-of (w / work-01
                  :ARG1 (d / data))
            :time (f / future))
      :ARG1 (ii / improve-01
            :ARG0 p
            :ARG1 (a / and
                  :op1 (k / know-01
                        :ARG0 p
                        :ARG1 (a2 / and
                              :op1 (m / mathematics)
                              :op2 (s / statistics)))
                  :op2 (c / capable-01
                        :ARG1 p
                        :ARG2 (a3 / and
                              :op1 (ii2 / identify-01
                                    :ARG0 p
                                    :ARG1 (s2 / set
                                          :consist-of (d2 / data)))
                              :op2 (c2 / collect-01
                                    :ARG0 p
                                    :ARG1 s2)
                              :purpose (l / learn-01
                                    :manner (m2 / machine)))
                        :op3 (t / track-01
                              :ARG0 p
                              :ARG1 (t2 / thing
                                    :ARG2-of (s3 / source-01
                                          :ARG1 (b / bias-01
                                                :ARG1 (d3 / data)))))
                        :op4 (f2 / foster-01
                              :ARG0 p
                              :ARG1 (a4 / and
                                    :op1 (f3 / fairness)
                                    :op2 (d4 / discriminate-01
                                          :polarity -)
                                    :op3 (d5 / diversity)))))))

# ::snt The initiative, which was named  ELLIS - Initiative to establish a European Lab for Learning & Intelligent Systems, was followed by another  initiative called CLAIRE - Confederation of Laboratories for Artificial Intelligence Research in Europe-   that is set to  nurture the creation of a unified community of AI European researchers that puts human  values , such as fairness, truthfulness and privacy , upfront .
# File 90

(f / follow-01
      :ARG1 (ii / initiative
            :name (n / name
                  :op1 "ECILIS"
                  :op2 "Initiative")
            :purpose (e / establish-01
                  :ARG1 (f2 / facility
                        :name (n2 / name
                              :op1 "European"
                              :op2 "Laboratory"
                              :op3 "for"
                              :op4 "Learning"
                              :op5 "&"
                              :op6 "Intelligent"
                              :op7 "Systems"))))
      :ARG2 (ii2 / initiative
            :mod (a / another)
            :ARG1-of (c / call-01
                  :ARG2 (n3 / name
                        :op1 "CLAIRE"
                        :op2 "Confederation"
                        :op3 "of"
                        :op4 "Laboratories"
                        :op5 "for"
                        :op6 "Artificial"
                        :op7 "Intelligence"
                        :op8 "Research"
                        :op9 "in"
                        :op10 "Europe"))
            :ARG1-of (s / set-08
                  :ARG2 (n4 / nurture-01
                        :ARG0 (o / organization
                              :ARG1 (c2 / create-01
                                    :ARG1 (c3 / community
                                          :ARG1-of (u / unify-01)
                                          :consist-of (p / person
                                                :ARG0-of (r / research-01
                                                      :mod (ii3 / intelligent-01
                                                            :mod (a2 / artificial)))
                                                :mod (c4 / continent
                                                      :name (n5 / name
                                                            :op1 "Europe")))
                                          :ARG0-of (p2 / put-01
                                                :ARG1 (v / value
                                                      :mod (h / human)
                                                      :example (a3 / and
                                                            :op1 (f3 / fairness)
                                                            :op2 (t / truthfulness)
                                                            :op3 (p3 / privacy)))
                                                :ARG2 (u2 / upfront)))))))))

# ::snt AI tightly developed  under human oversight and control), embed the principles of fairness and justice in algorithms, applied  in all phases of AI systems’ design, i mplementation and testing, while following through bias  complaints and other undesired effects reporting.
# File 90

(m / multi-sentence
      :snt1 (d / develop-02
            :ARG1 (ii / intelligent-01
                  :mod (a / artificial))
            :ARG1-of (t / tight-05)
            :prep-under (a2 / and
                  :op1 (o / oversee-01
                        :ARG0 (h / human))
                  :op2 (c / control-01
                        :ARG0 h)))
      :snt2 (e / embed-01
            :ARG1 (p / principle
                  :topic (a3 / and
                        :op1 (f / fairness)
                        :op2 (j / justice))
                  :ARG1-of (a4 / apply-02
                        :ARG2 (p2 / phase
                              :mod (a5 / all)
                              :subevent-of (d2 / design-01
                                    :ARG1 (s / system
                                          :mod (ii2 / intelligent-01))))
                        :time (a6 / and
                              :op1 (ii3 / implement-01
                                    :ARG0 (ii4 / i))
                              :op2 (t2 / test-01
                                    :ARG0 ii4)
                              :time (f2 / follow-through-07
                                    :ARG0 ii4
                                    :ARG1 (a7 / and
                                          :op1 (c2 / complain-01
                                                :ARG1 (b / bias-01))
                                          :op2 (r / report-01
                                                :ARG1 (a8 / affect-01
                                                      :ARG1-of (d3 / desire-01
                                                            :polarity -)
                                                      :mod (o2 / other))))))))
            :ARG2 (a9 / algorithm)))

# ::snt The people who are building AI systems are, of course,  required to comply with the broad range of laws around the  world that already govern fairness, privacy, injuries resulting  from unreasonable behaviors and the like.
# File 119

(r / require-01
      :ARG1 (c / comply-01
            :ARG0 (p / person
                  :ARG0-of (b / build-01
                        :ARG1 (s / system
                              :mod (ii / intelligent-01
                                    :mod (a / artificial)))))
            :ARG1 (r2 / range-01
                  :ARG1 (l / law
                        :location (a2 / around
                              :op1 (w / world))
                        :ARG0-of (g / govern-01
                              :ARG1 (a3 / and
                                    :op1 (f / fairness)
                                    :op2 (p2 / privacy)
                                    :op3 (ii2 / injure-01
                                          :ARG2-of (r3 / result-01
                                                :ARG1 a3
                                                :op1 (b2 / behave-01
                                                      :ARG1-of (r4 / reasonable-02
                                                            :polarity -))
                                                :op2 (t / thing
                                                      :ARG1-of (r5 / resemble-01
                                                            :ARG2 b2))))))
                        :time (a4 / already)))
            :ARG1-of (b3 / broad-02))
      :ARG2 p
      :mod (o / of-course))

# ::snt 57Fairness – AI systems should treat all people fairly.
# File 119

(m / multi-sentence
      :snt1 (f / fairness
            :li 57)
      :snt2 (r / recommend-01
            :ARG1 (t / treat-01
                  :ARG0 (s / system
                        :mod (ii / intelligent-01
                              :mod (a / artificial)))
                  :ARG1 (p / person
                        :mod (a2 / all))
                  :ARG1-of (f2 / fair-01))))

# ::snt To ensure that fairness  is the foundation for solutions using this new technology,  it’s imperative that developers understand how bias can be  introduced into AI systems and how it can affect AI-based  recommendations.
# File 119

(ii / imperative
      :domain (u / understand-01
            :ARG0 (p / person
                  :ARG0-of (d / develop-02))
            :ARG1 (a / and
                  :op1 (t / thing
                        :manner-of (p2 / possible-01
                              :ARG1 (ii2 / introduce-02
                                    :ARG1 (b / bias-01)
                                    :ARG2 (s / system
                                          :ARG1-of (ii3 / intelligent-01
                                                :mod (a2 / artificial))))))
                  :op2 (t2 / thing
                        :manner-of (p3 / possible-01
                              :ARG1 (a3 / affect-01
                                    :ARG0 b
                                    :ARG1 (r / recommend-01
                                          :ARG1-of (b2 / base-02
                                                :ARG2 ii3)))))))
      :purpose (e / ensure-01
            :ARG0 p
            :ARG1 (f / found-01
                  :ARG1 (s2 / solve-01
                        :ARG2 (t3 / technology
                              :ARG1-of (n / new-01)
                              :mod (t4 / this)))
                  :ARG2 (f2 / fairness))))

# ::snt The design of any AI systems starts with the choice of  training data, which is the first place where unfairness can  arise.
# File 119

(s / start-01
      :ARG1 (d / design-01
            :ARG1 (s2 / system
                  :mod (ii / intelligent-01
                        :mod (a / artificial))
                  :mod (a2 / any)))
      :ARG2 (c / choose-01
            :ARG1 (d2 / data
                  :purpose (t / train-01)
                  :mod (p / place
                        :ord (o / ordinal-entity
                              :value 1)
                        :location-of (p2 / possible-01
                              :ARG1 (a3 / arise-02
                                    :ARG1 (f / fairness
                                          :polarity -)))))))

# ::snt Finally — and this is vital — industry and academia should  continue the promising work underway to develop analytical  techniques to detect and address potential unfairness, like  methods that systematically assess the data used to train AI  systems for appropriate representativeness and document  information about its origins and characteristics.
# File 119

(r / recommend-01
      :ARG1 (c / continue-01
            :ARG0 (a / and
                  :op1 (ii / industry)
                  :op2 (a2 / academia))
            :ARG1 (w / work-01
                  :ARG1 (d / develop-02
                        :ARG0 a
                        :ARG1 (t / technique
                              :mod (a3 / analyze-01)
                              :purpose (a4 / and
                                    :op1 (d2 / detect-01
                                          :ARG0 a
                                          :ARG1 (f / fairness
                                                :polarity -
                                                :mod (p / potential)))
                                    :op2 (a5 / address-02
                                          :ARG0 a
                                          :ARG1 f)))
                        :ARG1-of (r2 / resemble-01
                              :ARG2 (m / method
                                    :ARG0-of (a6 / assess-01
                                          :ARG1 (d3 / data
                                                :ARG1-of (u / use-01
                                                      :ARG2 (t2 / train-01
                                                            :ARG1 (s / system
                                                                  :mod (ii2 / intelligent-01
                                                                        :mod (a7 / artificial)))
                                                            :ARG2 s)))
                                          :ARG2 (a8 / and
                                                :op1 (r3 / represent-01
                                                      :ARG1-of (a9 / appropriate-02))
                                                :op2 (d4 / document-01
                                                      :ARG1 (ii3 / information
                                                            :topic (a10 / and
                                                                  :op1 (o / originate-01
                                                                        :ARG1 s)
                                                                  :op2 (t3 / thing
                                                                        :ARG2-of (c2 / characteristic-02
                                                                              :ARG1 s))))))
                                          :manner (s2 / systematic)))))
                  :ARG0-of (p2 / promise-01)
                  :mod (u2 / underway)))
      :mod (f2 / final)
      :mod (v / vital))

# ::snt Academic research efforts such as those  highlighted at the annual conference for researchers on  Fairness, Accountability, and Transparency in Machine  Learning have raised awareness of the issue.
# File 119

(r / raise-01
      :ARG0 (e / effort-01
            :ARG1 (r2 / research-01)
            :mod (a / academia)
            :example (e2 / effort-01
                  :ARG1-of (h / highlight-01
                        :location (c / conference
                              :beneficiary (p / person
                                    :ARG0-of (r3 / research-01))
                              :frequency (r4 / rate-entity-91
                                    :ARG3 (t / temporal-quantity
                                          :quant 1
                                          :unit (y / year))))
                        :topic (a2 / and
                              :op1 (f / fairness)
                              :op2 (a3 / accountable-02)
                              :op3 (t2 / transparency
                                    :topic (l / learn-01
                                          :mod (m / machine)))))))
      :ARG1 (r5 / realize-01
            :ARG1 (ii / issue-02)))

# ::snt 74privacy and security of personal information, that govern  the flow of data and how it is used, that promote fairness in  the use of consumer information, or that govern decisions  on credit or employment apply broadly to digital products  and services or their use in decision-making, whether they  explicitly mention AI capabilities or not.
# File 119

(a / apply-02
      :li 74
      :ARG1 (a2 / and
            :op1 (p / private-02
                  :ARG1 (ii / information
                        :ARG1-of (p2 / personal-02)))
            :op2 (s / security
                  :poss ii)
            :ARG0-of (g / govern-01
                  :ARG1 (a3 / and
                        :op1 (f / flow-01
                              :ARG1 (d / data))
                        :op2 (t / thing
                              :manner-of (u / use-01
                                    :ARG1 d))))
            :ARG0-of (p3 / promote-02
                  :ARG1 (f2 / fair-01
                        :ARG1 (u2 / use-01
                              :ARG1 (ii2 / information
                                    :poss (p4 / person
                                          :ARG0-of (c / consume-01))))))
            :ARG0-of (g2 / govern-01
                  :ARG1 (d2 / decide-01
                        :ARG3 (o / or
                              :op1 (c2 / credit-02)
                              :op2 (e / employ-01)))))
      :ARG2 (o2 / or
            :op1 (a4 / and
                  :op1 (p5 / product
                        :mod (d3 / digital))
                  :op2 (s2 / serve-01))
            :op2 (u3 / use-01
                  :ARG1 a4
                  :ARG2 (m / make-01
                        :ARG1 (d4 / decide-01))))
      :manner (b / broad)
      :ARG1-of (r / regardless-91
            :ARG2 (m2 / mention-01
                  :ARG0 (t2 / they)
                  :ARG1 (o3 / or
                        :op1 (c3 / capable-01
                              :ARG2 (ii3 / intelligent-01
                                    :mod (a5 / artificial)))
                        :op2 (c4 / capable-01
                              :polarity -
                              :ARG2 ii3))
                  :ARG1-of (e2 / explicit-03))))

# ::snt The computer era has required us to grapple with  important questions about privacy, safety, security, fairness,  inclusion, and the importance and value of human labor.
# File 119

(r / require-01
      :ARG0 (e / era
            :mod (c / computer))
      :ARG1 (g / grapple-01
            :ARG0 (w / we)
            :ARG1 (q / question-01
                  :ARG1 (a / and
                        :op1 (p / privacy)
                        :op2 (s / safe-01)
                        :op3 (s2 / security)
                        :op4 (f / fairness)
                        :op5 (ii / include-01)
                        :op6 (ii2 / important-01)
                        :op7 (ii3 / important-01)
                        :op8 (v / value-01
                              :ARG1 (l / labor-01
                                    :ARG0 (h / human))))
                  :ARG1-of (ii4 / important-01)))
      :ARG2 w)

# ::snt Therefore,  the propo sed Data Act aims to provide fairness, clarity,  and certainty with respect to B2B access  and  sharing of data, both personal and non- personal, and to facilitate the use of privately held  data by the  public sector.
# File 81

(c / cause-01
      :ARG1 (a / aim-01
            :ARG0 (l / law
                  :name (n / name
                        :op1 "Proposition"
                        :op2 "Sensitive"
                        :op3 "Data"
                        :op4 "Act"))
            :ARG1 (a2 / and
                  :op1 (p / provide-01
                        :ARG0 l
                        :ARG1 (a3 / and
                              :op1 (f / fairness)
                              :op2 (c2 / clarity)
                              :op3 (c3 / certainty))
                        :ARG2 (a4 / and
                              :op1 (a5 / access-01
                                    :ARG1 (d / data
                                          :mod (b / both
                                                :op1 (p2 / personal-02)
                                                :op2 (p3 / personal-02
                                                      :polarity -))))
                              :op2 (s / share-01
                                    :ARG1 d)))
                  :op2 (f2 / facilitate-01
                        :ARG0 l
                        :ARG1 (u / use-01
                              :ARG0 (s2 / sector
                                    :ARG1-of (p4 / public-02))
                              :ARG1 (d2 / data
                                    :ARG1-of (h / hold-01
                                          :ARG0 (p5 / private-03))))))))

# ::snt First, to promote contractual fairness in private agreements to regulate B2B data sharing in asymmetric situation s. Second, to ensure that access and use of co -generated nonpersonal data, especially machine -generated data and linked to the use of IoT, AI and other emerging  technologies, do es not create unfair competition problems.
# File 81

(m / multi-sentence
      :snt2 (e / ensure-01
            :li 2
            :ARG1 (c / create-01
                  :polarity -
                  :ARG0 (a / and
                        :op1 (a2 / access-01
                              :ARG1 (d / data
                                    :ARG1-of (g / generate-01
                                          :ARG0 (m2 / machine))
                                    :ARG1-of (p / personal-02
                                          :polarity -)
                                    :mod (e2 / especially)))
                        :op2 (u / use-01
                              :ARG1 d)
                        :ARG1-of (l / link-01
                              :ARG2 (u2 / use-01
                                    :ARG1 (a3 / and
                                          :op1 (d2 / device
                                                :ARG0-of (s / sense-01
                                                      :ARG1-of (ii / intelligent-01))
                                                :op2 (a4 / artificial)
                                                :op3 (t / technology
                                                      :ARG0-of (e3 / emerge-02)
                                                      :mod (o / other)))))))
                  :ARG1 (p2 / problem
                        :topic (c2 / compete-01
                              :ARG1-of (f / fair-01
                                    :polarity -)))))
      :snt1 (p3 / promote-02
            :li 1
            :ARG1 (f2 / fairness
                  :mod (c3 / contract))
            :ARG2 (a5 / agree-01
                  :ARG1 (r / regulate-01
                        :ARG1 (s2 / share-01
                              :ARG1 (d3 / data
                                    :mod (b / business
                                          :ARG0-of (d4 / distribute-01
                                                :ARG1-of (c4 / close-02))))
                              :location (s3 / situation
                                    :mod (s4 / symmetric
                                          :polarity -)))
                        :ARG1-of (p4 / private-03)))))

# ::snt Thus, the proposed Data Act would fill the gaps identified in B2B data sharing to ensure fairness in market transactions and in B2G contexts to facilitate the use of data for public interest.
# File 81

(ii / infer-01
      :ARG1 (f / fill-in-05
            :ARG0 (l / law
                  :name (n / name
                        :op1 "Data"
                        :op2 "Act")
                  :ARG1-of (p / propose-01))
            :ARG1 (g / gap
                  :ARG1-of (ii2 / identify-01
                        :ARG0 (s / share-01
                              :ARG1 (d / data)
                              :mod (b / build-01
                                    :ARG1 (o / organization
                                          :name n
                                          :op1 "B2G"))))))
      :purpose (e / ensure-01
            :ARG0 l
            :ARG1 (f2 / fair-01
                  :ARG1 (t / transact-01
                        :ARG1 (m / market)))
            :location (c / context
                  :mod b)
            :purpose (f3 / facilitate-01
                  :ARG0 l
                  :ARG1 (u / use-01
                        :ARG1 (d2 / data)
                        :ARG2 (ii3 / interest-01
                              :ARG1 (p2 / public))))))

# ::snt Prior  beliefs together with heuristics and bias may over- inflate perceived risk or expectation about  fairness, reciprocity, and equity, especially for non- dominant private sector act ors.
# File 81

(p / possible-01
      :ARG1 (ii / inflate-01
            :ARG0 (a / and
                  :op1 (b / believe-01
                        :time (p2 / prior))
                  :op2 (h / heuristics)
                  :op3 (b2 / bias-01))
            :ARG1 (o / or
                  :op1 (r / risk-01)
                  :op2 (e / expect-01
                        :ARG1 (a2 / and
                              :op1 (f / fairness)
                              :op2 (r2 / reciprocity)
                              :op3 (e2 / equity)))
                  :ARG1-of (p3 / perceive-01))
            :ARG1-of (o2 / over-03))
      :ARG1-of (c / cause-01
            :ARG0 (o3 / or
                  :op1 (a3 / act-02
                        :mod (s / sector
                              :ARG1-of (p4 / private-03)))
                  :op2 (o4 / operate-01)
                  :ARG0-of (d / dominate-01
                        :polarity -)
                  :mod (e3 / especially))))

# ::snt The P2B Regulation aims to ensure fairness and transparency in these P2B relationships  by limiting  certain clauses, requiring transparency obligations, or imposing duties.
# File 81

(a / aim-01
      :ARG0 (r / regulate-01
            :name (n / name
                  :op1 "P2B"
                  :op2 "Regulation"))
      :ARG1 (e / ensure-01
            :ARG0 r
            :ARG1 (a2 / and
                  :op1 (f / fairness)
                  :op2 (t / transparency))
            :ARG3 (r2 / relation-03
                  :mod (t2 / this)
                  :mod (p / product
                        :name n
                        :op1 "P2B")))
      :manner (o / or
            :op1 (l / limit-01
                  :ARG1 (c / clause
                        :mod (c2 / certain)))
            :op2 (r3 / require-01
                  :ARG1 (o2 / obligate-01
                        :ARG2 (t3 / transparency)))
            :op3 (ii / impose-01
                  :ARG1 (d / duty))))

# ::snt In this respect, it is worth recalling  that the development, testing, training, deployment and use of AI systems do greatly depend upon an  environment conducive to promote trustworthiness, fairness, and safety of AI.
# File 81

(w / worth-02
      :ARG2 (r / recall-02
            :ARG1 (d / depend-01
                  :ARG0 (a / and
                        :op1 (d2 / develop-02
                              :ARG1 (s / system
                                    :mod (ii / intelligent-01
                                          :mod (a2 / artificial))))
                        :op2 (t / test-01
                              :ARG1 s)
                        :op3 (t2 / train-01
                              :ARG2 s)
                        :op4 (d3 / deploy-01
                              :ARG1 s)
                        :op5 (u / use-01
                              :ARG1 s))
                  :ARG1 (e / environment
                        :ARG1-of (c / conducive-01
                              :ARG2 (p / promote-02
                                    :ARG0 e
                                    :ARG1 (a3 / and
                                          :op1 (d4 / deserve-01
                                                :ARG0 s
                                                :ARG1 (t3 / trust-02
                                                      :ARG0 s))
                                          :op2 (f / fair-01
                                                :ARG1 s)
                                          :op3 (s2 / safe-01
                                                :ARG0 s)))))
                  :degree (g / great)))
      :topic (t4 / this))

# ::snt c) Opacity versus transparency  Transparency has been a constant in several  legal initiatives aimed to ensure fairness, well -informed  decisions, reduction of information asymmetry or protection and enforcement of rights.
# File 81

(c / constant
      :li "c"
      :domain (t / transparency)
      :topic (ii / initiate-01
            :ARG1-of (l / legal-02)
            :quant (s / several)
            :ARG0-of (a / aim-01
                  :ARG1 (e / ensure-01
                        :ARG0 ii
                        :ARG1 (o / or
                              :op1 (f / fairness)
                              :op2 (d / decide-01
                                    :ARG1-of (ii2 / inform-01
                                          :ARG1-of (w / well-09)))
                              :op3 (r / reduce-01
                                    :ARG1 (a2 / asymmetry
                                          :mod (ii3 / information)))
                              :op4 (a3 / and
                                    :op1 (p / protect-01
                                          :ARG1 (r2 / right-05))
                                    :op2 (e2 / enforce-01
                                          :ARG1 r2)))))))

# ::snt Furthermore, there is a gap  concerning B2B and B2G data sharing  that might be filled in the proposed Data Act to ensure  fairness in market transactions and in B2G contexts to facilitate the u se of data for public  interest.
# File 81

(a / and
      :op2 (g / gap
            :topic (s / share-01
                  :ARG1 (d / data)
                  :mod (o / organization
                        :name (n / name
                              :op1 "B2B"))
                  :mod (o2 / organization
                        :name (n2 / name
                              :op1 "B2G")))
            :ARG1-of (f / fill-01
                  :ARG0 (l / law
                        :name (n3 / name
                              :op1 "Data"
                              :op2 "Act")
                        :ARG1-of (p / propose-01))
                  :purpose (e / ensure-01
                        :ARG0 l
                        :ARG1 (f2 / fair-01
                              :ARG1 (a2 / and
                                    :op1 (t / transact-01
                                          :ARG0 (m / market))
                                    :op2 (c / context
                                          :mod o2)))
                        :purpose (f3 / facilitate-01
                              :ARG0 l
                              :ARG1 (d2 / data
                                    :purpose (ii / interest
                                          :mod (p2 / public)))))
                  :ARG1-of (p3 / possible-01))))

# ::snt To date, well over a hundred different AI ethics guidelines have been published.1 Nearly  all of them mention values such as privacy, fairness or non-discrimination, transparency,  safety, and accountability.
# File 37

(m / multi-sentence
      :snt1 (p / publish-01
            :ARG1 (g / guideline
                  :mod (e / ethics)
                  :mod (a / artificial)
                  :ARG1-of (d / differ-02)
                  :quant (o / over
                        :op1 100
                        :degree (w / well)))
            :time (t / to-date))
      :snt2 (m2 / mention-01
            :li 1
            :ARG0 (t2 / they
                  :mod (a2 / all
                        :ARG1-of (n / near-02)))
            :ARG1 (v / value
                  :example (a3 / and
                        :op1 (p2 / privacy)
                        :op2 (o2 / or
                              :op1 (f / fairness)
                              :op2 (d2 / discriminate-01
                                    :polarity -))
                        :op3 (t3 / transparency)
                        :op4 (s / safe-01)
                        :op5 (a4 / accountable-02)))))

# ::snt So how we implement and prioritise values such as  justice (here includes fairness or non-discrimination) and transparency in practice,  depends to some extent on the field of application and the cultural context an AI system  operates in.
# File 37

(d / depend-01
      :ARG0 (a / and
            :op1 (ii / implement-01
                  :ARG0 (w / we)
                  :ARG1 (v / value
                        :example (a2 / and
                              :op1 (j / justice)
                              :op2 (ii2 / include-01
                                    :ARG1 (o / or
                                          :op1 (f / fairness)
                                          :op2 (d2 / discriminate-01
                                                :polarity -))
                                    :location (h / here))
                              :op3 (t / transparency))))
            :op2 (p / prioritize-01
                  :ARG0 w
                  :ARG1 v)
            :ARG1-of (p2 / practice-01))
      :ARG1 (a3 / and
            :op1 (f2 / field
                  :mod (a4 / apply-02))
            :op2 (c / context
                  :mod (c2 / culture)
                  :location-of (o2 / operate-01
                        :ARG0 (s / system
                              :ARG1-of (ii3 / intelligent-01
                                    :mod (a5 / artificial))))))
      :degree (e / extent
            :mod (s2 / some)))

# ::snt A system used in the justice sector must necessarily exhibit higher levels of  privacy and fairness than a system used in the organisation of industrial production.
# File 37

(o / obligate-01
      :ARG2 (e / exhibit-01
            :ARG0 (s / system
                  :ARG1-of (u / use-01
                        :ARG2 (s2 / sector
                              :mod (j / justice))))
            :ARG1 (a / and
                  :op1 (p / private-02)
                  :op2 (f / fair-01)
                  :ARG1-of (h / have-degree-91
                        :ARG2 (h2 / high-02)
                        :ARG3 (m / more)
                        :ARG4 (s3 / system
                              :ARG1-of (u2 / use-01
                                    :ARG2 (o2 / organize-01
                                          :ARG1 (p2 / produce-01
                                                :mod (ii / industry)))))))
            :ARG1-of (n / need-01)))

# ::snt 2.1.1 Applying the VCIO  approach to transparency as a value (page 20/21) Justice The criteria subsumed under the value of justice in this example pertain to classic aspects  of algorithmic fairness such as bias prevention and assessment but emphasise a process  perspective to include a broader set of ethical considerations.
# File 37

(m / multi-sentence
      :snt1 (a / apply-02
            :li 1
            :ARG1 (a2 / approach-02
                  :ARG1 (t / transparency)
                  :ARG2 (v / value)
                  :mod (t2 / thing
                        :name (n / name
                              :op1 "VCIO")))
            :ARG2 v
            :ARG1-of (d / describe-01
                  :ARG0 (a3 / and
                        :op1 (p / page
                              :mod 20)
                        :op2 (p2 / page
                              :mod 21)
                        :topic (j / justice))))
      :snt2 (c / contrast-01
            :ARG1 (p3 / pertain-01
                  :ARG0 (c2 / criteria
                        :ARG1-of (s / subsume-01
                              :ARG2 (v2 / value
                                    :mod (j2 / justice)
                                    :example (t3 / this))))
                  :ARG1 (a4 / aspect
                        :mod (c3 / classic)
                        :topic (f / fairness
                              :mod (a5 / algorithmic))
                        :example (a6 / and
                              :op1 (p4 / prevent-01
                                    :ARG1 (b / bias-01))
                              :op2 (a7 / assess-01))))
            :ARG2 (e / emphasize-01
                  :ARG0 c2
                  :ARG1 (p5 / perspective
                        :mod (p6 / process-02))
                  :purpose (ii / include-01
                        :ARG0 c2
                        :ARG1 (s2 / set
                              :consist-of (t4 / thing
                                    :ARG1-of (c4 / consider-02)
                                    :mod (e2 / ethics))
                              :ARG1-of (h / have-degree-91
                                    :ARG2 (b2 / broad-02
                                          :ARG1 s2)
                                    :ARG3 (m2 / more)))))))

# ::snt In this sense, justice refers to a broader set  of ethical considerations than the often-used term fairness, which mostly focuses on  algorithmic outcomes themselves.
# File 37

(r / refer-01
      :ARG1 (j / justice)
      :ARG2 (s / set
            :consist-of (c / consider-02
                  :ARG1 (e / ethics))
            :ARG1-of (h / have-degree-91
                  :ARG2 (b / broad-02
                        :ARG1 s)
                  :ARG3 (m / more)
                  :ARG4 (t / term
                        :mod (f / fairness)
                        :ARG1-of (u / use-01
                              :mod (o / often))
                        :ARG0-of (f2 / focus-01
                              :ARG2 (o2 / outcome
                                    :mod (a / algorithm))
                              :mod (m2 / most)))))
      :mod (s2 / sense
            :mod (t2 / this)))

# ::snt 2.1.3 Applying the VCIO approach  to accountability as a value (page 24/25)Transparency as  explainability and  interpretability Justice with aspects of  algorithmic fairness and  inclusion Accountability refers to  questions of assigning  responsibility
# File 37

(m / multi-sentence
      :snt1 (a / apply-02
            :li 2.3
            :ARG1 (a2 / approach-02
                  :ARG1 (c / control-01
                        :ARG1 (a3 / and
                              :op1 (r / reproduce-01)
                              :op2 (o / operate-01)))
                  :mod (v / value))
            :ARG2 (a4 / accountable-02)
            :ARG1-of (d / describe-01
                  :ARG0 (p / publication-91
                        :ARG7 (a5 / and
                              :op1 (p2 / page
                                    :mod 24)
                              :op2 (p3 / page
                                    :mod 25)))))
      :snt2 (a6 / and
            :op1 (t / transparent
                  :prep-as (a7 / and
                        :op1 (p4 / possible-01
                              :ARG1 (e / explain-01))
                        :op2 (p5 / possible-01
                              :ARG1 (ii / interpret-01))))
            :op2 (j / justice
                  :prep-with (a8 / aspect
                        :topic (a9 / and
                              :op1 (f / fairness
                                    :mod (a10 / algorithmic))
                              :op2 (ii2 / include-01)))))
      :snt3 (r2 / refer-01
            :ARG0 (a11 / accountable-02)
            :ARG1 (q / question-01
                  :ARG1 (a12 / assign-01
                        :ARG1 (r3 / responsible-03)))))

# ::snt 22VALUES, CRITERIA, INDICATORS, OBSERVABLES (VCIO) AND THE AI ETHICS LABEL IN DETAIL ValueJUSTICE JUSTICE ValueCriteriaIdentifying  and assessing  trade-offsAssessment of different sources of potential biases to ensure fairness1Social justice  considerationsDetection and prevention of biases to ensure fairness Participatory procedures CriteriaIndicatorsHave tradeoffs been  identified and  assessed?Has the  training data  been analysed  for potential  biases?Has the  input design  (sensors, user  interface) and  input data  been reviewed  for potential  biases?Have the  requirements,  goals and task  definitions  been examined  for implicit  and explicit  discriminatory  effects?Were  possible selfreinforcing  processes  considered?Has due care  been taken  with regard to  discriminatory  effects caused  by the design  of the data  output?Have the  applied  methods (e.g.
# File 37

(m / multi-sentence
      :snt1 (a / and
            :op1 (c / criteria
                  :quant 22)
            :op2 (c2 / criteria
                  :ARG0-of (ii / indicate-01))
            :op3 (c3 / criteria
                  :name (n / name
                        :op1 "OBSERVABLES"))
            :op4 (l / label
                  :mod (e / ethics)
                  :mod (ii2 / intelligent-01
                        :mod (a2 / artificial))))
      :snt2 (a3 / and
            :op1 (ii3 / identify-01
                  :ARG1 (t / trade-off-02))
            :op2 (a4 / assess-01
                  :ARG1 t)
            :purpose (e2 / ensure-01
                  :ARG0 t
                  :ARG1 (f / fairness))
            :polarity (a5 / amr-unknown))
      :snt3 (r / review-01
            :ARG1 (a6 / and
                  :op1 (d / design-01
                        :ARG1 (ii4 / input)
                        :ARG1-of (m2 / mean-01
                              :ARG2 (s / sensor)))
                  :op2 (d2 / design-01
                        :ARG1 (ii5 / input)
                        :ARG1-of (m3 / mean-01
                              :ARG2 (ii6 / interface
                                    :poss (p / person
                                          :ARG0-of (u / use-01))))))
            :ARG3 (b / bias-01
                  :ARG1-of (p2 / possible-01)
                  :mod (ii7 / implicit))
            :polarity (a7 / amr-unknown)
            :purpose (e3 / ensure-01
                  :ARG0 b
                  :ARG1 (f2 / fairness)))
      :snt4 (c4 / consider-02
            :li 1
            :ARG1 (j / justice
                  :mod (s2 / social)))
      :snt5 (a8 / and
            :op1 (d3 / detect-01
                  :ARG1 (b2 / bias-01))
            :op2 (p3 / prevent-01
                  :ARG1 b2)
            :purpose (e4 / ensure-01
                  :ARG1 (f3 / fairness))))

# ::snt 23VALUES, CRITERIA, INDICATORS, OBSERVABLES (VCIO) AND THE AI ETHICS LABEL IN DETAIL ValueJUSTICE JUSTICE ValueCriteriaIdentifying  and assessing  trade-offsAssessment of different sources of potential biases to ensure fairness1Social justice  considerationsDetection and prevention of biases to ensure fairness Participatory procedures CriteriaIndicatorsHave tradeoffs been  identified and  assessed?Has the  training data  been analysed  for potential  biases?Has the  input design  (sensors, user  interface) and  input data  been reviewed  for potential  biases?Have the  requirements,  goals and task  definitions  been examined  for implicit  and explicit  discriminatory  effects?Were  possible selfreinforcing  processes  considered?Has due care  been taken  with regard to  discriminatory  effects caused  by the design  of the data  output?Have the  applied  methods (e.g.
# File 37

(m / multi-sentence
      :snt1 (a / and
            :op1 (c / criteria
                  :mod 23)
            :op2 (c2 / criteria
                  :mod 23)
            :op3 (ii / indicator)
            :op4 (ii2 / identifier)
            :op5 (l / label-01
                  :ARG2 (o / organization
                        :name (n / name
                              :op1 "Veterans"
                              :op2 "Anonymous"
                              :op3 "International"
                              :op4 "Defense"
                              :op5 "Organization"))))
      :snt2 (a2 / and
            :op1 (ii3 / identify-01
                  :ARG1 (t / trade-off-02))
            :op2 (a3 / assess-01
                  :ARG1 t)
            :purpose (e / ensure-01
                  :ARG0 t
                  :ARG1 (f / fair-01))
            :polarity (a4 / amr-unknown))
      :snt3 (r / review-01
            :ARG1 (a5 / and
                  :op1 (d / design-01
                        :ARG1 (ii4 / input)
                        :ARG1-of (m2 / mean-01
                              :ARG2 (a6 / and
                                    :op1 (s / sensor)
                                    :op2 (ii5 / interface
                                          :poss (p / person
                                                :ARG0-of (u / use-01))))))
                  :op2 (d2 / data
                        :mod (ii6 / input)))
            :ARG3 (b / bias-01
                  :ARG1-of (p2 / possible-01)
                  :mod (ii7 / implicit))
            :polarity (a7 / amr-unknown))
      :snt4 (c3 / consider-02
            :ARG1 (a8 / and
                  :op1 (d3 / discriminate-02)
                  :op2 (d4 / discriminate-02
                        :ARG1-of (e2 / explicit-03)))
            :purpose (e3 / ensure-01
                  :ARG0 a8
                  :ARG1 (f2 / fair-01))))

# ::snt While existing AI ethics guidelines typically focus on questions of algorithmic nondiscrimination and often frame those in terms of fairness, the VCIO approach broadens this  perspective.
# File 37

(b / broaden-01
      :ARG0 (a / approach-02
            :ARG1 (t / thing
                  :name (n / name
                        :op1 "VCIO")))
      :ARG1 (p / perspective
            :mod (t2 / this))
      :concession (a2 / and
            :op1 (f / focus-01
                  :ARG0 (g / guideline
                        :ARG1-of (e / exist-01)
                        :topic (e2 / ethics
                              :mod (a3 / artificial)))
                  :ARG2 (q / question-01
                        :ARG1 (d / discriminate-02
                              :polarity -
                              :mod (a4 / algorithmic)))
                  :ARG1-of (t3 / typical-02))
            :op2 (f2 / frame-06
                  :ARG0 g
                  :ARG1 q
                  :ARG2 (f3 / fairness)
                  :frequency (o / often))))

# ::snt 42CONCLUSION AND WHERE TO GO  FROM HERE classified in one of the higher risk levels, they may demand that an AI system must (1)  carry an ethics label that shows the rating for values such as transparency, robustness,  or fairness and (2) satisfy certain minimum levels within the rating.
# File 37

(a / and
      :li 42
      :op1 (c / conclude-01)
      :op2 (r / recommend-01
            :ARG1 (g / go-02
                  :ARG0 (s / system
                        :ARG1-of (ii / intelligent-01
                              :mod (a2 / artificial))
                        :ARG1-of (c2 / classify-01
                              :ARG2 (l / level
                                    :ARG1-of (ii2 / include-91
                                          :ARG2 (l2 / level
                                                :ARG1-of (h / have-degree-91
                                                      :ARG2 (h2 / high-02
                                                            :ARG1 l2)
                                                      :ARG3 (m / more)))))))
                  :ARG3 (h3 / here)))
      :op3 (p / possible-01
            :ARG1 (d / demand-01
                  :ARG0 (t / they)
                  :ARG1 (a3 / and
                        :op1 (o / obligate-01
                              :li 1
                              :ARG1 (c3 / carry-01
                                    :ARG0 s
                                    :ARG1 (l3 / label
                                          :mod (e / ethics)
                                          :ARG0-of (s2 / show-01
                                                :ARG1 (r2 / rate-01
                                                      :ARG1 (v / value
                                                            :example (o2 / or
                                                                  :op1 (t2 / transparency)
                                                                  :op2 (r3 / robustness)
                                                                  :op3 (f / fairness)))))))
                              :op2 (o3 / obligate-01
                                    :li 2
                                    :ARG1 s
                                    :ARG2 (s3 / satisfy-01
                                          :ARG0 s
                                          :ARG1 (l4 / level
                                                :mod (m2 / minimum)
                                                :mod (c4 / certain)
                                                :ARG1-of ii2
                                                :ARG2 r2))))))))

# ::snt Mittelstadt, B., Russell, C., Wachter, S. (2019) ‘Explaining Explanations in AI’ Proceedings  of the Conference on Fairness, Accountability, and Transparency – FAT*‚ 19, pp.
# File 37

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Mittelstadt")
                  :ARG0-of (h / have-rel-role-91
                        :ARG2 (m / member)))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "Russell")
                  :ARG0-of (h2 / have-rel-role-91
                        :ARG2 (m2 / member)))
            :op3 (p4 / person
                  :name (n3 / name
                        :op1 "Wachter")
                  :ARG0-of (h3 / have-rel-role-91
                        :ARG2 (m3 / member))))
      :ARG1 (p5 / publication
            :name (n4 / name
                  :op1 "Explaining"
                  :op2 "of"
                  :op3 "Explained"
                  :op4 "In"
                  :op5 "AI"
                  :op6 " Proceedings")
            :part-of (c / conference
                  :name (n5 / name
                        :op1 "Conference"
                        :op2 "on"
                        :op3 "Fairness"
                        :op4 "and"
                        :op5 "Accountability"
                        :op6 "and"
                        :op7 "Transparency")))
      :ARG7 (v / value-interval
            :op1 19
            :op2 19)
      :time (d / date-entity
            :year 2019))

# ::snt She also investigates findings of unfair terms  in consumer contracts in relation to non-performance of the supplier’s obligations while obliging the  consumer to fulfil the consumers’  own obligations — in what previous cases has the unfairness of this  condition been established, and what was the argumentation used by the claimants?
# File 55

(m / multi-sentence
      :snt1 (ii / investigate-01
            :ARG0 (s / she)
            :ARG1 (t / thing
                  :ARG1-of (f / find-01
                        :ARG2 (c / contract-02
                              :ARG2 (p / person
                                    :ARG0-of (c2 / consume-01))))
                  :ARG1-of (f2 / fair-01
                        :polarity -)
                  :ARG1-of (r / relate-01
                        :ARG2 (p2 / perform-02
                              :polarity -
                              :ARG1 (t2 / thing
                                    :ARG2-of (o / obligate-01
                                          :ARG1 (c3 / company
                                                :ARG0-of (s2 / supply-01))))
                              :time (o2 / obligate-01
                                    :ARG1 p
                                    :ARG2 (f3 / fulfill-01
                                          :ARG0 p
                                          :ARG1 (t3 / thing
                                                :ARG2-of o2
                                                :ARG1 p)))))))
      :mod (a / also)
      :snt2 (a2 / and
            :op1 (e / establish-01
                  :ARG1 (f4 / fair-01
                        :polarity -
                        :ARG1 (c4 / condition
                              :mod (t4 / this)))
                  :time (c5 / case-04
                        :mod (p3 / previous)))
            :op2 (u / use-01
                  :ARG0 (p4 / person
                        :ARG0-of (c6 / claim-01))
                  :ARG1 (t5 / thing
                        :ARG1-of (a3 / argue-01
                              :ARG0 p4)))))

# ::snt Another characteristic problem is only partly of a technical nature: bias and discrimination or unfairness  may be caused both by the data source used and by the algorithms and models evaluating the data.96  Bias may result from historical data skewed towards specific groups or from specific data collection  mechanics, from lack of data in certain areas97 (also called unobservable outcomes or survivorship  bias98), both resulting in what is called training data bias.99 Equally important is that bias can also be  introduced by reason of the chosen methods, models and architects, including statistical rules or the  optimisation methods and parameters for performance.100 A third major source of bias is related to  a change in the usage of the AI tool: systems originally intended for one purpose may be tried for  reuse in a different area (including cross-jurisdictional use of AI, e.g.
# File 55

(m / multi-sentence
      :snt1 (p / problem
            :mod (t / technical)
            :ARG1-of (c / characteristic-02)
            :mod (a / another)
            :ARG1-of (m2 / mean-01
                  :ARG2 (p2 / possible-01
                        :ARG1 (c2 / cause-01
                              :ARG0 (a2 / and
                                    :op1 (s / source-02
                                          :ARG1 (d / data)
                                          :ARG1-of (u / use-01))
                                    :op2 (a3 / and
                                          :op1 (a4 / algorithm)
                                          :op2 (m3 / model)
                                          :ARG0-of (e / evaluate-01
                                                :ARG1 d)))
                              :ARG1 (b / bias-01)))))
      :snt2 (p3 / possible-01
            :ARG1 (c3 / cause-01
                  :ARG0 (o / or
                        :op1 (s2 / skew-01
                              :ARG1 (d2 / data
                                    :mod (h / history))
                              :ARG2 (g / group
                                    :ARG1-of (s3 / specific-02)))
                        :op2 (m4 / mechanics
                              :mod (c4 / collect-01
                                    :ARG1 (d3 / data))
                              :ARG1-of (s4 / specific-02))
                        :ARG1-of (r / result-01
                              :ARG2 (t2 / thing
                                    :ARG1-of (c5 / call-01
                                          :ARG2 (o2 / or
                                                :op1 (o3 / outcome
                                                      :ARG1-of (o4 / observe-01
                                                            :polarity -))
                                                :op2 (b2 / bias-01
                                                      :topic (s5 / survive-01)))))))
                  :ARG1 b))
      :snt3 (ii / important-01
            :li 100
            :ARG1 (p4 / possible-01
                  :ARG1 (ii2 / introduce-02
                        :ARG0 (r2 / reason
                              :poss (a5 / and
                                    :op1 (m5 / method
                                          :ARG1-of (c6 / choose-01))
                                    :op2 m3)
                              :op3 (a6 / architect)
                              :ARG2-of (ii3 / include-01
                                    :ARG1 (a7 / and
                                          :op1 (r3 / rule
                                                :mod (s6 / statistics))
                                          :op2 (p5 / parameter
                                                :purpose (p6 / perform-02))))))
                  :ARG1 (b3 / bias-01)
                  :mod (a8 / also))
            :mod (a9 / also))
      :snt4 (r4 / relate-01
            :ARG1 (c7 / change-01
                  :ARG1 (u2 / use-01
                        :ARG1 (t3 / tool
                              :mod (ii4 / intelligent-01
                                    :mod (a10 / artificial))))))
      :ARG2 (p7 / possible-01
            :ARG1 (r5 / reuse-01
                  :ARG1 t3
                  :location (a11 / area
                        :ARG1-of (d4 / differ-02)))))

# ::snt 97 Nengfeng Zhou and others, ‘ Bias, Fairness, and Accountability with AI and ML Algorithms ’ [2021] arXiv:2105.06558 [cs,  stat] 5 accessed 18 December 2021.
# File 55

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Nengfeng"
                        :op2 "Zhou"))
            :op2 (o / other))
      :ARG1 (p3 / publication
            :name (n2 / name
                  :op1 "Bias"
                  :op2 "and"
                  :op3 "Fairness"
                  :op4 "and"
                  :op5 "Accountability"
                  :op6 "with"
                  :op7 "and"
                  :op8 "AI"
                  :op9 "ML"
                  :op10 "Algorithms")
            :time (d / date-entity
                  :year 2021))
      :ARG4 (j / journal
            :name (n3 / name
                  :op1 "ArXiv:2105.06558"))
      :ARG1-of (a2 / access-01
            :time (d2 / date-entity
                  :day 5
                  :month 12
                  :year 2021)))

# ::snt Zhang D and others, ‘ The AI Index 2021 Annual Report ’ [2021] arXiv:2103.06312 [cs] accessed 4  December 2021 Zhou N and others, ‘ Bias, Fairness, and Accountability with AI and ML Algorithms ’ [2021] arXiv:2105.06558  [cs, stat] accessed 18 December 2021.
# File 55

(m / multi-sentence
      :snt1 (p / publication-91
            :ARG0 (a / and
                  :op1 (p2 / person
                        :name (n / name
                              :op1 "Zhang"
                              :op2 "D"))
                  :op2 (o / other))
            :ARG1 (p3 / publication
                  :name (n2 / name
                        :op1 "The"
                        :op2 "AI"
                        :op3 "Index"
                        :op4 2021
                        :op5 "Annual"
                        :op6 "Report"))
            :ARG4 (j / journal
                  :name (n3 / name
                        :op1 "ArXiv"))
            :ARG1-of (a2 / access-01
                  :time (d / date-entity
                        :day 4
                        :month 12
                        :year 2021)))
      :snt2 (p4 / publication
            :ARG0 (a3 / and
                  :op1 (p5 / person
                        :name (n4 / name
                              :op1 "Zhou"
                              :op2 "N"))
                  :op2 (o2 / other))
            :ARG1 (p6 / publication
                  :name (n5 / name
                        :op1 "Bias"
                        :op2 ","
                        :op3 "Fairness"
                        :op4 "and"
                        :op5 "Accountability"
                        :op6 "with"
                        :op7 "AI"
                        :op8 "and"
                        :op9 "ML"
                        :op10 "Algorithms"))
            :ARG4 j
            :name (n6 / name
                  :op1 "ArXiv"))
      :ARG1-of (a4 / access-01
            :time (d2 / date-entity
                  :day 5
                  :month 12
                  :year 2021))
      :time (d3 / date-entity
            :day 5
            :month 12
            :year 2021))

# ::snt As set out in the  OECD AI Principles, t rustworthy AI systems benefit people and planet; uphold human rights,  democratic values and fairness; are transparent and explainable; robust, sec ure and safe; and are  operated by accountable  entities  (OECD, 2019 [2]).
# File 141

(a / and
      :op1 (b / benefit-01
            :ARG0 (s / system
                  :mod (ii / intelligent-01
                        :mod (a2 / artificial))
                  :ARG1-of (r / rust-01))
            :ARG1 (a3 / and
                  :op1 (p / person)
                  :op2 (p2 / planet)))
      :op2 (u / uphold-01
            :ARG0 s
            :ARG1 (a4 / and
                  :op1 (r2 / right-05
                        :ARG1 (h / human))
                  :op2 (v / value
                        :mod (d / democracy))
                  :op3 (f / fairness)))
      :op3 (p3 / possible-01
            :ARG1 (e / explain-01
                  :ARG1 s))
      :op4 (r3 / robust
            :domain s)
      :op5 (s2 / safe-01
            :ARG0 s)
      :op6 (s3 / secure-02
            :ARG1 s)
      :op7 (o / operate-01
            :ARG0 (e2 / entity
                  :ARG0-of (a5 / accountable-02))
            :ARG1 s)
      :ARG1-of (s4 / say-01
            :ARG0 (p4 / publication-91
                  :ARG0 (o2 / organization
                        :name (n / name
                              :op1 "OECD"))
                  :ARG1-of (c / cite-01
                        :ARG2 2)
                  :time (d2 / date-entity
                        :year 2019))))

# ::snt Wie in den KI -Prinzipien der OECD festgelegt,  kommen vertrauenswürdige KI -Systeme den Menschen und dem Planeten zugute;  Menschenrechte, demokratische Werte und Fairness wahren; sind transparent und verständlich ;  robust und sicher; und werden von verantwortlichen Stellen betrieben (OECD, 2019 [2]).
# File 141

(m / multi-sentence
      :snt1 (k / kommen-00
            :ARG0 (ii / i)
            :ARG1 (s / system
                  :mod (t / thing
                        :name (n / name
                              :op1 "KI"))
                  :mod (v / vertrauenswürdige))
            :ARG2 (a / and
                  :op1 (p / person
                        :mod (e / ethnic-group
                              :name (n2 / name
                                    :op1 "Menschen")))
                  :op2 (p2 / planet))
            :manner (z / zugute))
      :snt2 (w / wahren-00
            :ARG0 (a2 / and
                  :op1 (v2 / voluntary-02
                        :ARG0 p
                        :mod (m2 / male)))
            :op2 (w2 / Werte
                  :mod (d / democracy))
            :op3 (f / fairness))
      :ARG1 s
      :snt3 (a3 / and
            :op1 (t2 / transparent
                  :domain s)
            :op2 (v3 / verständlich
                  :domain s)
            :op3 (r / robust
                  :domain s)
            :op4 (s2 / safe-01
                  :ARG0 s))
      :snt4 (b / betrieb-00
            :ARG0 (s3 / stellen
                  :mod (v4 / verantwortlichen))
            :ARG1 s)
      :ARG1-of (d2 / describe-01
            :ARG0 (p3 / publication-91
                  :ARG0 (o / organization
                        :name (n3 / name
                              :op1 "OECD"))
                  :ARG1-of (c / cite-01
                        :ARG2 2)
                  :time (d3 / date-entity
                        :year 2019))))

# ::snt As set out in the  OECD AI Principles, trustworthy AI systems benefit peo ple and planet; uphold human rights,  democratic values and fairness; are transparent and explainable; robust, secure and safe; and are  operated by accountable entities (OECD, 2019 [2]).
# File 141

(a / and
      :op1 (b / benefit-01
            :ARG0 (s / system
                  :mod (ii / intelligent-01
                        :mod (a2 / artificial))
                  :mod (t / trustworthy))
            :ARG1 (a3 / and
                  :op1 (p / person)
                  :op2 (p2 / planet)))
      :op2 (u / uphold-01
            :ARG0 s
            :ARG1 (a4 / and
                  :op1 (r / right-05
                        :ARG1 (h / human))
                  :op2 (v / value
                        :mod (d / democracy))
                  :op3 (f / fairness)))
      :op3 (a5 / and
            :op1 (t2 / transparent
                  :domain s)
            :op2 (p3 / possible-01
                  :ARG1 (e / explain-01
                        :ARG1 s)))
      :op4 (r2 / robust
            :domain s)
      :op5 (s2 / secure-02
            :ARG1 s)
      :op6 (s3 / safe-01
            :ARG0 s)
      :op7 (o / operate-01
            :ARG0 (e2 / entity
                  :ARG0-of (a6 / accountable-02))
            :ARG1 s)
      :ARG1-of (s4 / set-out-06
            :ARG0 (p4 / principle
                  :mod ii
                  :mod (o2 / organization
                        :name (n / name
                              :op1 "OECD"))))
      :ARG1-of (d2 / describe-01
            :ARG0 (p5 / publication
                  :ARG0-of (c / cite-01
                        :ARG1 2)
                  :time (d3 / date-entity
                        :year 2019))))

# ::snt It appears nevertheless clear to many actors that an  improve d framework is needed to guarantee the fairness, transparency and accountability of AI  systems, an objective that can be pursued by enhancing representation at various levels of decision making.
# File 84

(a / appear-02
      :ARG1 (h / have-concession-91
            :ARG2 (c / clear-06
                  :ARG1 (n / need-01
                        :ARG1 (f / framework
                              :ARG1-of (ii / improve-01))
                        :purpose (g / guarantee-01
                              :ARG0 f
                              :ARG1 (a2 / and
                                    :op1 (f2 / fairness)
                                    :op2 (t / transparency)
                                    :op3 (a3 / accountable-02)
                                    :poss (s / system
                                          :mod (ii2 / intelligent-01
                                                :mod (a4 / artificial))))
                              :mod (o / objective
                                    :ARG1-of (p / pursue-01
                                          :ARG1-of (p2 / possible-01)
                                          :manner (e / enhance-01
                                                :ARG1 (r / represent-01
                                                      :location (l / level
                                                            :mod (v / various)
                                                            :mod (m / make-18
                                                                  :ARG1 (d / decide-01)))))))))
                  :ARG2 (p3 / person
                        :ARG0-of (a5 / act-01)
                        :quant (m2 / many)))))

# ::snt In the literature, there has been much discussion about how to improve the regulation of AI, notably  in terms of fairness, transparency  and accountability .
# File 84

(d / discuss-01
      :ARG1 (t / thing
            :manner-of (ii / improve-01
                  :ARG1 (r / regulate-01
                        :ARG1 (ii2 / intelligent-01
                              :mod (a / artificial)))
                  :ARG2-of (ii3 / include-91
                        :ARG1 (a2 / and
                              :op1 (f / fairness)
                              :op2 (t2 / transparency)
                              :op3 (a3 / accountable-02))
                        :ARG1-of (n / notable-04))))
      :location (l / literature)
      :quant (m / much))

# ::snt These notions are deeply intertwined, as  transparency is instrumental not only for instance in order to allow for the exercise of data subject  rights, but also to facilitate the detection of bias and discrimination, and thus support fairness.
# File 84

(ii / intertwine-01
      :ARG1 (n / notion
            :mod (t / this))
      :ARG1-of (d / deep-02)
      :ARG1-of (c / cause-01
            :ARG0 (ii2 / instrumental
                  :domain (t2 / transparency)
                  :ARG0-of (e / exemplify-01
                        :ARG1 (c2 / contrast-01
                              :ARG1 (h / have-purpose-91
                                    :ARG1 t2
                                    :ARG2 (a / allow-01
                                          :ARG1 (e2 / exercise-01
                                                :ARG1 (d2 / data
                                                      :ARG1-of (s / subject-02
                                                            :ARG2 (r / right-05))))))
                              :ARG2 (h2 / have-purpose-91
                                    :ARG1 t2
                                    :ARG2 (f / facilitate-01
                                          :ARG0 t2
                                          :ARG1 (d3 / detect-01
                                                :ARG1 (a2 / and
                                                      :op1 (b / bias-01)
                                                      :op2 (d4 / discriminate-02)))
                                          :ARG0-of (c3 / cause-01
                                                :ARG1 (s2 / support-01
                                                      :ARG0 t2
                                                      :ARG1 (f2 / fair-01))))))))))

# ::snt Conference on Fairness, Accountability, and  Transparency .
# File 84

(c / conference
      :topic (a / and
            :op1 (f / fairness)
            :op2 (a2 / accountable-02)
            :op3 (t / transparency)))

# ::snt ACM Conference on Fairness, Accountability, and Transparency (FAccT ' 21), March  1–10, 2021, Virtual Event, Canada.
# File 84

(c / conference
      :name (n / name
            :op1 "ACM"
            :op2 "Conference"
            :op3 "on"
            :op4 "Fairness"
            :op5 "Accountability"
            :op6 "and"
            :op7 "Transparency")
      :ARG1-of (d / describe-01
            :ARG0 (p / publication
                  :name (n2 / name
                        :op1 "FACCT"
                        :op2 21)))
      :time (d2 / date-interval
            :op1 (d3 / date-entity
                  :month 3
                  :day 1
                  :year 2021)
            :op2 (d4 / date-entity
                  :month 3
                  :day 10
                  :year 2021))
      :mod (e / event
            :mod (v / virtual))
      :location (c2 / country
            :name (n3 / name
                  :op1 "Canada")))

# ::snt Section 2   Basic Philosophy   Dignity: A society that has respect for human dignity   Diversity & Inclusion: A society where people with diverse backgrounds can pursue  their well- being   Sustainability: A sustainable society   Section 3  Social Changes Needed to Realize Society 5.0 - "AI-Ready Society5"  Human Potential, Social Systems, Industrial Structures,   Innovation Systems (environments that support innovation),  Governance   Section 4  Social Principles of Human -Centric AI   4.1 Social Principles of AI     (1) Human -Centric, (2) Education/Literacy, (3) Privacy Protection,     (4) Ensur ing Security,  (5) Fair Competition,     (6) Fairness, Accountability, and Transparency,  (7) Innovation   4.2 R&D and Utilization Principles of AI     Figure 1:  Overall Structure of This Document                                                          5 An "AI -Ready Society" means that society as a whole has undergone the necessary changes to maximize the  benefits of AI, enjoys the benefits of AI, or has introduced AI i mmediately when needed and is in a state of being  able to receive the benefits.
# File 19

(m / multi-sentence
      :snt1 (m2 / mean-01
            :ARG1 (s / society
                  :ARG1-of (r / ready-02
                        :ARG2 (ii / intelligent-01
                              :mod (a / artificial))))
            :ARG2 (o / or
                  :op1 (u / undergo-28
                        :ARG1 s
                        :ARG2 (c / change-01
                              :ARG1-of (n / need-01
                                    :purpose (m3 / maximize-01
                                          :ARG1 (b / benefit-01
                                                :ARG0 ii)))))
                  :op2 (e / enjoy-01
                        :ARG0 s
                        :ARG1 (b2 / benefit-01
                              :ARG0 ii))
                  :op3 (ii2 / introduce-02
                        :ARG0 s
                        :ARG1 ii
                        :time (ii3 / immediate)
                        :time n
                        :ARG1 ii2)))
      :snt2 (a2 / and
            :op1 (p / philosophy
                  :mod (b3 / basic))
            :op2 (d / dignity
                  :mod (h / human))
            :op3 (a3 / and
                  :op1 (d2 / diversity)
                  :op2 (ii4 / inclusion)
                  :domain (s2 / society
                        :location-of (p2 / possible-01
                              :ARG1 (p3 / pursue-01
                                    :ARG0 (p4 / person
                                          :ARG0-of (h2 / have-03
                                                :ARG1 (b4 / background
                                                      :mod (d3 / diverse))))
                                    :ARG1 (w / well-09
                                          :ARG1 p4))))))
      :op4 (s3 / sustain-01
            :ARG1 s2
            :ARG1-of (p5 / possible-01))
      :op5 (s4 / section
            :mod 3)
      :op6 (l / law
            :name (n2 / name
                  :op1 "Social"
                  :op2 "Change"
                  :op3 "Needed"
                  :op4 "to"
                  :op5 "Realize"
                  :op6 "Society"
                  :op7 "5"))
      :op7 (l2 / law
            :name (n3 / name
                  :op1 "Fair"
                  :op2 "Competition"))
      :op8 (l3 / law
            :name (n4 / name
                  :op1 "Fair"
                  :op2 "Accountability"))
      :op9 (l4 / law
            :name (n5 / name
                  :op1 "Transparency"))
      :op10 (l5 / law
            :name (n6 / name
                  :op1 "Innovate-01"
                  :op2 "Technology"))
      :op11 (l6 / law
            :name (n7 / name
                  :op1 "Technology"
                  :op2 "Maintenance"
                  :op3 "Allowance"
                  :op4 "Act"))
      :op12 (l7 / law
            :name (n8 / name
                  :op1 "Technology"
                  :op2 "Act"))
      :op13 "Technology"
      :op14 "Appropriations"
      :op15 "Act"
      :op14 "Technology"
      :op15 "Appropriations"
      :op16 "Act"
      :op15 "Technology"
      :op16 "Appropriations"
      :op17 "Act"
      :op17 ""
      :op17 ""
      :op18 "Technology"
      :op19 "Appropriations"
      :op20 ""
      :op21 ""
      :op20 ""
      :op21 ""
      :op21 "Technology"
      :op22 "Appropriations"
      :op21 ""
      :op21 ""
      :op22 ""
      :op23 "Technology"
      :op23 ""
      :op24 ""
      :op21 "Technology"
      :op21 ""
      :op22 ""
      :op23 ""
      :op24 "Technology"
      :op25 ""
      :op21 "Technology"
      :op21 ""
      :op21 ""
      :op22 "Technology"
      :op21 ""
      :op21 ""
      :op22 "Technology"
      :op23 ""
      :op21 ""
      :op21 "Technology"
      :op22 ""
      :op21 "Technology"
      :op23 ""
      :op21 ""
      :op22 "Technology"
      :op21 ""
      :op21 ""
      :op21 "Technology"
      :op21 ""
      :op21 "Technology"
      :op22 ""
      :op21 "Technology"
      :op21 "Technology"
      :quant ""
      :quant ""
      :quant "4.1"
      :quant "4.2"
      :quant "4.1"
      :quant "4.1")

# ::snt These characteristics include  bias in data, the possibility of causing   bias depending on how AI is used , and  issues of fairness, impartiality , and p rivacy  protection that are inherent ly needed  in the use of AI.
# File 19

(ii / include-01
      :ARG1 (a / and
            :op1 (b / bias-01
                  :ARG1 (d / data))
            :op2 (p / possible-01
                  :ARG1 (c / cause-01
                        :ARG1 (b2 / bias-01)
                        :ARG0-of (d2 / depend-01
                              :ARG1 (t / thing
                                    :manner-of (u / use-01
                                          :ARG1 (ii2 / intelligent-01
                                                :mod (a2 / artificial)))))))
            :op3 (ii3 / issue-02
                  :ARG0 (a3 / and
                        :op1 (f / fairness)
                        :op2 (ii4 / impartiality)
                        :op3 (p2 / protect-01
                              :ARG1 (p3 / prejudice-01))
                        :ARG1-of (n / need-01
                              :ARG0 (u2 / use-01
                                    :ARG1 ii2)
                              :mod (ii5 / inherent)))))
      :ARG2 t
      :ARG2-of (c2 / characteristic-02)
      :mod (t2 / this))

# ::snt (6) The Principle  of Fairness, Accountability, and Transparency     In an "AI- Ready Society", it is necessary to ensure fairness and transparency in  decision -making , appropriate accountability for the results , and trust in  the technology ,  so that people who use AI are not subject to  undue discriminatio n with regard to  personal  background, or to unfair treatment  in terms  of human dignity.
# File 19

(n / need-01
      :li 6
      :ARG1 (e / ensure-01
            :ARG0 (s / society
                  :ARG1-of (r / ready-02
                        :ARG2 (ii / intelligent-01
                              :mod (a / artificial))))
            :ARG1 (a2 / and
                  :op1 (f / fairness)
                  :op2 (t / transparency)
                  :topic (a3 / and
                        :op1 (d / decide-01)
                        :op2 (a4 / accountable-02
                              :ARG1 (r2 / result-01)
                              :ARG1-of (a5 / appropriate-02))
                        :op3 (t2 / trust-02
                              :ARG1 (t3 / technology)))))
      :purpose (s2 / subject-01
            :polarity -
            :ARG1 (p / person
                  :ARG0-of (u / use-01
                        :ARG1 ii))
            :ARG2 (o / or
                  :op1 (d2 / discriminate-02
                        :ARG1 p
                        :ARG2 (b / background
                              :ARG1-of (p2 / personal-02)))
                  :op2 (t4 / treat-01
                        :ARG1 p
                        :ARG1-of (f2 / fair-01
                              :polarity -)
                        :topic (d3 / dignity
                              :mod (h / human))))))

# ::snt (6) The Principle  of Fairness, Accountability, and Transparency     In an "AI- Ready Society", it is necessary to ensure fairness and transparency in  decision -making , appropriate accountability for the results , and trust in  the technology ,  so that people who use AI are not subject to  undue discriminatio n with regard to  personal  background, or to unfair treatment  in terms  of human dignity.
# File 19

(n / need-01
      :li 6
      :ARG1 (e / ensure-01
            :ARG0 (s / society
                  :ARG1-of (r / ready-02
                        :ARG2 (ii / intelligent-01
                              :mod (a / artificial))))
            :ARG1 (a2 / and
                  :op1 (f / fairness)
                  :op2 (t / transparency)
                  :topic (a3 / and
                        :op1 (d / decide-01)
                        :op2 (a4 / accountable-02
                              :ARG1 (r2 / result-01)
                              :ARG1-of (a5 / appropriate-02))
                        :op3 (t2 / trust-02
                              :ARG1 (t3 / technology)))))
      :purpose (s2 / subject-01
            :polarity -
            :ARG1 (p / person
                  :ARG0-of (u / use-01
                        :ARG1 ii))
            :ARG2 (o / or
                  :op1 (d2 / discriminate-02
                        :ARG1 p
                        :ARG2 (b / background
                              :ARG1-of (p2 / personal-02)))
                  :op2 (t4 / treat-01
                        :ARG1 p
                        :ARG1-of (f2 / fair-01
                              :polarity -)
                        :topic (d3 / dignity
                              :mod (h / human))))))

# ::snt The rise of AI decision-making also implicates fundamental rights of fairness, accountability, and democracy.
# File 5

(ii / implicate-01
      :ARG0 (r / rise-01
            :ARG1 (d / decide-01
                  :manner (a / artificial)))
      :ARG1 (r2 / right-05
            :ARG2 (a2 / and
                  :op1 (f / fairness)
                  :op2 (a3 / accountable-02)
                  :op3 (d2 / democracy))
            :mod (f2 / fundamental))
      :mod (a4 / also))

# ::snt Fairness Obligation.
# File 5

(o / obligate-01
      :ARG2 (f / fairness))

# ::snt The New Frontier: Artificial Intelligence at Work   07 Our key findings A core source of anxiety is a pronounced sense of unfairness and  lack of agency around automated decisions that determine  access or fundamental aspects of work.
# File 111

(m / multi-sentence
      :snt1 (p / publication
            :name (n / name
                  :op1 "The"
                  :op2 "New"
                  :op3 "Frontline"
                  :op4 "Artificial"
                  :op5 "Intelligence"
                  :op6 "at"
                  :op7 "Work")
            :time (d / date-entity
                  :day 7
                  :month 7))
      :snt2 (t / thing
            :ARG1-of (f / find-01
                  :ARG0 (w / we))
            :ARG1-of (k / key-02))
      :snt3 (s / source-02
            :ARG0 (a / and
                  :op1 (s2 / sense-01
                        :ARG1 (f2 / fairness
                              :polarity -)
                        :ARG1-of (p2 / pronounced-02))
                  :op2 (l / lack-01
                        :ARG1 (a2 / agency)
                        :topic (t2 / thing
                              :ARG1-of (d2 / decide-01)
                              :ARG1-of (a3 / automate-01)
                              :ARG0-of (d3 / determine-01
                                    :ARG1 (o / or
                                          :op1 (a4 / access-01)
                                          :op2 (a5 / aspect
                                                :mod (f3 / fundamental)
                                                :mod (w2 / work-01)))))))
            :ARG1 (a6 / anxiety)
            :mod (c / core)))

# ::snt Workers are not confident of how their  data is being used, and how this is making decisions about their  performance,32 leading to a sense of unfairness and an absence  of agency and effective remedy.
# File 111

(l / lead-03
      :li 32
      :ARG0 (c / confident-01
            :polarity -
            :ARG1 (p / person
                  :ARG0-of (w / work-01))
            :ARG2 (a / and
                  :op1 (t / thing
                        :manner-of (u / use-01
                              :ARG1 (d / data
                                    :poss p)))
                  :op2 (t2 / thing
                        :manner-of (d2 / decide-01
                              :ARG1 (t3 / thing
                                    :ARG1-of (p2 / perform-02
                                          :ARG0 p))))))
      :ARG2 (a2 / and
            :op1 (s / sense-01
                  :ARG0 p
                  :ARG1 (f / fairness
                        :polarity -))
            :op2 (a3 / absent-01
                  :ARG1 (a4 / and
                        :op1 (a5 / agency)
                        :op2 (t4 / thing
                              :ARG3-of (r / remedy-01)
                              :ARG0-of (e / effective-04))))))

# ::snt This is associated with low levels  of trust in the ability of AI to make fair, transparent and  accountable decisions.33 For clarity and fairness, we therefore propose establishing a new,  freestanding right for a full explanation of purpose and outcomes  and impacts of algorithmic systems at work, which would include  access to relevant AIAs.34 This right would enable workers to find  out the use of, purpose for and metrics within AI technologies used  to monitor, allocate work, pay and discipline workers as modelled  by the new Californian Bill in the US and the subject of a new  consultation on “ a Bill of Rights for an AI-Powered World” .35   The right for an explanation would be mirrored by a new  transparency duty on employers to disclose such information,  alongside any AIA.
# File 111

(m / multi-sentence
      :snt1 (a / associate-01
            :li 33
            :ARG1 (t / this)
            :ARG2 (t2 / trust-01
                  :ARG1 (c / capable-01
                        :ARG1 (ii / intelligent-01
                              :mod (a2 / artificial))
                        :ARG2 (m2 / make-01
                              :ARG0 ii
                              :ARG1 (d / decide-01
                                    :ARG1-of (f / fair-01)
                                    :mod (t3 / transparent)
                                    :ARG0-of (a3 / accountable-02))))
                  :ARG1-of (l / low-04)))
      :snt2 (c2 / cause-01
            :ARG0 (p / propose-01
                  :ARG0 (w / we)
                  :ARG1 (e / establish-01
                        :ARG1 (r / right-05
                              :ARG2 (e2 / explain-01
                                    :ARG1 (a4 / and
                                          :op1 (p2 / purpose)
                                          :op2 (o / outcome)
                                          :op3 (ii2 / impact-01
                                                :ARG0 (s / system
                                                      :mod (a5 / algorithm)
                                                      :location (w2 / work-01))))
                                    :mod (f2 / full)
                                    :ARG2-of (ii3 / include-01
                                          :ARG1 (a6 / access-01
                                                :ARG1 (p3 / product
                                                      :name (n / name
                                                            :op1 "AIA")
                                                      :ARG1-of (r2 / relevant-01)))))
                              :ARG1-of (m3 / model-01
                                    :ARG0 (l2 / law
                                          :name (n2 / name
                                                :op1 "California"
                                                :op2 "Bill")
                                          :location (c3 / country
                                                :name (n3 / name
                                                      :op1 "US"))
                                          :ARG1-of (n4 / new-01)))))
                  :purpose (a7 / and
                        :op1 (c4 / clear-06)
                        :op2 (f3 / fair-01))))
      :snt3 (m4 / mirror-01
            :li 35
            :ARG1 (d2 / duty
                  :mod (t4 / transparency)
                  :ARG1-of (n5 / new-01)
                  :topic (d3 / disclose-01
                        :ARG0 (c5 / company
                              :ARG0-of (e3 / employ-01))
                        :ARG1 (ii4 / information
                              :mod (s2 / such))))
            :ARG2 (a8 / act-02
                  :mod (a9 / any)
                  :ARG1-of (a10 / add-02))))

# ::snt ” In Proceedings of the 2021 ACM Conference on Fairness,   Accountability, and Transparency, pp.
# File 111

(p / publication-91
      :ARG4 (c / conference
            :name (n / name
                  :op1 "ACM"
                  :op2 "Conference"
                  :op3 "on"
                  :op4 "Fairness"
                  :op5 "and"
                  :op6 "Accountability"
                  :op7 "and"
                  :op8 "Transparency")
            :time (d / date-entity
                  :year 2021))
      :ARG7 (v / value-interval
            :op1 1
            :op2 2))

# ::snt This  is  particularly   the  case  in  the  areas  of   transpar ency   and  explainability ,  as  well  as  in  the  areas  of  activ e  fairness   and  non-discrimina tion   T h e  S t a t e  o f  A I  E t h i c s  R e p o r t ,  V o l u m e  6  ( J a nu a r y  2 0 2 2 )   4 7
# File 126

(a / and
      :op1 (c / case-04
            :ARG1 (t / this)
            :mod (p / particular)
            :location (a2 / area
                  :topic (a3 / and
                        :op1 (e / enforce-01
                              :ARG1 (t2 / transgender))
                        :op2 (p2 / possible-01
                              :ARG1 (e2 / explain-01)))))
      :op2 (c2 / case-04
            :ARG1 t
            :location (a4 / area
                  :topic (a5 / and
                        :op1 (f / fairness)
                        :op2 (d / discriminate-01
                              :polarity -)))))

# ::snt The  team   used   manual   coding   to  iden tify  unifying  themes   and  came   up  with   11  of  them:    transpar ency   (appear ed  in  87%   of  the  documen ts),  justice  and  Fairness   (81%),   non-male ficence    (71%),   responsibility   (71%),   Privacy  (56%),   bene ficence   (49%),   freedom   and  autonom y  (40%),    Trust (33%), sus tainability (17%), dignity (15%), and solidarity (7%).
# File 126

(a / and
      :op1 (u / use-01
            :ARG0 (t / team)
            :ARG1 (c / code-01
                  :mod (m / manual))
            :ARG2 (ii / indify-01
                  :ARG0 t
                  :ARG1 (t2 / theme
                        :ARG0-of (u2 / unify-01))))
      :op2 (c2 / come-up-13
            :ARG1 (t3 / theme
                  :quant 11
                  :ARG1-of (ii2 / include-91
                        :ARG2 t2)
                  :ARG2-of (ii3 / include-91
                        :ARG1 (a2 / and
                              :op1 (e / entitlement
                                    :mod (t4 / transpar)
                                    :ARG1-of (a3 / appear-01
                                          :location ii3
                                          :ARG1 e
                                          :ARG2 (d / document
                                                :mod (m2 / male
                                                      :polarity -))
                                          :ARG3 (p / percentage-entity
                                                :value 87))))
                        :op2 (j / justice)
                        :op3 (f / fair-01)
                        :op4 (p2 / percentage-entity
                              :value 81)
                        :op5 (r / responsible-02
                              :ARG1-of (ii4 / include-91
                                    :ARG2 t2))
                        :op6 (p3 / privacy
                              :ARG1-of (ii5 / include-91
                                    :ARG2 t2
                                    :ARG3 (p4 / percentage-entity
                                          :value 71)))
                        :op7 (p5 / percentage-entity
                              :value 56)
                        :op8 (g / generosity
                              :mod (b / bene))
                        :op9 (f2 / free-04
                              :ARG1-of (ii6 / include-91
                                    :ARG2 t2
                                    :ARG3 (p6 / percentage-entity
                                          :value 49)))
                        :op10 (a4 / autonomy
                              :ARG1-of (ii7 / include-91
                                    :ARG2 t2
                                    :ARG3 (p7 / percentage-entity
                                          :value 40)))
                        :op11 (t5 / trust-02
                              :ARG1-of (ii8 / include-91
                                    :ARG2 t2
                                    :ARG3 (p8 / percentage-entity
                                          :value 33)))
                        :op12 (p9 / possible-01
                              :polarity -
                              :ARG1 (s / spare-01))
                        :op13 (d2 / dignity
                              :ARG1-of (ii9 / include-91
                                    :ARG2 t2
                                    :ARG3 (p10 / percentage-entity
                                          :value 15)))
                        :op14 (s2 / solidarity
                              :ARG1-of (ii10 / include-91
                                    :ARG2 t3
                                    :ARG3 (p11 / percentage-entity
                                          :value 7)))))))

# ::snt They  started  by  choosing   ten  keywords  as  core  terms:   humanity ,  collabor ation,   shar e,   fairness,   transpar ency ,  privacy,  security ,  safety,  accountability ,  and  AGI  (artificial   gener al   intelligence).
# File 126

(s / start-01
      :ARG0 (t / they)
      :ARG2 (c / choose-01
            :ARG0 t
            :ARG1 (k / keyword
                  :quant 10
                  :prep-as (t2 / term
                        :mod (c2 / core)
                        :example (a / and
                              :op1 (h / humanity)
                              :op2 (c3 / collaborate-01)
                              :op3 (s2 / shar-e)
                              :op4 (f / fairness)
                              :op5 (e / enforce-01
                                    :mod (p / parity))
                              :op6 (p2 / privacy)
                              :op7 (s3 / security)
                              :op8 (s4 / safe-01)
                              :op9 (a2 / accountable-02)
                              :op10 (ii / intelligent-01
                                    :mod (a3 / artificial)
                                    :ARG1-of (m / mean-01
                                          :ARG2 (ii2 / intelligent-01
                                                :mod (g / generative)))))))))

# ::snt The  team   found   that  the  prominence   of  each   theme   depends   on  the  backgr ound   of  the   documen t:   ●  Corpor ations   :  The  top  three  themes   are  humanity ,  collabor ation,   fairness,   transpar ency ,   safety.
# File 126

(m / multi-sentence
      :snt1 (f / find-01
            :ARG0 (t / team)
            :ARG1 (d / depend-01
                  :ARG0 (p / prominence
                        :poss (t2 / theme
                              :mod (e / each)))
                  :ARG1 (b / backgr
                        :poss (d2 / documentumen))))
      :snt2 (t3 / theme
            :quant 3
            :mod (t4 / top)
            :domain (a / and
                  :op1 (h / humanity)
                  :op2 (c / collaborate-01)
                  :op3 (f2 / fairness)
                  :op4 (e2 / equitable)
                  :op5 (t5 / transpar)
                  :op6 (s / safe-01))))

# ::snt The  author s  extracted  ethical  themes   from  these   documen ts  by  manual   coding ,  resulting   in   eigh t  themes:   fairness   and  non-discrimina tion  (appear ed  in  100%   of  documen ts),  privacy  (97%),    accountability   (97%),   transpar ency   and  explainability   (94%),   safety  and  security   (81%),    professional   responsibility   (78%),   human   control  of  technology   (69%),   and  promotion   of  human    values (69%).
# File 126

(e / extract-01
      :ARG0 (p / person
            :ARG0-of (a / author-01))
      :ARG1 (t / theme
            :mod (e2 / ethics))
      :ARG2 (d / documen
            :mod (t2 / this))
      :manner (c / code-01
            :ARG0 p
            :manner (m / manual)
            :ARG2-of (r / result-01
                  :ARG1 (t3 / theme
                        :mod e2
                        :ARG1-of (m2 / mean-01
                              :ARG2 (a2 / and
                                    :op1 (f / fairness)
                                    :op2 (d2 / discriminate-01
                                          :polarity -)
                                    :op3 (c2 / control-01
                                          :ARG0 (h / human)
                                          :ARG1 (t4 / technology)
                                          :mod (p2 / percentage-entity
                                                :value 69))
                                    :op4 (a3 / and
                                          :op1 (p3 / private-02)
                                          :op2 (e3 / explain-01)
                                          :op3 (p4 / percentage-entity
                                                :value 94)
                                          :op4 (a4 / and
                                                :op1 (s / safe-01)
                                                :op2 (s2 / security))
                                          :op5 (p5 / percentage-entity
                                                :value 81)
                                          :op6 (r2 / responsible-03
                                                :ARG0 (p6 / professional)
                                                :mod (p7 / percentage-entity
                                                      :value 78))
                                          :op7 (p8 / promote-02
                                                :ARG1 (v / value
                                                      :mod (h2 / human))
                                                :mod (p9 / percentage-entity
                                                      :value 69)))))))))

# ::snt Hagendorf f  iden tified   eigh t  themes:   privacy  protection   (appear ed  in  82%   of  documen ts),   fairness,   non-discrimina tion,   justice  (82%),   accountability   (77%),   transpar ency/ openness   (73%),    safety,  cyber -security   (73%),   common   good,   sustainability ,  well-being   (73%),   human   oversight,   control, auditing (54%), and solidarity , inclusion, social c ohesion (50%).
# File 126

(d / define-01
      :ARG0 (p / person
            :name (n / name
                  :op1 "Hagendorf"))
      :ARG1 (t / theme
            :example (a / and
                  :op1 (p2 / protect-01
                        :ARG1 (p3 / privacy))
                  :op2 (a2 / appear-02
                        :ARG1 (e / equal-01
                              :ARG2 (p4 / percentage-entity
                                    :value 82)
                              :ARG3 (p5 / percentage-entity
                                    :value 82)))
                  :op3 (a3 / and
                        :op1 (f / fairness)
                        :op2 (d2 / discriminate-02
                              :polarity -)
                        :op3 (j / justice
                              :quant (p6 / percentage-entity
                                    :value 82))
                        :op4 (a4 / accountable-02)
                        :op5 (o / openness
                              :quant (p7 / percentage-entity
                                    :value 73))
                        :op6 (s / safe-01)
                        :op7 (s2 / security
                              :mod (c / cyber))
                        :op8 (s3 / share-01
                              :ARG1 (c2 / common))
                        :op9 (p8 / possible-01
                              :ARG1 (s4 / sustain-01))
                        :op10 (w / well-09)
                        :op11 (o2 / oversight-02
                              :ARG0 (h / human))
                        :op12 (c3 / control-01)
                        :op13 (a5 / audit-01)
                        :op14 (s5 / solidarity)
                        :op15 (o3 / organize-01
                              :ARG1 (s6 / society)
                              :ARG1-of (p9 / percentage-entity
                                    :value 50))))))

# ::snt For  example,   within   predictiv e  policing ,  an   unrepresen tative  data  set  fed  into  the  algorithm   (such   as  featuring   more  criminal   records  of  one   race  over  another)   would   be  more  likely  to  predict   a  dispr oportiona tely  higher   likelihood   to   commit a crime f or some r aces o ver other s.   AI fairness    I  commen ted  on  how  algorithmic   fairness   is  the  principle   that  the  outputs   of  an  AI  system   should   be  uncorrelated  with   certain  char acteristics  such   as  gender ,  race,  or  sexuality .
# File 126

(m / multi-sentence
      :snt1 (e / exemplify-01
            :ARG0 (l / likely-01
                  :ARG1 (p / predict-01
                        :ARG0 (s / set
                              :consist-of (d / data
                                    :ARG0-of (r / represent-01
                                          :polarity -)))
                        :ARG1 (c / crime-02))
                  :ARG2-of (h / have-degree-91
                        :ARG1 p
                        :ARG3 (m2 / more))
                  :ARG2-of (h2 / have-degree-91
                        :ARG1 p
                        :ARG3 (m3 / more)))
            :snt2 (f / fair-01
                  :mod (a / artificial))
            :snt3 (d2 / discuss-01
                  :ARG0 (ii / i)
                  :ARG1 (p2 / principle
                        :domain (r2 / recommend-01
                              :ARG1 (r3 / relate-01
                                    :polarity -
                                    :ARG1 (t / thing
                                          :ARG1-of (o / output-00
                                                :ARG0 (s2 / system
                                                      :mod (ii2 / intelligent-01))))
                                    :ARG2 (c2 / correlate-01
                                          :ARG1 t
                                          :ARG2 t
                                          :example (o2 / or
                                                :op1 (g / gender)
                                                :op2 (r4 / race)
                                                :op3 (s3 / sexuality)))))))))

# ::snt Being    able   to  best  evalua te  an  AI’s  fairness   is  to  know  wher e  and  how  it  went  wrong,  preventing  the   proliferation of “black bo x” alg orithms.
# File 126

(c / capable-01
      :ARG2 (e / evaluate-01
            :ARG1 (f / fair-01
                  :ARG1 (ii / intelligent-01
                        :mod (a / artificial)))
            :ARG1-of (g / good-02
                  :ARG2-of (h / have-degree-91
                        :ARG1 e
                        :ARG3 (m / most))))
      :ARG1-of (m2 / mean-01
            :ARG2 (a2 / and
                  :op1 (k / know-01
                        :ARG1 (a3 / and
                              :op1 (t / thing
                                    :manner-of (w / wrong-02
                                          :ARG1 (ii2 / it)))
                              :op2 (t2 / thing
                                    :manner-of (g2 / go-08
                                          :ARG1 ii2
                                          :ARG2 w)))))
            :op2 (p / prevent-01
                  :ARG1 (p2 / proliferate-01
                        :ARG0 (o / or
                              :op1 (b / bo
                                    :ARG1-of (b2 / black-05))
                              :op2 (t3 / thing
                                    :name (n / name
                                          :op1 "alg")))))))

# ::snt When   it  comes   to  ensuring   a   ‘Good   AI  Socie ty’,  the  documen ts  focus   on  ethical  principles   such   as  privacy,  fairness   and   transpar ency .
# File 126

(f / focus-01
      :ARG0 (g / government-organization
            :name (n / name
                  :op1 "Department"
                  :op2 "of"
                  :op3 "Development"
                  :op4 "Administration"))
      :ARG1 (p / principle
            :mod (e / ethics)
            :example (a / and
                  :op1 (p2 / private-02)
                  :op2 (f2 / fair-01)
                  :op3 (e2 / equitable
                        :mod (t / transpar))))
      :time (c / come-01
            :ARG1 (ii / it)
            :ARG4 (e3 / ensure-01
                  :ARG0 g
                  :ARG1 (g2 / good-02
                        :ARG1 (t2 / technology
                              :name (n2 / name
                                    :op1 "AI"))
                        :ARG2 (s / society)))))

# ::snt To  under stand  some   of  the  recen t   key  decisions   of  the  IBM  AI  Ethics   Boar d,  we  need   to  first  zoom   in  on  the  fact  that  Trust  &   Trustworthiness   are  central  concep ts  to  the  current  IBM  strategy,  and  they  emer ge  out  of  5   “pillar s of trus t”: Explainability , Fairness, R obus tness, T ranspar ency , Priv acy.
# File 126

(n / need-01
      :ARG0 (w / we)
      :ARG1 (z / zoom-01
            :ARG0 w
            :ARG1 (f / fact
                  :topic (a / and
                        :op1 (c / concepute-01
                              :ARG0 (s / strategy
                                    :mod (c2 / company
                                          :name (n2 / name
                                                :op1 "IBM"))
                                    :time (c3 / current))
                              :ARG1 (a2 / and
                                    :op1 (t / trust-02)
                                    :op2 (d / deserve-01
                                          :ARG1 t))
                              :mod (c4 / central))
                        :op2 (ii / include-91
                              :ARG1 (t2 / they)
                              :ARG2 (d2 / decide-01
                                    :ARG1-of (k / key-02)
                                    :ARG1-of ii
                                    :ARG2 (d3 / decide-01
                                          :ARG0 c2
                                          :name (n3 / name
                                                :op1 "Boeing")
                                          :mod (ii2 / intelligent-01
                                                :mod (a3 / artificial)))
                                    :ARG1 (a4 / and
                                          :op1 (e / explain-01
                                                :ARG1-of (p / possible-01))
                                          :op2 (f2 / fairness)
                                          :op3 (r / rob-01
                                                :ARG1-of (r2 / right-06))
                                          :op4 (p2 / person
                                                :name (n4 / name
                                                      :op1 "Tony"
                                                      :op2 "Blair"))
                                          :op5 p2
                                          :name (n5 / name
                                                :op1 "Tony"
                                                :op2 "Ranspar"
                                                :op3 "Ency"))
                                    :op6 p2
                                    :name (n6 / name
                                          :op1 "Tony"
                                          :op2 "Blair"))
                              :op7 p2
                              :name (n7 / name
                                    :op1 "Tony"
                                    :op2 "Blair")))))
      :ord (o / ordinal-entity
            :value 1))

# ::snt  ●  Fairness   :  together   with   the  IBM  Cloud   Pak  for  Data,  the  IBM  AI  Fairness   360  toolkit   for   detecting   biases   in  AI  is  a  tool  that  could   help   avoid  discrimina tion  and  unequal    treatmen t in the design of AI t echnologies.
# File 126

(t / tool
      :ARG0-of (h / help-01
            :ARG1 (a / avoid-01
                  :ARG1 (a2 / and
                        :op1 (d / discriminate-02)
                        :op2 (t2 / treat-01
                              :ARG1-of (e / equal-01
                                    :polarity -))))
            :ARG2 (d2 / design-01
                  :ARG1 (e2 / engineer-01
                        :ARG1 (a3 / artificial))))
      :domain (o / organization
            :name (n / name
                  :op1 "IBM"
                  :op2 "AI"
                  :op3 "Fairness"
                  :op4 360)
            :ARG1-of (m / mean-01
                  :ARG2 (o2 / organization
                        :name (n2 / name
                              :op1 "IBM"
                              :op2 "Cloud"
                              :op3 "Pak")
                        :purpose (d3 / data)))))

# ::snt These   are  by  frequency   of  the  number   of  sour ces  in   which   they  appear ed:  transpar ency ,  justice,   and  fairness,   non-male ficence,    responsibility ,  privacy,  bene ficence,   freedom   and  autonom y,  trust,  dignity ,  sustainability ,   and solidarity .
# File 126

(b / be-temporally-at-91
      :ARG1 (t / this)
      :ARG2 (n / number
            :quant-of (c / coefficient
                  :ARG1-of (s / sour-02)
                  :ARG1-of (a / appear-01
                        :ARG2 (a2 / and
                              :op1 (j / justice)
                              :op2 (f / fairness)
                              :op3 (f2 / fidelity
                                    :mod (m / male
                                          :polarity -))
                              :op4 (r / responsible-03)
                              :op5 (p / privacy)
                              :op6 (f3 / fidelity
                                    :mod (b2 / bene))
                              :op7 (f4 / free-04)
                              :op8 (a3 / autonomy)
                              :op9 (t2 / trust-01)
                              :op10 (d / dignity)
                              :op11 (s2 / sustain-01)
                              :op12 (s3 / solidarity))))))

# ::snt ●  The  resear cher s  found   that  no  single   ethical  principle   was  found   common   to  the  entire   corpus   of  documen t,  however,  an  emer ging   convergence   was  found   around   the   following   principles:   transpar ency ,  justice  and  fairness,   non-male ficence,   responsibility ,   and priv acy.
# File 126

(h / have-concession-91
      :ARG1 (f / find-01
            :ARG0 (r / research-institute
                  :name (n / name
                        :op1 "Research"
                        :op2 "Criminal"
                        :op3 "Sciences"))
            :ARG1 (c / common
                  :polarity -
                  :domain (p / principle
                        :mod (e / ethics)
                        :ARG1-of (s / single-02))
                  :prep-to (c2 / corpus
                        :mod (e2 / entire)
                        :consist-of (d / documen))))
      :ARG2 (f2 / find-01
            :ARG1 (c3 / converge-01
                  :ARG1 (p2 / principle
                        :ARG1-of (f3 / follow-01)
                        :example (a / and
                              :op1 (e3 / entitlement
                                    :mod (t / transpar))
                              :op2 (j / justice)
                              :op3 (f4 / fairness)
                              :op4 f4)
                        :op5 (f5 / fidelity
                              :mod (m / male
                                    :polarity -))
                        :op6 (r2 / responsible-03)
                        :op7 e)
                  :op8 (p3 / private-03))))

# ::snt It  seems   that  MEDC   is  shaping   this  deba te,   which   raises   concerns   about   “neglecting   local  knowledg e,  cultur al  pluralism   and  global    fairness.
# File 126

(s / seem-01
      :ARG1 (s2 / shape-01
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "MEDC"))
            :ARG1 (o2 / organization
                  :name (n2 / name
                        :op1 "Deba"
                        :op2 "Te")
                  :mod (t / this))
            :ARG0-of (r / raise-01
                  :ARG1 (c / concern-01
                        :ARG0 (a / and
                              :op1 (n3 / neglect-01
                                    :ARG0 o
                                    :ARG1 (a2 / and
                                          :op1 (k / knowledge
                                                :ARG1-of (l / local-02))
                                          :op2 (p / pluralism)
                                          :op3 (f / fairness
                                                :mod (g / globe)))))))))

# ::snt AI  systems,   in  particular ,  should   not  be  used   for  social   scoring   or  mass    surveillance purposes;    ●  Safe  and  secur e  AI  systems  shall   be  prioritiz ed  and  any  threat  emana ting  from  such    systems shall be addr essed t o ensur e human and en vironmen tal well-being;    ●  AI  actors  shall   safeguar d  fairness   and  non-discrimina tion  and  also  ensur e  that  the   bene fits of AI t echnologies ar e available t o all;    ●  The  continuous   assessmen t  of  the  human,   social,   cultur al,  economic   and  environmen tal   impact   of  AI  technologies   should   be  carried   out  to  ascert ain  whe ther   they  are  in   conformity   with   the  sustainable   goals,   such   as,  those   currently  iden tified   in  the  Unit ed   Nations Sus tainable De velopmen t Goals (UNSDGs);    ●  Privacy shall be pr otected thr oughout the lif e cycle of the AI s ystems;    T h e  S t a t e  o f  A I  E t h i c s  R e p o r t ,  V o l u m e  6  ( J a nu a r y  2 0 2 2 )   9 3
# File 126

(m / multi-sentence
      :snt1 (r / recommend-01
            :ARG1 (u / use-01
                  :polarity -
                  :ARG1 (s / system
                        :mod (ii / intelligent-01
                              :mod (a / artificial)))
                  :ARG2 (o / or
                        :op1 (s2 / score-01
                              :mod (s3 / social))
                        :op2 (s4 / surveil-01
                              :mod (m2 / mass)))))
      :snt2 (r2 / recommend-01
            :ARG1 (p / protect-01
                  :ARG0 (p2 / privacy)
                  :ARG1 (c / cycle-02
                        :ARG0 (s5 / system
                              :mod (ii2 / intelligent-01
                                    :mod a)))
                  :ARG1 (a2 / and
                        :op1 (s6 / safeguard-01
                              :ARG0 s5
                              :ARG1 (a3 / and
                                    :op1 (f / fairness)
                                    :op2 (d / discriminate-01
                                          :polarity -)))
                        :op2 (a4 / available-02
                              :ARG2 (a5 / and
                                    :op1 (t / threaten-01
                                          :mod (a6 / any))
                                    :op2 (t2 / thing
                                          :ARG0-of (ii3 / indicate-01
                                                :ARG1 (e / emana)))))))))

# ::snt Some   of  the  other   values   emphasiz ed   in  the  documen t  include   impr oving  human   well-being ,  promoting   fairness   and  justice,    protecting priv acy and sa fety, and r aising e thical lit eracy.
# File 126

(ii / include-01
      :ARG1 (v / value
            :quant (s / some)
            :ARG1-of (ii2 / include-91
                  :ARG2 (v2 / value
                        :mod (o / other))))
      :ARG2 (a / and
            :op1 (e / enrich-01
                  :ARG1 (h / human)
                  :ARG2 (w / well-09
                        :ARG1 h))
            :op2 (p / promote-02
                  :ARG1 (a2 / and
                        :op1 (f / fairness)
                        :op2 (j / justice)))
            :op3 (p2 / protect-01
                  :ARG1 (a3 / and
                        :op1 (a4 / accountable-02
                              :ARG0 (p3 / private-03))
                        :op2 (a5 / accountable-02
                              :ARG0 (s2 / social-03))))
            :op4 (a6 / aise-02
                  :ARG1 (a7 / accountable-02
                        :ARG1 (t / thing
                              :ARG1-of (l / light-07)
                              :mod (a8 / any)))))
      :ARG1-of (e2 / emphasize-01
            :location (d / document)))

# ::snt Carr ying  on  with   practic al  appr oaches   to  bias  mitig ation,   the  next  piece   in  this  chap ter  walks   through   co-designed   checklis ts,  a  piece   from  Micr osoft   Resear ch  that  highligh ts  resear ch  work   that  draws  from  an  under standing   of  how  practitioner s  appr oach   fairness   concerns   today,  wha t   are  their   desider ata  for  fairness   checklis ts,  and  how  they  want  them   to  be  implemen ted.
# File 126

(a / and
      :op1 (t / try-01
            :ARG0 (p / person
                  :ARG0-of (p2 / practice-01))
            :ARG1 (b / bias-01
                  :ARG0 p
                  :ARG1 (ii / initiative)))
      :op2 (p3 / piece
            :mod (n / next)
            :location (c / chap
                  :mod (t2 / this))
            :ARG0-of (w / walk-01
                  :ARG2 (t3 / through
                        :op1 (a2 / and
                              :op1 (c2 / checklis
                                    :ARG1-of (d / design-01
                                          :ARG1-of (c3 / collaborate-01)))
                              :op2 (p4 / piece
                                    :source (c4 / company
                                          :name (n2 / name
                                                :op1 "Micr"
                                                :op2 "Osoft"))
                                    :ARG0-of (w2 / work-01)
                                    :ARG0-of (h / highlight-01
                                          :ARG1 (s / stand-11
                                                :ARG1 (p5 / person
                                                      :ARG0-of p2)
                                                :ARG0-of (a3 / approach-02
                                                      :ARG1 (f / fairness)))
                                          :ARG2 (u / under)))))))
      :op3 (c5 / concern-01
            :ARG0 (a4 / amr-unknown)
            :ARG1 p)
      :op4 (w3 / want-01
            :ARG0 p
            :ARG1 (e / equal-01
                  :ARG1 p
                  :ARG2 p5)))

# ::snt This  chap ter  has  some   fascina ting  examples   from  the  work  of  Cynthia  Dwork  on   “fairness   through   awareness”   and  work  that’s  been   done   at  Vimeo   to  uncover  biases   in  sear ch   and  recommenda tion  systems.
# File 126

(h / have-03
      :ARG0 (c / chap
            :mod (t / this))
      :ARG1 (t2 / thing
            :ARG0-of (e / exemplify-01)
            :source (w / work-01
                  :ARG0 (p / person
                        :name (n / name
                              :op1 "Cynthia"
                              :op2 "Dwork"))
                  :ARG1 (a / and
                        :op1 (f / fairness
                              :manner (t3 / through
                                    :op1 (r / realize-01)))
                        :op2 (w2 / work-01
                              :ARG1 (u / uncover-01
                                    :ARG1 (b / bias-01)
                                    :location (a2 / and
                                          :op1 (s / system
                                                :mod (s2 / sear-01))
                                          :op2 (s3 / system
                                                :mod (r2 / recommend-01)))))
                        :location (p2 / publication
                              :name (n2 / name
                                    :op1 "Vimeo"))))
            :quant (s4 / some)
            :mod (f2 / fascinate-01)))

# ::snt Co-Designing   Checklis ts  to  Under stand  Organizational   Challeng es  and   Opportunities ar ound F airness in AI    [  Original   paper   by  Michael   A.  Madaio ,  Jennif er  Wortman   Vaughan,   Luke  Stark  and  Hanna    Wallach]    [Resear ch Summar y by Anne Boily]    Overview  :  Among   the  burgeoning   literature  on  AI  ethics   and  the  values   that  would   be   import ant  to  respect   in  the  developmen t  and  use  of  artificial   intelligence   systems  (AIS),   fairness    comes   up  a  few  times,   perhap s  as  an  echo   of  the  very  current  notion   of  social   justice.
# File 126

(m / multi-sentence
      :snt1 (a / and
            :op1 (d / design-01
                  :ARG1 (t / thing
                        :name (n / name
                              :op1 "Checklis"))
                  :ARG4 (s / stand
                        :mod (u / under)
                        :mod (o / organize-01)))
            :op2 (a2 / and
                  :op1 (c / challenge-01)
                  :op2 (o2 / opportunity)
                  :topic (ii / intelligent-01
                        :mod (a3 / artificial))))
      :snt2 (b / be-located-at-91
            :ARG1 (a4 / and
                  :op1 (e / ethics
                        :mod (a5 / artificial))
                  :op2 (v / value
                        :ARG1-of (ii2 / important-01))
                  :topic (a6 / and
                        :op1 (d2 / develop-02
                              :ARG1 (s2 / system
                                    :mod (ii3 / intelligent-01
                                          :mod (a7 / artificial))))
                        :op2 (u2 / use-01
                              :ARG1 s2)))
            :ARG2 (a8 / among
                  :op1 (l / literature
                        :ARG1-of (b2 / burgeon-01))))
      :snt3 (p / paraphrase-01
            :ARG1 (p2 / publication-91
                  :ARG0 (p3 / person
                        :name (n2 / name
                              :op1 "Anne"
                              :op2 "Boily"))
                  :ARG1 (p4 / publication
                        :name (n3 / name
                              :op1 "Research"
                              :op2 "Ch"
                              :op3 "Summary")))))

# ::snt Author s   Madaio ,  Vaughan,   Stark  and  Wallach   (Micr osoft   Resear ch)  have  co-de veloped   a  checklis t  that   seek s  to  ensur e  fairness,   while   recognizing   that  a  procedur e  alone   cannot   overcome   the  value    tensions and inc ompa tibilities in e thical pr actice.
# File 126

(d / develop-02
      :ARG0 (a / and
            :op1 (p / person
                  :name (n / name
                        :op1 "Madaio"))
            :op2 (p2 / person
                  :name (n2 / name
                        :op1 "Vaughan"))
            :op3 (p3 / person
                  :name (n3 / name
                        :op1 "Stark"))
            :op4 (p4 / person
                  :name (n4 / name
                        :op1 "Wallach"))
            :ARG0-of (a2 / author-01)
            :ARG0-of (h / have-org-role-91
                  :ARG1 (c / company
                        :name (n5 / name
                              :op1 "Micr"
                              :op2 "Osoft"
                              :op3 "Resear"
                              :op4 "Ch"))))
      :ARG1 (c2 / checklis
            :ARG0-of (s / seek-01
                  :ARG1 (e / ensur-01
                        :ARG0 c2
                        :ARG1 (f / fairness))
                  :time (r / recognize-02
                        :ARG0 a
                        :ARG1 (p5 / possible-01
                              :polarity -
                              :ARG1 (o / overcome-01
                                    :ARG0 (p6 / proceed-01
                                          :mod (a3 / alone))
                                    :ARG1 (a4 / and
                                          :op1 (v / value)
                                          :op2 (t / tension)
                                          :op3 (t2 / thing
                                                :ARG1-of (o2 / opine-01
                                                      :ARG0 (p7 / person)))))))))
      :manner (t3 / together))

# ::snt RQ3:  How  do  practitioners   envision   AI  fairness   checklis ts  migh t  be  implemen ted  within   their    organiz ations?
# File 126

(e / envision-01
      :ARG0 (p / person
            :ARG0-of (p2 / practice-01))
      :ARG1 (f / fairness
            :mod (a / artificial))
      :manner (a2 / amr-unknown)
      :manner (p3 / possible-01
            :ARG1 (e2 / enforce-01
                  :ARG0 (p4 / person
                        :name (n / name
                              :op1 "Checklis"))
                  :ARG1 f)
            :location (w / within
                  :op1 (o / organization
                        :poss p4)))
      :ARG1-of (q / quote-01
            :ARG2 (p5 / person
                  :name (n2 / name
                        :op1 "RQ3"))))

# ::snt explicitly   ackno wledg e  that  the  very  concep t  of  equity   can  be  under stood   differently  in  different  contexts:  “Fairness   is  a  comple x  concep t  and  deeply   contextual  [and]   [ …]   Ther e  is  no  single   definition   of  fairness   that  will  apply   equally   well  to  different  applic ations   of   AI” (p.15).
# File 126

(m / multi-sentence
      :snt1 (p / possible-01
            :ARG1 (s / stand-11
                  :ARG1 (e / equity)
                  :ARG2 (u / under)
                  :ARG1-of (d / differ-02)
                  :location (c / context
                        :ARG1-of (d2 / differ-02)))
            :ARG1-of (e2 / explicit-03))
      :snt2 (d3 / define-01
            :polarity -
            :ARG1 (f / fairness)
            :ARG2 (a / and
                  :op1 (c2 / context
                        :ARG1-of (c3 / complete-02))
                  :op2 (c4 / context
                        :ARG1-of (d4 / deep-02))
                  :op3 (e3 / et-cetera))
            :ARG1-of (m2 / mean-01
                  :ARG2 (q / quote-01
                        :ARG2 (p2 / publication
                              :ARG1-of (c5 / cite-01
                                    :ARG2 15))))))

# ::snt explicitly   ackno wledg e  that  the  very  concep t  of  equity   can  be  under stood   differently  in  different  contexts:  “Fairness   is  a  comple x  concep t  and  deeply   contextual  [and]   [ …]   Ther e  is  no  single   definition   of  fairness   that  will  apply   equally   well  to  different  applic ations   of   AI” (p.15).
# File 126

(m / multi-sentence
      :snt1 (p / possible-01
            :ARG1 (s / stand-11
                  :ARG1 (e / equity)
                  :ARG2 (u / under)
                  :ARG1-of (d / differ-02)
                  :location (c / context
                        :ARG1-of (d2 / differ-02)))
            :ARG1-of (e2 / explicit-03))
      :snt2 (d3 / define-01
            :polarity -
            :ARG1 (f / fairness)
            :ARG2 (a / and
                  :op1 (c2 / context
                        :ARG1-of (c3 / complete-02))
                  :op2 (c4 / context
                        :ARG1-of (d4 / deep-02))
                  :op3 (e3 / et-cetera))
            :ARG1-of (m2 / mean-01
                  :ARG2 (q / quote-01
                        :ARG2 (p2 / publication
                              :ARG1-of (c5 / cite-01
                                    :ARG2 15))))))

# ::snt “E volve”   At  all  stages  of  the  checklis t,  it  is  necessar y  to  ensur e  that  the  criterion   of  fairness   can  be   respect ed  or,  if  compr omises   are  necessar y,  to  documen t  them   and  to  consider   dropping   the   project   if  this  would   be  preferable   (pp.16-20).
# File 126

(n / necessitate-01
      :ARG1 (o / or
            :op1 (e / enforce-01
                  :ARG1 (c / criterion
                        :topic (f / fairness)))
            :op2 (p / possible-01
                  :ARG1 (r / respect-01
                        :ARG1 c))
            :condition (n2 / necessitate-01
                  :ARG1 (a / and
                        :op1 (d / document-01
                              :ARG1 (t / they))
                        :op2 (c2 / consider-02
                              :ARG1 (d2 / drop-05
                                    :ARG1 (p2 / project))))))
      :time (s / stage
            :mod (a2 / all)
            :subevent-of (c3 / checklis))
      :ARG1-of (d3 / describe-01
            :ARG0 (p3 / publication-91
                  :ARG7 (v / value-interval
                        :op1 16
                        :op2 20))))

# ::snt The  dang er  is  there  and,   basic ally,  it  is  difficult   to  reduce   the  richness   of  a  concep t  such   as   equity   to  a  definition   and  a  procedur e.  The  author s  hear d  these   concerns   and  adap ted  their    model   accordingly:   “[ … ]  our  checklis t  items  are  intended   to  promp t  critic al  conversations,   using    words  like  ‘scrutiniz e’  and  asking   teams   to  ‘define  fairness   criteria’   rather   than   including   specific    fairness crit eria or thr esholds t o mee t” (p.8).
# File 126

(m / multi-sentence
      :snt1 (a / and
            :op1 (b / be-located-at-91
                  :ARG1 (d / dang)
                  :ARG2 (t / there))
            :op2 (d2 / difficult
                  :domain (r / reduce-01
                        :ARG1 (r2 / richness
                              :poss (c / conceive-01
                                    :example (e / equity)))
                        :manner (a2 / and
                              :op1 (u / use-01
                                    :ARG1 (w / word
                                          :example (s / string-entity
                                                :value "scrutiniz e")))
                              :op2 (a3 / ask-02
                                    :ARG1 (d3 / define-01
                                          :ARG1 (c2 / criteria
                                                :mod (f / fairness)))
                                    :ARG2 (t2 / team)
                                    :ARG1-of (ii / instead-of-91
                                          :ARG2 (ii2 / include-01
                                                :ARG1 (o / or
                                                      :op1 c2
                                                      :ARG1-of (s2 / specific-02)
                                                      :mod (f2 / fairness))
                                                :op2 (t3 / thing
                                                      :ARG1-of (h / hold-01
                                                            :ARG0 (t4 / thr))))
                                          :ARG2 (c3 / converse-01
                                                :ARG0 (w2 / we))))))))
      :snt2 (a4 / and
            :op1 (h2 / hear-01
                  :ARG0 (p / person
                        :ARG0-of (a5 / author-01))
                  :ARG1 (c4 / concern-01
                        :mod (t5 / this)))
            :op2 (a6 / adjust-01
                  :ARG0 p
                  :ARG1 (m2 / model-01
                        :ARG0 p
                        :ARG1 (t6 / they))))
      :ARG1-of (d4 / describe-01
            :ARG0 (p2 / publication
                  :ARG1-of (c5 / cite-01
                        :ARG2 8))))

# ::snt On  the  contrary,  this  checklis t  would    rather   refer  to  “[ … ]  a  way  to  spur   ‘good  tension, ’  promp ting  critic al  conversations   and  prying   open   discussion   about   AI  fairness   [ …]”  (p.10).
# File 126

(c / contrast-01
      :ARG2 (r / refer-01
            :ARG0 (c2 / checklis
                  :mod (t / this))
            :ARG1 (w / way
                  :manner-of (s / spur-01
                        :ARG1 (a / and
                              :op1 (t2 / tension
                                    :ARG1-of (g / good-02))
                              :op2 (d / dialogue-01
                                    :ARG0 (p / person
                                          :ARG0-of (c3 / criticize-01))
                                    :mod (a2 / all)
                                    :ARG1-of (p2 / public-02))
                              :op3 (p3 / pry-02
                                    :ARG1 (d2 / discuss-01
                                          :ARG1 (f / fair-01
                                                :mod (a3 / artificial))
                                          :ARG1-of (o / open-04))))))
            :ARG1-of (ii / instead-of-91))
      :ARG1-of (d3 / describe-01
            :ARG0 (p4 / publication
                  :ARG1-of (c4 / cite-01
                        :ARG2 10))))

# ::snt Tackling   fairness   in  AI-in fused   systems,   Dwork  talks  about   her  work  titled   “Fairness   through    Awareness”   which   takes  into  account  both   individual   and  group  fairness   and  how  to  achie ve   both.
# File 126

(t / talk-01
      :ARG0 (p / person
            :name (n / name
                  :op1 "Dwork"))
      :ARG1 (w / work-01
            :ARG0 p
            :ARG1-of (t2 / title-01
                  :ARG2 (p2 / publication
                        :name (n2 / name
                              :op1 "Fairness"
                              :op2 "through"
                              :op3 "awareness")
                        :ARG0-of (t3 / take-into-account-04
                              :ARG1 (a / and
                                    :op1 (f / fairness
                                          :mod (ii / individual))
                                    :op2 (f2 / fairness
                                          :mod (g / group)))
                              :op2 (t4 / thing
                                    :manner-of (a2 / achieve-01
                                          :ARG1 (a3 / and
                                                :op1 f
                                                :op2 f2)))))))
      :topic (t5 / tackle-01
            :ARG0 p
            :ARG1 (f3 / fairness)
            :location (s / system
                  :ARG1-of (f4 / fuse-01)
                  :mod (a4 / artificial))))

# ::snt Tackling   fairness   in  AI-in fused   systems,   Dwork  talks  about   her  work  titled   “Fairness   through    Awareness”   which   takes  into  account  both   individual   and  group  fairness   and  how  to  achie ve   both.
# File 126

(t / talk-01
      :ARG0 (p / person
            :name (n / name
                  :op1 "Dwork"))
      :ARG1 (w / work-01
            :ARG0 p
            :ARG1-of (t2 / title-01
                  :ARG2 (p2 / publication
                        :name (n2 / name
                              :op1 "Fairness"
                              :op2 "through"
                              :op3 "awareness")
                        :ARG0-of (t3 / take-into-account-04
                              :ARG1 (a / and
                                    :op1 (f / fairness
                                          :mod (ii / individual))
                                    :op2 (f2 / fairness
                                          :mod (g / group)))
                              :op2 (t4 / thing
                                    :manner-of (a2 / achieve-01
                                          :ARG1 (a3 / and
                                                :op1 f
                                                :op2 f2)))))))
      :topic (t5 / tackle-01
            :ARG0 p
            :ARG1 (f3 / fairness)
            :location (s / system
                  :ARG1-of (f4 / fuse-01)
                  :mod (a4 / artificial))))

# ::snt The   article   also  has  several  great  examples   of  how  applying   individual   fairness   isn’t   enough   and  how   her  experience   with   piano   practice   reinforced  the  import ance   of  consider ations   for  fair   affirma tive action t o achie ve group f airness.
# File 126

(h / have-03
      :ARG0 (a / article)
      :ARG1 (a2 / and
            :op1 (e / example
                  :quant (s / several)
                  :mod (g / great)
                  :topic (a3 / apply-02
                        :ARG1 (f / fairness
                              :mod (ii / individual))
                        :ARG1-of (h2 / have-quant-91
                              :polarity -
                              :ARG3 (e2 / enough))))
            :op2 (r / reinforce-01
                  :ARG0 (e3 / experience-01
                        :ARG0 (s2 / she)
                        :ARG1 (p / piano
                              :ARG1-of (p2 / practice-01
                                    :ARG0 s2)))
                  :ARG1 (ii2 / important-01
                        :ARG1 (c / consider-02
                              :ARG1 (f2 / fairness)
                              :ARG2 (a4 / affirmative-action
                                    :ARG0-of (e4 / enable-01
                                          :ARG1 (a5 / achieve-01
                                                :ARG0 (g2 / group)
                                                :ARG1 (f3 / fairness))))))))
      :mod (a6 / also))

# ::snt Why  it  matters  :  The  field   of  AI  ethics   is  inunda ted  with   work  on  how  to  best  achie ve  fairness   in   machine   learning.
# File 126

(m / multi-sentence
      :snt1 (m2 / matter-01
            :ARG1 (ii / it)
            :ARG1-of (c / cause-01
                  :ARG0 (a / amr-unknown)))
      :snt2 (ii2 / inundate-01
            :ARG1 (f / field
                  :topic (e / ethics
                        :mod (ii3 / intelligent-01
                              :mod (a2 / artificial))))
            :ARG2 (w / work-01
                  :ARG1 (t / thing
                        :manner-of (a3 / achieve-01
                              :ARG1 (f2 / fairness)
                              :manner (g / good-02
                                    :ARG2-of (h / have-degree-91
                                          :ARG1 a3
                                          :ARG3 (m3 / most)))
                              :manner (l / learn-01
                                    :mod (m4 / machine)))))))

# ::snt Yet,  a  lot  of  it  struggles  to  articula te  how  to  account  for  tradeof fs  that  are   bound   to  occur   when   offering   preferential  treatmen t  to  some   over  other s  in  the  interest  of   achie ving  fairness.
# File 126

(h / have-concession-91
      :ARG2 (s / struggle-02
            :ARG0 (ii / it
                  :quant (l / lot))
            :ARG1 (e / explain-01
                  :ARG0 ii
                  :ARG1 (t / thing
                        :manner-of (a / account-01
                              :ARG0 ii
                              :ARG1 (t2 / trade-01
                                    :ARG1 (r / resource
                                          :name (n / name
                                                :op1 "Fish"
                                                :op2 "and"
                                                :op3 "Fish"))
                                    :ARG1-of (b / bind-02
                                          :ARG2 (b2 / be-temporally-at-91
                                                :ARG1 t2
                                                :ARG2 (o / offer-01
                                                      :ARG1 (t3 / treatman
                                                            :ARG1-of (p / prefer-01
                                                                  :ARG2 (p2 / person
                                                                        :mod (s2 / some))))
                                                      :ARG3 (p3 / person
                                                            :mod (o2 / other))
                                                      :purpose (ii2 / interest-01
                                                            :ARG2 (f / fairness)))))))))))

# ::snt  Between  the  lines   :  Bias  and  fairness   are  extremely   challenging   concep ts  when   it  comes   to   machine   learning   because   they  don’t   have  clear   metrics   as  is  the  case  with   privacy  wher e  we   are  fairly   certain  of  wha t  the  outcomes   need   to  be.
# File 126

(a / and
      :op1 (b / between
            :op1 (l / line))
      :op2 (c / challenge-01
            :ARG0 (a2 / and
                  :op1 (b2 / bias-01)
                  :op2 (f / fairness))
            :degree (e / extreme)
            :time (c2 / come-12
                  :ARG1 (l2 / learn-01
                        :ARG0 (m / machine)))
            :ARG1-of (c3 / cause-01
                  :ARG0 (h / have-03
                        :polarity -
                        :ARG0 (t / they)
                        :ARG1 (m2 / metric
                              :ARG1-of (c4 / clear-06))
                        :ARG1-of (r / resemble-01
                              :ARG2 (c5 / case-04
                                    :topic (p / privacy)))))
            :ARG1-of (f2 / fair-01)
            :topic (c6 / certain
                  :domain (o / outcome
                        :ARG1-of (n / need-01)))))

# ::snt Between the lines    In  my  view,  ethical  AI  practice   is  both   necessar y  and  sufficien t  to  oper ationalise   principles   like   transpar ency ,  fairness   and  equality .
# File 126

(v / view-02
      :ARG0 (ii / i)
      :ARG1 (h / have-purpose-91
            :ARG1 (p / practice-01
                  :ARG1 (ii2 / intelligent-01
                        :mod (a / artificial))
                  :mod (e / ethics))
            :ARG2 (a2 / and
                  :op1 (n / necessitate-01
                        :ARG1 p)
                  :op2 (s / suffice-01
                        :ARG0 p
                        :ARG1 p))
            :purpose (o / operate-01
                  :ARG1 (p2 / principle
                        :example (a3 / and
                              :op1 (l / law
                                    :name (n2 / name
                                          :op1 "Transpar"
                                          :op2 "Ency"))
                              :op2 (f / fairness)
                              :op3 (e2 / equal-01)))))
      :location (b / between
            :op1 (l2 / line)))

# ::snt In   particular ,  they  look   at  AI4SG   (AI  for  social   good)   principles,   which   are  actionable   guidelines,    inspir ed  by  the  more  high   level  values   of  “respect   for  human   autonom y,  prevention  of  harm,    fairness, and e xplic ability ”.
# File 126

(l / look-01
      :ARG0 (t / they)
      :ARG1 (p / principle
            :mod (ii / intelligent-01
                  :mod (a / artificial)
                  :ARG1-of (m / mean-01
                        :ARG2 (ii2 / intelligent-01
                              :mod (s / social)
                              :ARG1-of (g / good-04))))
            :mod (g2 / guideline
                  :ARG1-of (a2 / act-02
                        :ARG1-of (p2 / possible-01)))
            :ARG1-of (ii3 / inspire-01
                  :ARG0 (v / value
                        :mod (l2 / level
                              :ARG1-of (h / have-degree-91
                                    :ARG2 (h2 / high-02)
                                    :ARG3 (m2 / more)))
                        :example (a3 / and
                              :op1 (r / respect-01
                                    :ARG1 (a4 / autonomy
                                          :poss (h3 / human)))
                              :op2 (p3 / prevent-01
                                    :ARG1 (h4 / harm-01))
                              :op3 (f / fair-01)
                              :op4 (a5 / ability
                                    :ARG1-of (e / extend-01
                                          :ARG1-of p2))))))
      :mod (p4 / particular))

# ::snt These ar e the principles:    “(i)  falsifiability   and  incremen tal  deplo ymen t;  (ii)  safeguar ds  against  the  manipula tion  of   predict ors;  (iii)  receiv er-contextualiz ed  intervention;   (iv)  receiv er-contextualiz ed  explana tion  and   transpar ent  purposes;   (v)  privacy  protection   and  data  subject   consen t;  (vi)  situa tional   fairness;    and (vii) human- friendly seman ticization.
# File 126

(p / principle
      :domain (t / this)
      :ARG1-of (m / mean-01
            :ARG2 (a / and
                  :op1 (p2 / possible-01
                        :polarity -
                        :li "i"
                        :ARG1 (f / falsify-01))
                  :op2 (ii / increase-01
                        :li "3"
                        :ARG1 p2
                        :ARG1 (d / deplo-ymen)))
            :op3 (s / safeguard-01
                  :li "ii"
                  :ARG1 s
                  :ARG1 s
                  :ARG1 (r / resist-01
                        :ARG1 (m2 / manipulate-02
                              :ARG1 (p3 / predict-01)))))
      :op4 (ii2 / intervene-01
            :li "iii"
            :ARG1-of (r2 / receive-01
                  :ARG1 (c / contextualize-00)))
      :op5 (a2 / and
            :li "iv"
            :op1 (e / explana-)
            :op2 (p4 / purpose
                  :mod (t2 / transpar-ent)))
      :op6 (a3 / and
            :li "v"
            :op1 (p5 / private-02)
            :op2 (p6 / protect-01
                  :ARG1 (d2 / data))
            :op3 (s2 / subject
                  :mod (c2 / consen-t))
            :op4 (s3 / situa-tional)
            :op5 (f2 / fairness)
            :op6 (e2 / et-cetera)
            :op7 e2)
      :op8 e2
      :op9 e2
      :op10 e2
      :op11 e2
      :op12 (t3 / treat-04
            :li "vi"
            :ARG1 (h / human)
            :ARG2 (f3 / friendly-01
                  :ARG1 h)))

# ::snt fairness,   respect   for  user s’  privacy).
# File 126

(a / and
      :op1 (f / fairness)
      :op2 (r / respect-01
            :ARG1 (p / private-02
                  :ARG1 (p2 / person
                        :ARG0-of (u / use-01)))))

# ::snt The  paper   also  highligh ts  eigh t  policy   recommenda tions   for  policymak ers  and  regula tors  to   follow:   ●  Help   provide   working   definitions   for  ADMS   –  regula tors  shall   define  for  organizations   the   material   scope  for  EBA  by  providing   working   definitions   or  risk  classific ations   of  ADMS    that enable pr oportiona te and pr ogressiv e governance;    ●  Provide   guidance   on  how  to  resolv e  tensions   –  when   designing   and  oper ating  ADMS,    conflicts   may  arise   between  different  ethical  principles   such   as  fairness,   privacy  etc.,  for   which   there  are  no  fixed  solutions.
# File 126

(m / multi-sentence
      :snt2 (p / possible-01
            :ARG1 (a / arise-02
                  :ARG1 (c / conflict-01
                        :ARG0 (p2 / principle
                              :mod (e / ethics)
                              :ARG1-of (d / differ-02)
                              :example (a2 / and
                                    :op1 (f / fairness)
                                    :op2 (p3 / privacy)
                                    :op3 (e2 / et-cetera)))))
            :time (a3 / and
                  :op1 (d2 / design-01
                        :ARG1 (l / law
                              :name (n / name
                                    :op1 "ADMS")))
                  :op2 (o / operate-01
                        :ARG1 l)))
      :snt3 (a4 / and
            :op1 (h / help-01)
            :op2 (p4 / provide-01
                  :ARG1 (d3 / define-01
                        :ARG1 (l2 / law
                              :name (n2 / name
                                    :op1 "ADMS"))))
            :op3 (r / recommend-01
                  :ARG1 (a5 / and
                        :op1 (p5 / person
                              :ARG0-of (m2 / make-01
                                    :ARG1 (p6 / policy-01)))
                        :op2 (r2 / regulate-01
                              :ARG1 r2)))
            :purpose (f2 / follow-02))
      :snt4 (s / solution
            :polarity -
            :ARG1-of (f3 / fix-03)))

# ::snt Optimizing P eople Y ou Ma y Know (P YMK) f or equity in ne twork cr eation   [Original article b y  LinkedIn Engineering   ]   Wha t  happened   :  LinkedIn   has  applied   two  fairness   measur es  of  equality   of  opportunity   and   equaliz ed  odds   to  mak e  the  recommenda tions   for  potential  connections   more  equit able   across   the  user s  of  the  platform,   especially   for  those   who   don’t   have  as  “influen tial”  profiles   as  some    of  the  more  frequen t  member s  (FM)   of  the  platform.
# File 126

(a / apply-02
      :ARG0 (c / company
            :name (n / name
                  :op1 "LinkedIn"))
      :ARG1 (a2 / and
            :op1 (f / fairness
                  :quant 2)
            :op2 (e / equalize-01)
            :op3 (e2 / equalize-01))
      :purpose (m / make-01
            :ARG0 c
            :ARG1 (t / thing
                  :ARG1-of (r / recommend-01
                        :ARG3 (c2 / connect-01
                              :mod (p / potential)))
                  :ARG1-of (h / have-quant-91
                        :ARG3 (m2 / more)))
            :location (a3 / across
                  :op1 (p2 / person
                        :ARG0-of (u / use-01
                              :ARG1 (p3 / platform)))))
      :ARG1-of (m3 / mean-01
            :ARG2 (p4 / person
                  :mod (t2 / that)
                  :ARG0-of (h2 / have-03
                        :polarity -
                        :ARG1 (p5 / profile
                              :ARG0-of (ii / influence-01)))
                  :quant (s / some)
                  :ARG1-of (ii2 / include-91
                        :ARG2 (p6 / person
                              :ARG0-of (h3 / have-org-role-91
                                    :ARG1 p3
                                    :ARG2 (m4 / member))
                              :ARG1-of (h4 / have-degree-91
                                    :ARG2 (f2 / frequent-02
                                          :ARG1 m4)
                                    :ARG3 (m5 / more)))))))

# ::snt In  applying   these   fairness   measur es  on  top   of  their   ranking   algorithms,   they’ve  found   that  engagemen t  on  the  platform  didn”t   go  down,   showing tha t fairness objectiv es don’t necessarily ha ve to stand ag ainst the business objectiv es.
# File 126

(f / find-01
      :ARG0 (t / they)
      :ARG1 (g / go-01
            :polarity -
            :ARG1 (p / person
                  :mod (p2 / political-party
                        :name (n / name
                              :op1 "Republican"))
                  :location (p3 / platform))
            :ARG4 (d / down-03
                  :ARG1 p)
            :ARG0-of (s / show-01
                  :ARG1 (o / obligate-01
                        :polarity -
                        :ARG1 (o2 / objective
                              :mod (f2 / fairness))
                        :ARG2 (s2 / stand-11
                              :ARG0 o2
                              :ARG1 (o3 / objective
                                    :mod (b / business)
                                    :mod (f3 / fairness))))))
      :manner (a / apply-02
            :ARG0 t
            :ARG1 (f4 / fairness
                  :mod (t2 / this)
                  :ARG1-of (m / mean-01
                        :ARG2 (b2 / be-located-at-91
                              :ARG1 f4
                              :ARG2 (t3 / top
                                    :part-of (a2 / algorithm
                                          :ARG2-of (r / rank-01)
                                          :poss t)))))))

# ::snt Problem   : the in fluence ma y only be minut e.   Appeals   to  human   intervention  :  involving   humans   in  the  process   to  better  ensur e  fairness   and   establish some f orm of r esponsibility .
# File 126

(m / multi-sentence
      :snt1 (p / problem
            :domain (m2 / minutia
                  :mod (o / only)))
      :snt2 (a / appeal-02
            :ARG2 (ii / intervene-01
                  :ARG0 (h / human))
            :ARG1-of (m3 / mean-01
                  :ARG2 (ii2 / involve-01
                        :ARG1 (h2 / human)
                        :ARG2 (p2 / process-02)
                        :purpose (a2 / and
                              :op1 (b / better-01
                                    :ARG0 h2
                                    :ARG1 (f / fairness))
                              :op2 (e / establish-01
                                    :ARG0 h2
                                    :ARG1 (a3 / accountable-02
                                          :ARG0 h2
                                          :mod (s / some))))))))

# ::snt Problem   :  assumes   that  having  a  human   in  the  process   does   help   to  ensur e  fairness   and  doesn’t    ackno wledg e ho w alg orithmic da ta can in fluence human decision making.
# File 126

(p / problem
      :mod (a / assume-02
            :ARG1 (a2 / and
                  :op1 (h / help-01
                        :ARG0 (h2 / have-03
                              :ARG1 (h3 / human)
                              :prep-in (p2 / process-02))
                        :ARG1 (e / ensur-01
                              :ARG1 (f / fairness)))
                  :op2 (g / get-01
                        :polarity -
                        :ARG0 h2
                        :ARG1 (w / wledge-01
                              :ARG0 h3
                              :ARG1 (p3 / possible-01
                                    :ARG1 (m / make-01
                                          :ARG0 (h4 / human)
                                          :ARG1 (d / decide-01
                                                :ARG0 h4))))))))

# ::snt High-le vel overview   Belo w is a high-le vel overview of the Code:    Chap ter One (“ One” as giv en in the Code) (Gener al Pr ovisions) (Articles 1- 4)    This  chap ter  talks  about   integrating  ethics   and  morals  into  the  full  life  cycle  of  AI,  promoting    fairness   and  avoiding   problems   such   as  discrimina tion,   privacy  etc.
# File 126

(m / multi-sentence
      :snt1 (o / overview
            :mod (v / vel
                  :ARG1-of (h / high-02))
            :topic (c / code))
      :snt2 (o2 / overview
            :mod v
            :ARG1-of (h2 / high-02))
      :topic (a / and
            :op1 (l / law
                  :name (n / name
                        :op1 "Chap"
                        :op2 "ter"
                        :op3 "one")
                  :ARG1-of (m2 / mean-01
                        :ARG2 (l2 / law
                              :name (n2 / name
                                    :op1 "General"
                                    :op2 "Prisions"))))
            :op2 (l3 / law
                  :name (n3 / name
                        :op1 "Article"
                        :op2 "1-of ( include-91 :ARG2 ( law_3 :name ( name_3 :op1 "))))

# ::snt ●  Promot e  fairness   and  justice  –  It  talks  about   adher ence   to  inclusiv eness   and   inclusiv eness,   which   again  does   not  convey  any  meaning ,  wha tsoe ver.
# File 126

(a / and
      :op1 (p / promote-02
            :ARG1 (a2 / and
                  :op1 (f / fairness)
                  :op2 (j / justice)))
      :op2 (t / talk-01
            :ARG0 p
            :ARG1 (a3 / and
                  :op1 (e / enforce-01
                        :ARG1 (a4 / affirmative-action))
                  :op2 (e2 / enforce-01
                        :ARG1 a4)
                  :ARG0-of (c / convey-01
                        :polarity -
                        :ARG1 (m / mean-01
                              :mod (a5 / any))
                        :mod (a6 / again)))))

# ::snt The  other   ethical   norms   clubbed   under   this  broad  heading   effectiv ely  protect  the  legitima te  rights  and   interests  of  all  relevant  subjects,   promot e  social   fairness   and  justice  and  equal    opportunities.
# File 126

(c / club-01
      :ARG1 (n / norm
            :mod (e / ethics)
            :mod (o / other))
      :ARG2 (u / under
            :op1 (h / heading
                  :ARG1-of (b / broad-02)
                  :mod (t / this)
                  :ARG0-of (p / protect-01
                        :ARG1 (a / and
                              :op1 (r / right-05
                                    :ARG1 (s / subject
                                          :ARG1-of (r2 / relevant-01)
                                          :mod (a2 / all)))
                              :op2 (ii / interest-01
                                    :ARG1 s)
                              :op3 (o2 / opportunity
                                    :ARG1-of (e2 / equal-01)))
                        :mod (e3 / effective-04))))
      :ARG0-of (p2 / promote-02
            :ARG1 (a3 / and
                  :op1 (f / fairness
                        :mod (s2 / society))
                  :op2 (j / justice)
                  :op3 o2)))

# ::snt In  the  current   ecosystem  of  AI  ethics   resear ch,  these   are  severely  under -discussed   aspects,   with   mos t  of  the   focus on issues lik e fairness and priv acy.
# File 126

(a / aspect
      :domain (t / this)
      :ARG1-of (d / discuss-01
            :ARG1-of (u / under-03
                  :degree (s / severe)))
      :ARG1-of (c / cause-01
            :ARG0 (f / focus-01
                  :ARG2 (ii / issue-02
                        :example (a2 / and
                              :op1 (f2 / fairness)
                              :op2 (a3 / accountable-02
                                    :ARG1 (p / private-03))))))
      :location (e / ecosystem
            :time (c2 / current)
            :mod (e2 / ethics
                  :mod (a4 / artificial))
            :mod (r / research-01)))

# ::snt Why  it  matters  :  Our  penchan t  for  larger  AI  systems  has  man y  impacts   that  exacerba te  the   problems   in  the  domain   of  Responsible   AI  including   bias  and  fairness,   privacy,  inclusion,    accountability ,  and  increasingly   an  environmen tal  impact   as  well.
# File 126

(m / multi-sentence
      :snt1 (m2 / matter-01
            :ARG1 (ii / it)
            :ARG1-of (c / cause-01
                  :ARG0 (a / amr-unknown)))
      :snt2 (ii2 / impact-01
            :ARG0 (p / penchan-00
                  :ARG0 (w / we)
                  :purpose (s / system
                        :mod (ii3 / intelligent-01
                              :mod (a2 / artificial))
                        :ARG1-of (h / have-degree-91
                              :ARG2 (l / large)
                              :ARG3 (m3 / more))))
            :ARG1 (p2 / problem
                  :topic (ii4 / intelligent-01
                        :ARG1-of (r / responsible-01))
                  :ARG2-of (ii5 / include-01
                        :ARG1 (a3 / and
                              :op1 (b / bias-01)
                              :op2 (f / fairness)
                              :op3 (p3 / privacy)
                              :op4 ii5
                              :ARG1 (a4 / accountable-02))
                        :op5 (ii6 / increase-01
                              :ARG1 (ii7 / impact-01
                                    :ARG0 (e / environment))))))
      :mod (a5 / as-well))

# ::snt balancing   different  measur es  of  fairness   ),  the  downsides   for  each,   realis tic   thresholds   for  bias  (e.g.
# File 126

(a / and
      :op1 (b / balance-01
            :ARG1 (m / measur-e
                  :ARG1-of (d / differ-02)
                  :topic (f / fairness)))
      :op2 (d2 / drawback
            :beneficiary (e / each))
      :op3 (t / threshold
            :ARG1-of (r / real-04)
            :topic (b2 / bias-01))
      :example (t2 / thing
            :name (n / name
                  :op1 "Keynes")))

# ::snt Although   AI  governance   tooling   is  one  necessar y  componen t  for  creating  and  implemen ting  AI   responsibly ,  it  is  not  sufficien t.  You  can’t  know  if  your  datasets  or  models   are  biased   for  or   against  some   groups  if  you  are  unable   to  analy ze  measur es  like  dispar ate  impact   or  individual    versus  group  fairness.
# File 126

(m / multi-sentence
      :snt2 (s / suffice-01
            :polarity -
            :ARG0 (ii / it))
      :snt3 (p / possible-01
            :polarity -
            :ARG1 (k / know-01
                  :ARG0 (y / you)
                  :ARG1 (t / truth-value
                        :polarity-of (b / bias-01
                              :ARG1 (o / or
                                    :op1 (d / dataset
                                          :poss y)
                                    :op2 (m2 / model
                                          :poss y))
                              :ARG2 (o2 / or
                                    :op1 (b2 / benefit-01
                                          :ARG1 (g / group
                                                :mod (s2 / some)))
                                    :op2 (b3 / benefit-01
                                          :polarity -
                                          :ARG1 g)))))
            :condition (p2 / possible-01
                  :polarity -
                  :ARG1 (a / analyze-01
                        :ARG0 y
                        :ARG1 (m3 / measur
                              :example (o3 / or
                                    :op1 (ii2 / impact-01
                                          :ARG0 (d2 / disparage-01))
                                    :op2 (f / fairness
                                          :mod (ii3 / individual)
                                          :ARG1-of (c / compare-01
                                                :ARG2 (g2 / group))))))))
      :snt1 (h / have-concession-91
            :ARG1 (n / need-01
                  :ARG0 (g3 / govern-01
                        :manner (ii4 / intelligent-01
                              :mod (a2 / artificial)))
                  :ARG1 (o4 / one))
            :ARG2 (c2 / create-01
                  :ARG1 g3
                  :ARG1-of (r / responsible-02))))

# ::snt However,  iden tifying  bias,   analy zing  by  different  definitions   of  fairness,    T h e  S t a t e  o f  A I  E t h i c s  R e p o r t ,  V o l u m e  6  ( J a nu a r y  2 0 2 2 )   2 5 3
# File 126

(c / contrast-01
      :ARG2 (a / and
            :op1 (n / notify-01
                  :ARG1 (b / bias-01))
            :op2 (z / zing-01
                  :ARG0 (d / define-01
                        :ARG1 (f / fairness)
                        :ARG1-of (d2 / differ-02)))
            :op3 (s / string-entity
                  :value "T h e")
            :op4 (s2 / string-entity
                  :value "S t a t e")
            :op5 (s3 / string-entity
                  :value "A")
            :op6 (s4 / string-entity
                  :value "R e p o r t")
            :op7 (s5 / string-entity
                  :value "V o l u m e")
            :op8 (s6 / string-entity
                  :value "J a nu a r y")
            :op9 (s7 / string-entity
                  :value "2 0 2 2")
            :op10 (s8 / string-entity
                  :value "5 3 5 3")))

# ::snt Different  aspects   of  fairness   and  founda tional   assump tions   about   those   that   will  be  impact ed  are  often  left  out  of  debiasing ,  providing   creators  the  ability   to  game   an  audit    and appear t o comply with r egula tions when the y do not.
# File 126

(a / and
      :op1 (l / leave-out-03
            :ARG1 (a2 / aspect
                  :ARG1-of (d / differ-02)
                  :topic (a3 / and
                        :op1 (f / fairness)
                        :op2 (a4 / authority
                              :mod (c / collective))))
            :ARG2 (d2 / debilitate-01)
            :frequency (o / often))
      :op2 (p / provide-01
            :ARG0 a2
            :ARG1 (c2 / capable-01
                  :ARG1 (p2 / person
                        :ARG0-of (c3 / create-01))
                  :ARG2 (a5 / and
                        :op1 (g / game-01
                              :ARG0 p2)
                        :op2 (a6 / audit-01
                              :ARG1 p2)
                        :op3 (a7 / appear-02
                              :ARG1 (c4 / comply-01
                                    :ARG0 p2
                                    :ARG1 (r / rule-01
                                          :ARG3 (e / emotion)))
                              :time (c5 / comply-01
                                    :polarity -
                                    :ARG0 p2
                                    :ARG1 r))))
            :ARG2 p2))

# ::snt For  example,   through    gener ative  artw orks  it  may  be  possible   to  highligh t  different  viewpoin ts  regarding   fairness   based    on  the  local  context  such   as  social   practices,   religious   belie fs,  economic   status,  etc.
# File 126

(e / exemplify-01
      :ARG0 (p / possible-01
            :ARG1 (h / have-manner-91
                  :ARG1 (h2 / highlight-02
                        :ARG1 (v / view-02
                              :ARG1-of (d / differ-02)
                              :ARG0-of (r / regard-01
                                    :ARG1 (f / fairness))
                              :ARG1-of (b / base-02
                                    :ARG2 (c / context
                                          :ARG1-of (l / local-02)
                                          :example (a / and
                                                :op1 (p2 / practice-01
                                                      :ARG1 (s / social-03))
                                                :op2 (b2 / belie-01
                                                      :ARG1 (r2 / religion))
                                                :op3 (s2 / status
                                                      :mod (e2 / economy))
                                                :op4 (e3 / et-cetera)))))))
            :ARG1-of h
            :ARG2 (p3 / person
                  :name (n / name
                        :op1 "Artwin"
                        :op2 "Orks")
                  :mod (g / generative))))

# ::snt  with   the  issues   relating  to  fairness,   bias  and  governance   ques tions   pertaining   to  transpar ency ,   and  regula tory  frame works.
# File 126

(c / concern-02
      :ARG1 (a / and
            :op1 (ii / issue-02
                  :ARG1-of (r / relate-01
                        :ARG2 (a2 / and
                              :op1 (f / fairness)
                              :op2 (b / bias-01)
                              :op3 (g / govern-01))))
            :op2 (q / ques
                  :ARG0-of (r2 / relate-01
                        :ARG2 (a3 / and
                              :op1 (e / equitable
                                    :mod (t / transpar))
                              :op2 (w / work-09
                                    :ARG1 (f2 / frame))
                              :op3 (r3 / regulate-01
                                    :ARG1 (p / political-party
                                          :name (n / name
                                                :op1 "Tory"))
                                    :ARG1-of (r4 / regular-03)))))))

# ::snt Between  the  lines   :  The  area  of  machine   learning   security   today  is  highly   under -explor ed  with    mos t  of  the  focus   on  issues   like  fairness   and  privacy,  which   while   import ant  don’t   cover  the  full   gamut   of  ethical  issues   with   AI  systems.
# File 126

(a / and
      :op1 (b / between
            :op1 (l / line))
      :op2 (e / exploit-01
            :ARG1 (a2 / area
                  :topic (a3 / and
                        :op1 (m / machine)
                        :op2 (l2 / learn-01
                              :ARG1 (s / security))
                        :op3 (ii / intelligent-01
                              :mod (a4 / artificial))))
            :degree (h / high-02)
            :degree (u / under)
            :time (t / today)
            :ARG1-of (c / cause-01
                  :ARG0 (f / focus-01
                        :ARG2 (ii2 / issue-02
                              :example (a5 / and
                                    :op1 (f2 / fairness)
                                    :op2 (p / privacy)))
                        :ARG0-of (c2 / cover-01
                              :polarity -
                              :ARG1 (g / gamut
                                    :mod (f3 / full)
                                    :topic (ii3 / issue-02
                                          :mod (e2 / ethics)))
                              :ARG2 (s2 / system
                                    :mod ii)
                              :concession (ii4 / import-01
                                    :polarity -))))))

# ::snt The General Data Protection Regulation   The GDPR contains seven core principles for the collection and processing of personal data:   ➔ Lawfulness, fairness and transparency   ➔ Purpose limitation   ➔ Data minimisation   ➔ Accuracy   ➔ Storage limitation   ➔ Integrity and confidentiality (security)   14 ➔ Accountability   15 There is a broad European consensus by experts interviewed for this report that the GDPR ​   ​ ​ will be   relevant to AI development—but precisely how and to what extent is contested.
# File 32

(m / multi-sentence
      :snt1 (c / contain-01
            :ARG0 (l / law
                  :name (n / name
                        :op1 "General"
                        :op2 "Data"
                        :op3 "Protection"
                        :op4 "Regulation"))
            :ARG1 (p / principle
                  :quant 7
                  :mod (c2 / core)
                  :purpose (a / and
                        :op1 (c3 / collect-01
                              :ARG1 (d / data
                                    :ARG1-of (p2 / personal-02)))
                        :op2 (p3 / process-01
                              :ARG1 d))
                  :example (a2 / and
                        :op1 (l2 / law
                              :polarity -)
                        :op2 (f / fairness)
                        :op3 (t / transparency)
                        :op4 (l3 / limit-01
                              :ARG1 (p4 / purpose))
                        :op5 (m2 / minimize-01
                              :ARG1 (d2 / data))
                        :op6 (a3 / accurate)
                        :op7 (l4 / limit-01
                              :ARG1 (s / storage))
                        :op8 (a4 / and
                              :op1 (ii / integrity)
                              :op2 (c4 / confidentiality)
                              :op9 (s2 / security))
                        :op10 (a5 / accountable-02))))
      :snt2 (c5 / contrast-01
            :ARG1 (c6 / consensus
                  :ARG1-of (b / broad-02)
                  :mod (c7 / continent
                        :name (n2 / name
                              :op1 "Europe"))
                  :poss (p5 / person
                        :ARG1-of (ii2 / interview-01
                              :ARG2 (r / report
                                    :mod (t2 / this)))
                        :ARG0-of (h / have-org-role-91
                              :ARG1-of (e / expert-01))
                        :ARG2-of h))
            :topic (r2 / relevant-01
                  :ARG1 l
                  :ARG2 (d3 / develop-02
                        :ARG1 (ii3 / intelligent-01
                              :mod (a6 / artificial)))))
      :ARG2 (c8 / contest-01
            :ARG1 (a7 / and
                  :op1 (t3 / thing
                        :manner-of (a8 / amr-unknown))
                  :op2 (t4 / thing
                        :manner-of (a9 / amr-unknown)))))

# ::snt ​ ​  These will address multiple rights   issues and AI: “the future of work, fairness, safety, security, social inclusion and algorithmic   transparency,” as well as AI’s impact on human rights such as “privacy, dignity, consumer   protection and non-discrimination.” The Commission will act on the ethical advice of a “high-level   group on artificial intelligence” of 52 experts.
# File 32

(m / multi-sentence
      :snt1 (a / address-01
            :ARG0 (t / this)
            :ARG1 (a2 / and
                  :op1 (ii / issue-02
                        :ARG0 (r / right-05)
                        :quant (m2 / multiple))
                  :op2 (ii2 / intelligent-01
                        :mod (a3 / artificial))
                  :example (a4 / and
                        :op1 (f / future
                              :poss (w / work-01))
                        :op2 (f2 / fairness)
                        :op3 (s / safe-01)
                        :op4 (s2 / security)
                        :op5 (ii3 / include-01
                              :ARG2 (s3 / society))
                        :op6 (t2 / transparency
                              :mod (a5 / algorithm)))
                  :op7 (ii4 / impact-01
                        :ARG0 ii2
                        :ARG1 (r2 / right-05
                              :ARG1 (h / human)
                              :example (a6 / and
                                    :op1 (p / privacy)
                                    :op2 (d / dignity)
                                    :op3 (p2 / protect-01
                                          :ARG1 (p3 / person
                                                :ARG0-of (c / consume-01)))
                                    :op4 (d2 / discriminate-02
                                          :polarity -))))))
      :snt2 (a7 / act-02
            :ARG0 (g / government-organization
                  :name (n / name
                        :op1 "Commission"))
            :ARG1 (a8 / advise-01
                  :ARG0 (g2 / group
                        :consist-of (p4 / person
                              :quant 52
                              :ARG1-of (e / expert-01))
                        :mod (l / level
                              :ARG1-of (h2 / high-02)))
                  :ARG1 g
                  :topic ii2)
            :mod (e2 / ethics)))

# ::snt The chapter be gins by presenting the general principles that law enforcement should endeavour to adhere to, namely  the respect for human rights, democracy, justice and rule of law, as well as the related requirements  of fairness, accountability, transparency and explainability that should be adopted in order for law en forcement to meet these principles.
# File 173

(g / gins-00
      :ARG0 (c / chapter)
      :manner (p / present-01
            :ARG0 c
            :ARG1 (p2 / principle
                  :ARG1-of (g2 / general-02)
                  :ARG1-of (a / adhere-02
                        :ARG0 (e / enforce-01
                              :ARG1 (l / law))
                        :ARG1-of (r / recommend-01))
                  :ARG1-of (m / mean-01
                        :ARG2 (a2 / and
                              :op1 (r2 / respect-01
                                    :ARG1 (r3 / right-05
                                          :ARG1 (h / human)))
                              :op2 (d / democracy)
                              :op3 (j / justice)
                              :op4 (r4 / rule-03
                                    :ARG1 l)
                              :op5 (r5 / require-01
                                    :ARG1 (a3 / and
                                          :op1 (f / fairness)
                                          :op2 (a4 / accountable-02)
                                          :op3 (t / transparency)
                                          :op4 (e2 / explain-01))
                                    :ARG1-of (r6 / relate-01)
                                    :ARG1-of (a5 / adopt-01
                                          :ARG1-of (r7 / recommend-01)
                                          :purpose (m2 / meet-01
                                                :ARG0 e
                                                :ARG1 p2))))))))

# ::snt To achieve these principles, law enforcement agencies must work to guarantee that the design and use  of AI complies with the requirements of fairness, accountability, transparency and explainability (FATE).
# File 173

(o / obligate-01
      :ARG1 (a / agency
            :ARG0-of (e / enforce-01
                  :ARG1 (l / law)))
      :ARG2 (w / work-01
            :ARG0 a
            :ARG1 (g / guarantee-01
                  :ARG0 a
                  :ARG1 (c / comply-01
                        :ARG0 (a2 / and
                              :op1 (d / design-01
                                    :ARG1 (ii / intelligent-01
                                          :mod (a3 / artificial)))
                              :op2 (u / use-01
                                    :ARG1 ii))
                        :ARG1 (r / require-01
                              :ARG1 (a4 / and
                                    :op1 (f / fairness)
                                    :op2 (a5 / accountable-02)
                                    :op3 (t / transparency)
                                    :op4 (e2 / explain-01
                                          :ARG1-of (p / possible-01)))))))
      :purpose (a6 / achieve-01
            :ARG0 a
            :ARG1 (p2 / principle
                  :mod (t2 / this))))

# ::snt Fairness  implies that algorithmic decisions do not create a discriminatory or unjust  impact on the end users.
# File 173

(ii / imply-01
      :ARG0 (f / fairness)
      :ARG1 (c / create-01
            :polarity -
            :ARG0 (t / thing
                  :ARG1-of (d / decide-01)
                  :mod (a / algorithm))
            :ARG1 (ii2 / impact-01
                  :ARG0 t
                  :ARG1 (p / person
                        :ARG0-of (u / use-01
                              :mod (e / end)))
                  :ARG1-of (d2 / discriminate-02)
                  :ARG1-of (j / just-02
                        :polarity -))))

# ::snt Fairness  requires that all AI systems are rigorously audited to show compliance with the right  to non-discrimination and, in the event discrimination arises, measures to deliver the  right to effective remedy must be put in place.
# File 173

(r / require-01
      :ARG0 (f / fairness)
      :ARG1 (a / and
            :op1 (a2 / audit-01
                  :ARG1 (s / system
                        :mod (ii / intelligent-01
                              :mod (a3 / artificial))
                        :mod (a4 / all))
                  :manner (r2 / rigorous)
                  :purpose (s2 / show-01
                        :ARG0 s
                        :ARG1 (c / comply-01
                              :ARG0 s
                              :ARG1 (r3 / right-05
                                    :ARG2 (d / discriminate-02
                                          :polarity -)))))
            :op2 (o / obligate-01
                  :ARG2 (p / put-03
                        :ARG1 (ii2 / in-place
                              :domain (m / measure-02
                                    :ARG1 (d2 / deliver-01
                                          :ARG1 (r4 / right-05
                                                :ARG2 (r5 / remedy-01
                                                      :ARG0-of (e / effective-04)))))))
                  :condition (a5 / arise-02
                        :ARG1 (d3 / discriminate-02)))))

# ::snt Unlike the other requirements of fairness, accountability and  transparency, explainability is very much a technical challenge for developers and  manufacturers.
# File 173

(c / challenge-01
      :ARG1 (a / and
            :op1 (p / person
                  :ARG0-of (d / develop-02))
            :op2 (p2 / person
                  :ARG0-of (m / manufacture-01)))
      :ARG2 (e / explain-01)
      :mod (t / technical)
      :mod (m2 / much
            :degree (v / very))
      :ARG1-of (r / resemble-01
            :polarity -
            :ARG2 (r2 / require-01
                  :ARG1 (a2 / and
                        :op1 (f / fairness)
                        :op2 (a3 / accountable-02)
                        :op3 (t2 / transparency))
                  :mod (o / other))))

# ::snt It contains six  core principles for the collection and processing of personal data: 1) Lawfulness, fairness and transpar ency; 2) Purpose limitation; 3) Data minimization; 4) Accuracy; 5) Storage limitation and 6) Integrity and  confidentiality (security).22  The LED, also known as Police Directive, entered into force in May 2016 and aims to apply the rules  governing personal data in GDPR to the activities of law enforcement.
# File 173

(m / multi-sentence
      :li 22
      :snt1 (c / contain-01
            :ARG0 (ii / it)
            :ARG1 (p / principle
                  :quant 6
                  :mod (c2 / core)
                  :purpose (a / and
                        :op1 (c3 / collect-01
                              :ARG1 (d / data
                                    :ARG1-of (p2 / personal-02)))
                        :op2 (p3 / process-01
                              :ARG1 d))
                  :domain (a2 / and
                        :op1 (l / law
                              :name (n / name
                                    :op1 "Laws"))
                        :op2 (f / fairness)
                        :op3 (l2 / law
                              :name (n2 / name
                                    :op1 "Transpar"
                                    :op2 "Ency"))
                        :op4 (l3 / limit-01
                              :li 2
                              :ARG1 (p4 / purpose))
                        :op5 (m2 / minimize-01
                              :li 3
                              :ARG1 (d2 / data))
                        :op6 (a3 / accurate
                              :li 4)
                        :op7 (l4 / limit-01
                              :li 5
                              :ARG1 (s / store-01))
                        :op8 (a4 / and
                              :op1 (ii2 / integrity)
                              :op2 (c4 / confidentiality)
                              :op3 (s2 / security)
                              :domain (l5 / law
                                    :name (n3 / name
                                          :op1 "Police"
                                          :op2 "Directive"))))))
      :snt2 (a5 / and
            :op1 (e / enter-01
                  :ARG0 (l6 / law
                        :name (n4 / name
                              :op1 "LED")
                        :ARG1-of (k / know-02
                              :ARG2 l5
                              :mod (a6 / also)))
                  :ARG1 (f2 / force)
                  :time (d3 / date-entity
                        :month 5
                        :year 2016))
            :op2 (a7 / aim-01
                  :ARG0 l6
                  :ARG1 (a8 / apply-02
                        :ARG0 l6
                        :ARG1 (r / rule
                              :ARG0-of (g / govern-01
                                    :ARG1 (d4 / data
                                          :ARG1-of (p5 / personal-02))
                                    :medium (l7 / law
                                          :name (n5 / name
                                                :op1 "GDPR"))))
                        :ARG2 (a9 / activity-06
                              :ARG0 (e2 / enforce-01
                                    :ARG1 (l8 / law)))))))

# ::snt On this basis, the Ethics Guidelines present four overarching ethical principles underlying  the development, deployment and use of AI systems: respect for human autonomy; prevention of harm;  and fairness and explicability.
# File 173

(p / present-01
      :ARG0 (o / organization
            :name (n / name
                  :op1 "Ethics"
                  :op2 "Guidelines"))
      :ARG1 (p2 / principle
            :quant 4
            :mod (e / ethics)
            :ARG0-of (u / underlie-01
                  :ARG1 (a / and
                        :op1 (d / develop-02
                              :ARG1 (s / system
                                    :mod (ii / intelligent-01
                                          :mod (a2 / artificial))))
                        :op2 (d2 / deploy-01
                              :ARG1 s)
                        :op3 (u2 / use-01
                              :ARG1 s)))
            :ARG1-of (m / mean-01
                  :ARG2 (a3 / and
                        :op1 (r / respect-01
                              :ARG1 (a4 / autonomy
                                    :mod (h / human)))
                        :op2 (p3 / prevent-01
                              :ARG1 (h2 / harm-01))
                        :op3 (a5 / and
                              :op1 (f / fair-01)
                              :op2 (e2 / explain-01)))))
      :ARG1-of (b / base-02
            :ARG2 (t / this)))

# ::snt A series of seven requirements for the development, deployment and use of AI systems in a trustworthy  manner are further identified, namely: human agency and oversight; technical robustness and safety;  privacy and data governance; transparency; diversity; non-discrimination and fairness; societal and en vironmental well-being; and accountability.
# File 173

(ii / identify-01
      :ARG1 (t / thing
            :quant 7
            :ARG1-of (r / require-01
                  :ARG0 (a / and
                        :op1 (d / develop-02
                              :ARG1 (s / system
                                    :mod (ii2 / intelligent-01
                                          :mod (a2 / artificial))))
                        :op2 (d2 / deploy-01
                              :ARG1 s)
                        :op3 (u / use-01
                              :ARG1 s)
                        :manner (t2 / trustworthy)))
            :ARG1-of (m / mean-01
                  :ARG2 (a3 / and
                        :op1 (a4 / agency
                              :mod (h / human))
                        :op2 (o / oversee-01
                              :ARG0 h)
                        :op3 (a5 / and
                              :op1 (r2 / robustness
                                    :mod (t3 / technical))
                              :op2 (s2 / safe-01))
                        :op4 (a6 / and
                              :op1 (p / privacy)
                              :op2 (g / govern-01
                                    :ARG1 (d3 / data)))
                        :op5 (t4 / transparency)
                        :op6 (d4 / diversity)
                        :op7 (d5 / discriminate-02
                              :polarity -)
                        :op8 (f / fair-01)
                        :op9 (w / well-09
                              :mod (s3 / society)
                              :mod (v / vironmental))
                        :op10 (a7 / accountable-02)))
            :quant (s4 / series))
      :mod (f2 / further))

# ::snt By way of example, in the financial sector, the Monetary Authority of Singapore (MAS) published  its Principles to Promote Fairness, Ethics, Accountability and Transparency in the Use of AI and Data Ana lytics in Singapore’s Financial Sector  in November 2018 to provide guidance to firms offering financial  products and services on the responsible use of AI and data analytics in order to strengthen internal gov ernance around data management and use and, ultimately, to foster greater confidence and trust in the  use of AI in this sector.33 The Netherlands Central Bank (De Nederlandsche Bank) similarly released its  own guidance document in July 2019, containing principles for the responsible use of AI in the financial  sector to prevent any harmful effects for banks, their clients, or the credibility or reputation of the finan cial sector as a whole.34 In the healthcare sector, there has also been movement in terms of responsible  AI.
# File 173

(m / multi-sentence
      :snt1 (e / exemplify-01
            :ARG0 (p / publish-01
                  :ARG0 (g / government-organization
                        :name (n / name
                              :op1 "Monetary"
                              :op2 "Authority"
                              :op3 "of"
                              :op4 "Singapore"))
                  :ARG1 (p2 / principle
                        :topic (p3 / promote-02
                              :ARG0 g
                              :ARG1 (a / and
                                    :op1 (f / fairness)
                                    :op2 (e2 / ethics)
                                    :op3 (a2 / accountable-02)
                                    :op4 (t / transparency))
                              :topic (u / use-01
                                    :ARG1 (a3 / and
                                          :op1 (ii / intelligent-01
                                                :mod (a4 / artificial))
                                          :op2 (m2 / machine
                                                :name (n2 / name
                                                      :op1 "ARG0-of ( analyze-01 :ARG1 ( data_0 ) ) ) ) :location ( sector_0 :mod ( finance_0 ) :location ( country :name ( name_2 :op1 ")))))))))

# ::snt RECOMMENDED ACTIONS Define a statement of principles on the use of AI in law enforcement that will guide law  enforcement to ensure respect for human rights, democracy, justice and the rule of law  and support it to prioritize the key requirements of fairness, accountability, transparen cy and explainability, as well as safety and robustness;  ›Develop guidance for law enforcement on the implementation of new technology to  support and encourage law enforcement agencies to explore and invest in new AI  opportunities and to develop training in new AI applications and disseminate best  practices;  ›Create a knowledge-base with the law enforcement community on the requiremen ts for the adoption of AI, such as what kinds of problems AI is capable of tackling,  the current or inherent limitations and the resources (tools, data, expertise, com puting power) required to implement AI solutions;   ›Develop guidance for law enforcement on the admissibility of AI in court that as sesses the impact and results of the specific use of AI in courts, while ensuring the  respect for human rights and rule of law;  ›Create an expert advisory committee that can provide guidance to law enforcement  in terms of legislation and serve as a forum for discussing appropriate legislative  models with legal experts and other key stakeholders;  ›Identify an external global body to provide advisory support to law enforcement  on ethical issues and to provide support in carrying out audits to check whether a  system is responsible and complies with legal requirements;  ›Foster a community and organize training courses and workshops to attract and  connect different stakeholders from law enforcement, industry, academia, civil  society and international bodies with the diverse backgrounds and essential per spectives to gather and synthesize views from cross-sections of society, in order to  provide a balanced and facts-based picture of the opportunities and challenges of  the use of AI and to highlight the application of AI to law enforcement and provide  hands-on support.
# File 173

(m / multi-sentence
      :snt1 (r / recommend-01
            :ARG1 (a / and
                  :op1 (d / define-01
                        :ARG1 (s / state-01
                              :ARG1 (p / principle
                                    :topic (u / use-01
                                          :ARG1 (ii / intelligent-01
                                                :mod (a2 / artificial))
                                          :ARG2 (e / enforce-01)))
                              :ARG0-of (g / guide-01
                                    :ARG1 (e2 / enforce-01
                                          :mod (l / law))
                                    :purpose (e3 / ensure-01
                                          :ARG0 e2
                                          :ARG1 (a3 / and
                                                :op1 (r2 / respect-01
                                                      :ARG1 (a4 / and
                                                            :op1 (r3 / right-05
                                                                  :ARG1 (h / human))
                                                            :op2 (d2 / democracy)
                                                            :op3 (j / justice)
                                                            :op4 (r4 / rule-03
                                                                  :ARG1 (l2 / law)))))))))
                  :op2 (a5 / and
                        :op1 (o / organize-01
                              :ARG1 (a6 / and
                                    :op1 (c / course
                                          :mod (t / train-01))
                                    :op2 (w / workshop))
                              :purpose (a7 / and
                                    :op1 (a8 / and
                                          :op1 (a9 / attract-01
                                                :ARG1 (s2 / stake
                                                      :ARG1-of (d3 / differ-02)
                                                      :source (a10 / and
                                                            :op1 e2
                                                            :op2 (ii2 / industry)
                                                            :op3 (a11 / academia)
                                                            :op4 (s3 / society
                                                                  :mod (c2 / civil))
                                                            :op5 (b / body
                                                                  :mod (ii3 / international))
                                                            :ARG0-of (h2 / have-03
                                                                  :ARG1 (a12 / and
                                                                        :op1 (b2 / background
                                                                              :mod (d4 / diverse))
                                                                        :op2 (t2 / transparency)
                                                                        :op3 (r5 / robustness))
                                                                  :mod (e4 / essential)))))
                                          :op2 (s4 / synthesize-01
                                                :ARG1 (v / view-02
                                                      :ARG0 (a13 / and
                                                            :op1 (t3 / tool)
                                                            :op2 (d5 / data)
                                                            :op3 (e5 / expertise)
                                                            :op4 (p2 / power
                                                                  :mod (c3 / circuit
                                                                        :ARG1-of (c4 / close-01)))))))))
                        :op2 (a14 / and
                              :op1 (s5 / support-01
                                    :ARG1 (ii4 / implement-01
                                          :ARG1 (s6 / solution
                                                :mod ii)))
                              :op2 (e6 / encourage-01
                                    :ARG1 (a15 / agency
                                          :ARG0-of (e7 / enforce-01))
                                    :ARG2 (a16 / and
                                          :op1 (a17 / and
                                                :op1 (e8 / explore-01
                                                      :ARG0 a15
                                                      :ARG1 (o2 / opportunity
                                                            :ARG1-of (n / new-01
                                                                  :ARG1 (a18 / apply-02
                                                                        :ARG1 ii))))
                                                :op2 (ii5 / invest-01
                                                      :ARG0 a15
                                                      :ARG2 o2))
                                          :op2 (a19 / and
                                                :op1 t
                                                :ARG1 a18)
                                          :op2 (d6 / disseminate-01
                                                :ARG0 a15
                                                :ARG1 (p3 / practice-01
                                                      :ARG1-of (h3 / have-degree-91
                                                            :ARG2 (g2 / good-02
                                                                  :ARG1 p3)
                                                            :ARG3 (m2 / most))))))))))
      :op2 (s7 / support-01
            :ARG1 (a20 / audit-01
                  :ARG1 (c5 / check-01
                        :ARG1 (t4 / truth-value
                              :polarity-of (a21 / and
                                    :op1 (r6 / responsible-02
                                          :ARG0 (s8 / system))
                                    :op2 (c6 / comply-01
                                          :ARG0 s8
                                          :ARG1 (t5 / thing
                                                :ARG1-of (r7 / require-01
                                                      :ARG0 (l3 / law)))))))))
      :snt2 (c7 / create-01
            :ARG1 (c8 / committee
                  :ARG1-of (e9 / expert-01)
                  :ARG0-of (a22 / advise-01)
                  :ARG0-of (a23 / advise-01)
                  :ARG1-of (p4 / possible-01))))

# ::snt The focus of the toolkit could include:  ›A general explanation of AI, including a relevant working definition for law enforcement;   ›Guidance on the use of AI for law enforcement, including the identification and compilation of major  technology domains and possible use-cases;   ›Considerations of examples or best practices of trustworthy, lawful and responsible use of AI in  law enforcement – synthesis of important requirements, such as fairness, accountability, transpa rency and explainability, for consideration when a law enforcement agency intends to develop an  AI-enabled project (in-house) or procure an AI-tool/system (external solutions) – and a series of  recommended good practices that reflect the general principles and seek to build trust and social  acceptance; 47
# File 173

(m / multi-sentence
      :snt1 (p / possible-01
            :ARG1 (ii / include-01
                  :ARG1 (a / and
                        :op1 (e / explain-01
                              :ARG1 (ii2 / intelligent-01
                                    :mod (a2 / artificial))
                              :ARG1-of (g / general-02)
                              :ARG2-of (ii3 / include-01
                                    :ARG1 (d / define-01
                                          :ARG1 (e2 / enforce-01
                                                :ARG1 (l / law))
                                          :ARG1-of (r / relevant-01)
                                          :ARG1-of (w / work-01))))
                        :op2 (a3 / advise-01
                              :ARG2 (u / use-01
                                    :ARG1 ii2
                                    :ARG2 (e3 / enforce-01
                                          :ARG1 (l2 / law)))
                              :ARG2-of (ii4 / include-01
                                    :ARG1 (a4 / and
                                          :op1 (ii5 / identify-01
                                                :ARG1 (d2 / domain
                                                      :mod (t / technology)
                                                      :ARG1-of (m2 / major-02)))
                                          :op2 (c / compile-01
                                                :ARG1 (c2 / case-04
                                                      :ARG1 (u2 / use-01
                                                            :ARG1 ii2)
                                                      :ARG1-of (p2 / possible-01)))))))
                  :op3 (c3 / consider-02
                        :ARG1 (o / or
                              :op1 (e4 / example)
                              :op2 (p3 / practice-01
                                    :ARG1 (u3 / use-01
                                          :ARG1 ii2
                                          :ARG2 e3
                                          :mod (l3 / lawful)
                                          :ARG1-of (r2 / responsible-02)
                                          :mod (t2 / trustworthy))
                                    :ARG1-of (r3 / recommend-01)))
                        :ARG2 (s / synthesize-01
                              :ARG1 (t3 / thing
                                    :ARG1-of (r4 / require-01)
                                    :ARG1-of (ii6 / important-01)
                                    :example-of (a5 / and
                                          :op1 (f / fairness)
                                          :op2 (a6 / accountable-02)
                                          :op3 (r5 / rency
                                                :mod (t4 / transpa))
                                          :op4 (e5 / explain-01))))
                        :time (ii7 / intend-01
                              :ARG0 (a7 / agency
                                    :ARG0-of (e6 / enforce-01
                                          :ARG1 (l4 / law))
                                    :ARG1 (o2 / or
                                          :op1 (d3 / develop-02
                                                :ARG0 a7
                                                :ARG1 (p4 / project
                                                      :ARG1-of (e7 / enable-01
                                                            :ARG0 ii2))
                                                :mod (ii8 / in-house))
                                          :op2 (p5 / procure-01
                                                :ARG0 a7
                                                :ARG1 (s2 / slash
                                                      :op1 (t5 / tool)
                                                      :op2 (s3 / system)
                                                      :mod (s4 / solution
                                                            :mod (e8 / external)))))))))))

# ::snt ANNEX II   LIST OF   ABBREVIATIONS  ADM    Automated Decision-Making AFP   Australian Federal Police AI  Artificial intelligence  AI-HLEG  High-Level Expert Group on AI AiLECS  Artificial Intelligence for Law Enforcement of Community Safety CCTV   Closed-Circuit Television  EU   European Union  FATE   Fairness, Accountability, Transparency and Explainability GDPR  General Data Protection Regulation GPS  Global Positioning Services IC   INTERPOL’s Innovation Centre IEDs   Improvised Explosive Devices IGCI   INTERPOL’s Global Complex for Innovation  INTERPOL  International Criminal Police Organization LED   Law Enforcement Directive 2016/680 MAS   Monetary Authority of Singapore NLP   Natural Language Processing non-POI  non-Person of Interest  NPA   Japan National Police Agency OECD   Organisation for Economic Co-operation and Development  R&D   Research and Development  UAV   Unmanned Aerial Vehicles UNICRI   United Nations Interregional Crime and Justice Research Institute ZITiS   Central Office for Information Technology in the Security Sector 53
# File 173

(a / and
      :op1 (e / event
            :name (n / name
                  :op1 "ANNEX"
                  :op2 "II"))
      :op2 (l / list-01
            :ARG2 (t / thing
                  :ARG1-of (b / break-01)))
      :op3 (p / publication
            :name (n2 / name
                  :op1 "ADM"))
      :op4 (p2 / publication
            :name (n3 / name
                  :op1 "Automated"
                  :op2 "Decision"
                  :op3 "Making"
                  :op4 "AFP"))
      :op5 (p3 / publication
            :name (n4 / name
                  :op1 "Australian"
                  :op2 "Federal"
                  :op3 "Police")
            :mod (a2 / artificial))
      :op6 (p4 / publication
            :name (n5 / name
                  :op1 "Artificial"
                  :op2 "Intelligence"
                  :op3 "For"
                  :op4 "Law"
                  :op5 "Enforcement"
                  :op6 "of"
                  :op7 "Community"
                  :op8 "Safety"))
      :op7 (p5 / publication
            :name (n6 / name
                  :op1 "Closed-Circuit"
                  :op2 "Television"))
      :op8 (p6 / publication
            :name (n7 / name
                  :op1 "European"
                  :op2 "Union"
                  :op3 "FATE"))
      :op9 (p7 / publication
            :name (n8 / name
                  :op1 "General"
                  :op2 "Data"
                  :op3 "Protection"
                  :op4 "Regulation"))
      :op10 (p8 / publication
            :name (n9 / name
                  :op1 "Global"
                  :op2 "Positioning"
                  :op3 "Services"
                  :op4 "IC"))
      :op11 (p9 / publication
            :name (n10 / name
                  :op1 "Innovation"
                  :op2 "Centre"
                  :op3 "for"
                  :op4 "Innovation")
            :poss (o / organization
                  :name (n11 / name
                        :op1 "International"
                        :op2 "Criminal"
                        :op3 "Police"
                        :op4 "Organization")))
      :op12 (p10 / publication
            :name (n12 / name
                  :op1 "International"
                  :op2 "Criminal"
                  :op3 "Police"
                  :op4 "Organization"
                  :op5 "LED"))
      :op13 (p11 / publication
            :name (n13 / name
                  :op1 "Law"
                  :op2 "Enforcement"
                  :op3 "Division"
                  :op4 "2016/680"
                  :op5 "MAS"))
      :op14 (p12 / publication
            :name (n14 / name
                  :op1 "Natural"
                  :op2 "Language"
                  :op3 "Processing"
                  :op4 "Non-Poi"))
      :op15 (p13 / publication
            :name (n15 / name
                  :op1 "Non-Person"
                  :op2 "of"
                  :op3 "Interest"))
      :op16 "NPA"
      :op17 (o2 / organization
            :name (n16 / name
                  :op1 "Organization"
                  :op2 "for"
                  :op3 "Economic"
                  :op4 "Cooperation"
                  :op5 "and"
                  :op6 "Development"))
      :op18 (r / research-01)
      :op19 "and"
      :op20 "Development"
      :op21 (o3 / organization
            :name (n17 / name
                  :op1 "Unmanned"
                  :op22 "Aeric"
                  :op23 "Vehicle"
                  :op24 "International"
                  :op25 "Research"
                  :op26 "Institute"))
      :op22 "ZITI"
      :op23 (o4 / organization
            :name (n18 / name
                  :op21 "Central"
                  :op22 "Office"
                  :op23 "for"
                  :op24 "Information"
                  :op25 "Technology"
                  :op26 "in"
                  :op27 "the"
                  :op28 "Security"
                  :op29 "Sector"
                  :op31 "53"
                  :op32 "Jerusalem")))

# ::snt The ir value -based principles  aim to foster innovation and trust in AI by promoting the responsible stewardship of trustworthy AI while  ensuring respect for human rights and democratic value s. They identify  five complementary value -based  principles:    inclusive growth, sustainable development and well -being;    human -centred values and fairness;    transparency and explainability;    robustness, security and safety;    and accountability.
# File 144

(m / multi-sentence
      :snt1 (a / aim-01
            :ARG0 (p / principle
                  :ARG1-of (b / base-02
                        :ARG2 (v / value)))
            :ARG1 (f / foster-01
                  :ARG0 p
                  :ARG1 (a2 / and
                        :op1 (ii / innovate-01)
                        :op2 (t / trust-02
                              :ARG1 (ii2 / intelligent-01
                                    :mod (a3 / artificial))))
                  :manner (p2 / promote-02
                        :ARG0 p
                        :ARG1 (s / stewardship
                              :ARG1-of (r / responsible-02)
                              :poss ii2)
                        :time (e / ensure-01
                              :ARG0 p
                              :ARG1 (r2 / respect-01
                                    :ARG1 (a4 / and
                                          :op1 (r3 / right-05
                                                :ARG1 (h / human))
                                          :op2 (v2 / value
                                                :mod (d / democracy))))))))
      :snt2 (ii3 / identify-01
            :ARG0 (t2 / they)
            :ARG1 (p3 / principle
                  :quant 5
                  :ARG1-of (b2 / base-02
                        :ARG2 (v3 / value))
                  :ARG1-of (c / complement-01))
            :ARG2 (a5 / and
                  :op1 (g / grow-01
                        :ARG1-of (ii4 / include-91)
                        :ARG2-of ii4))
            :op2 (d2 / develop-02
                  :ARG1-of (s2 / sustain-01
                        :ARG1-of (p4 / possible-01)))
            :op3 (w / well-09))
      :op4 (a6 / and
            :op1 (t3 / transparency)
            :op2 (e2 / explain-01))
      :op5 (r4 / robustness)
      :op6 (s3 / security)
      :op7 (s4 / safe-01)
      :op8 (a7 / accountable-02))

# ::snt    18  © OECD 2020     fairness  (a G20 AI Principle) .
# File 144

(m / multi-sentence
      :snt1 (p / publication
            :name (n / name
                  :op1 "OECD")
            :time (d / date-entity
                  :year 2020))
      :snt2 (f / fairness
            :ARG1-of (m2 / mean-01
                  :ARG2 (p2 / principle
                        :mod (ii / intelligent-01
                              :mod (a / artificial))
                        :mod (o / organization
                              :name (n2 / name
                                    :op1 "G20")))))
      :snt3 (n3 / number
            :value 18))

# ::snt Common principles were: promotion of human values, p rofessional responsibility, human  control of technology, fairness and non- discrimination,  transparency and explainability, s afety and security,   accountability,  privacy , and top- down ethical theories  (utilitarianism, contractarianism, Kantianism, v irtue ethics,  ethics of c are, etc.)
# File 67

(p / principle
      :mod (c / common)
      :domain (a / and
            :op1 (p2 / promote-02
                  :ARG1 (v / value
                        :mod (h / human)))
            :op2 (r / responsible-03
                  :mod (p3 / public))
            :op3 (c2 / control-01
                  :ARG0 h
                  :ARG1 (t / technology))
            :op4 (a2 / and
                  :op1 (f / fairness)
                  :op2 (d / discriminate-02
                        :polarity -))
            :op5 (a3 / and
                  :op1 (t2 / transparency)
                  :op2 (e / explain-01
                        :ARG1-of (p4 / possible-01)))
            :op6 (a4 / and
                  :op1 f)
            :op2 (s / security))
      :op7 (a5 / accountable-02)
      :op8 (p5 / privacy)
      :op9 (t3 / theory
            :mod (e2 / ethics)
            :mod (t4 / top-down)
            :example (a6 / and
                  :op1 (u / utilitarianism)
                  :op2 (c3 / contractarianism)
                  :op3 (k / Kantianism)
                  :op4 (e3 / ethics
                        :mod (u2 / unique))
                  :op5 (e4 / ethics
                        :mod (a7 / amr-unknown))
                  :op6 (e5 / et-cetera))))

# ::snt IBM is trying to make AI systems more transparent and biases more visible with the AI Fairness 360 toolkit.
# File 67

(t / try-01
      :ARG0 (c / company
            :name (n / name
                  :op1 "IBM"))
      :ARG1 (m / make-02
            :ARG0 c
            :ARG1 (a / and
                  :op1 (t2 / transparent
                        :ARG2-of (h / have-degree-91
                              :ARG1 (s / system
                                    :mod (ii / intelligent-01
                                          :mod (a2 / artificial)))
                              :ARG3 (m2 / more)))
                  :op2 (s2 / see-01
                        :ARG1 (b / bias-01)
                        :ARG2-of (h2 / have-degree-91
                              :ARG1 b
                              :ARG3 (m3 / more)))))
      :instrument (t3 / toolkit
            :name (n2 / name
                  :op1 "AI"
                  :op2 "Fairness"
                  :op3 360)))

# ::snt Proceedings of the Conference on Fairness, Accountability, and Transparency.
# File 67

(p / proceed-01
      :ARG1 (c / conference
            :name (n / name
                  :op1 "Conference"
                  :op2 "on"
                  :op3 "Fairness"
                  :op4 "Accountability"
                  :op5 "and"
                  :op6 "Transparency")))

# ::snt AI Fairness 360 Open Source Toolkit.
# File 67

(t / toolkit
      :name (n / name
            :op1 "AI"
            :op2 "Fairness"
            :op3 360
            :op4 "Open"
            :op5 "Source"
            :op6 "Technology"))

# ::snt A unified approach to quantifying algorithmic  unfairness: Measuring individual and g roup unfairness via inequality  indices .
# File 67

(a / approach-02
      :ARG1 (q / quantify-01
            :ARG1 (f / fair-01
                  :polarity -
                  :mod (a2 / algorithm)))
      :ARG1-of (u / unify-01)
      :ARG1-of (m / mean-01
            :ARG2 (m2 / measure-01
                  :ARG1 (f2 / fair-01
                        :polarity -
                        :ARG1 (a3 / and
                              :op1 (ii / individual)
                              :op2 (g / group
                                    :name (n / name
                                          :op1 "Grap"))))
                  :instrument (ii2 / index
                        :mod (e / equal-01
                              :polarity -)))))

# ::snt Sovereign  Capability     Safety   Reliability and safety: Throughout their  lifecycle, AI systems should reliably operate in accordance with their intended purpose      Fairness: Throughout their lifecycle, AI systems should be inclusive and accessible, and should not involve or Data Agency: A/IS  creators shall empower individuals with the ability to access and securely share their data,  to maintain  people’s capacity to EQUITABLE: DoD should  take deliberate steps to avoid unintended bias in the development and deployment of combat or non-combat AI systems  that would inadvertently cause harm to persons.
# File 67

(m / multi-sentence
      :snt1 (a / and
            :op1 (c / capable-01
                  :mod (s / sovereign))
            :op2 (s2 / safe-01)
            :op3 (r / rely-01))
      :snt2 (a2 / and
            :op1 (r2 / recommend-01
                  :ARG1 (o / operate-01
                        :ARG1 (s3 / system
                              :mod (ii / intelligent-01)
                              :mod (a3 / artificial))
                        :ARG1-of (r3 / rely-01
                              :ARG1-of (p / possible-01))
                        :ARG1-of (r4 / regular-02)
                        :ARG1-of (a4 / accord-02
                              :ARG2 (p2 / purpose
                                    :ARG1-of (ii2 / intend-01)
                                    :poss s3)))
                  :duration (l / lifecycle
                        :poss s3))
            :op2 (r5 / recommend-01
                  :ARG1 (a5 / and
                        :op1 (a6 / and
                              :op1 (ii3 / include-01
                                    :ARG1 s3
                                    :ARG2 s3)
                              :op2 (a7 / access-01
                                    :ARG1 s3))
                        :op2 (ii4 / involve-01
                              :polarity -
                              :ARG1 (a8 / agency
                                    :mod (d / data))))))
      :snt3 (e / empower-01
            :ARG0 (p3 / person
                  :ARG0-of (c2 / create-01
                        :ARG1 (a9 / and
                              :op1 (s4 / system
                                    :mod (ii5 / intelligent-01)
                                    :mod a3))
                        :op2 (s5 / system
                              :mod (c3 / combat-01
                                    :polarity -)))))
      :ARG1 (ii6 / individual)
      :ARG2 (c4 / capable-01
            :ARG1 ii6
            :ARG2 (a10 / and
                  :op1 (a11 / access-01
                        :ARG0 ii6
                        :ARG1 (d2 / data
                              :poss ii6))
                  :op2 (s6 / share-01
                        :ARG0 ii6
                        :ARG1 d2
                        :ARG1-of (s7 / secure-02))))
      :purpose (m2 / maintain-01
            :ARG0 p3
            :ARG1 (c5 / capable-01
                  :ARG1 (p4 / person)
                  :ARG2 (e2 / equal-01)))
      :snt4 (r6 / recommend-01
            :ARG1 (s8 / step-01
                  :ARG0 (g / government-organization
                        :name (n / name
                              :op1 "Department"
                              :op2 "of"
                              :op3 "Defense"))
                  :ARG2 (a12 / avoid-01
                        :ARG0 g
                        :ARG1 (b / bias-01
                              :ARG1 (a13 / and
                                    :op1 (d3 / develop-02
                                          :ARG1 (a14 / and
                                                :op1 (s9 / system
                                                      :mod (ii7 / intelligent-01)
                                                      :mod a3)
                                                :mod (c6 / combat-01)))
                                    :op2 s5)
                              :ARG0-of (c7 / cause-01
                                    :ARG1 (h / harm-01
                                          :ARG1 p4
                                          :manner (ii8 / inadvertent))))))
            :ARG1-of ii2
            :polarity -)
      :ARG1-of (d4 / deliberate-01))

# ::snt Fairness and non discrimination     Safety and Security     Privacy Justice and  fairness     Non- maleficence    Privacy
# File 67

(a / and
      :op1 (a2 / and
            :op1 (f / fairness)
            :op2 (d / discriminate-02
                  :polarity -))
      :op2 (a3 / and
            :op1 (s / safe-01)
            :op2 (s2 / security))
      :op3 (a4 / and
            :op1 (j / justice)
            :op2 (f2 / fairness)
            :op3 (m / maleficiary
                  :polarity -)
            :op4 (p / privacy)))

# ::snt Fairness and non discrimination     Safety and Security     Privacy Justice and  fairness     Non- maleficence    Privacy
# File 67

(a / and
      :op1 (a2 / and
            :op1 (f / fairness)
            :op2 (d / discriminate-02
                  :polarity -))
      :op2 (a3 / and
            :op1 (s / safe-01)
            :op2 (s2 / security))
      :op3 (a4 / and
            :op1 (j / justice)
            :op2 (f2 / fairness)
            :op3 (m / maleficiary
                  :polarity -)
            :op4 (p / privacy)))

# ::snt Nonetheless it is worth recognising that this is one potentially beneficial use to  which they have been put; see for instance the work of IBM which has developed its “AI Fairness 360 Open Source Toolkit” – http://aif360.mybluemix.net/?utm_campaign=the_algorithm.
# File 76

(m / multi-sentence
      :snt1 (h / have-concession-91
            :ARG2 (w / worth-02
                  :ARG1 (r / recognize-02
                        :ARG1 (u / use-01
                              :ARG1 (t / this)
                              :ARG0-of (b / benefit-01
                                    :mod (p / potential))
                              :ARG2-of (p2 / put-03
                                    :ARG1 (t2 / they))))))
      :snt2 (s / see-01
            :mode imperative
            :ARG0 (y / you)
            :ARG1 (w2 / work-01
                  :ARG0 (c / company
                        :name (n / name
                              :op1 "IBM")
                        :ARG0-of (d / develop-02
                              :ARG1 (t3 / toolkit
                                    :name (n2 / name
                                          :op1 "AI"
                                          :op2 "Fairness"
                                          :op3 360
                                          :op4 "Open"
                                          :op5 "Source"
                                          :op6 "Toolkit")
                                    :ARG1-of (m2 / mean-01
                                          :ARG2 (u2 / url-entity
                                                :value "http://aif360.mybluemix.net/?utm_campaign=the_algorithm.html")))))
                  :ARG0-of (e / exemplify-01))))

# ::snt In Conference on fairness, accountability and transparency, PMLR 81:77-91, 2018; see http://proceedings.mlr.press/v81/buolamwini18a.html 54 Grother, P., Ngan, M. and Hanaoka, K., 2019.
# File 76

(m / multi-sentence
      :snt1 (c / conference
            :topic (a / and
                  :op1 (f / fairness)
                  :op2 (a2 / accountable-02)
                  :op3 (t / transparency))
            :mod (p / publication
                  :name (n / name
                        :op1 "PMLR")
                  :ARG1-of (c2 / cite-01
                        :ARG2 (v / value-interval
                              :op1 81
                              :op2 91)))
            :time (d / date-entity
                  :year 2018))
      :snt2 (s / see-01
            :mode imperative
            :ARG0 (y / you)
            :ARG1 (u / url-entity
                  :value "http://proceedings.mlr.press/v81/buolamwini18a.html"))
      :snt3 a
      :op1 (c3 / cite-01
            :ARG2 (p2 / person
                  :name (n2 / name
                        :op1 "Grother")))
      :op2 (c4 / cite-01
            :ARG2 (p3 / person
                  :name (n3 / name
                        :op1 "Ngan")))
      :op3 (c5 / cite-01
            :ARG2 (p4 / person
                  :name (n4 / name
                        :op1 "Hanaoka")))
      :time (d2 / date-entity
            :year 2019))

# ::snt In addition to identifying the purpose of “ethical AI”, this paper explains the principles  which should define any AI system as follows: respect for human autonomy,  prevention of harm, fairness, and explicability.
# File 76

(a / and
      :op1 (e / explain-01
            :ARG0 (p / paper
                  :mod (t / this))
            :ARG1 (p2 / principle
                  :ARG0-of (d / define-01
                        :ARG1 (s / system
                              :mod (ii / intelligent-01
                                    :mod (a2 / artificial)))
                        :ARG2 (a3 / and
                              :op1 (r / respect-01
                                    :ARG1 (a4 / autonomy
                                          :mod (h / human)))
                              :op2 (p3 / prevent-01
                                    :ARG1 (h2 / harm-01))
                              :op3 (f / fairness)
                              :op4 e
                              :ARG1-of (p4 / possible-01)))
                  :ARG1-of (r2 / recommend-01)))
      :op2 (ii2 / identify-01
            :ARG0 p
            :ARG1 (p5 / purpose
                  :poss ii)))

# ::snt Diversity, non-discrimination and fairness: AI systems should consider the whole  range of human abilities, skills and requirements, and ensure accessibility.
# File 76

(m / multi-sentence
      :snt1 (a / and
            :op1 (d / diversity)
            :op2 (d2 / discriminate-01
                  :polarity -)
            :op3 (f / fair-01))
      :snt2 (r / recommend-01
            :ARG1 (a2 / and
                  :op1 (c / consider-02
                        :ARG0 (s / system
                              :mod (ii / intelligent-01
                                    :mod (a3 / artificial)))
                        :ARG1 (r2 / range-01
                              :ARG1 (a4 / and
                                    :op1 (c2 / capable-01
                                          :ARG1 (h / human))
                                    :op2 (s2 / skill
                                          :poss h)
                                    :op3 (r3 / require-01
                                          :ARG0 h))
                              :mod (w / whole)))
                  :op2 (e / ensure-01
                        :ARG0 s
                        :ARG1 (a5 / access-01
                              :ARG1 s)))))

# ::snt Finding good 'exploration' strategies is a defining challenge in  reinforcement learning that might require optimizing such strategies in a data- driven way, while  constr aining them to satisfy constraints on safety, fairness, and explainability.
# File 155

(c / challenge-01
      :ARG2 (f / find-01
            :ARG1 (s / strategy
                  :purpose (e / explore-01)
                  :ARG1-of (g / good-02)))
      :ARG0-of (d / define-01
            :ARG1 (l / learn-01
                  :ARG1 (r / reinforce-01)))
      :ARG0-of (r2 / require-01
            :ARG1 (o / optimize-01
                  :ARG1 (s2 / strategy
                        :mod (s3 / such))
                  :manner (d2 / drive-02
                        :ARG0 (d3 / data))
                  :time (c2 / constrain-01
                        :ARG1 s2
                        :purpose (s4 / satisfy-01
                              :ARG0 s2
                              :ARG1 (c3 / constraint
                                    :topic (a / and
                                          :op1 (s5 / safe-01)
                                          :op2 (f2 / fairness)
                                          :op3 (e2 / explain-01
                                                :ARG1-of (p / possible-01)))))))
            :ARG1-of (p2 / possible-01)))

# ::snt 24 FACT refers to questions related to Fairness, Accuracy, Confidentiality and Transparency (see  http://www.responsibledatascience.org/ ).
# File 155

(r / refer-01
      :li 24
      :ARG0 (f / fact)
      :ARG1 (q / question-01
            :ARG1 (a / and
                  :op1 (f2 / fairness)
                  :op2 (a2 / accuracy)
                  :op3 (c / confidentiality)
                  :op4 (t / transparency)))
      :ARG1-of (d / describe-01
            :ARG0 (s / see-01
                  :ARG0 (y / you)
                  :ARG1 (u / url-entity
                        :value "http://www.responsibledatascience.org/"))))

# ::snt Included is  a specific module focusing on  six  principles that we believe should guide AI development and use — fairness, reliability  and safety, privacy and security, inclusiveness, transpar ency, and accountability.
# File 162

(ii / include-01
      :ARG1 (m / module
            :ARG1-of (s / specific-02)
            :ARG0-of (f / focus-01
                  :ARG2 (p / principle
                        :quant 6
                        :ARG0-of (g / guide-01
                              :ARG1 (a / and
                                    :op1 (d / develop-02
                                          :ARG1 (ii2 / intelligent-01
                                                :mod (a2 / artificial)))
                                    :op2 (u / use-01
                                          :ARG1 ii2))
                              :ARG1-of (r / recommend-01
                                    :ARG1-of (b / believe-01
                                          :ARG0 (w / we))))
                        :ARG1-of (m2 / mean-01
                              :ARG2 (a3 / and
                                    :op1 (f2 / fairness)
                                    :op2 (r2 / rely-01
                                          :ARG1-of (p2 / possible-01))
                                    :op3 (s2 / safe-01)
                                    :op4 (p3 / privacy)
                                    :op5 (s3 / security)
                                    :op6 (ii3 / inclusiveness)
                                    :op7 (e / equitable
                                          :mod (t / transpar))
                                    :op8 (a4 / accountable-02)))))))

# ::snt Intrinsic requirements , such as fairness, absence of bias or non- discrimination , can be expressed as  properties o f the algorithm itself in its application context.
# File 89

(p / possible-01
      :ARG1 (e / express-01
            :ARG1 (r / require-01
                  :example (a / and
                        :op1 (f / fairness)
                        :op2 (a2 / absent-01
                              :ARG1 (b / bias-01))
                        :op3 (d / discriminate-01
                              :polarity -))
                  :mod (ii / intrinsic))
            :ARG3 (p2 / property
                  :poss (a3 / algorithm)
                  :location (c / context
                        :mod (a4 / apply-02
                              :ARG1 a3)))))

# ::snt We equate ' fairness ' with 'absence of  undesirable bias ' and we characteri se 'discrimination ' as a particular form of unfairness related to  the use of specific types of data (such as ethnic origin, politica l opinions, gender, etc.).
# File 89

(a / and
      :op1 (e / equate-01
            :ARG0 (w / we)
            :ARG1 (f / fair-01)
            :ARG2 (a2 / absent-01
                  :ARG1 (b / bias-01
                        :ARG1-of (d / desire-01
                              :polarity -))))
      :op2 (c / characterize-01
            :ARG0 w
            :ARG1 (d2 / discriminate-02)
            :ARG2 (f2 / form
                  :mod (p / particular)
                  :ARG1-of (r / relate-01
                        :ARG2 (u / use-01
                              :ARG1 (d3 / data
                                    :mod (t / type
                                          :ARG1-of (s / specific-02))
                                    :example (a3 / and
                                          :op1 (o / originate-01
                                                :ARG2 (e2 / ethnic-group))
                                          :op2 (o2 / opine-01
                                                :ARG1 (p2 / politics))
                                          :op3 (g / gender)
                                          :op4 (e3 / et-cetera)))))
                  :ARG0-of (f3 / fair-01
                        :polarity -))))

# ::snt • Fairness (absence of undesirable bias):  ADS are often based on machine learning  algorithms that are trained using collected data.
# File 89

(m / multi-sentence
      :snt1 (f / fairness
            :ARG1-of (m2 / mean-01
                  :ARG2 (b / bias-01
                        :polarity -
                        :ARG1-of (d / desire-01
                              :polarity -))))
      :snt2 (b2 / base-02
            :ARG1 (p / product
                  :name (n / name
                        :op1 "ADS"))
            :ARG2 (a / algorithm
                  :instrument-of (l / learn-01
                        :manner (m3 / machine))
                  :ARG2-of (t / train-01
                        :instrument (d2 / data
                              :ARG1-of (c / collect-01))))
            :frequency (o / often)))

# ::snt Th is process includes  multiple potential  sources of unfairness.
# File 89

(ii / include-01
      :ARG1 (s / source-02
            :ARG1 (f / fairness
                  :polarity -)
            :mod (p / potential)
            :quant (m / multiple))
      :ARG2 (p2 / process-02))

# ::snt As shown in this study , there are different  definitions of fairness , and others will be proposed in the future.
# File 89

(a / and
      :op1 (d / define-01
            :ARG1 (f / fair-01)
            :ARG1-of (d2 / differ-02))
      :op2 (p / propose-01
            :ARG1 (d3 / define-01
                  :ARG1 f
                  :mod (o / other))
            :time (f2 / future))
      :ARG1-of (s / show-01
            :ARG0 (s2 / study-01
                  :mod (t / this))))

# ::snt STOA  | Panel for the Future of Science and Technology   IV however that many definitions of fairness are actu ally incompatible.
# File 89

(m / multi-sentence
      :snt1 (o / organization
            :name (n / name
                  :op1 "STOA"))
      :snt2 (o2 / organization
            :name (n2 / name
                  :op1 "Panel"
                  :op2 "for"
                  :op3 "the"
                  :op4 "Future"
                  :op5 "of"
                  :op6 "Science"
                  :op7 "and"
                  :op8 "Technology"))
      :snt3 (h / have-concession-91
            :ARG1 (c / compatible
                  :polarity -
                  :domain (t / thing
                        :ARG2-of (d / define-01
                              :ARG1 (f / fair-01))
                        :quant (m2 / many))
                  :mod (a / act-02))))

# ::snt • Beyond existing fairness criteria already identified in anti -discriminat ion laws, what types of  treatment should be considered undesirable?
# File 89

(r / recommend-01
      :ARG1 (c / consider-01
            :ARG1 (d / desire-01
                  :polarity -
                  :ARG1 (t / treat-03
                        :mod (t2 / type
                              :mod (a / amr-unknown)))))
      :mod (b / beyond
            :op1 (c2 / criteria
                  :ARG1-of (e / exist-01)
                  :topic (f / fairness)
                  :ARG1-of (ii / identify-01
                        :time (a2 / already)
                        :location (l / law
                              :ARG0-of (o / oppose-01
                                    :ARG1 (d2 / discriminate-02
                                          :ARG1 (ii2 / ion))))))))

# ::snt Other challenges are ' operational ', such  as the implementation of explainability by design, fairness by design or privacy by d esign.
# File 89

(o / operate-01
      :ARG1 (c / challenge-01
            :mod (o2 / other)
            :example (ii / implement-01
                  :ARG1 (o3 / or
                        :op1 (p / possible-01
                              :ARG1 (e / explain-01)
                              :manner (d / design-01))
                        :op2 (f / fair-01
                              :manner (d2 / design-01))
                        :op3 (p2 / private-02
                              :manner (t / thing
                                    :name (n / name
                                          :op1 "ign")))))))

# ::snt More research  is needed, for example, on ADS security, safety, privacy, fairness or explainability.
# File 89

(n / need-01
      :ARG1 (r / research-01
            :ARG1 (o / or
                  :op1 (s / security
                        :mod (p / product
                              :name (n2 / name
                                    :op1 "ADS")))
                  :op2 (s2 / safe-01)
                  :op3 (p2 / privacy)
                  :op4 (f / fairness)
                  :op5 (e / explain-01
                        :ARG1-of (p3 / possible-01)))
            :mod (m / more))
      :ARG0-of (e2 / exemplify-01))

# ::snt Development of tools to enhance accountability : Most ADS designers and developers  are not experts in privacy, security, fairness or explainability.
# File 89

(d / develop-02
      :ARG1 (t / tool
            :ARG0-of (e / enhance-01
                  :ARG1 (a / accountable-02)))
      :ARG1-of (c / cause-01
            :ARG0 (e2 / expert-01
                  :polarity -
                  :ARG1 (a2 / and
                        :op1 (p / person
                              :ARG0-of (d2 / design-01
                                    :ARG1 (p2 / product
                                          :name (n / name
                                                :op1 "ADS"))))
                        :op2 (p3 / person
                              :ARG0-of (d3 / develop-02
                                    :ARG1 p2))
                        :quant (m / most))
                  :ARG2 (o / or
                        :op1 (p4 / privacy)
                        :op2 (s / security)
                        :op3 (f / fairness)
                        :op4 (e3 / explain-01
                              :ARG1-of (p5 / possible-01))))))

# ::snt It is therefore important to  provide tools and meth odologies to help them reconcile the tensions that exist between  accuracy, cost and explainability/fairness/privacy.
# File 89

(c / cause-01
      :ARG1 (ii / important-01
            :ARG1 (p / provide-01
                  :ARG1 (a / and
                        :op1 (t / tool)
                        :op2 (o / odology
                              :mod (m / meth)))
                  :purpose (h / help-01
                        :ARG1 (r / reconcile-01
                              :ARG0 (t2 / they)
                              :ARG1 (t3 / tension
                                    :ARG1-of (e / exist-01)
                                    :mod (b / between
                                          :op1 (a2 / accuracy)
                                          :op2 (c2 / cost)
                                          :op3 (s / slash
                                                :op1 (f / fairness)
                                                :op2 f)
                                          :op3 (p2 / privacy)))))
                  :ARG2 t2)))

# ::snt In fact, transparency and explainability may allow for the discovery of deficiencies, but  do not provide absolute guarantees for the reliability, security or fairness of an ADS.
# File 89

(c / contrast-01
      :ARG1 (p / possible-01
            :ARG1 (a / allow-01
                  :ARG0 (a2 / and
                        :op1 (t / transparency)
                        :op2 (e / explain-01))
                  :ARG1 (d / discover-01
                        :ARG1 (d2 / deficiency)))
            :mod (ii / in-fact))
      :ARG2 (g / guarantee-01
            :polarity -
            :ARG0 a2
            :ARG1 (o / or
                  :op1 (r / rely-01
                        :ARG1 (p2 / product
                              :name (n / name
                                    :op1 "ADS"))
                        :ARG1-of (p3 / possible-01))
                  :op2 (s / security
                        :poss p2)
                  :op3 (f / fairness
                        :poss p2))
            :degree (a3 / absolute)))

# ::snt Finally , we believe that if appropriate accountability measures are taken, in certain situations ADS  have the potential to improve transparency and reduce unfairness and discrimination.
# File 89

(b / believe-01
      :ARG0 (w / we)
      :ARG1 (p / potential
            :domain (a / and
                  :op1 (ii / improve-01
                        :ARG0 (p2 / product
                              :name (n / name
                                    :op1 "ADS"))
                        :ARG1 (t / transparency))
                  :op2 (r / reduce-01
                        :ARG0 p2
                        :ARG1 (a2 / and
                              :op1 (f / fairness
                                    :polarity -)
                              :op2 (d / discriminate-02))))
            :condition (t2 / take-01
                  :ARG1 (m / measure-02
                        :ARG1 (a3 / accountable-02)
                        :ARG1-of (a4 / appropriate-02)))
            :time (s / situation
                  :mod (c / certain)))
      :mod (f2 / final))

# ::snt ADS Fairness  _____________________________________________________________ 40  5.4.1.
# File 89

(a / and
      :op1 (f / fairness
            :poss (o / organization
                  :name (n / name
                        :op1 "ADS")))
      :op2 (n2 / number
            :value 40)
      :op3 (d / distribution-range-91
            :ARG4 5.1))

# ::snt The various sources of unfairness  __________________________________________ 40  5.4.2.
# File 89

(s / source-02
      :ARG0 (t / thing
            :mod (v / various))
      :ARG1 (f / fairness
            :polarity -)
      :li (a / and
            :op1 40
            :op2 5.4))

# ::snt Definitions of fairness  ____________________________________________________ 43  5.4.3.
# File 89

(d / define-01
      :ARG1 (f / fair-01)
      :li 43
      :li 5.3)

# ::snt Towards fairness -aware algorithms  _________________________________________ 46  5.5.
# File 89

(c / concern-02
      :ARG1 (a / algorithm
            :ARG0-of (r / realize-01
                  :ARG1 (f / fairness)))
      :mod (d / distribution-range-91
            :ARG1 46
            :ARG4 5.5))

# ::snt In addition, key issues such as explainability and, to a less extent, fairness have not received enough  attention from the research community in the past.
# File 89

(a / and
      :op2 (a2 / attend-02
            :polarity -
            :ARG0 (c / community
                  :ARG0-of (r / research-01))
            :ARG1 (ii / issue-02
                  :ARG1-of (k / key-02)
                  :example (a3 / and
                        :op1 (p / possible-01
                              :ARG1 (e / explain-01))
                        :op2 (f / fairness
                              :ARG1-of (e2 / extend-01
                                    :ARG1-of (h / have-quant-91
                                          :ARG3 (l / less))))))
            :time (p2 / past)
            :ARG1-of h
            :ARG3 (e3 / enough)))

# ::snt STOA  | Panel for the Future of Science and Technology   2 Artificial Intelligence) Workshop co -located with the flagship artificial conference,  IJCAI,1 took place  in 2017, the annual Workshop on Human Interpretability in machine learning (WHI) was initiated in  2016,  and the FAT/ML workshop on 'Fairness, Accountability and Transparency in Machine Learning '  was launched in 2014.
# File 89

(m / multi-sentence
      :snt1 (o / organization
            :name (n / name
                  :op1 "STOA"))
      :snt2 (o2 / organization
            :name (n2 / name
                  :op1 "Panel"
                  :op2 "for"
                  :op3 "the"
                  :op4 "Future"
                  :op5 "of"
                  :op6 "Science"
                  :op7 "and"
                  :op8 "Technology"))
      :snt3 (c / conference
            :quant 2
            :name (n3 / name
                  :op1 "Artificial"
                  :op2 "Intelligence")
            :ARG1-of (c2 / colocate-01
                  :ARG2 (c3 / conference
                        :name (n4 / name
                              :op1 "IJCAI")
                        :mod (a / artificial)
                        :mod (f / flagship))))
      :snt4 (a2 / and
            :op1 (e / event
                  :time (d / date-entity
                        :year 2017))
            :op2 (ii / initiate-01
                  :ARG1 (c4 / conference
                        :name (n5 / name
                              :op1 "Workshop"
                              :op2 "on"
                              :op3 "Human"
                              :op4 "Interpretable"
                              :op5 "in"
                              :op6 "Machine"
                              :op7 "Learning")
                        :frequency (r / rate-entity-91
                              :ARG3 (t / temporal-quantity
                                    :quant 1
                                    :unit (y / year))))
                  :time (d2 / date-entity
                        :year 2016))
            :op3 (l / launch-01
                  :ARG1 (c5 / conference
                        :name (n6 / name
                              :op1 "FAT/ML"
                              :op2 "Workshop")
                        :topic (a3 / and
                              :op1 (f2 / fairness)
                              :op2 (a4 / accountable-02)
                              :op3 (t2 / transparency)
                              :topic (l2 / learn-01
                                    :mod a)))
                  :time (d3 / date-entity
                        :year 2014))))

# ::snt Sections 5.1, 5.2 and 5.3 focus  respectively on safety, security and privacy, while Sections 5.4 and 5.5 are devoted to fairness and  explainability respectively.
# File 89

(c / contrast-01
      :ARG1 (f / focus-01
            :ARG0 (a / and
                  :op1 (s / section
                        :mod 5.1)
                  :op2 (s2 / section
                        :mod 5.2)
                  :op3 (s3 / section
                        :mod 5.3))
            :ARG1 (a2 / and
                  :op1 (s4 / safe-01)
                  :op2 (s5 / security)
                  :op3 (p / privacy)))
      :ARG2 (d / devote-01
            :ARG1 (a3 / and
                  :op1 (f2 / fairness)
                  :op2 (e / explain-01)
                  :ARG2-of d)))

# ::snt However, they also give rise to a  variety of risks , such as discrimination, unfairness, manipulation or privacy breaches.
# File 89

(c / contrast-01
      :ARG2 (r / rise-01
            :ARG0 (t / they)
            :ARG1 (r2 / risk-01
                  :mod (v / variety)
                  :example (o / or
                        :op1 (d / discriminate-02)
                        :op2 (f / fairness
                              :polarity -)
                        :op3 (m / manipulate-02)
                        :op4 (b / breach-01
                              :ARG1 (p / privacy))))
            :mod (a / also)))

# ::snt Chouldochava even shows that different fairness criteria cannot be   satisfied simultaneously.
# File 89

(s / show-01
      :ARG0 (p / person
            :name (n / name
                  :op1 "Chouldochava"))
      :ARG1 (p2 / possible-01
            :polarity -
            :ARG1 (s2 / satisfy-01
                  :ARG1 (c / criteria
                        :topic (f / fair-01)
                        :ARG1-of (d / differ-02))
                  :mod (s3 / simultaneous)))
      :mod (e / even))

# ::snt The fact that a decision procedure is automated (or partly automated) may also encourage public  discussion about the criteria used by the system, the underlying logic and the expectations of  society in this respec t, in particular in terms of fairness or non -discrimination.
# File 89

(p / possible-01
      :ARG1 (e / encourage-01
            :ARG0 (o / or
                  :op1 (a / automate-01
                        :ARG1 (p2 / procedure
                              :purpose (d / decide-01)))
                  :op2 (a2 / automate-01
                        :ARG1 p2
                        :degree (p3 / part)))
            :ARG1 (d2 / discuss-01
                  :ARG1 (a3 / and
                        :op1 (c / criteria
                              :ARG1-of (u / use-01
                                    :ARG0 (s / system)))
                        :op2 (l / logic
                              :ARG0-of (u2 / underlie-01))
                        :op3 (e2 / expect-01
                              :ARG0 (s2 / society)
                              :topic (r / resource
                                    :mod (t / this)))
                        :topic (o2 / or
                              :op1 (f / fairness)
                              :op2 (d3 / discriminate-01
                                    :polarity -)
                              :mod (p4 / particular)))
                  :ARG1-of (p5 / public-02)))
      :mod (a4 / also))

# ::snt They  should therefore also meet additional requirements, which can be classified into two main  categories:   • Intrinsic requirements , such as fairness, absence of bias or non- discrimination , which can  be expressed as properties of the algorithm itself (as a mathematical function from its inputs  to its outputs) in its application context.
# File 89

(c / cause-01
      :ARG1 (r / recommend-01
            :ARG1 (m / meet-01
                  :ARG0 (t / they)
                  :ARG1 (r2 / require-01
                        :mod (a / additional)
                        :ARG1-of (c2 / classify-01
                              :ARG2 (c3 / category
                                    :quant 2
                                    :mod (m2 / main)
                                    :ARG1-of (m3 / mean-01
                                          :ARG2 (r3 / require-01
                                                :mod (ii / intrinsic)
                                                :example (o / or
                                                      :op1 (f / fairness)
                                                      :op2 (a2 / absent-01
                                                            :ARG1 (b / bias-01))
                                                      :op3 (d / discriminate-01
                                                            :polarity -))
                                                :ARG1-of (e / express-01
                                                      :ARG2 (p / property
                                                            :poss (a3 / algorithm))
                                                      :ARG1-of (p2 / possible-01)
                                                      :manner (f2 / function-01
                                                            :ARG0 a3
                                                            :manner (m4 / mathematics)
                                                            :source (ii2 / input
                                                                  :poss a3)
                                                            :destination (o2 / output
                                                                  :poss a3))
                                                      :location (c4 / context
                                                            :mod (a4 / apply-02))))))
                              :ARG1-of (p3 / possible-01)))
                  :mod (a5 / also))))

# ::snt In this report, we equate  'fairness ' with 'absence of undesirable bias ' and characterise ' discrimination ' as a specific  form of unfairness related to the use of specific types o f data (such as ethnic origin, political  opinions, gender, etc.).
# File 89

(a / and
      :op1 (e / equate-01
            :ARG0 (w / we)
            :ARG1 (f / fairness)
            :ARG2 (a2 / absent-01
                  :ARG1 (b / bias-01
                        :ARG1-of (d / desire-01
                              :polarity -))))
      :op2 (c / characterize-01
            :ARG0 w
            :ARG1 (d2 / discriminate-02)
            :ARG2 (f2 / form
                  :ARG1-of (s / specific-02)
                  :mod (f3 / fairness
                        :polarity -)
                  :ARG1-of (r / relate-01
                        :ARG2 (u / use-01
                              :ARG1 (t / type
                                    :ARG1-of (s2 / specific-02)
                                    :mod (d3 / data
                                          :example (a3 / and
                                                :op1 (o / originate-01
                                                      :ARG2 (e2 / ethnic-group))
                                                :op2 (o2 / opine-01
                                                      :topic (p / politics))
                                                :op3 (g / gender)
                                                :op4 (e3 / et-cetera))))))))
      :medium (r2 / report
            :mod (t2 / this)))

# ::snt Other definitions and terms used in the literature   Many papers use terms such as transparency, explainability, interpretability, accountability or  fairness with different mea nings or without defining them properly (and often without introducing  clear distinctions between them).
# File 89

(m / multi-sentence
      :snt1 (a / and
            :op1 (t / thing
                  :ARG2-of (d / define-01))
            :op2 (t2 / thing
                  :ARG2-of (t3 / term-01))
            :mod (o / other)
            :ARG1-of (u / use-01
                  :location (l / literature)))
      :snt2 (u2 / use-01
            :ARG0 (p / paper
                  :quant (m2 / many))
            :ARG1 (t4 / term-01
                  :example (o2 / or
                        :op1 (t5 / transparency)
                        :op2 (p2 / possible-01
                              :ARG1 (e / explain-01))
                        :op3 (p3 / possible-01
                              :ARG1 (ii / interpret-01))
                        :op4 (a2 / accountable-02)
                        :op5 (f / fairness
                              :topic (t6 / thing
                                    :name (n / name
                                          :op1 "Mea"
                                          :op2 "Ning")
                                    :ARG1-of (d2 / differ-02)))))
            :manner o2
            :op1 (d3 / define-01
                  :polarity -
                  :ARG1 t4
                  :manner (p4 / proper))
            :op2 (ii2 / introduce-02
                  :polarity -
                  :ARG1 (d4 / distinguish-01
                        :ARG1 t4
                        :ARG1-of (c / clear-06))
                  :frequency (o3 / often))))

# ::snt Fairness  is sometimes defined as the fact that the provider of the ADS does not misrepresent its  functionalities or divert it a gainst the interest of the users of the ADS or people affected by its  results.78 This version of fairness is more a subjective requirement on the behaviour and claims of  the provider of the ADS than a requirement on the ADS itself.
# File 89

(m / multi-sentence
      :li 78
      :snt1 (d / define-01
            :ARG1 (f / fairness)
            :ARG2 (o / or
                  :op1 (m2 / misrepresent-01
                        :polarity -
                        :ARG0 (c / company
                              :ARG0-of (p / provide-01
                                    :ARG1 (p2 / product
                                          :name (n / name
                                                :op1 "ADS"))))
                        :ARG1 (f2 / functional-03
                              :ARG1 p2))
                  :op2 (d2 / divert-01
                        :polarity -
                        :ARG0 c
                        :ARG1 (ii / interest-01
                              :ARG1 (o2 / or
                                    :op1 (p3 / person
                                          :ARG0-of (u / use-01
                                                :ARG1 p2))
                                    :op2 (p4 / person
                                          :ARG1-of (a / affect-01
                                                :ARG0 (r / result-01
                                                      :ARG1 p2))))
                              :ARG2 p2)))
            :frequency (s / sometimes))
      :snt2 (h / have-degree-91
            :ARG1 (v / version
                  :mod (t / this)
                  :mod (f3 / fairness))
            :ARG2 (r2 / require-01
                  :ARG3 (a2 / and
                        :op1 (b / behave-01
                              :ARG0 c)
                        :op2 (c2 / claim-01
                              :ARG0 c))
                  :ARG1-of (s2 / subjective-03))
            :ARG3 (m3 / more)
            :ARG4 (r3 / require-01
                  :ARG3 p2)))

# ::snt Fairness  is sometimes defined as the fact that the provider of the ADS does not misrepresent its  functionalities or divert it a gainst the interest of the users of the ADS or people affected by its  results.78 This version of fairness is more a subjective requirement on the behaviour and claims of  the provider of the ADS than a requirement on the ADS itself.
# File 89

(m / multi-sentence
      :li 78
      :snt1 (d / define-01
            :ARG1 (f / fairness)
            :ARG2 (o / or
                  :op1 (m2 / misrepresent-01
                        :polarity -
                        :ARG0 (c / company
                              :ARG0-of (p / provide-01
                                    :ARG1 (p2 / product
                                          :name (n / name
                                                :op1 "ADS"))))
                        :ARG1 (f2 / functional-03
                              :ARG1 p2))
                  :op2 (d2 / divert-01
                        :polarity -
                        :ARG0 c
                        :ARG1 (ii / interest-01
                              :ARG1 (o2 / or
                                    :op1 (p3 / person
                                          :ARG0-of (u / use-01
                                                :ARG1 p2))
                                    :op2 (p4 / person
                                          :ARG1-of (a / affect-01
                                                :ARG0 (r / result-01
                                                      :ARG1 p2))))
                              :ARG2 p2)))
            :frequency (s / sometimes))
      :snt2 (h / have-degree-91
            :ARG1 (v / version
                  :mod (t / this)
                  :mod (f3 / fairness))
            :ARG2 (r2 / require-01
                  :ARG3 (a2 / and
                        :op1 (b / behave-01
                              :ARG0 c)
                        :op2 (c2 / claim-01
                              :ARG0 c))
                  :ARG1-of (s2 / subjective-03))
            :ARG3 (m3 / more)
            :ARG4 (r3 / require-01
                  :ARG3 p2)))

# ::snt We therefore stick to the  more  restrictive definition of fairness introduced in Section 4.1.
# File 89

(c / cause-01
      :ARG1 (s / stick-01
            :ARG1 (w / we)
            :ARG2 (d / define-01
                  :ARG1 (f / fair-01)
                  :ARG1-of (ii / introduce-02
                        :location (s2 / section
                              :mod 4.1))
                  :ARG1-of (h / have-degree-91
                        :ARG2 (r / restrict-01
                              :ARG0 d)
                        :ARG3 (m / more)))))

# ::snt Definitions   Terms  Definition used in this report  Alternative definitions found in  the literature   Fairness  Absence of undesirable bias  No misrepresentation of the  functionality of the system   Transparency  Availability (public or controlled)  of the ADS code with its design  documentation, parameters and  learning dataset.
# File 89

(a / and
      :op1 (d / define-01)
      :op2 (t / term)
      :op3 (d2 / define-01
            :ARG1-of (u / use-01
                  :ARG2 (r / report
                        :mod (t2 / this))))
      :op4 (f / find-01
            :ARG1 (d3 / define-01
                  :mod (a2 / alternative))
            :location (l / literature))
      :op5 (f2 / fairness)
      :op6 (a3 / absent-01
            :ARG1 (b / bias-01
                  :ARG1-of (d4 / desire-01
                        :polarity -)))
      :op7 (m / misrepresent-01
            :polarity -
            :ARG1 (f3 / function-01
                  :ARG0 (s / system)))
      :op8 (t3 / transparency)
      :op9 (a4 / available-02
            :ARG2 (c / code
                  :name (n / name
                        :op1 "ADT")
                  :part (a5 / and
                        :op1 (d5 / design-01
                              :ARG1 c)
                        :op2 (d6 / documentation)
                        :op3 (p / parameter)
                        :op4 (d7 / dataset
                              :mod (l2 / learn-01))))
            :manner (o / or
                  :op1 (p2 / public-02)
                  :op2 (c2 / control-01))))

# ::snt Sections 5.1, 5.2 and 5.3 focus on safety, security and privacy respectively  while Section 5.4 is devoted to fairness and 5.5 to explainability.
# File 89

(c / contrast-01
      :ARG1 (f / focus-01
            :ARG0 (a / and
                  :op1 (s / section
                        :mod 5.1)
                  :op2 (s2 / section
                        :mod 5.2)
                  :op3 (s3 / section
                        :mod 5.3))
            :ARG1 (a2 / and
                  :op1 (s4 / safe-01)
                  :op2 (s5 / security)
                  :op3 (p / privacy)))
      :ARG2 (a3 / and
            :op1 (d / devote-01
                  :ARG1 (s6 / section
                        :mod 5.4)
                  :ARG2 (f2 / fairness))
            :op2 (d2 / devote-01
                  :ARG1 (s7 / section
                        :mod 5.5)
                  :ARG2 (e / explain-01))))

# ::snt ADS Fairness   As ADS replace or support human decision -makers in a number of sensitive domains such as justice,  health or education, it is important to ensure that they do not result in decisions that are considered  unfair or discriminatory.
# File 89

(ii / important-01
      :ARG1 (e / ensure-01
            :ARG1 (r / result-01
                  :polarity -
                  :ARG1 (t / thing
                        :ARG1-of (d / decide-01))
                  :ARG2 (t2 / thing
                        :ARG1-of (d2 / decide-01)
                        :ARG1-of (c / consider-01
                              :ARG3 (o / or
                                    :op1 (f / fair-01
                                          :polarity -)
                                    :op2 (d3 / discriminate-01))))))
      :ARG1-of (c2 / cause-01
            :ARG0 (o2 / or
                  :op1 (r2 / replace-01
                        :ARG1 (p / person
                              :ARG0-of (d4 / decide-01)
                              :mod (h / human))
                        :ARG2 (p2 / product
                              :name (n / name
                                    :op1 "ADS")))
                  :op2 (s / support-01
                        :ARG1 p)
                  :topic (d5 / domain
                        :quant (n2 / number)
                        :ARG0-of (s2 / sensitive-03)
                        :example (o3 / or
                              :op1 (j / justice)
                              :op2 (h2 / health)
                              :op3 (e2 / educate-01))))))

# ::snt In this section, we first discuss the various sources of unfairness  (Section 5.4.1), before presenting several definitions of fairness (Section 5.4.2) and technical  solutions to build fairness- aware ADS (Section 5.4.3).
# File 89

(d / discuss-01
      :ARG0 (w / we)
      :ARG1 (s / source-02
            :ARG1 (f / fairness
                  :polarity -)
            :mod (v / various)
            :ARG1-of (d2 / describe-01
                  :ARG0 (s2 / section
                        :mod "5.4.1")))
      :time (b / before
            :op1 (p / present-01
                  :ARG0 w
                  :ARG1 (a / and
                        :op1 (t / thing
                              :ARG2-of (d3 / define-01
                                    :ARG1 (f2 / fairness))
                              :quant (s3 / several)
                              :ARG1-of (d4 / describe-01
                                    :ARG0 (s4 / section
                                          :mod "5.4.2")))
                        :op2 (t2 / thing
                              :ARG2-of (s5 / solve-01)
                              :mod (t3 / technical)
                              :purpose (b2 / build-01
                                    :ARG1 (t4 / thing
                                          :name (n / name
                                                :op1 "ADS")
                                          :ARG0-of (r / realize-01
                                                :ARG1 (f3 / fairness))))))))
      :location (s6 / section
            :mod "5.4.3"))

# ::snt The various sources of unfairness  ADS are often based on machine learning algorithms trained on collected data.
# File 89

(b / base-02
      :ARG1 (t / thing
            :ARG2-of (s / source-01
                  :ARG1 (f / fair-01
                        :polarity -))
            :mod (v / various))
      :ARG2 (a / algorithm
            :instrument-of (l / learn-01
                  :mod (m / machine))
            :ARG1-of (t2 / train-01
                  :ARG2 (d / data
                        :ARG1-of (c / collect-01))))
      :frequency (o / often))

# ::snt There are multiple  potential sources o f unfairness in this process .135 Unfair treatment can result, for example, from the  content of the training data, the way the data is labelled or the feature selection .136   Biased training data.
# File 89

(m / multi-sentence
      :snt1 (s / source-02
            :ARG1 (f / fairness
                  :polarity -)
            :ARG2 (p / process-02
                  :mod (t / this))
            :mod (p2 / potential)
            :quant (m2 / multiple))
      :snt2 (p3 / possible-01
            :li 135
            :ARG1 (r / result-01
                  :ARG1 (t2 / treat-01
                        :ARG1-of (f2 / fair-01
                              :polarity -))
                  :ARG2 (o / or
                        :op1 (c / content
                              :poss (d / data
                                    :purpose (t3 / train-01)))
                        :op2 (w / way
                              :manner-of (l / label-01
                                    :ARG1 d))
                        :op3 (s2 / select-01
                              :ARG1 (f3 / feature))))
            :ARG0-of (e / exemplify-01))
      :snt3 (d2 / data
            :topic (t4 / train-01)
            :ARG1-of (b / bias-01)
            :li 136))

# ::snt 136  Gal Yona ; A Gentle Introduction to the Discussion on Algorithmic Fairness; 2017; https://towardsdatascience.com/agentle -introduction -to-the -discussion -on-algorithmic -fairness -740bbb469b6 .
# File 89

(p / publication-91
      :ARG2 136
      :ARG0 (p2 / person
            :name (n / name
                  :op1 "Gal"
                  :op2 "Yona"))
      :ARG1 (ii / introduce-02
            :ARG2 (d / discuss-01
                  :ARG1 (f / fairness
                        :mod (a / algorithm)))
            :ARG1-of (g / gentle-01))
      :time (d2 / date-entity
            :year 2017)
      :medium (u / url-entity
            :value "https://towardsdatascience.com/agentle-introduction-to-the-discussion-on-algorithmic-fairness -740bbb469b6"))

# ::snt 136  Gal Yona ; A Gentle Introduction to the Discussion on Algorithmic Fairness; 2017; https://towardsdatascience.com/agentle -introduction -to-the -discussion -on-algorithmic -fairness -740bbb469b6 .
# File 89

(p / publication-91
      :ARG2 136
      :ARG0 (p2 / person
            :name (n / name
                  :op1 "Gal"
                  :op2 "Yona"))
      :ARG1 (ii / introduce-02
            :ARG2 (d / discuss-01
                  :ARG1 (f / fairness
                        :mod (a / algorithm)))
            :ARG1-of (g / gentle-01))
      :time (d2 / date-entity
            :year 2017)
      :medium (u / url-entity
            :value "https://towardsdatascience.com/agentle-introduction-to-the-discussion-on-algorithmic-fairness -740bbb469b6"))

# ::snt 140  Joy Buolamwini, Timnit Gebru  ; 1st Conference on Fairness, Accountability and Transparency; PMLR; (81); 2018.
# File 89

(c / conference
      :li 140
      :name (n / name
            :op1 "Conference"
            :op2 "on"
            :op3 "Fairness"
            :op4 "Accountability"
            :op5 "and"
            :op6 "Transparency")
      :ord (o / ordinal-entity
            :value 1)
      :ARG1-of (d / describe-01
            :ARG0 (p / publication
                  :name (n2 / name
                        :op1 "PMLR")
                  :ARG1-of (c2 / cite-01
                        :ARG2 81)))
      :ARG2-of (ii / include-91
            :ARG1 (a / and
                  :op1 (p2 / person
                        :name (n3 / name
                              :op1 "Joy"
                              :op2 "Buolamwini"))
                  :op2 (p3 / person
                        :name (n4 / name
                              :op1 "Timnit"
                              :op2 "Gebru"))))
      :time (d2 / date-entity
            :year 2018))

# ::snt Differences in classification  accuracy  between different groups are a major and underappreci ated source of unfairness.
# File 89

(s / source-02
      :ARG0 (d / differ-02
            :ARG1 (a / accurate
                  :domain (g / group
                        :ARG1-of d)))
      :ARG1 (f / fair-01
            :polarity -)
      :ARG1-of (m / major-02)
      :ARG1-of (a2 / appreciate-02
            :degree (u / under)))

# ::snt Definitions of fairness  Discussions of fairness in ADS are often too rhetoric al and lack rigour and precision.
# File 89

(m / multi-sentence
      :snt1 (d / define-01
            :ARG1 (f / fairness))
      :snt2 (a / and
            :op1 (h / have-degree-91
                  :ARG1 (d2 / discuss-01
                        :ARG1 (f2 / fairness)
                        :medium (p / product
                              :name (n / name
                                    :op1 "ADS")))
                  :ARG2 (r / rhetoric
                        :mod (a2 / al))
                  :ARG3 (t / too)
                  :frequency (o / often))
            :op2 (l / lack-01
                  :ARG0 d2
                  :ARG1 (a3 / and
                        :op1 (r2 / rigor)
                        :op2 (p2 / precise)))))

# ::snt In fact,  characterising the notion of fairness is far from trivial and many different and sometimes  incompatible definitions have been proposed .141 There is a growing body  of work on this topic and  we point the reader to Baroc as and Selbst142 and the survey by Romei and Ruggieri143 for more  comprehensive introductions.
# File 89

(a / and
      :li 141
      :op1 (b / body
            :ARG1-of (g / grow-01)
            :consist-of (w / work-01
                  :ARG1 (t / topic
                        :mod (t2 / this))))
      :op2 (p / point-01
            :ARG0 (w2 / we)
            :ARG1 (p2 / person
                  :ARG0-of (r / read-01))
            :ARG2 (a2 / and
                  :op1 (p3 / person
                        :name (n / name
                              :op1 "Baroc"))
                  :op2 (p4 / person
                        :name (n2 / name
                              :op1 "Selbst"))
                  :op3 (s / survey-01
                        :ARG0 (a3 / and
                              :op1 (p5 / person
                                    :name (n3 / name
                                          :op1 "Romei"))
                              :op2 (p6 / person
                                    :name (n4 / name
                                          :op1 "Ruggieri")))))
            :purpose (ii / introduce-02
                  :ARG1-of (h / have-degree-91
                        :ARG2 (c / comprehensive)
                        :ARG3 (m / more))))
      :op3 (p7 / propose-01
            :ARG1 (d / define-01
                  :ARG1-of (d2 / differ-02)
                  :ARG1-of (c2 / compatible
                        :polarity -
                        :frequency (s2 / sometimes))
                  :quant (m2 / many)))
      :op4 (t3 / trivial
            :polarity -
            :domain (c3 / characterize-01
                  :ARG1 (n5 / notion
                        :topic (f / fairness)))
            :mod (ii2 / in-fact)))

# ::snt At a high level, existing definitions of fairness usually rely on  'protected groups' .
# File 89

(r / rely-01
      :ARG0 (t / thing
            :ARG2-of (d / define-01
                  :ARG1 (f / fair-01))
            :ARG1-of (e / exist-01))
      :ARG1 (g / group
            :ARG1-of (p / protect-01))
      :mod (u / usual)
      :manner (l / level
            :ARG1-of (h / high-02)))

# ::snt For  example, it is well known that, in certain cities, there is a strong correlation between the reli gion or                                                                141  Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, Aaron Roth; Fairness in Criminal Justice Risk Assessments:  The State of the Art; Sociological Methods & Research; 2018.
# File 89

(m / multi-sentence
      :snt1 (e / exemplify-01
            :ARG0 (k / know-01
                  :ARG1 (c / correlate-01
                        :ARG1 (o / or
                              :op1 (g / government-organization
                                    :name (n / name
                                          :op1 "Reli"
                                          :op2 "Generation"))
                              :op2 (p / person
                                    :name (n2 / name
                                          :op1 "Hoda"
                                          :op2 "Heidari"))
                              :op3 (p2 / person
                                    :name (n3 / name
                                          :op1 "Shahin"
                                          :op2 "Jabbari"))
                              :op4 (p3 / person
                                    :name (n4 / name
                                          :op1 "Michael"
                                          :op2 "Kearns"))
                              :op5 (p4 / person
                                    :name (n5 / name
                                          :op1 "Aaron"
                                          :op2 "Roth")))
                        :ARG1-of (s / strong-02)
                        :location (c2 / city
                              :mod (c3 / certain)))
                  :degree (w / well)))
      :snt2 (p5 / publication-91
            :ARG1 (p6 / publication
                  :name (n6 / name
                        :op1 "The"
                        :op2 "State"
                        :op3 "of"
                        :op4 "the"
                        :op5 "Art"
                        :op6 ","
                        :op7 " Sociological"
                        :op8 "Methods"
                        :op9 "&"
                        :op10 "Research"))
            :ARG4 (a / assess-01
                  :ARG1 (f / fairness)
                  :ARG2 (r / risk-01
                        :ARG2 (j / justice
                              :mod (c4 / criminal))))
            :time (d / date-entity
                  :year 2018)))

# ::snt EPV is another measure of fairness, which is widely accepted  and ado pted by the psychometrics community .146 It guarantees that a system is fair in the sense of  being free of predictive biases.
# File 89

(m / multi-sentence
      :li 146
      :snt2 (g / guarantee-01
            :ARG0 (ii / it)
            :ARG1 (f / fair-01
                  :ARG1 (s / system)
                  :manner (f2 / free-04
                        :ARG1 s
                        :ARG2 (b / bias-01
                              :ARG1-of (p / predict-01)))))
      :snt1 (m2 / measure-01
            :ARG1 (f3 / fair-01)
            :ARG2 (t / thing
                  :name (n / name
                        :op1 "EPV"))
            :mod (a / another)
            :ARG1-of (a2 / accept-01
                  :ARG0 (c / community
                        :mod (p2 / psychometrics))
                  :ARG1-of (w / wide-02))
            :ARG1-of (b2 / butt-in-01
                  :ARG0 c)))

# ::snt 147  Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P. Gummadi ; Fairness Beyond Disparate  Treatment & Disparate Impact: Learning Classification without Disparate Mistreatment; 26th International Conference  on World Wide Web  (WWW '17); 2017.
# File 89

(p / publication-91
      :ARG7 147
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Muhammad"
                        :op2 "Bilal"
                        :op3 "Zafar"))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "Isabel"
                        :op2 "Valera"))
            :op3 (p4 / person
                  :name (n3 / name
                        :op1 "Manuel"
                        :op2 "Gomez"
                        :op3 "Roduez"))
            :op4 (p5 / person
                  :name (n4 / name
                        :op1 "Krishna"
                        :op2 "P."
                        :op3 "Gummadi")))
      :ARG1 (p6 / publication
            :name (n5 / name
                  :op1 "Fairness"
                  :op2 "Beyond"
                  :op3 "Disparate"
                  :op4 "Treatment"
                  :op5 "and"
                  :op6 "Disparate"
                  :op7 "Impact"
                  :op8 "Learning"
                  :op9 "without"
                  :op10 "Disparate"
                  :op11 "Mistreatment"))
      :ARG4 (c / conference
            :name (n6 / name
                  :op1 "International"
                  :op2 "Conference")
            :location p6
            :name (n7 / name
                  :op1 "World"
                  :op2 "Wide"
                  :op3 "Web"))
      :time (d / date-entity
            :year 2017)
      :ord (o / ordinal-entity
            :value 26))

# ::snt Understanding algorithmic decision -making: Opportunities and challenges      45 • Equali sed false positive ensures that people who do not pay back their loan have equal  opportunity to get a loan:   𝑃𝑃{𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷 =𝐴𝐴𝐷𝐷𝐷𝐷𝐷𝐷𝐴𝐴𝐴𝐴|𝑅𝑅𝑅𝑅𝐷𝐷𝐷𝐷 =𝑊𝑊ℎ𝐷𝐷𝐴𝐴𝐷𝐷,𝑊𝑊𝐷𝐷𝐷𝐷′𝐴𝐴 𝐴𝐴𝑅𝑅𝑝𝑝  𝑏𝑏𝑅𝑅𝐷𝐷𝑘𝑘}~𝑃𝑃{𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷𝐷 =𝐴𝐴𝐷𝐷𝐷𝐷𝐷𝐷𝐴𝐴𝐴𝐴|𝑅𝑅𝑅𝑅𝐷𝐷𝐷𝐷 =𝐵𝐵𝐵𝐵𝑅𝑅𝐷𝐷𝑘𝑘,𝑊𝑊𝐷𝐷𝐷𝐷′𝐴𝐴 𝐴𝐴𝑅𝑅𝑝𝑝  𝑏𝑏𝑅𝑅𝐷𝐷𝑘𝑘}  Incompatibility of different definitions of fairness .
# File 89

(m / multi-sentence
      :snt1 (a / and
            :op1 (o / opportunity)
            :op2 (c / challenge-01)
            :topic (u / understand-01
                  :ARG1 (d / decide-01
                        :mod (a2 / algorithm))))
      :snt2 (e / ensure-01
            :ARG0 (l / law
                  :name (n / name
                        :op1 "Equali"
                        :op2 "Sed")
                  :mod (f / false))
            :ARG1 (h / have-03
                  :ARG0 (p / person
                        :ARG0-of (p2 / pay-01
                              :polarity -
                              :ARG3 (l2 / loan-01
                                    :ARG2 p)))
                  :ARG1 (o2 / opportunity
                        :ARG1-of (e2 / equal-01)))))

# ::snt Considering that several definitions of fairness  exist, it is useful to understand how they relate to each other.
# File 89

(u / useful-05
      :ARG1 (u2 / understand-01
            :ARG1 (t / thing
                  :manner-of (r / relate-01
                        :ARG1 (t2 / they)
                        :ARG2 (t3 / thing
                              :ARG2-of (d / define-01
                                    :ARG1 (f / fair-01))
                              :quant (s / several)))))
      :condition (c / consider-02
            :ARG1 (e / exist-01
                  :ARG1 t3)))

# ::snt One of the lessons to be drawn from these incompatibility results is that experts can only provide  precise definitions and explain them , whereas  the ultimate choices in terms of fairness a re not  technical, but a matter of public policy.
# File 89

(c / contrast-01
      :ARG1 (p / possible-01
            :ARG1 (a / and
                  :op1 (p2 / provide-01
                        :ARG0 (p3 / person
                              :ARG1-of (e / expert-01))
                        :ARG1 (d / define-01
                              :mod (p4 / precise)))
                  :op2 (e2 / explain-01
                        :ARG0 p3
                        :ARG1 d))
            :mod (o / only))
      :ARG2 c
      :ARG1 (c2 / choose-01
            :mod (u / ultimate)
            :topic (f / fairness)
            :mod (t / technical
                  :polarity -))
      :ARG2 (m / matter
            :topic (p5 / policy-01
                  :ARG2 (p6 / public))
            :domain c2)
      :ARG1-of (ii / include-91
            :ARG2 (l / lesson
                  :ARG1-of (d2 / draw-02
                        :ARG2 (r / result-01
                              :mod (c3 / compatible
                                    :polarity -)
                              :mod (t2 / this))))))

# ::snt Towards fairness- aware algorithms   Several research groups have focused on the design of ADS that attempt to address fairness and  discrimination issues.151 A detailed description of these schemes is outwith th e scope of this report.
# File 89

(m / multi-sentence
      :snt1 (f / focus-01
            :ARG0 (g / group
                  :ARG0-of (r / research-01)
                  :quant (s / several))
            :ARG1 (d / design-01
                  :ARG1 (p / product
                        :name (n / name
                              :op1 "ADS")
                        :ARG0-of (a / attempt-01
                              :ARG1 (a2 / address-02
                                    :ARG0 p
                                    :ARG1 (ii / issue-02
                                          :ARG0 (a3 / and
                                                :op1 (f2 / fairness)
                                                :op2 (d2 / discriminate-02)))))))
            :topic (a4 / algorithm
                  :ARG0-of (r2 / realize-01
                        :ARG1 (f3 / fairness))))
      :snt2 (d3 / describe-01
            :li 151
            :ARG1 (s2 / scheme-01
                  :mod (t / this))
            :ARG1-of (d4 / detail-01)
            :part-of (s3 / scope
                  :poss (r3 / report
                        :mod (t2 / this)))))

# ::snt In a nutshell, fairness adds an extra constraint to the learning algorithm.
# File 89

(a / add-02
      :ARG0 (f / fairness)
      :ARG1 (c / constraint
            :mod (e / extra))
      :ARG2 (a2 / algorithm
            :instrument-of (l / learn-01))
      :manner (n / nutshell))

# ::snt hypothesis) that minimi se the classification errors on the training data , while satisfying the  fairness constraint.
# File 89

(p / propose-01
      :ARG1 (m / minimize-01
            :ARG1 (e / error
                  :mod (c / classify-01)
                  :location (d / data
                        :purpose (t / train-01)))
            :time (s / satisfy-01
                  :ARG1 (c2 / constraint
                        :mod (f / fairness)))))

# ::snt There is therefore generally a trade- off between fairness and accuracy.
# File 89

(c / cause-01
      :ARG1 (t / trade-off-02
            :ARG1 (f / fairness)
            :ARG2 (a / accurate))
      :ARG1-of (g / general-02))

# ::snt Fairness -aware ADS rely on one of the following approaches :152  • Pre-processing approach:  This consists of pre -processing the training data to re move the  sources of unfairness or to map the training data into a space where the dependencies between  sensitive attributes and class labels disappear .153 Kamiran and Calders ,154 and Hajian et al.155  adopt this approach by performing a controlled distortion of t he training data that leads to an                                                                150  Jeff Larson, Surya Mattu, Lauren Kirchner and Julia Angwin  ; How We Analyzed the COMPAS  Recidivism Algorithm;  Propublica ; https://www.propublica.org/article/how -we-analyzed -the -compas -recidivism algorithm ; 2016.
# File 89

(m / multi-sentence
      :snt1 (r / rely-01
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "ADT")
                  :ARG0-of (r2 / realize-01
                        :ARG1 (f / fairness)))
            :ARG1 (a / approach-02
                  :quant 1
                  :ARG1-of (ii / include-91
                        :ARG2 (a2 / approach-02
                              :ARG1-of (f2 / follow-01)))))
      :snt2 (c / consist-01
            :li 153
            :ARG1 (t / this)
            :ARG2 (p / process-01
                  :ARG1 (d / data
                        :purpose (t2 / train-01))
                  :purpose (o2 / or
                        :op1 (m2 / move-01
                              :ARG1 (s / source-02
                                    :ARG1 (f3 / fairness
                                          :polarity -))
                              :mod (a3 / again))
                        :op2 (m3 / map-01
                              :ARG1 d
                              :ARG2 (s2 / space
                                    :location-of (d2 / disappear-01
                                          :ARG1 (d3 / depend-01
                                                :ARG0 (a4 / attribute-01
                                                      :ARG1-of (s3 / sensitive-03))
                                                :ARG1 (l / label
                                                      :mod (c2 / class)))))))
                  :manner (d4 / distort-01
                        :ARG1 d
                        :ARG1-of (c3 / control-01))))
      :snt3 (p2 / publication-91
            :ARG0 (a5 / and
                  :op1 (p3 / person
                        :name (n2 / name
                              :op1 "Jeff"
                              :op2 "Larson"))
                  :op2 (p4 / person
                        :name (n3 / name
                              :op1 "Surya"
                              :op2 "Mattu"))
                  :op3 (p5 / person
                        :name (n4 / name
                              :op1 "Lauren"
                              :op2 "Kirchner"))
                  :op4 (p6 / person
                        :name (n5 / name
                              :op1 "Julia"
                              :op2 "Angwin")))
            :ARG1 (p7 / publication
                  :name (n6 / name
                        :op1 "How"
                        :op2 "We"
                        :op3 "Analyze"
                        :op4 "the"
                        :op5 "Compas"
                        :op6 "Recidivism"
                        :op7 "Algorithm"))
            :ARG4 (u / url-entity
                  :value "https://www.propublica.org/article/how-we-analyzed -the-compas-recidivism"))
      :time (d5 / date-entity
            :year 2016))

# ::snt Fairness -aware ADS rely on one of the following approaches :152  • Pre-processing approach:  This consists of pre -processing the training data to re move the  sources of unfairness or to map the training data into a space where the dependencies between  sensitive attributes and class labels disappear .153 Kamiran and Calders ,154 and Hajian et al.155  adopt this approach by performing a controlled distortion of t he training data that leads to an                                                                150  Jeff Larson, Surya Mattu, Lauren Kirchner and Julia Angwin  ; How We Analyzed the COMPAS  Recidivism Algorithm;  Propublica ; https://www.propublica.org/article/how -we-analyzed -the -compas -recidivism algorithm ; 2016.
# File 89

(m / multi-sentence
      :snt1 (r / rely-01
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "ADT")
                  :ARG0-of (r2 / realize-01
                        :ARG1 (f / fairness)))
            :ARG1 (a / approach-02
                  :quant 1
                  :ARG1-of (ii / include-91
                        :ARG2 (a2 / approach-02
                              :ARG1-of (f2 / follow-01)))))
      :snt2 (c / consist-01
            :li 153
            :ARG1 (t / this)
            :ARG2 (p / process-01
                  :ARG1 (d / data
                        :purpose (t2 / train-01))
                  :purpose (o2 / or
                        :op1 (m2 / move-01
                              :ARG1 (s / source-02
                                    :ARG1 (f3 / fairness
                                          :polarity -))
                              :mod (a3 / again))
                        :op2 (m3 / map-01
                              :ARG1 d
                              :ARG2 (s2 / space
                                    :location-of (d2 / disappear-01
                                          :ARG1 (d3 / depend-01
                                                :ARG0 (a4 / attribute-01
                                                      :ARG1-of (s3 / sensitive-03))
                                                :ARG1 (l / label
                                                      :mod (c2 / class)))))))
                  :manner (d4 / distort-01
                        :ARG1 d
                        :ARG1-of (c3 / control-01))))
      :snt3 (p2 / publication-91
            :ARG0 (a5 / and
                  :op1 (p3 / person
                        :name (n2 / name
                              :op1 "Jeff"
                              :op2 "Larson"))
                  :op2 (p4 / person
                        :name (n3 / name
                              :op1 "Surya"
                              :op2 "Mattu"))
                  :op3 (p5 / person
                        :name (n4 / name
                              :op1 "Lauren"
                              :op2 "Kirchner"))
                  :op4 (p6 / person
                        :name (n5 / name
                              :op1 "Julia"
                              :op2 "Angwin")))
            :ARG1 (p7 / publication
                  :name (n6 / name
                        :op1 "How"
                        :op2 "We"
                        :op3 "Analyze"
                        :op4 "the"
                        :op5 "Compas"
                        :op6 "Recidivism"
                        :op7 "Algorithm"))
            :ARG4 (u / url-entity
                  :value "https://www.propublica.org/article/how-we-analyzed -the-compas-recidivism"))
      :time (d5 / date-entity
            :year 2016))

# ::snt 153  C. Dwork, M. Hardt, T. Pitassi, O. Reingold, and R. Zemel; Fairness through awareness; In novations in Theoretical  Computer Science; 2012.
# File 89

(p / publication-91
      :ARG7 153
      :ARG1 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "C."
                        :op2 "Dwork"))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "M."
                        :op2 "Hardt"))
            :op3 (p4 / person
                  :name (n3 / name
                        :op1 "T."
                        :op2 "Pitassi"))
            :op4 (p5 / person
                  :name (n4 / name
                        :op1 "O."
                        :op2 "Reingold"))
            :op5 (p6 / person
                  :name (n5 / name
                        :op1 "R."
                        :op2 "Zemel")))
      :ARG4 (p7 / publication
            :name (n6 / name
                  :op1 "Innovations"
                  :op2 "in"
                  :op3 "Theoretical"
                  :op4 "Computer"
                  :op5 "Science"))
      :time (d / date-entity
            :year 2012)
      :topic (f / fairness
            :manner (a2 / awareness)))

# ::snt 156  T. Kamishima, S.Ahako, H.Asoh, J. Sakuma; Fairness -aware Classifier w ith Prejudice Remover Regularized; PADM; 2011.
# File 89

(m / multi-sentence
      :li 156
      :snt1 (a / and
            :op1 (p / person
                  :name (n / name
                        :op1 "T."
                        :op2 "Kamishima"))
            :op2 (p2 / person
                  :name (n2 / name
                        :op1 "S."
                        :op2 "Ahako"))
            :op3 (p3 / person
                  :name (n3 / name
                        :op1 "H."
                        :op2 "Asoh"))
            :op4 (p4 / person
                  :name (n4 / name
                        :op1 "J."
                        :op2 "Sakuma")))
      :snt2 (c / classifier
            :ARG0-of (r / realize-01
                  :ARG1 (f / fairness))
            :ARG0-of (r2 / remove-01
                  :ARG1 (p5 / prejudice-01))
            :ARG1-of (r3 / regularize-01)
            :source (o / organization
                  :name (n5 / name
                        :op1 "PADM"))
            :time (d / date-entity
                  :year 2011)))

# ::snt Fairness.
# File 89

(f / fairness)

# ::snt Definitions of fairness that consider individuals instead of groups are also  worth considering .185 Final ly, it has been shown that it is impossible to satisfy all notions of fairness  and, at the same time, maximi se accuracy and fairness .186 It is therefore necessary to consider  challenging trade- offs, and these trade- offs have to be discussed by stakeholders, not statisticians  or computer scientists.
# File 89

(m / multi-sentence
      :li 185
      :snt1 (w / worth-02
            :ARG1 (d / define-01
                  :ARG1 (f / fairness)
                  :ARG0-of (c / consider-02
                        :ARG1 (ii / individual
                              :ARG1-of (ii2 / instead-of-91
                                    :ARG2 (g / group)))))
            :ARG2 (c2 / consider-02
                  :ARG1 d)
            :mod (a / also))
      :snt2 (s / show-01
            :li 186
            :ARG1 (p / possible-01
                  :polarity -
                  :ARG1 (s2 / satisfy-02
                        :ARG1 (n / notion
                              :mod (a2 / all)
                              :topic (f2 / fairness))
                        :ARG2 (a3 / and
                              :op1 (a4 / accuracy)
                              :op2 (f3 / fairness)
                              :mod (m2 / maximum))
                        :time (t / time
                              :ARG1-of (s3 / same-01))))
            :mod (t2 / therefore))
      :snt3 (a5 / and
            :op1 (n2 / need-01
                  :ARG1 (c3 / consider-02
                        :ARG1 (t3 / trade-off-02
                              :ARG1-of (c4 / challenge-01))))
            :op2 (o / obligate-01
                  :ARG1 (d2 / discuss-01
                        :ARG0 (s4 / stake-01)
                        :ARG1 t3
                        :ARG1-of (c5 / contrast-01
                              :ARG2 (d3 / discuss-01
                                    :polarity -
                                    :ARG0 (o2 / or
                                          :op1 (s5 / statistician)
                                          :op2 (s6 / scientist
                                                :mod (c6 / computer)))
                                    :ARG1 t3))))))

# ::snt For example, it is not up to computer scientists to decide between different  definitions of fairness and its trade -off with accuracy.
# File 89

(r / responsible-03
      :polarity -
      :ARG0 (s / scientist
            :mod (c / computer))
      :ARG1 (d / decide-01
            :ARG0 s
            :ARG1 (b / between
                  :op1 (t / thing
                        :ARG2-of (d2 / define-01
                              :ARG1 (f / fair-01))
                        :ARG1-of (d3 / differ-02))
                  :op2 (t2 / trade-off-02
                        :ARG1 f
                        :ARG2 (a / accurate))))
      :ARG0-of (e / exemplify-01))

# ::snt 185  Aaron Roth; Between 'statistical ' and 'individual' notions of fairness in Machine Learning;  https://aaronsadventures.blogspot.fr/2017/11/between -statistica l-and -individual.html ; 2017.
# File 89

(p / publication-91
      :li 185
      :ARG0 (p2 / person
            :name (n / name
                  :op1 "Aaron"
                  :op2 "Roth"))
      :ARG1 (b / between
            :op1 (n2 / notion
                  :mod (s / statistics))
            :op2 (n3 / notion
                  :mod (ii / individual))
            :topic (f / fair-01)
            :mod (m / machine
                  :ARG0-of (l / learn-01)))
      :ARG4 (u / url-entity
            :value "https://aaronsadventures.blogspot.fr/2017/11/between-statistica-l-and-individual.html")
      :time (d / date-entity
            :year 2017))

# ::snt 186  Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, Aaron Roth; Fairness in Criminal Justice Risk Assessments:  The State of the Art; Sociological Methods & Research; 2018.
# File 89

(p / publication-91
      :li 186
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Richard"
                        :op2 "Berk"))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "Hoda"
                        :op2 "Heidari"))
            :op3 (p4 / person
                  :name (n3 / name
                        :op1 "Shahin"
                        :op2 "Jabbari"))
            :op4 (p5 / person
                  :name (n4 / name
                        :op1 "Michael"
                        :op2 "Kearns"))
            :op5 (p6 / person
                  :name (n5 / name
                        :op1 "Aaron"
                        :op2 "Roth")))
      :ARG1 (a2 / assess-01
            :ARG1 (f / fairness)
            :ARG2 (r / risk-01
                  :ARG2 (j / justice
                        :mod (c / criminal))))
      :ARG4 (p7 / publication
            :name (n6 / name
                  :op1 "The"
                  :op2 "State"
                  :op3 "of"
                  :op4 "the"
                  :op5 "Art"))
      :ARG7 p7
      :name (n7 / name
            :op1 "Social"
            :op2 "Methods"
            :op3 "&"
            :op4 "Research")
      :time (d / date-entity
            :year 2018))

# ::snt 187  Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, Aaron Roth; Fairness in Criminal Justice Risk Assessments:  The State of the Art; Sociological Methods & Research; 2018.
# File 89

(p / publication-91
      :li 187
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Richard"
                        :op2 "Berk"))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "Hoda"
                        :op2 "Heidari"))
            :op3 (p4 / person
                  :name (n3 / name
                        :op1 "Shahin"
                        :op2 "Jabbari"))
            :op4 (p5 / person
                  :name (n4 / name
                        :op1 "Michael"
                        :op2 "Kearns"))
            :op5 (p6 / person
                  :name (n5 / name
                        :op1 "Aaron"
                        :op2 "Roth")))
      :ARG1 (p7 / publication
            :name (n6 / name
                  :op1 "The"
                  :op2 "State"
                  :op3 "of"
                  :op4 "the"
                  :op5 "Art")
            :ARG1-of (a2 / assess-01
                  :ARG2 (r / risk-01
                        :ARG2 (j / justice
                              :mod (c / criminal)))))
      :ARG4 a
      :op1 (m / method
            :mod (s / sociology))
      :op2 (r2 / research-01)
      :time (d / date-entity
            :year 2018))

# ::snt The regulator  should be able to audit the ADS on a regular basis and these audits should include sufficient  tests of the systems to detect biases or other sources of unfairness.
# File 89

(a / and
      :op1 (r / recommend-01
            :ARG1 (p / possible-01
                  :ARG1 (a2 / audit-01
                        :ARG0 (p2 / person
                              :ARG0-of (r2 / regulate-01))
                        :ARG1 (p3 / product
                              :name (n / name
                                    :op1 "ADS"))
                        :ARG1-of (r3 / regular-02))))
      :op2 (r4 / recommend-01
            :ARG1 (ii / include-01
                  :ARG1 (t / test-01
                        :ARG1 (s / system)
                        :ARG0-of (s2 / suffice-01
                              :ARG1 (d / detect-01
                                    :ARG0 s
                                    :ARG1 (o / or
                                          :op1 (b / bias-01)
                                          :op2 (s3 / source-02
                                                :ARG1 (f / fair-01
                                                      :polarity -)
                                                :mod (o2 / other))))))
                  :ARG2 a2)))

# ::snt Complementary measures are necessary to make technical  and legal instruments effective in terms of fairness, explainabi lity and accountability.
# File 89

(n / need-01
      :ARG1 (m / measure-02
            :mod (c / complement-01))
      :purpose (m2 / make-02
            :ARG0 m
            :ARG1 (e / effective-04
                  :ARG0 (a / and
                        :op1 (ii / instrument
                              :mod (t / technical))
                        :op2 (ii2 / instrument
                              :ARG1-of (l / legal-02)))
                  :ARG1 (a2 / and
                        :op1 (f / fairness)
                        :op2 (e2 / explainabi
                              :mode expressive)
                        :op3 (h / honesty)
                        :op4 (a3 / accountable-02)))))

# ::snt Such unfairness could target virtual groups that are not necessarily identified in  society (such as, to take a few random examples, left -handed people, people who have learned  the same foreign language , or lik e the same movies).
# File 89

(p / possible-01
      :ARG1 (t / target-01
            :ARG0 (f / fairness
                  :polarity -
                  :mod (s / such))
            :ARG1 (g / group
                  :mod (v / virtual)
                  :ARG1-of (ii / identify-01
                        :ARG2 (s2 / society)
                        :ARG1-of (p2 / possible-01
                              :polarity -))
                  :example (o / or
                        :op1 (p3 / person
                              :mod (l / left-handed))
                        :op2 (p4 / person
                              :ARG0-of (l2 / learn-01
                                    :ARG1 (l3 / language
                                          :mod (f2 / foreign)
                                          :ARG1-of (s3 / same-01))))
                        :op3 (p5 / person
                              :ARG0-of (l4 / like-01
                                    :ARG1 (m / movie
                                          :ARG1-of (s4 / same-01)))))
                  :example-of (e / example
                        :quant (f3 / few)
                        :mod (r / random)))))

# ::snt In the context of US law, the AINow institute also calls for clarification on this matter :211  'In order to conduct the research necessary for examining, measuring, and evaluating the  impact of AI sy stems on public and private institutional decision -making, especially in terms  of key social concerns such as fairness and bias, researchers must be clearly allowed to test  systems across numerous domains and via numerous methodologies.
# File 89

(c / call-03
      :ARG0 (r / research-institute
            :name (n / name
                  :op1 "AINow"))
      :ARG1 (c2 / clarify-10
            :ARG1 (m / matter
                  :mod (t / this)))
      :mod (a / also)
      :ARG1-of (d / describe-01
            :ARG0 (p / publication
                  :ARG1-of (c3 / cite-01
                        :ARG2 211)))
      :condition (o / obligate-01
            :ARG2 (a2 / allow-01
                  :ARG1 (t2 / test-01
                        :ARG0 (p2 / person
                              :ARG0-of (r2 / research-01))
                        :ARG1 (s / system)
                        :path (a3 / and
                              :op1 (d2 / domain
                                    :quant (n2 / numerous))
                              :op2 (m2 / methodology
                                    :quant (n3 / numerous))))
                  :ARG1-of (c4 / clear-06))
            :purpose (c5 / conduct-01
                  :ARG1 (r3 / research-01
                        :ARG1-of (n4 / need-01
                              :purpose (a4 / and
                                    :op1 (e / examine-01
                                          :ARG1 (ii / impact-01
                                                :ARG0 ii
                                                :ARG0 (a5 / artificial))))
                              :op2 (m3 / measure-01
                                    :ARG1 ii)
                              :op3 (e2 / evaluate-01
                                    :ARG1 ii))
                        :ARG1-of (s2 / stem-02
                              :ARG2 (a6 / and
                                    :op1 (d3 / decide-01
                                          :ARG0 (ii2 / institution
                                                :ARG1-of (p3 / public-02)))
                                    :op2 (d4 / decide-01
                                          :ARG0 (ii3 / institution
                                                :ARG1-of (p4 / private-03)))
                                    :topic (c6 / concern-01
                                          :ARG0 (a7 / and
                                                :op1 (f / fairness)
                                                :op2 (b / bias-01))
                                          :ARG1-of (k / key-02)
                                          :mod (s3 / society))
                                    :mod (e3 / especially))))))
      :topic (l / law
            :mod (c7 / country
                  :name (n5 / name
                        :op1 "US"))))

# ::snt These challenges can  be classified into two main categories:   • Conceptual   – How to define complex and subjective notions such as discrimination, unfairness, privacy  or manipul ation.
# File 89

(p / possible-01
      :ARG1 (c / classify-01
            :ARG1 (c2 / challenge-01
                  :mod (t / this))
            :ARG2 (c3 / category
                  :quant 2
                  :mod (m / main)
                  :ARG1-of (m2 / mean-01
                        :ARG2 (c4 / conceptual
                              :domain (d / define-01
                                    :ARG1 (n / notion
                                          :mod (c5 / complex)
                                          :ARG1-of (s / subjective-03)
                                          :example (o / or
                                                :op1 (d2 / discriminate-02)
                                                :op2 (f / fairness
                                                      :polarity -)
                                                :op3 (p2 / private-02)
                                                :op4 (m3 / manipulate-02)))))))))

# ::snt As seen in Section 5.4, se veral incompatible definitions of fairness have been  proposed.
# File 89

(p / propose-01
      :ARG1 (d / define-01
            :ARG1 (f / fair-01)
            :ARG1-of (c / compatible-03
                  :polarity -)
            :mod (v / verifiable))
      :ARG1-of (s / see-01
            :location (s2 / section
                  :mod 5.4)))

# ::snt • Operational :   – How can the tensions between accuracy, cost and explainability/fairness/privacy be  reconciled?
# File 89

(p / possible-01
      :ARG1 (r / reconcile-01
            :ARG1 (t / tension
                  :mod (b / between
                        :op1 (a / accurate)
                        :op2 (c / cost-01)
                        :op3 p
                        :ARG1 (e / explain-01))
                  :op4 (f / fairness)
                  :op5 (p2 / private-02)))
      :manner (a2 / amr-unknown)
      :mod (o / operate-01))

# ::snt – What are the best technical approaches and mechanisms to provide explainability,  fairness and privacy in ADS?
# File 89

(a / and
      :op1 (a2 / approach-02)
      :op2 (m / mechanism)
      :mod (t / technical)
      :ARG1-of (h / have-degree-91
            :ARG2 (g / good-02)
            :ARG3 (m2 / most))
      :purpose (p / provide-01
            :ARG1 (a3 / and
                  :op1 (e / explain-01
                        :ARG1 (p2 / product
                              :name (n / name
                                    :op1 "ADS")))
                  :op2 (f / fairness)
                  :op3 (p3 / privacy))
            :ARG2 p2)
      :ARG0-of p
      :domain (a4 / amr-unknown))

# ::snt For example, fairness can be achieved using a preprocessing, in -processing or post- processing approach (see Section 5.4.3).
# File 89

(p / possible-01
      :ARG1 (a / achieve-01
            :ARG1 (f / fair-01)
            :manner (o / or
                  :op1 (p2 / process-01
                        :time (b / before))
                  :op2 (p3 / process-01
                        :manner (ii / in-process-02))
                  :op3 (a2 / approach-02
                        :time (a3 / after
                              :op1 p2))))
      :ARG0-of (e / exemplify-01)
      :ARG1-of (d / describe-01
            :ARG0 (s / section
                  :mod "5.4.3")))

# ::snt The same question holds for  fairness by design and privacy by design.
# File 89

(h / hold-02
      :ARG0 (q / question-01
            :ARG1-of (s / same-01))
      :ARG1 (a / and
            :op1 (f / fairness
                  :manner (d / design-01))
            :op2 (p / private-02
                  :manner (d2 / design-01))))

# ::snt – How should explainability, fairness and  privacy of ADS be assessed?
# File 89

(r / recommend-01
      :ARG1 (a / assess-01
            :ARG1 (a2 / and
                  :op1 (e / explain-01
                        :ARG1 (p / product
                              :name (n / name
                                    :op1 "ADS")))
                  :op2 (f / fair-01
                        :ARG1 p)
                  :op3 (p2 / private-02
                        :ARG1 p))
            :ARG2 (a3 / amr-unknown)))

# ::snt More research  is also needed to design methods and tools to enhance the security, safety, priva cy, fairness  and explainability of ADS.
# File 89

(n / need-01
      :ARG1 (r / research-01
            :ARG1 (d / design-01
                  :ARG1 (a / and
                        :op1 (m / method)
                        :op2 (t / tool))
                  :ARG3 (e / enhance-01
                        :ARG0 a
                        :ARG1 (a2 / and
                              :op1 (s / security)
                              :op2 (s2 / safe-01)
                              :op3 (p / privilege-01)
                              :op4 (f / fairness)
                              :op5 (e2 / explain-01
                                    :ARG1 (p2 / product
                                          :name (n2 / name
                                                :op1 "ADS"))))))
            :mod (m2 / more))
      :mod (a3 / also))

# ::snt Further progress has also to  be made on the characterisation of notions like explainability and fairness and their  implementation 'by design '.
# File 89

(o / obligate-01
      :ARG2 (p / progress-01
            :ARG1 (a / and
                  :op1 (c / characterize-01
                        :ARG1 (n / notion
                              :example (a2 / and
                                    :op1 (e / explain-01)
                                    :op2 (f / fair-01))))
                  :op2 (ii / implement-01
                        :ARG1 n
                        :manner (d / design-01)))
            :degree (f2 / further))
      :mod (a3 / also))

# ::snt Engineers should be trained and supervised,  in order to consider essential  requirements such as fairness or explainability from the beginning of the design phase and  throughout the ADS development cycle.
# File 89

(r / recommend-01
      :ARG1 (a / and
            :op1 (t / train-01
                  :ARG2 (p / person
                        :ARG0-of (e / engineer-01)))
            :op2 (s / supervise-01
                  :ARG1 p)
            :purpose (c / consider-02
                  :ARG0 p
                  :ARG1 (t2 / thing
                        :ARG1-of (r2 / require-01)
                        :mod (e2 / essential)
                        :example (o / or
                              :op1 (f / fairness)
                              :op2 (e3 / explain-01
                                    :ARG1-of (p2 / possible-01))))
                  :time (a2 / and
                        :op1 (b / begin-01
                              :ARG1 (p3 / phase
                                    :mod (d / design-01)))
                        :op2 (c2 / cycle-02
                              :ARG1 (d2 / develop-02
                                    :ARG1 (p4 / product
                                          :name (n / name
                                                :op1 "ADS"))))))))

# ::snt Most ADS designers and developers are not experts in privacy, security, fairness o r explainability.
# File 89

(e / expert-01
      :polarity -
      :ARG1 (a / and
            :op1 (p / person
                  :ARG0-of (d / design-01
                        :ARG1 (p2 / product
                              :name (n / name
                                    :op1 "ADS"))))
            :op2 (p3 / person
                  :ARG0-of (d2 / develop-02
                        :ARG1 p2))
            :quant (m / most))
      :ARG2 (a2 / and
            :op1 (p4 / private-02)
            :op2 (s / security)
            :op3 (f / fairness)
            :op4 (e2 / explain-01
                  :ARG1-of (p5 / possible-01))))

# ::snt It  is therefore important to provide tools and methodologies to help them reconcile the tensions that  exist between accuracy, cost and explainability/fairness/privacy.
# File 89

(c / cause-01
      :ARG1 (ii / important-01
            :ARG1 (p / provide-01
                  :ARG1 (a / and
                        :op1 (t / tool)
                        :op2 (m / methodology))
                  :purpose (h / help-01
                        :ARG1 (r / reconcile-01
                              :ARG0 (t2 / they)
                              :ARG1 (t3 / tension
                                    :ARG1-of (e / exist-01)
                                    :mod (b / between
                                          :op1 (a2 / accuracy)
                                          :op2 (c2 / cost)
                                          :op3 (s / slash
                                                :op1 (e2 / explain-01
                                                      :ARG1-of (p2 / possible-01))
                                                :op2 (f / fairness)
                                                :op3 (p3 / privacy))))
                              :ARG2 t2)))))

# ::snt Dillon Reisman and his colleagues have already advocated AIA as a ' practical framework for public  agency accountability'  in a recent AINow Institute report .226 Beyond a 'self-assessment of existing  and proposed automated d ecision systems, evaluating potential impacts on fairness, justice, bias,  or other concerns across affected communities ', they emphasi se the need for ' researcher review  processes before the system has been acquired '.
# File 89

(e / emphasize-01
      :li 226
      :ARG0 (a / and
            :op1 (p / person
                  :name (n / name
                        :op1 "Dillon"
                        :op2 "Reisman"))
            :op2 (p2 / person
                  :ARG0-of (h / have-rel-role-91
                        :ARG1 p
                        :ARG2 (c / colleague))))
      :ARG1 (n2 / need-01
            :ARG1 (r / review-01
                  :ARG0 (p3 / person
                        :ARG0-of (r2 / research-01))
                  :ARG1 (p4 / process-02)
                  :time (b / before
                        :op1 (a2 / acquire-01
                              :ARG1 (s / system)))))
      :time (a3 / already)
      :medium (r3 / report
            :source (o / organization
                  :name (n3 / name
                        :op1 "AINow"
                        :op2 "Institute"))
            :time (r4 / recent))
      :manner (f / framework
            :ARG1-of (p5 / practical-02)
            :purpose (a4 / accountable-02
                  :ARG0 (a5 / agency
                        :ARG1-of (p6 / public-02)))
            :domain o
            :name (n4 / name
                  :op1 "AIA"))
      :manner (a6 / assess-01
            :ARG0 a
            :ARG1 a
            :ARG2 (a7 / and
                  :op1 (s2 / system
                        :ARG0-of (d / decide-01)
                        :ARG1-of (a8 / automate-01)
                        :ARG1-of (e2 / exist-01))
                  :op2 (s3 / system
                        :ARG1-of (p7 / propose-01))
                  :ARG0-of (e3 / evaluate-01
                        :ARG1 (ii / impact-01
                              :ARG1 (o2 / or
                                    :op1 (f2 / fairness)
                                    :op2 (j / justice)
                                    :op3 (b2 / bias)
                                    :op4 (c2 / concern-01
                                          :mod (o3 / other)))
                              :mod (p8 / potential))
                        :location (a9 / across
                              :op1 (c3 / community
                                    :ARG1-of (a10 / affect-01)))))))

# ::snt As discussed in Chapter 5, the expected  properties include fairness, privacy, reliability, security, accuracy, etc.
# File 89

(ii / include-01
      :ARG1 (a / and
            :op1 (f / fairness)
            :op2 (p / privacy)
            :op3 (r / rely-01
                  :ARG1-of (p2 / possible-01))
            :op4 (s / security)
            :op5 (a2 / accurate)
            :op6 (e / et-cetera))
      :ARG2 (p3 / property
            :ARG1-of (e2 / expect-01))
      :ARG1-of (d / discuss-01
            :ARG0 (c / chapter
                  :mod 5)))

# ::snt Great  care must be paid in particular to the justification of the choices made when several  properties are in tension (such as accuracy and fairness) and when different definitions are  available for a g iven objective (such as fairness or privacy).
# File 89

(o / obligate-01
      :ARG2 (p / pay-01
            :ARG1 (c / care-03
                  :mod (g / great))
            :ARG2 (j / justify-01
                  :ARG1 (c2 / choose-01
                        :time (a / and
                              :op1 (t / tense-03
                                    :ARG1 (p2 / property
                                          :quant (s / several)
                                          :example (a2 / and
                                                :op1 (a3 / accuracy)
                                                :op2 (f / fairness))))
                              :op2 (a4 / available-02
                                    :ARG2 (d / define-01
                                          :ARG1-of (d2 / differ-02))
                                    :purpose (o2 / objective
                                          :mod (s2 / subjective)
                                          :example (o3 / or
                                                :op1 (f2 / fairness)
                                                :op2 (p3 / privacy)))))))
            :mod (p4 / particular)))

# ::snt ORCAA reviews algorithms using an ' ethical matrix ' including criteria such as ' accuracy,  consistency, bias, transpare ncy, fairness and timeliness '.235   8.6.
# File 89

(m / multi-sentence
      :snt1 (r / review-01
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "ORCAA"))
            :ARG1 (a / algorithm)
            :manner (u / use-01
                  :ARG0 o
                  :ARG1 (m2 / matrix
                        :mod (e / ethics)
                        :ARG2-of (ii / include-01
                              :ARG1 (c / criteria
                                    :example (a2 / and
                                          :op1 (a3 / accuracy)
                                          :op2 (c2 / consistent-02)
                                          :op3 (b / bias-01)
                                          :op4 (t / transpare-ncy)
                                          :op5 (f / fairness)
                                          :op6 (t2 / timely)))))))
      :snt2 (h / have-li-91
            :ARG2 "8.6.235"))

# ::snt This end can be, for example, to be able to improve the fairness of an ADS or  to challenge a decision.
# File 89

(p / possible-01
      :ARG1 (o / or
            :op1 (p2 / possible-01
                  :ARG1 (ii / improve-01
                        :ARG1 (f / fair-01
                              :ARG1 (p3 / product
                                    :name (n / name
                                          :op1 "ADS")))))
            :op2 (c / challenge-01
                  :ARG1 (t / thing
                        :ARG1-of (d / decide-01)))
            :domain (e / end
                  :mod (t2 / this)))
      :ARG0-of (e2 / exemplify-01))

# ::snt In fact, transparency and  explainability may allow for the  discovery of deficiencies, but they do  not guarantee the reliability, security  and fairness of an ADS.
# File 89

(c / contrast-01
      :ARG1 (p / possible-01
            :ARG1 (a / allow-01
                  :ARG0 (a2 / and
                        :op1 (t / transparency)
                        :op2 (e / explain-01))
                  :ARG1 (d / discover-01
                        :ARG1 (d2 / deficiency)))
            :mod (ii / in-fact))
      :ARG2 (g / guarantee-01
            :polarity -
            :ARG0 a2
            :ARG1 (a3 / and
                  :op1 (r / rely-01
                        :ARG1 (p2 / product
                              :name (n / name
                                    :op1 "ADS"))
                        :ARG1-of (p3 / possible-01))
                  :op2 (s / security
                        :poss p2)
                  :op3 (f / fair-01
                        :ARG1 p2))))

# ::snt Last, but not least, we believe that, if appropriate accountability measures are taken, AD S also have  the potential to improve transparency and reduce unfairness and discrimination.
# File 89

(b / believe-01
      :li -1
      :ARG0 (w / we)
      :ARG1 (p / potential
            :domain (a / act-02
                  :ARG0 (g / government-organization
                        :name (n / name
                              :op1 "AD"
                              :op2 "S")))
            :purpose (a2 / and
                  :op1 (ii / improve-01
                        :ARG0 a
                        :ARG1 (t / transparency))
                  :op2 (r / reduce-01
                        :ARG0 a
                        :ARG1 (a3 / and
                              :op1 (f / fairness
                                    :polarity -)
                              :op2 (d / discriminate-02))))
            :mod (a4 / also)
            :condition (t2 / take-01
                  :ARG1 (m / measure-02
                        :ARG1 (a5 / accountable-02)
                        :ARG1-of (a6 / appropriate-02)))))

# ::snt Berk R., Heidari H., Jabbari S., Kearns M., Roth A.; Fairness in Criminal Justice Risk Assessments: The State  of the Art;  Sociological Methods & Research;   2018.
# File 89

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Berk"
                        :op2 "R."))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "Heidari"
                        :op2 "H."))
            :op3 (p4 / person
                  :name (n3 / name
                        :op1 "Jabbari"
                        :op2 "S"))
            :op4 (p5 / person
                  :name (n4 / name
                        :op1 "Kearns"
                        :op2 "M."))
            :op5 (p6 / person
                  :name (n5 / name
                        :op1 "Roth"
                        :op2 "A.")))
      :ARG1 (p7 / publication
            :name (n6 / name
                  :op1 "The"
                  :op2 "State"
                  :op3 "of"
                  :op4 "the"
                  :op5 "Art")
            :topic (a2 / assess-01
                  :ARG1 (f / fairness)
                  :ARG2 (r / risk-01
                        :ARG2 (j / justice
                              :mod (c / criminal)))))
      :ARG4 (a3 / and
            :op1 (m / method
                  :mod (s / sociology))
            :op2 (r2 / research-01))
      :time (d / date-entity
            :year 2018))

# ::snt STOA  | Panel for the Future of Science and Technology   82 Dwork C., Hardt M., Pitassi T., Reingold O., Zemel R.; Fairness through awareness; Proc.
# File 89

(p / publication-91
      :ARG7 82
      :ARG1 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Dwork"
                        :op2 "C."))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "Hardt"))
            :op3 (p4 / person
                  :name (n3 / name
                        :op1 "Pitassi"
                        :op2 "T."))
            :op4 (p5 / person
                  :name (n4 / name
                        :op1 "Reingold"
                        :op2 "O."))
            :op5 (p6 / person
                  :name (n5 / name
                        :op1 "Zemel"
                        :op2 "R.")))
      :ARG4 (p7 / publication
            :name (n6 / name
                  :op1 "Panel"
                  :op2 "for"
                  :op3 "the"
                  :op4 "Future"
                  :op5 "of"
                  :op6 "Science"
                  :op7 "and"
                  :op8 "Technology"))
      :ARG7 (p8 / publication
            :name (n7 / name
                  :op1 "Prol"
                  :op2 "a"
                  :op3 "Don't"
                  :op4 "Tell")))

# ::snt Kamishima T., Ahako S., Asoh H., Sakuma J.; Fairness-aware Classifier with Prejudice Remover Regularized;  PADM; 2011;   Kamiran, F., Calders, T.;  Classification with no discrimination by preferential sampli ng; Proc.
# File 89

(m / multi-sentence
      :snt1 (a / and
            :op1 (p / person
                  :name (n / name
                        :op1 "Kamishima")
                  :ARG0-of (c / classify-02))
            :op2 (p2 / person
                  :name (n2 / name
                        :op1 "Ahako")
                  :ARG0-of (c2 / classify-02))
            :op3 (p3 / person
                  :name (n3 / name
                        :op1 "Asoh"
                        :op2 "H.")
                  :ARG0-of (c3 / classify-02))
            :op4 (p4 / person
                  :name (n4 / name
                        :op1 "Sakuma"
                        :op2 "J.")
                  :ARG0-of (c4 / classify-02))
            :snt2 (a2 / and
                  :op1 (o / organization
                        :name (n5 / name
                              :op1 "PADM")
                        :time (d / date-entity
                              :year 2011))
                  :op2 (p5 / person
                        :name (n6 / name
                              :op1 "Kamiran")
                        :ARG0-of (c5 / classify-02))
                  :op3 (p6 / person
                        :name (n7 / name
                              :op1 "Calders")
                        :ARG0-of (c6 / classify-02))
                  :snt3 (p7 / publication
                        :name (n8 / name
                              :op1 "Prol")))))

# ::snt Zafar M., Valera I., Gomez Rodriguez M. and Gummadi K.; Fairness Beyond Disparate Treatment &  Disparate Impact: Learning Classification without Disparate Mistreatment; Proceedings  of the 26th  International Conference on World Wide Web (WWW '17); 2017.
# File 89

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Zafar"
                        :op2 "M."))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "Valera"
                        :op2 "I."))
            :op3 (p4 / person
                  :name (n3 / name
                        :op1 "Gomez"
                        :op2 "Rodriguez"))
            :op4 (p5 / person
                  :name (n4 / name
                        :op1 "Gummadi"
                        :op2 "K.")))
      :ARG1 (a2 / and
            :op1 (f / fairness
                  :location (b / beyond
                        :op1 (t / treat-01
                              :ARG1-of (d / discriminate-02
                                    :polarity -))))
            :op2 (ii / impact-01
                  :ARG0 t)
            :op3 (c / classify-01
                  :ARG3 (l / learn-01)
                  :manner t
                  :polarity -
                  :ARG1-of d))
      :ARG4 (p6 / Proceedings
            :part-of (c2 / conference
                  :name (n5 / name
                        :op1 "International"
                        :op2 "Conference"
                        :op3 "on"
                        :op4 "World"
                        :op5 "Wide"
                        :op6 "Web")
                  :ord (o / ordinal-entity
                        :value 26)
                  :time (d2 / date-entity
                        :year 2017))))

# ::snt Access, Fairness, and Accountability in the Law  of Search, 93 Cornell L. Rev.
# File 149

(a / and
      :op1 (a2 / access-01)
      :op2 (f / fairness)
      :op3 (a3 / accountable-02)
      :topic (l / law
            :mod (s / search-01))
      :ARG1-of (c / cite-01
            :ARG2 93
            :ARG2 (p / person
                  :name (n / name
                        :op1 "Cornell"
                        :op2 "L."
                        :op3 "Rev."))))

# ::snt In particular, the legal basis for any court challenge is contract law, where the standard  is generally the lack of fairness of contractual terms, i.e.
# File 149

(b / base-02
      :ARG1 (c / challenge-01
            :ARG0 (c2 / court)
            :mod (a / any))
      :ARG2 (l / law
            :mod (c3 / contract-02)
            :location-of (s / standard-02
                  :ARG1 c
                  :ARG2 (l2 / lack-01
                        :ARG0 (t / term
                              :ARG1-of c3)
                        :ARG1-of (m / mean-01
                              :ARG2 (f / fairness)))
                  :ARG1-of (g / general-02)))
      :mod (p / particular))

# ::snt They can  be classified as follows: Lack of respect for the rule of law: Current industry initiatives around AI  are narrowly focused on the development of technical standards, ethical  frameworks, and concepts such as fairness, transparency, and accountability.
# File 149

(m / multi-sentence
      :snt1 (p / possible-01
            :ARG1 (c / classify-01
                  :ARG1 (t / they)
                  :ARG2 (f / follow-04
                        :ARG2 (a / and
                              :op1 (l / lack-01
                                    :ARG1 (r / respect-01
                                          :ARG1 (r2 / rule-03
                                                :ARG1 (l2 / law))))
                              :op2 (f2 / focus-01
                                    :ARG1 (ii / initiate-01
                                          :ARG0 (ii2 / industry)
                                          :time (c2 / current)
                                          :topic (ii3 / intelligent-01
                                                :mod (a2 / artificial)))
                                    :ARG2 (d / develop-02
                                          :ARG1 (a3 / and
                                                :op1 (s / standard
                                                      :mod (t2 / technical))
                                                :op2 (f3 / framework
                                                      :mod (e / ethics))
                                                :op3 (c3 / concept
                                                      :example (a4 / and
                                                            :op1 (f4 / fairness)
                                                            :op2 (t3 / transparency)
                                                            :op3 (a5 / accountable-02)))))
                                    :ARG1-of (n / narrow-02)))))))

# ::snt Understanding how data use    In particular, the legal basis for any court challenge is contract law, where the standard  is generally the lack of fairness of contractual terms, i.e.
# File 149

(m / multi-sentence
      :snt1 (u / understand-01
            :ARG1 (t / thing
                  :manner-of (u2 / use-01
                        :ARG1 (d / data))))
      :snt2 (b / base-02
            :ARG1 (c / challenge-01
                  :ARG0 (c2 / court)
                  :mod (a / any))
            :ARG2 (l / law
                  :mod (c3 / contract-02)
                  :location-of (s / standard
                        :domain (l2 / lack-01
                              :ARG1 (f / fair-01
                                    :ARG1 (t2 / term
                                          :mod (c4 / contract-02)
                                          :ARG1-of (m2 / mean-01
                                                :ARG2 (t3 / thing
                                                      :ARG1-of (s2 / standard-02)))))
                              :ARG1-of (g / general-02))))
            :mod (p / particular)
            :ARG1-of (l3 / legal-02)))

# ::snt The EU General Data Protection Regulation (GDPR), which takes effect on 25 May  2018, requires a legal basis for processing data - and in addition to the principles of  fairness, accountability and transparency, includes the core principles of purpose  limitation and data minimisation,65  which have implications for the development, use  and application of AI systems.
# File 149

(a / and
      :op1 (r / require-01
            :ARG0 (l / law
                  :name (n / name
                        :op1 "General"
                        :op2 "Data"
                        :op3 "Protection"
                        :op4 "Regulation")
                  :mod (o / organization
                        :name (n2 / name
                              :op1 "EU"))
                  :ARG1-of (e / effect-03
                        :time (d / date-entity
                              :day 25
                              :month 5
                              :year 2018)))
            :ARG1 (t / thing
                  :ARG2-of (b / base-02
                        :ARG1 (p / process-01
                              :ARG1 (d2 / data)))
                  :ARG1-of (l2 / legal-02)))
      :op2 (ii / include-01
            :ARG1 (p2 / principle
                  :topic (a2 / and
                        :op1 (f / fairness)
                        :op2 (a3 / accountable-02)
                        :op3 (t2 / transparency))
                  :ARG1-of (c / core-02)
                  :ARG0-of (ii2 / imply-01
                        :ARG1 (a4 / and
                              :op1 (d3 / develop-02
                                    :ARG1 (s / system
                                          :mod (a5 / artificial)))
                              :op2 (u / use-01
                                    :ARG1 s)
                              :op3 (a6 / apply-02
                                    :ARG1 s)))
                  :ARG1-of (c2 / cite-01
                        :ARG2 65))
            :ARG2 (p3 / principle
                  :topic (a7 / and
                        :op1 (l3 / limit-01
                              :ARG1 (p4 / purpose))
                        :op2 (m / minimize-01
                              :ARG1 (d4 / data))))))

# ::snt Discrimination, unfairness, inaccuracies, bias: AI-driven identification,  profiling and automated decision-making may lead to unfair, discriminatory, or  biased outcomes.86 Individuals can be misclassified, misidentified, or judged  negatively, and such errors or biases may disproportionately affect certain  groups of people.
# File 149

(m / multi-sentence
      :li 86
      :snt1 (a / and
            :op1 (d / discriminate-02)
            :op2 (f / fair-01
                  :polarity -)
            :op3 (a2 / accurate
                  :polarity -)
            :op4 (b / bias-01))
      :snt2 (p / possible-01
            :ARG1 (l / lead-03
                  :ARG0 (a3 / and
                        :op1 (ii / identify-01
                              :ARG1-of (d2 / drive-02
                                    :ARG0 (a4 / artificial-intelligence)))
                        :op2 (p2 / profile-01)
                        :op3 (m2 / make-01
                              :ARG1 (d3 / decide-01)
                              :ARG1-of (a5 / automate-01)))
                  :ARG2 (o / outcome
                        :mod (o2 / or
                              :op1 (f2 / fair-01
                                    :polarity -)
                              :op2 (d4 / discriminate-02)
                              :op3 (b2 / bias-01)))))
      :snt3 (a6 / and
            :op1 (p3 / possible-01
                  :ARG1 (o3 / or
                        :op1 (m3 / misclassified-02
                              :ARG1 (ii2 / individual))
                        :op2 (m4 / misidentify-01
                              :ARG1 ii2)
                        :op3 (j / judge-01
                              :ARG1 ii2
                              :ARG2 (n / negative-02))))
            :op2 (p4 / possible-01
                  :ARG1 (a7 / affect-01
                        :ARG0 (o4 / or
                              :op1 (e / error)
                              :op2 (b3 / bias-01)
                              :mod (s / such))
                        :ARG1 (g / group
                              :mod (c / certain)
                              :consist-of (p5 / person))
                        :manner (d5 / disproportionate)))))

# ::snt Many companies have begun to explore the ideas of fairness, inclusion, accountability, and  transparency in machine learning, including Microsoft, Google, and Deepmind (Alphabet).
# File 186

(b / begin-01
      :ARG0 (c / company
            :quant (m / many)
            :ARG2-of (ii / include-91
                  :ARG1 (a / and
                        :op1 (c2 / company
                              :name (n / name
                                    :op1 "Microsoft"))
                        :op2 (c3 / company
                              :name (n2 / name
                                    :op1 "Google"))
                        :op3 (c4 / company
                              :name (n3 / name
                                    :op1 "Deepmind")
                              :ARG1-of (m2 / mean-01
                                    :ARG2 (c5 / company
                                          :name (n4 / name
                                                :op1 "Alphabet")))))))
      :ARG1 (e / explore-01
            :ARG0 c
            :ARG1 (ii2 / idea
                  :topic (a2 / and
                        :op1 (f / fairness)
                        :op2 (ii3 / include-01)
                        :op3 (a3 / accountable-02)
                        :op4 (t / transparency))
                  :topic (l / learn-01
                        :mod (m3 / machine)))))

# ::snt 5 How to Prevent Discriminatory Outcomes in Machine LearningDrawing on existing work, we propose four central principles  to combat bias in machine learning and uphold human  rights and dignity: Active Inclusion Fairness Right to Understanding Access to Remedy – Active Inclusion: The development and design of  ML applications must actively seek a diversity of  input, especially of the norms and values of specific  populations affected by the output of AI systems.
# File 186

(p / propose-01
      :li 5
      :ARG0 (w / we)
      :ARG1 (p2 / principle
            :quant 4
            :mod (c / central)
            :purpose (a / and
                  :op1 (c2 / combat-01
                        :ARG0 p2
                        :ARG1 (b / bias-01
                              :ARG1 (l / learn-01
                                    :ARG1 (m / machine))))
                  :op2 (u / uphold-01
                        :ARG0 p2
                        :ARG1 (a2 / and
                              :op1 (r / right-05
                                    :ARG1 (h / human))
                              :op2 (d / dignity
                                    :poss h))))
            :ARG1-of (m2 / mean-01
                  :ARG2 (a3 / and
                        :op1 (r2 / right-05
                              :ARG2 (f / fairness)
                              :ARG1-of (a4 / activity-06))
                        :op2 (r3 / right-05
                              :ARG2 (u2 / understand-01
                                    :ARG1 (a5 / access-01
                                          :ARG1 (r4 / remedy-01)))
                              :ARG1-of (a6 / activity-06))))
            :ARG1-of (m3 / mean-01
                  :ARG2 (o / obligate-01
                        :ARG1 (a7 / and
                              :op1 (d2 / develop-02
                                    :ARG1 (a8 / application
                                          :mod (m4 / machine)))
                              :op2 (d3 / design-01
                                    :ARG1 a8))
                        :ARG2 (s / seek-01
                              :ARG0 a7
                              :ARG1 (d4 / diverse
                                    :domain (ii / input
                                          :mod (e / especially)
                                          :consist-of (a9 / and
                                                :op1 (n / norm)
                                                :op2 (v / value)
                                                :poss (p3 / population
                                                      :ARG1-of (s2 / specific-02)
                                                      :ARG1-of (a10 / affect-01
                                                            :ARG0 (o2 / output
                                                                  :poss (s3 / system
                                                                        :mod (ii2 / intelligent-01
                                                                              :mod (a11 / artificial)))))))))
                              :ARG1-of (a12 / activity-06)))))
      :ARG1-of (d5 / draw-02
            :ARG2 (w2 / work-01
                  :ARG1-of (e2 / exist-01))))

# ::snt – Fairness: People involved in conceptualizing,  developing, and implementing machine learning  systems should consider which definition of fairness  best applies to their context and application, and  prioritize it in the architecture of the machine learning  system and its evaluation metrics.
# File 186

(a / and
      :op1 (f / fairness)
      :op2 (r / recommend-01
            :ARG1 (a2 / and
                  :op1 (c / consider-02
                        :ARG0 (p / person
                              :ARG1-of (ii / involve-01
                                    :ARG2 (a3 / and
                                          :op1 (c2 / conceptualize-01
                                                :ARG0 p
                                                :ARG1 (s / system
                                                      :mod (l / learn-01
                                                            :ARG1 (m / machine))))
                                          :op2 (d / develop-02
                                                :ARG0 p
                                                :ARG1 s)
                                          :op3 (ii2 / implement-01
                                                :ARG0 p
                                                :ARG1 s))))
                        :ARG1 (t / thing
                              :ARG2-of (d2 / define-01
                                    :ARG1 (f2 / fairness))
                              :ARG1-of (a4 / apply-02
                                    :ARG2 (a5 / and
                                          :op1 (c3 / context
                                                :poss p)
                                          :op2 (a6 / application
                                                :poss p))
                                    :ARG1-of (h / have-degree-91
                                          :ARG2 (g / good-02
                                                :ARG1 a4)
                                          :ARG3 (m2 / most)))))
                  :op2 (p2 / prioritize-01
                        :ARG0 p
                        :ARG1 t
                        :location (a7 / and
                              :op1 (a8 / architecture
                                    :poss (s2 / system
                                          :mod l))
                              :op2 (m3 / metric
                                    :purpose (e / evaluate-01
                                          :ARG1 s2)))))))

# ::snt – Fairness: People involved in conceptualizing,  developing, and implementing machine learning  systems should consider which definition of fairness  best applies to their context and application, and  prioritize it in the architecture of the machine learning  system and its evaluation metrics.
# File 186

(a / and
      :op1 (f / fairness)
      :op2 (r / recommend-01
            :ARG1 (a2 / and
                  :op1 (c / consider-02
                        :ARG0 (p / person
                              :ARG1-of (ii / involve-01
                                    :ARG2 (a3 / and
                                          :op1 (c2 / conceptualize-01
                                                :ARG0 p
                                                :ARG1 (s / system
                                                      :mod (l / learn-01
                                                            :ARG1 (m / machine))))
                                          :op2 (d / develop-02
                                                :ARG0 p
                                                :ARG1 s)
                                          :op3 (ii2 / implement-01
                                                :ARG0 p
                                                :ARG1 s))))
                        :ARG1 (t / thing
                              :ARG2-of (d2 / define-01
                                    :ARG1 (f2 / fairness))
                              :ARG1-of (a4 / apply-02
                                    :ARG2 (a5 / and
                                          :op1 (c3 / context
                                                :poss p)
                                          :op2 (a6 / application
                                                :poss p))
                                    :ARG1-of (h / have-degree-91
                                          :ARG2 (g / good-02
                                                :ARG1 a4)
                                          :ARG3 (m2 / most)))))
                  :op2 (p2 / prioritize-01
                        :ARG0 p
                        :ARG1 t
                        :location (a7 / and
                              :op1 (a8 / architecture
                                    :poss (s2 / system
                                          :mod l))
                              :op2 (m3 / metric
                                    :purpose (e / evaluate-01
                                          :ARG1 s2)))))))

# ::snt Active Inclusion Fairness Right to Understanding Access to RemedyActive Inclusion Fairness Right to Understanding Access to RemedyActive Inclusion Fairness Right to Understanding Access to RemedyActive Inclusion Fairness Right to Understanding Access to Remedy
# File 186

(a / and
      :op1 (r / right-05
            :ARG1 (o / organization
                  :name (n / name
                        :op1 "Active"
                        :op2 "Inclusion"
                        :op3 "Fairness"))
            :ARG2 (u / understand-01
                  :ARG0 o
                  :ARG1 (a2 / access-01
                        :ARG1 (r2 / remedy-01))))
      :op2 (r3 / right-05
            :ARG1 o
            :ARG2 (u2 / understand-01
                  :ARG0 o
                  :ARG1 (a3 / access-01
                        :ARG1 r2)))
      :op3 (r4 / right-05
            :ARG1 o
            :ARG2 (u3 / understand-01
                  :ARG0 o
                  :ARG1 a3))
      :op4 (r5 / right-05
            :ARG1 o
            :ARG2 (u4 / understand-01
                  :ARG0 o
                  :ARG1 a3)))

# ::snt The nuances  of how it works may be difficult for non-experts to digest,  but its promise is plain: increased efficiency, accuracy, scale  and speed in making decisions and finding the best answers  to questions ranging from “What type of illness is this?” to  “What should you do next?” ML systems could potentially increase fairness in making  decisions about which humans can be biased.
# File 186

(m / multi-sentence
      :snt1 (c / contrast-01
            :ARG1 (p / possible-01
                  :ARG1 (d / difficult
                        :domain (d2 / digest-01
                              :ARG0 (p2 / person
                                    :ARG1-of (e / expert-01
                                          :polarity -))
                              :ARG1 (n / nuances
                                    :topic (t / thing
                                          :manner-of (w / work-09
                                                :ARG1 (ii / it)))))))
            :ARG2 (p3 / promise-01
                  :ARG0 ii
                  :ARG2 (a / and
                        :op1 (e2 / efficient-01)
                        :op2 (a2 / accurate)
                        :op3 (s / scale)
                        :op4 (s2 / speed)
                        :topic (a3 / and
                              :op1 (d3 / decide-01)
                              :op2 (f / find-01
                                    :ARG1 (t2 / thing
                                          :ARG2-of (a4 / answer-01
                                                :ARG1 (q / question-01
                                                      :ARG1 (a5 / and
                                                            :op1 (ii2 / ill-01
                                                                  :mod (t3 / type
                                                                        :mod (a6 / amr-unknown)))
                                                            :op2 (r / recommend-01
                                                                  :ARG1 (d4 / do-02
                                                                        :ARG0 (y / you)
                                                                        :ARG1 (t4 / thing)
                                                                        :time (n2 / next))))))
                                          :ARG1-of (r2 / range-01
                                                :ARG3 (p4 / possible-01
                                                      :ARG1 (b / bias-01
                                                            :ARG1 (h / human)))))))
                        :ARG1-of (ii3 / increase-01))
                  :mod (p5 / plain)))
      :snt2 (p6 / possible-01
            :ARG1 (ii4 / increase-01
                  :ARG0 (s3 / system
                        :mod (t5 / thing
                              :name (n3 / name
                                    :op1 "ML")))
                  :ARG1 (f2 / fair-01
                        :ARG1 (d5 / decide-01
                              :ARG1 (t6 / thing
                                    :ARG2-of b))))
            :mod (p7 / potential)))

# ::snt Concerns Around Algorithm Design Modeling for fairness   Where is the risk for discrimination in  algorithm design and deployment?
# File 186

(m / multi-sentence
      :snt1 (c / concern-01
            :ARG0 (m2 / model-01
                  :ARG1 (d / design-01
                        :ARG1 (a / algorithm))
                  :ARG3 (f / fairness)))
      :snt2 (r / risk-01
            :ARG2 (d2 / discriminate-02
                  :ARG1 (a2 / and
                        :op1 (d3 / design-01
                              :ARG1 (a3 / algorithm))
                        :op2 (d4 / deploy-01
                              :ARG1 a3)))
            :location (a4 / amr-unknown)))

# ::snt Building a model with inadvertently discriminatory  features Humans have to define for algorithms what “success”  looks like – and it usually means maximizing profits or  accuracy or efficiency, rather than maximizing fairness.17 For  example, one ML model tasked with predicting likelihood  to re-offend had a similar error rate for black and white  defendants, but was more likely to err by wrongly predicting  that black defendants would re-offend and that white  defendants would not.18 When humans specify what weight  ML algorithms should give to variables, this can create  bias: for example, an algorithm to assess loan applicants  may consider both income levels and reliability of past  repayments; a human decision to give more weight to the  former may unfairly discriminate against members of groups  which tend to be lower-income, such as women.
# File 186

(m / multi-sentence
      :li 17
      :snt1 (a / and
            :op1 (o / obligate-01
                  :ARG1 (h / human)
                  :ARG2 (d / define-01
                        :ARG0 h
                        :ARG1 (r / resemble-01
                              :ARG1 (s / success)
                              :ARG2 (t / thing
                                    :ARG1-of (l / look-02
                                          :ARG0 (a2 / algorithm))))))
            :op2 (m2 / mean-01
                  :ARG1 d
                  :ARG2 (m3 / maximize-01
                        :ARG1 (o2 / or
                              :op1 (t2 / thing
                                    :ARG2-of (p / profit-01))
                              :op2 (a3 / accuracy)
                              :op3 (e / efficient-01))
                        :ARG1-of (ii / instead-of-91
                              :ARG2 (m4 / maximize-01
                                    :ARG1 (f / fairness))))
                  :mod (u / usual)))
      :snt2 (p2 / possible-01
            :ARG1 (c / create-01
                  :ARG0 (s2 / specify-01
                        :ARG0 (h2 / human)
                        :ARG1 (r2 / recommend-01
                              :ARG1 (g / give-01
                                    :ARG0 (a4 / algorithm
                                          :mod (m5 / machine
                                                :ARG1-of (a5 / automate-01)))
                                    :ARG1 (w / weight)
                                    :ARG2 (v / variable))))
                  :ARG1 (b / bias-01
                        :example (a6 / and
                              :op1 (p3 / possible-01
                                    :ARG1 (c2 / consider-02
                                          :ARG0 (a7 / algorithm
                                                :ARG0-of (a8 / assess-01
                                                      :ARG1 (p4 / person
                                                            :ARG0-of (a9 / apply-01
                                                                  :ARG1 (l2 / loan-01)))))
                                          :ARG1 (a10 / and
                                                :op1 (l3 / level
                                                      :mod (ii2 / income))
                                                :op2 (r3 / rely-01
                                                      :ARG1 (r4 / repay-01
                                                            :time (p5 / past))))))
                              :op2 (p6 / possible-01
                                    :ARG1 (d2 / discriminate-02
                                          :ARG0 (d3 / decide-01
                                                :ARG0 h2
                                                :ARG1 (g2 / give-01
                                                      :ARG0 h2
                                                      :ARG1 (w2 / weight
                                                            :mod (m6 / more))
                                                      :ARG2 (p7 / person
                                                            :ARG1-of (b2 / black-05)
                                                            :ARG1-of (w3 / white-02))))
                                          :ARG1-of (f2 / fair-01
                                                :polarity -)))))))
      :snt3 (c3 / contrast-01
            :ARG1 (h3 / have-03
                  :ARG0 (m7 / model
                        :quant 1
                        :mod (t3 / thing
                              :name (n / name
                                    :op1 "ML"))
                        :ARG1-of (t4 / task-01
                              :ARG2 (p8 / predict-01
                                    :ARG0 m7
                                    :ARG1 (l4 / likelihood
                                          :mod (o3 / offend-03
                                                :mod (a11 / again))))))
                  :ARG1 (r5 / rate
                        :mod (e2 / error)
                        :ARG1-of (r6 / resemble-01)))
            :ARG2 (l5 / likely-01
                  :ARG1 (e3 / err-01
                        :ARG0 m7
                        :manner (p9 / predict-01
                              :ARG0 m7
                              :ARG1 (a12 / and
                                    :op1 (o4 / offend-03
                                          :ARG1 (p10 / person
                                                :ARG1-of b2)
                                          :ARG1-of (d4 / defend-01)))
                              :op2 (o5 / offend-03
                                    :polarity -
                                    :ARG1-of w3)))))
      :ARG2-of (h4 / have-degree-91
            :ARG1 m7
            :ARG3 m6))

# ::snt What-if scenario: China and social credit  scores   While few details are publicly available,  reports suggest that China is creating a  model to score its citizens by analyzing  a wide range of data from banking, tax,  professional, and performance records,  to smartphones, e-commerce, and social  media.22 The aim is speculated to be “to  use the data to enforce a moral authority as designed by  the Communist Party.”23 One open question is what it will  mean if governments act on scores computed using data  that is incomplete, historically biased, and using models not  built for “fairness”.
# File 186

(m / multi-sentence
      :snt1 (s / scenario
            :topic (a / and
                  :op1 (c / country
                        :name (n / name
                              :op1 "China"))
                  :op2 (s2 / score-01
                        :ARG1 c
                        :ARG3 (c2 / credit-02
                              :mod (s3 / social))))
            :snt2 (c3 / contrast-01
                  :ARG1 (s4 / suggest-01
                        :ARG0 (r / report-01)
                        :ARG1 (c4 / create-01
                              :ARG0 c
                              :name (n2 / name
                                    :op1 "China"))
                        :ARG1 (m2 / model)
                        :purpose (s5 / score-01
                              :ARG0 c
                              :ARG1 (c5 / citizen
                                    :poss c)
                              :manner (a2 / analyze-01
                                    :ARG0 c
                                    :ARG1 (r2 / range-01
                                          :ARG1 (d / data)
                                          :ARG3 (a3 / and
                                                :op1 (b / bank-01)
                                                :op2 (t / tax-01)
                                                :op3 (p / professional)
                                                :op4 (p2 / perform-02))
                                          :ARG4 (a4 / and
                                                :op1 (s6 / smartphone)
                                                :op2 (e / e-commerce)
                                                :op3 (m3 / media
                                                      :mod s3)))
                                    :ARG1-of (w / wide-02)))))
            :ARG2 (a5 / available-02
                  :ARG2 (d2 / detail
                        :quant (f / few))
                  :ARG1-of (p3 / public-02)))
      :snt3 (s7 / speculate-01
            :li 22
            :ARG1 (a6 / aim-01
                  :ARG1 (u / use-01
                        :ARG1 (d3 / data)
                        :ARG2 (e2 / enforce-01
                              :ARG1 (a7 / authority
                                    :ARG1-of (m4 / moral-02)
                                    :ARG1-of (d4 / design-01
                                          :ARG0 (p4 / political-party
                                                :name (n3 / name
                                                      :op1 "Communist"
                                                      :op2 "Party"))))))))
      :snt4 (q / question-01
            :li 23
            :ARG1 (t2 / thing
                  :ARG2-of (m5 / mean-01
                        :ARG1 (ii / it)
                        :condition (a8 / act-02
                              :ARG0 (g / government-organization
                                    :ARG0-of (g2 / govern-01))
                              :ARG1 t2
                              :ARG2-of (s8 / score-01
                                    :ARG1-of (c6 / compute-01
                                          :manner (u2 / use-01
                                                :ARG1 (d5 / data
                                                      :ARG1-of (b2 / bias-01
                                                            :mod (h / history)))
                                                :ARG1-of (b3 / build-01
                                                      :polarity -
                                                      :purpose (f2 / fairness)))))))))
      :ARG1-of (o / open-04))

# ::snt – The FATML (Fairness, Accountability and  Transparency in Machine Learning) Principles  (2016)  – on accountable algorithms; developed by a  large network of scientists, researchers, and industry  professionals.
# File 186

(a / and
      :op1 (p / publication
            :name (n / name
                  :op1 "FATML")
            :ARG1-of (m / mean-01
                  :ARG2 (a2 / and
                        :op1 (f / fairness)
                        :op2 (a3 / accountable-02)
                        :op3 (t / transparency
                              :mod (m2 / machine
                                    :ARG1-of (l / learn-01)))))
            :time (d / date-entity
                  :year 2016))
      :op2 (d2 / develop-02
            :ARG0 (n2 / network
                  :mod (l2 / large)
                  :consist-of (a4 / and
                        :op1 (s / scientist)
                        :op2 (p2 / person
                              :ARG0-of (r / research-01))
                        :op3 (p3 / professional
                              :mod (ii / industry))))
            :ARG1 (a5 / algorithm
                  :ARG0-of (a6 / accountable-02))))

# ::snt Fairness  There are many different ways of defining  fairness; people involved in conceptualizing,  developing, and implementing machine  learning systems should consider which  definition best applies to their context and application.
# File 186

(m / multi-sentence
      :snt1 (h / have-manner-91
            :ARG1 (d / define-01
                  :ARG1 (f / fairness))
            :ARG2 (w / way
                  :quant (m2 / many)
                  :ARG1-of (d2 / differ-02)))
      :snt2 (r / recommend-01
            :ARG1 (c / consider-02
                  :ARG0 (p / person
                        :ARG1-of (ii / involve-01
                              :ARG2 (a / and
                                    :op1 (c2 / conceptualize-01
                                          :ARG0 p
                                          :ARG1 (s / system
                                                :mod (l / learn-01
                                                      :mod (m3 / machine))))
                                    :op2 (d3 / develop-02
                                          :ARG0 p
                                          :ARG1 s)
                                    :op3 (ii2 / implement-01
                                          :ARG0 p
                                          :ARG1 s))))
                  :ARG1 (t / thing
                        :ARG2-of (d4 / define-01)
                        :ARG1-of (a2 / apply-02
                              :ARG2 (a3 / and
                                    :op1 (c3 / context
                                          :poss s)
                                    :op2 (a4 / apply-02
                                          :ARG2 s))
                              :ARG1-of (h2 / have-degree-91
                                    :ARG2 (g / good-02
                                          :ARG1 t)
                                    :ARG3 (m4 / most))))))
      :snt3 (f2 / fairness))

# ::snt Fairness  There are many different ways of defining  fairness; people involved in conceptualizing,  developing, and implementing machine  learning systems should consider which  definition best applies to their context and application.
# File 186

(m / multi-sentence
      :snt1 (h / have-manner-91
            :ARG1 (d / define-01
                  :ARG1 (f / fairness))
            :ARG2 (w / way
                  :quant (m2 / many)
                  :ARG1-of (d2 / differ-02)))
      :snt2 (r / recommend-01
            :ARG1 (c / consider-02
                  :ARG0 (p / person
                        :ARG1-of (ii / involve-01
                              :ARG2 (a / and
                                    :op1 (c2 / conceptualize-01
                                          :ARG0 p
                                          :ARG1 (s / system
                                                :mod (l / learn-01
                                                      :mod (m3 / machine))))
                                    :op2 (d3 / develop-02
                                          :ARG0 p
                                          :ARG1 s)
                                    :op3 (ii2 / implement-01
                                          :ARG0 p
                                          :ARG1 s))))
                  :ARG1 (t / thing
                        :ARG2-of (d4 / define-01)
                        :ARG1-of (a2 / apply-02
                              :ARG2 (a3 / and
                                    :op1 (c3 / context
                                          :poss s)
                                    :op2 (a4 / apply-02
                                          :ARG2 s))
                              :ARG1-of (h2 / have-degree-91
                                    :ARG2 (g / good-02
                                          :ARG1 t)
                                    :ARG3 (m4 / most))))))
      :snt3 (f2 / fairness))

# ::snt In every case, fairness and the dignity of affected people  should be prioritized in the architecture of the machine  learning system and its evaluation metrics, as issues  with  bias are long-term and structural.29  Guiding Questions: – Have we identified a definition of fairness that suits the  context and application for our product and aligns with  the International Declaration of Human Rights?
# File 186

(m / multi-sentence
      :snt1 (r / recommend-01
            :ARG1 (p / prioritize-01
                  :ARG1 (a / and
                        :op1 (f / fairness)
                        :op2 (d / dignity
                              :poss (p2 / person
                                    :ARG1-of (a2 / affect-01))))
                  :location (a3 / and
                        :op1 (a4 / architect-01
                              :ARG1 (s / system
                                    :instrument-of (l / learn-01
                                          :ARG1 (m2 / machine))))
                        :op2 (m3 / metric
                              :instrument-of (e / evaluate-01
                                    :ARG1 s))))
            :ARG1-of (c / cause-01
                  :ARG0 (a5 / and
                        :op1 (l2 / long-03)
                        :op2 (s2 / structure)
                        :domain (ii / issue-02
                              :ARG0 (b / bias-01)))))
      :snt2 (q / question-01
            :li 29
            :ARG1 (ii2 / identify-01
                  :ARG0 (w / we)
                  :ARG1 (d2 / define-01
                        :ARG1 (f2 / fairness)
                        :ARG1-of (s3 / suit-01
                              :ARG2 (a6 / and
                                    :op1 (c2 / context)
                                    :op2 (a7 / apply-02
                                          :ARG2 (p3 / product
                                                :poss w))))
                        :ARG1-of (a8 / align-01
                              :ARG2 (p4 / publication
                                    :name (n / name
                                          :op1 "International"
                                          :op2 "Declaration"
                                          :op3 "of"
                                          :op4 "Human"
                                          :op5 "Rights"))))
                  :polarity (a9 / amr-unknown))
            :ARG0-of (g / guide-01))
      :mod (c3 / case
            :mod (e2 / every)))

# ::snt – Have we included all the relevant domain experts whose  interdisciplinary insights allow us to understand potential  sources of bias or unfairness and design ways to  counteract them?
# File 186

(ii / include-01
      :polarity (a / amr-unknown)
      :ARG0 (w / we)
      :ARG1 (p / person
            :ARG1-of (e / expert-01
                  :ARG2 (d / domain))
            :ARG1-of (r / relevant-01)
            :mod (a2 / all)
            :ARG0-of (ii2 / insight-05
                  :mod (ii3 / interdisciplinary)
                  :ARG0-of (a3 / allow-01
                        :ARG1 (a4 / and
                              :op1 (u / understand-01
                                    :ARG0 w
                                    :ARG1 (s / source-02
                                          :ARG1 (o / or
                                                :op1 (b / bias-01)
                                                :op2 (f / fairness
                                                      :polarity -))
                                          :mod (p2 / potential)))
                              :op2 (d2 / design-01
                                    :ARG0 w
                                    :ARG1 (w2 / way
                                          :ARG0-of (c / counteract-01
                                                :ARG1 s))))))))

# ::snt – Have we applied “rigorous pre-release trials to ensure  that [the ML system] will not amplify biases and error  due to any issues with the training data, algorithms, or  other elements of system design?”30  – Have we outlined an ongoing system for evaluating  fairness throughout the life cycle of our product?
# File 186

(m / multi-sentence
      :snt2 (o / outline-01
            :li 30
            :ARG0 (w / we)
            :ARG1 (s / system
                  :ARG1-of (g / go-on-15)
                  :purpose (e / evaluate-01
                        :ARG1 (f / fairness)
                        :duration (t / throughout
                              :op1 (c / cycle-02
                                    :ARG1 (p / product
                                          :poss w)
                                    :ARG2 (l / live-01)))))
            :polarity (a / amr-unknown))
      :snt1 (a2 / apply-02
            :ARG0 w
            :ARG1 (t2 / try-01
                  :ARG1-of (r / rigorous-00)
                  :time (b / before
                        :op1 (r2 / release-01
                              :ARG1 p)))
            :purpose (e2 / ensure-01
                  :ARG0 w
                  :ARG1 (a3 / amplify-01
                        :polarity -
                        :ARG0 (s2 / system
                              :mod (m2 / machine
                                    :ARG1-of (a4 / automate-01)))
                        :ARG1 (a5 / and
                              :op1 (b2 / bias-01)
                              :op2 (e3 / err-01))
                        :ARG1-of (c2 / cause-01
                              :ARG0 (ii / issue-02
                                    :ARG0 (o2 / or
                                          :op1 (d / data
                                                :mod (t3 / train-01))
                                          :op2 (a6 / algorithm)
                                          :op3 (e4 / element
                                                :mod (o3 / other)
                                                :part-of (d2 / design-01
                                                      :ARG1 s2))
                                          :mod (a7 / any))))))))

# ::snt Do  we have an escalation/emergency procedure to correct  unforeseen cases of unfairness when we uncover  them?
# File 186

(h / have-03
      :polarity (a / amr-unknown)
      :ARG0 (w / we)
      :ARG1 (p / procedure
            :mod (s / slash
                  :op1 (e / escalate-01)
                  :op2 (e2 / emergency))
            :purpose (c / correct-01
                  :ARG0 w
                  :ARG1 (c2 / case-04
                        :ARG1 (f / fairness
                              :polarity -)
                        :ARG1-of (f2 / foresee-01
                              :polarity -))
                  :time (u / uncover-01
                        :ARG0 w
                        :ARG1 c2))))

# ::snt 29 In “Fairness in Criminal Justice Risk Assessments: The State of the  Art” Berk et al, 2017 provide a through review of the technical pathways  towards promoting fairness in machine learning.
# File 186

(p / provide-01
      :li 29
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Berk"))
            :op2 (p3 / person
                  :mod (o / other)))
      :ARG1 (r / review-01
            :ARG1 (p4 / pathway
                  :mod (t / technical)
                  :direction (p5 / promote-02
                        :ARG1 (f / fairness
                              :prep-in (l / learn-01
                                    :mod (m / machine))))))
      :medium (p6 / publication-91
            :ARG1 (a2 / assess-01
                  :ARG1 (f2 / fairness
                        :prep-in (j / justice
                              :mod (c / criminal)))
                  :ARG2 (r2 / risk-01))
            :ARG4 (s / state
                  :mod (a3 / art)))
      :time (d / date-entity
            :year 2017))

# ::snt 29 In “Fairness in Criminal Justice Risk Assessments: The State of the  Art” Berk et al, 2017 provide a through review of the technical pathways  towards promoting fairness in machine learning.
# File 186

(p / provide-01
      :li 29
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Berk"))
            :op2 (p3 / person
                  :mod (o / other)))
      :ARG1 (r / review-01
            :ARG1 (p4 / pathway
                  :mod (t / technical)
                  :direction (p5 / promote-02
                        :ARG1 (f / fairness
                              :prep-in (l / learn-01
                                    :mod (m / machine))))))
      :medium (p6 / publication-91
            :ARG1 (a2 / assess-01
                  :ARG1 (f2 / fairness
                        :prep-in (j / justice
                              :mod (c / criminal)))
                  :ARG2 (r2 / risk-01))
            :ARG4 (s / state
                  :mod (a3 / art)))
      :time (d / date-entity
            :year 2017))

# ::snt Berk et al, 2017, Fairness  in Criminal Justice Risk Assessments: The State of the Art https://arxiv.org/ abs/1703.0920730 Ai Now Institute 2017 Report
# File 186

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Berk"))
            :op2 (p3 / person
                  :mod (o / other)))
      :ARG1 (p4 / publication
            :name (n2 / name
                  :op1 "Fairness"
                  :op2 "in"
                  :op3 "Criminal"
                  :op4 "Justice"
                  :op5 "Risk"
                  :op6 "Assessments"
                  :op7 "The"
                  :op8 "State"
                  :op9 "of"
                  :op10 "the"
                  :op11 "Art"))
      :time (d / date-entity
            :year 2017)
      :ARG4 p4
      :name (n3 / name
            :op1 "Ai"
            :op2 "Now"
            :op3 "Institute")
      :time (d2 / date-entity
            :year 2017
            :month 2
            :day 30))

# ::snt to design a fair and  contextually appropriate ML model Train ML designers/developers and AI  leaders on human rights responsibilitiesHave leaders and data scientists who are able to translate ethics into code that runs the  ML systems; minimize risk of inadvertent or blatant discrimination  What can companies do to avoid building a model with discriminatory features?50 Action Impact Organize research Have an up-to-date understanding of how certain models have performed in similar  contexts to guide model and data selection Ensure diversity in ML development  teamsBring different perspectives together; afford insights into which model types and data  types may need to be considered in order to design an ML system that is both accurate  and non-discriminating  Keep models up to date and contextually  relevantReduce chances of bias and error that can result from static ML applications that no  longer reflect the real-time realities and needs of a given context Map out risks Have a sense of what could go wrong in order to identify what stages will require humanin-the-loop checks and how to leverage dynamic testing; determine what set of indicators  could be used to detect discrimination and might be helpful for dynamic testing Include dynamic testing Determine how algorithms are performing according to a chosen set of indicators that  reflect non-discrimination in order to course correct (either by changing the training data,  target variables, parameters, cost functions, or other elements of the ML application) if  necessary  Calibrate models to include fairness  criteria where appropriateBalance a model’s success according not only to accuracy but also to fairness and nondiscrimination Engage stakeholders and domain experts  in participatory mannerBest identify what types of considerations should be made for an ML model being  applied in a particular domain (industry, geography, population, etc.)
# File 186

(m / multi-sentence
      :snt1 (h / have-purpose-91
            :ARG2 (d / design-01
                  :ARG1 (m2 / model
                        :ARG1-of (ii / intelligent-01))
                  :ARG1-of (a / appropriate-02
                        :mod (c / context))))
      :snt2 (a2 / and
            :op1 (t / train-01
                  :ARG1 (a3 / and
                        :op1 (p / person
                              :ARG0-of (d2 / design-01
                                    :ARG1 (p2 / product
                                          :name (n / name
                                                :op1 "ML"))))
                        :op2 (p3 / person
                              :ARG0-of (d3 / develop-02
                                    :ARG1 p2)))
                  :ARG2 (a4 / and
                        :op1 (p4 / person
                              :ARG0-of (d4 / design-01
                                    :ARG1 p2))
                        :op2 (p5 / person
                              :ARG0-of (l / lead-02)
                              :mod (d5 / data)))
                  :topic (r / responsible-03
                        :ARG1 (r2 / right-05
                              :ARG1 (h2 / human)))))
      :op2 (e / ensure-01
            :ARG1 (d6 / diversity)
            :ARG2 (t2 / team
                  :ARG0-of (d7 / develop-02
                        :ARG1 p2)))
      :op3 (a5 / and
            :op1 (b / bring-01
                  :ARG1 (p6 / perspective
                        :ARG1-of (d8 / differ-02))
                  :ARG2 (t3 / together))
            :op2 (a6 / afford-02
                  :ARG1 (ii2 / insight
                        :topic (o / obligate-01
                              :ARG2 (c2 / consider-02
                                    :ARG1 (a7 / and
                                          :op1 (t4 / type
                                                :mod (m3 / model))
                                          :op2 (t5 / type
                                                :mod (d9 / data))))
                              :purpose (d10 / design-01
                                    :ARG1 (s / system
                                          :ARG3 (a8 / and
                                                :op1 (a9 / accurate)
                                                :op2 (d11 / discriminate-01
                                                      :polarity -)))))))
            :op4 (m4 / minimize-01
                  :ARG1 (r3 / risk-01
                        :ARG1 (d12 / discriminate-01
                              :mod (b2 / blatant))))
            :op5 (ii3 / identify-01
                  :ARG1 (p7 / possible-01
                        :ARG1 (a10 / avoid-01
                              :ARG0 (c3 / company)
                              :ARG1 (b3 / build-01
                                    :ARG0 c3
                                    :ARG1 (m5 / model
                                          :ARG0-of (h3 / have-03
                                                :ARG1 (f / feature
                                                      :ARG0-of d12
                                                      :polarity -))))))))
      :condition (n2 / need-01)
      :snt3 (ii4 / include-01
            :ARG1 (c4 / criteria
                  :mod (f2 / fairness))
            :ARG2 (t6 / test-01))
      :snt4 (a11 / and
            :op1 (t7 / test-01
                  :mod (d13 / dynamic))
            :op2 (d14 / determine-01
                  :ARG1 (s2 / set
                        :ARG1-of (c5 / choose-01)
                        :consist-of (ii5 / indicate-01)
                        :ARG0-of (p8 / possible-01
                              :ARG1 (c6 / correct-01
                                    :ARG1 (o2 / or
                                          :op1 (v / variable
                                                :ARG1-of (t8 / target-01))
                                          :op2 (p9 / parameter)
                                          :op3 (f3 / function
                                                :mod (c7 / cost))
                                          :op4 (e2 / element
                                                :mod (o3 / other)
                                                :part-of (a12 / apply-02
                                                      :ARG1 (a13 / and
                                                            :ARG1 (a14 / automate-01)))))))))))

# ::snt to design a fair and  contextually appropriate ML model Train ML designers/developers and AI  leaders on human rights responsibilitiesHave leaders and data scientists who are able to translate ethics into code that runs the  ML systems; minimize risk of inadvertent or blatant discrimination  What can companies do to avoid building a model with discriminatory features?50 Action Impact Organize research Have an up-to-date understanding of how certain models have performed in similar  contexts to guide model and data selection Ensure diversity in ML development  teamsBring different perspectives together; afford insights into which model types and data  types may need to be considered in order to design an ML system that is both accurate  and non-discriminating  Keep models up to date and contextually  relevantReduce chances of bias and error that can result from static ML applications that no  longer reflect the real-time realities and needs of a given context Map out risks Have a sense of what could go wrong in order to identify what stages will require humanin-the-loop checks and how to leverage dynamic testing; determine what set of indicators  could be used to detect discrimination and might be helpful for dynamic testing Include dynamic testing Determine how algorithms are performing according to a chosen set of indicators that  reflect non-discrimination in order to course correct (either by changing the training data,  target variables, parameters, cost functions, or other elements of the ML application) if  necessary  Calibrate models to include fairness  criteria where appropriateBalance a model’s success according not only to accuracy but also to fairness and nondiscrimination Engage stakeholders and domain experts  in participatory mannerBest identify what types of considerations should be made for an ML model being  applied in a particular domain (industry, geography, population, etc.)
# File 186

(m / multi-sentence
      :snt1 (h / have-purpose-91
            :ARG2 (d / design-01
                  :ARG1 (m2 / model
                        :ARG1-of (ii / intelligent-01))
                  :ARG1-of (a / appropriate-02
                        :mod (c / context))))
      :snt2 (a2 / and
            :op1 (t / train-01
                  :ARG1 (a3 / and
                        :op1 (p / person
                              :ARG0-of (d2 / design-01
                                    :ARG1 (p2 / product
                                          :name (n / name
                                                :op1 "ML"))))
                        :op2 (p3 / person
                              :ARG0-of (d3 / develop-02
                                    :ARG1 p2)))
                  :ARG2 (a4 / and
                        :op1 (p4 / person
                              :ARG0-of (d4 / design-01
                                    :ARG1 p2))
                        :op2 (p5 / person
                              :ARG0-of (l / lead-02)
                              :mod (d5 / data)))
                  :topic (r / responsible-03
                        :ARG1 (r2 / right-05
                              :ARG1 (h2 / human)))))
      :op2 (e / ensure-01
            :ARG1 (d6 / diversity)
            :ARG2 (t2 / team
                  :ARG0-of (d7 / develop-02
                        :ARG1 p2)))
      :op3 (a5 / and
            :op1 (b / bring-01
                  :ARG1 (p6 / perspective
                        :ARG1-of (d8 / differ-02))
                  :ARG2 (t3 / together))
            :op2 (a6 / afford-02
                  :ARG1 (ii2 / insight
                        :topic (o / obligate-01
                              :ARG2 (c2 / consider-02
                                    :ARG1 (a7 / and
                                          :op1 (t4 / type
                                                :mod (m3 / model))
                                          :op2 (t5 / type
                                                :mod (d9 / data))))
                              :purpose (d10 / design-01
                                    :ARG1 (s / system
                                          :ARG3 (a8 / and
                                                :op1 (a9 / accurate)
                                                :op2 (d11 / discriminate-01
                                                      :polarity -)))))))
            :op4 (m4 / minimize-01
                  :ARG1 (r3 / risk-01
                        :ARG1 (d12 / discriminate-01
                              :mod (b2 / blatant))))
            :op5 (ii3 / identify-01
                  :ARG1 (p7 / possible-01
                        :ARG1 (a10 / avoid-01
                              :ARG0 (c3 / company)
                              :ARG1 (b3 / build-01
                                    :ARG0 c3
                                    :ARG1 (m5 / model
                                          :ARG0-of (h3 / have-03
                                                :ARG1 (f / feature
                                                      :ARG0-of d12
                                                      :polarity -))))))))
      :condition (n2 / need-01)
      :snt3 (ii4 / include-01
            :ARG1 (c4 / criteria
                  :mod (f2 / fairness))
            :ARG2 (t6 / test-01))
      :snt4 (a11 / and
            :op1 (t7 / test-01
                  :mod (d13 / dynamic))
            :op2 (d14 / determine-01
                  :ARG1 (s2 / set
                        :ARG1-of (c5 / choose-01)
                        :consist-of (ii5 / indicate-01)
                        :ARG0-of (p8 / possible-01
                              :ARG1 (c6 / correct-01
                                    :ARG1 (o2 / or
                                          :op1 (v / variable
                                                :ARG1-of (t8 / target-01))
                                          :op2 (p9 / parameter)
                                          :op3 (f3 / function
                                                :mod (c7 / cost))
                                          :op4 (e2 / element
                                                :mod (o3 / other)
                                                :part-of (a12 / apply-02
                                                      :ARG1 (a13 / and
                                                            :ARG1 (a14 / automate-01)))))))))))

# ::snt Map out risks Have a sense of what could go wrong in order to identify what stages will require  human-in-the-loop checks and how to leverage dynamic testing; determine what set  of indicators could be used to detect discrimination and might be helpful for dynamic  testing Include dynamic testing Determine how algorithms are performing according to a chosen set of indicators that  reflect non-discrimination in order to course correct (either by changing the training data,  the target variables, parameters, cost functions, or other elements of the ML application)  if necessary  Calibrate models to include fairness crite ria where appropriateCreate automatic checks and balances in the ML system that might be able to prevent  discrimination even when it is intended; balance a model’s success according not only to  accuracy but also to fairness and non-discrimination Train ML designers/developers and AI  leaders on human rights responsibilitiesHave leaders and data scientists who are able to translate ethics into code that runs the  ML systems; minimize risk of inadvertent or blatant discrimination  Restrict ML deployment in cases where it  is judged incongruous with human rightsProtect people from discriminatory outcomes in the most sensitive application contexts;  limit human rights abuses
# File 186

(m / multi-sentence
      :snt1 (m2 / map-01
            :ARG1 (r / risk-01))
      :snt2 (h / have-03
            :ARG1 (s / sense-01
                  :ARG1 (p / possible-01
                        :ARG1 (g / go-08
                              :ARG1 (w / wrong-02)))
                  :purpose (ii / identify-01
                        :ARG1 (a / and
                              :op1 (s2 / stage
                                    :ARG0-of (r2 / require-01
                                          :ARG1 (c / check-01
                                                :ARG0 (h2 / human
                                                      :location (l / loop)))))
                              :op2 (t / thing
                                    :manner-of (l2 / leverage-01
                                          :ARG1 (t2 / test-01
                                                :mod (d / dynamic))))))))
      :snt3 (a2 / and
            :op1 (r3 / restrict-01
                  :ARG1 (d2 / deploy-01
                        :ARG1 (p2 / product
                              :name (n / name
                                    :op1 "ML")))
                  :condition (j / judge-01
                        :ARG1 p2
                        :ARG2 (a3 / appropriate-02)))
            :op2 (c2 / create-01
                  :ARG1 (a4 / and
                        :op1 (c3 / check-01)
                        :op2 (b / balance-01
                              :ARG1 (s3 / succeed-01
                                    :ARG0 (m3 / model))
                              :ARG1-of (c4 / conform-01
                                    :ARG2 (a5 / and
                                          :op1 (a6 / accuracy)
                                          :op2 (d3 / discriminate-02
                                                :polarity -))))
                        :mod (a7 / automatic)
                        :ARG0-of (p3 / prevent-01
                              :ARG1 (d4 / discriminate-02)
                              :ARG1-of (p4 / possible-01)
                              :concession (e / even-when
                                    :op1 (ii2 / intend-01
                                          :ARG1 d4))))))
      :op3 (l3 / limit-01
            :ARG1 (a8 / abuse-01
                  :ARG1 (r4 / right-05
                        :ARG1 (h3 / human))))
      :op4 (h4 / have-03
            :ARG1 (a9 / and
                  :op1 (p5 / person
                        :ARG0-of (d5 / design-01
                              :ARG1 p2))
                  :op2 (p6 / person
                        :ARG0-of (d6 / develop-02
                              :ARG1 p2))
                  :op3 (p7 / person
                        :ARG0-of (l4 / lead-02
                              :ARG1 p2)
                        :mod (a10 / artificial)))
            :ARG0-of (t3 / translate-01
                  :ARG1 (e2 / ethics)
                  :ARG2 (c5 / code
                        :ARG0-of (r5 / run-01
                              :ARG1 p2)))))

# ::snt 21 How to Prevent Discriminatory Outcomes in Machine LearningAppendix 3: Principles on the Ethical Design  and Use of AI and Autonomous Systems  Asilomar Principles (Ethics and  Values) on Safe, Ethical, and  Beneficial use of AI*FATML Principles for Accountable  AlgorithmsIEEE Principles on Ethically Aligned  Design* Safety/Security/ Accuracy (Verifiability)  Safety – AI systems should be  safe and secure throughout their  operational lifetime, and verifiably so  where applicable and feasible  Accuracy –  Identify, log, and  articulate sources of AI error  and uncertainty throughout the  algorithm and its data sources  so that expected and worst-case  implications can be understood and  inform mitigation proceduresHuman Benefit (Safety) – AI must be  verifiably safe and secure throughout  its operational lifetime Transparency/ Explainability/ AuditabilityFailure Transparency –  If systems  cause harm, it should be possible  to ascertain why Judicial Transparency –  If systems  are involved in key judicial decisionmaking, an explanation that is  auditable by a competent human  authority should be made availableExplainability –  Ensure that  algorithmic decisions, as well as any  data driving those decisions, can be  explained to end users and other  stakeholders in nontechnical terms Auditability –  Enable interested third  parties to probe, understand, and  review the behavior of the algorithm  through disclosure of information  that enables monitoring, checking,  or criticism, including through the  provision of detailed documentation,  technically suitable APIs, and  permissive use of termsTransparency/Traceability –  It must  be possible to discover how and why  a system made a particular decision  or acted in a certain way, and, if a  system causes harm, to discover the  root cause Responsibility Responsibility –  Designers  and builders of AI systems  are stakeholders in the moral  implications of their use, misuse,  and actions  Responsibility –  Make available  externally visible avenues of redress  for adverse individual or societal  effects, and designate an internal role  for the person who is responsible for  the timely remedy of such issues  Responsibility – Designers and  developers of systems should remain  aware of and take into account the  diversity of existing relevant cultural  norms; manufacturers must be  able to provide programmatic-level  accountability proving why a system  operates in certain ways Fairness and  Values AlignmentShared Benefit –  AI technologies  should benefit and empower as  many people as possible  Shared Prosperity –  The  economic prosperity created by AI  should be shared broadly, to the  benefit all of humanity Non-Subversion –  The power  conferred by control of highly  advanced AI systems should  respect and improve, rather than  subvert, social and civic processesFairness –  Ensure that algorithmic  decisions do not create  discriminatory or unjust impacts  when comparing across different  demographics  Embedding Values into AI –  Identify  the norms and elicit the values  of a specific community affected  by a particular AI, and ensure the  norms and values included in AI  are compatible with the relevant  community Human Benefit (Human Rights) –   Design and operate AI in a way that  respects human rights, freedoms,  human dignity, and cultural diversity   Privacy Personal Privacy –  People should  have the right to access, manage,  and control the data they generate,  given AI systems’ power to analyze  and utilize that data  Liberty and Privacy –  The use  of personal data by AI must not  unreasonably curtail people’s real or  perceived liberty Personal Data and Individual  Access Control –  People must be  able to define, access, and manage  their personal data as curators of their  unique identity       Notes: (*) Both the Asilomar and IEEE guidelines include additional principles that relate to human control, the avoidance of lethal autonomous weapons arms  race, and long-term capability questions regarding the beneficence of artificial general intelligence and superintelligence.
# File 186

(m / multi-sentence
      :snt1 (a / and
            :li 21
            :op1 (p / prevent-01
                  :ARG1 (e / event
                        :ARG0-of (d / discriminate-02))
                  :ARG2 (a2 / automate-01))
            :op2 (ii / include-01
                  :ARG1 (p2 / principle
                        :topic (a3 / and
                              :op1 (d2 / design-01
                                    :ARG1 (s / system
                                          :mod (a4 / artificial)))
                              :op2 (u / use-01
                                    :ARG1 s)))
                  :ARG2 (p3 / principle
                        :topic (a5 / and
                              :op1 (d3 / design-01
                                    :ARG1 s)
                              :op2 (u2 / use-01
                                    :ARG1 (s2 / system
                                          :mod (a6 / autonomy)))))))
      :snt2 (a7 / and
            :op1 (e2 / ensure-01
                  :ARG1 (p4 / possible-01
                        :ARG1 (e3 / explain-01
                              :ARG0 (a8 / and
                                    :op1 (p5 / person
                                          :ARG0-of (u3 / use-01)
                                          :ARG1-of (c / competent-01))
                                    :op2 (p6 / person
                                          :ARG0-of (b / build-01
                                                :ARG1 s2)))))))
      :op2 (p7 / possible-01
            :ARG1 (p8 / provide-01
                  :ARG0 p6
                  :ARG1 (a9 / accountable-02
                        :ARG0 p6
                        :mod (l / level
                              :mod (p9 / program))
                        :ARG0-of (p10 / prove-01
                              :ARG1 (c2 / cause-01
                                    :ARG1 (o / operate-01
                                          :ARG0 (s3 / system)
                                          :manner (c3 / certain)))))))
      :snt3 (a10 / and
            :op1 (a11 / and
                  :op1 (ii2 / identify-01
                        :ARG1 (s4 / source-02
                              :ARG1 (a12 / and
                                    :op1 (e4 / error
                                          :mod (a13 / artificial))
                                    :op2 (c4 / certainty
                                          :polarity -))))
                  :op2 (l2 / log-01
                        :ARG1 s4)
                  :op3 (a14 / articulate-01
                        :ARG1 s4)))
      :op2 (e5 / ensure-01
            :ARG1 (c5 / compatible-00
                  :ARG1 (a15 / and
                        :op1 (n / norm)
                        :op2 (v / value)
                        :ARG1-of (ii3 / include-91
                              :ARG2 (n2 / norm
                                    :ARG1-of (r / relevant-01)))))
            :ARG2 (a16 / and
                  :op1 (d4 / design-01
                        :ARG1 (s5 / system))
                  :op2 (o2 / operate-01
                        :ARG1 s5)))
      :snt4 (a17 / and
            :op1 (a18 / and_11
                  :op1 (s6 / safe-01)
                  :op2 (s7 / secure-02)
                  :ARG1-of (p11 / possible-01))
            :op2 (s8 / slash
                  :op1 (p12 / possible-01
                        :ARG1 (e6 / explain-01))
                  :op2 (p13 / possible-01
                        :ARG1 (a19 / audit-01))))
      :op3 (s9 / slash
            :op1 (p14 / possible-01
                  :ARG1 (e7 / explain-01))
            :op2 (a20 / audit-01))
      :op4 (p15 / possible-01
            :ARG1 (f / fail-01))
      :snt5 (a21 / and
            :op1 (p16 / privacy)
            :op2 (p17 / privacy))
      :snt6 (h / have-condition-91
            :ARG1 (r2 / recommend-01
                  :ARG1 (a22 / and
                        :ARG1 (a23 / and
                              :op1 (r3 / respect-01
                                    :ARG1 (a24 / and
                                          :ARG1 (a25 / and
                                                :ARG1 (a26 / and
                                                      :op1 (r4 / right-05
                                                            :ARG1 (h2 / human))
                                                      :op2 (f2 / free-04
                                                            :ARG1 (h3 / human)))))
                                    :op2 (e8 / et-cetera)))
                        :ARG2 (p18 / possible-01
                              :ARG1 a25
                              :ARG1 a26
                              :ARG1 (a27 / and
                                    :ARG1 a25
                                    :ARG1 a25)))))
      :ARG2 (c6 / cause-01
            :ARG0 (c7 / control-01
                  :ARG1 (b2 / behave-01
                        :ARG0 (a28 / algorithm
                              :ARG1-of (a29 / advanced-02))))))

# ::snt As this is a rapidly  changing field, the methods and assumptions by  which such testing is conducted, along with the  results, should be openly documented and publicly  available, with clear versioning to accommodate  updates and new findings.”54  Map human rights risks throughout the life cycle  of machine learning products, from development  to deployment and use; this mapping should take  into account risks inherent in machine learning,  including data bias and inadequate data, and must  include the intended uses and the potential for  human rights abuses in each case Update human rights risks for each new use case  of a ML applicationBusinesses involved in  developing or deploying  machine learning systems Public-sector entities  involved in deploying  machine learning systems,  such as has been done  by New York City where  an initial mapping of risks  led the  City Council to  consider a bill  to ensure  transparency and testing  of algorithmic decisionmaking systems  54 “The 10 Top Recommendations for the AI Field in 2017” AiNow Institute https://medium.com/@AINowInstitute/the-10-top-recommendations-for-the-ai-field-in2017-b3253624a7Fairness Active inclusion Right to Understanding Access to Redress
# File 186

(m / multi-sentence
      :snt1 (c / cause-01
            :ARG0 (f / field
                  :ARG1-of (c2 / change-01
                        :manner (r / rapid))
                  :domain (t / this))
            :ARG1 (r2 / recommend-01
                  :ARG1 (a / and
                        :op1 (d / document-01
                              :ARG1 (a2 / and
                                    :op1 (m2 / method)
                                    :op2 (t2 / thing
                                          :ARG1-of (a3 / assume-02))
                                    :instrument-of (c3 / conduct-01
                                          :ARG1 (t3 / test-01
                                                :mod (s / such))))
                              :ARG1-of (o / open-04))
                        :op2 (a4 / available-02
                              :ARG2 a2
                              :ARG1-of (p / public-02))
                        :manner (v / version-01
                              :ARG1-of (a5 / accommodate-01
                                    :ARG0 a2
                                    :ARG1 (a6 / and
                                          :op1 (u / update-01)
                                          :op2 (t4 / thing
                                                :ARG1-of (f2 / find-01)
                                                :ARG1-of (n / new-01))))))))
      :snt2 (r3 / recommend-01
            :ARG1 (m3 / map-01
                  :ARG1 (r4 / risk-01
                        :ARG2 (r5 / right-05
                              :ARG1 (h / human)))
                  :duration (c4 / cycle-02
                        :ARG1 (p2 / product
                              :ARG0-of (l / learn-01
                                    :ARG1 (m4 / machine)))
                        :ARG2 (a7 / and
                              :op1 (d2 / develop-02
                                    :ARG1 p2)
                              :op2 (d3 / deploy-01
                                    :ARG1 p2)))
                  :example (m5 / map-01
                        :ARG0 (c5 / city
                              :name (n2 / name
                                    :op1 "New"
                                    :op2 "York"))
                        :ARG1 (r6 / risk-01)
                        :ARG0-of (l2 / lead-03
                              :ARG1 c5
                              :ARG2 (c6 / consider-02
                                    :ARG0 c5
                                    :ARG1 (b / bill
                                          :ARG0-of (e / ensure-01
                                                :ARG1 (a8 / and
                                                      :op1 (t5 / transparency)
                                                      :op2 (t6 / test-01
                                                            :ARG1 (s2 / system
                                                                  :mod (d4 / decide-01
                                                                        :manner (a9 / algorithm))))))))))))
      :snt3 (p3 / publication
            :mod 54
            :name (n3 / name
                  :op1 "AiNow"
                  :op2 "Institute")
            :ARG1-of (c7 / cite-01
                  :ARG2 (u2 / url-entity
                        :value "https://medium.com/@AINowInstitute/the-10-top-recommendations-for-the-ai-field-in2017-b3253624a7Fairness"))))

# ::snt 23 How to Prevent Discriminatory Outcomes in Machine LearningDevelop  and/or  enhance  Industry  Stan dardsDevelop  or  augment standards  to evaluate fairness,  inclusion, and  accountability in  machine learningCompanies with the capacity to do so should  partake in industry-wide efforts to arrive at a  common understanding and set of standards  for fairness and non-discrimination and dignity  assurance in machine learning.Businesses involved in  developing or deploying  machine learning systems.
# File 186

(m / multi-sentence
      :snt1 (t / thing
            :li 23
            :manner-of (p / prevent-01
                  :ARG1 (o / outcome
                        :ARG1-of (d / discriminate-02
                              :polarity -))
                  :ARG2 (l / learn-01
                        :ARG1 (m2 / machine))))
      :snt2 (s / say-01
            :ARG0 (p2 / person
                  :name (n / name
                        :op1 "Stan"
                        :op2 "Dardard"))
            :ARG1 (r / recommend-01
                  :ARG1 (p3 / partake-01
                        :ARG0 (c / company
                              :ARG1-of (c2 / capable-01
                                    :ARG2 (d2 / do-02
                                          :ARG0 c
                                          :ARG1 (s2 / so))))
                        :ARG1 (e / effort-01
                              :ARG1 (a / arrive-01
                                    :ARG1 (a2 / and
                                          :op1 (u / understand-01
                                                :ARG1-of (s3 / share-01
                                                      :ARG0 (ii / industry)))
                                          :op2 (s4 / set
                                                :consist-of (s5 / standard-02
                                                      :ARG1 (e2 / evaluate-01
                                                            :ARG1 (a3 / and
                                                                  :op1 (f / fairness)
                                                                  :op2 (ii2 / include-01)
                                                                  :op3 (a4 / accountable-02)
                                                                  :topic (l2 / learn-01
                                                                        :ARG1 (m3 / machine))))))))))
                  :ARG2 (b / business
                        :ARG1-of (ii3 / involve-01
                              :ARG2 (o2 / or
                                    :op1 (d3 / develop-02
                                          :ARG1 (s6 / system
                                                :mod (l3 / learn-01
                                                      :ARG1 (m4 / machine))))
                                    :op2 (d4 / deploy-01
                                          :ARG1 s6)))))))

# ::snt This might look similar  to approaches taken to  develop standards for  fairness in trade in the Fair  Trade movement.
# File 186

(p / possible-01
      :ARG1 (r / resemble-01
            :ARG1 (t / this)
            :ARG2 (a / approach-02
                  :ARG1 (d / develop-02
                        :ARG1 (s / standard-02
                              :ARG2 (f / fair-01
                                    :ARG1 (t2 / trade-01))))
                  :subevent-of (m / movement-07
                        :ARG1 (f2 / fair-01
                              :ARG1 (t3 / trade-01))))))

# ::snt Public-sector entities  involved in deploying  machine learning systems Develop  or augment  standards to evaluate  fairness, inclusion, and  accountability in machine  learningCompanies with the capacity to do so should  partake in industry-wide efforts to arrive at a  common understanding and set of standards  for fairness and non-discrimination in machine  learning.
# File 186

(r / recommend-01
      :ARG1 (p / partake-01
            :ARG0 (c / company
                  :ARG1-of (c2 / capable-01
                        :ARG2 (d / do-02
                              :ARG0 c
                              :ARG1 (s / so))))
            :ARG1 (e / effort-01
                  :ARG1 (a / arrive-01
                        :ARG1 (a2 / and
                              :op1 (u / understand-01
                                    :mod (c3 / common))
                              :op2 (s2 / set
                                    :consist-of (s3 / standard
                                          :topic (a3 / and
                                                :op1 (f / fairness)
                                                :op2 (d2 / discriminate-01
                                                      :polarity -)
                                                :topic (l / learn-01
                                                      :mod (m / machine)))))))
                  :ARG1-of (w / wide-02
                        :ARG2 (ii / industry))))
      :ARG2 (o / or
            :op1 (d3 / develop-02
                  :ARG0 (e2 / entity
                        :mod (s4 / sector
                              :ARG1-of (p2 / public-02))
                        :ARG1-of (ii2 / involve-01
                              :ARG2 (d4 / deploy-01
                                    :ARG0 e2
                                    :ARG1 (s5 / system
                                          :mod l))))
                  :ARG1 s3)
            :op2 (a4 / augment-01
                  :ARG0 e2
                  :ARG1 s3)
            :purpose (e3 / evaluate-01
                  :ARG0 c
                  :ARG1 (a5 / and
                        :op1 f
                        :op2 (ii3 / include-01)
                        :op3 (a6 / accountable-02)
                        :topic l))))

# ::snt This might look  similar to approaches  taken to develop standards  for fairness in trade in the  Fair Trade movement.
# File 186

(p / possible-01
      :ARG1 (l / look-02
            :ARG0 (t / this)
            :ARG1 (a / approach-02
                  :ARG1 (d / develop-02
                        :ARG1 (s / standard-02
                              :ARG2 (f / fair-01
                                    :ARG1 (t2 / trade-01))))
                  :subevent-of (m / movement-07
                        :ARG1 (f2 / fair-01
                              :ARG1 (t3 / trade-01))))))

# ::snt 26 How to Prevent Discriminatory Outcomes in Machine LearningOptimize  ML mod els for  fairness,  account ability,  transpar ency, and  editabilityCalibrate models to  include fairness criteria In general, calibrating false positive and false  negative rates in each group or population  for which an algorithm is making decisions  can help to equalize impacts.
# File 186

(m / multi-sentence
      :snt1 (t / thing
            :li 26
            :manner-of (p / prevent-01
                  :ARG1 (o / outcome
                        :ARG1-of (d / discriminate-02))
                  :ARG2 (l / learn-01
                        :ARG1 (m2 / machine))))
      :snt2 (a / and
            :op1 (o2 / optimize-01
                  :ARG1 (m3 / mod-02
                        :ARG1 m2)
                  :ARG2 (t2 / thing
                        :name (n / name
                              :op1 "ML")))
            :purpose (a2 / and
                  :op1 (f / fairness)
                  :op2 (c / capable-01
                        :ARG2 (a3 / account-01))
                  :op3 (t3 / thing
                        :name n
                        :op1 "Transpar"
                        :op2 "Ency"))
            :op4 (e / edit-01
                  :ARG1-of (p2 / possible-01)))
      :op2 (c2 / calibrate-01
            :ARG1 (m4 / model)
            :purpose (ii / include-01
                  :ARG1 (c3 / criteria
                        :topic (f2 / fairness))
                  :ARG2 m4))
      :snt3 (p3 / possible-01
            :ARG1 (h / help-01
                  :ARG0 (c4 / calibrate-01
                        :ARG1 (a4 / and
                              :op1 (r / rate
                                    :mod (p4 / positive
                                          :mod (f3 / false)))
                              :op2 (r2 / rate
                                    :mod (n2 / negative
                                          :mod f3))
                              :location (o3 / or
                                    :op1 (g / group)
                                    :op2 (p5 / population)
                                    :ARG2-of (d2 / decide-01
                                          :ARG0 (a5 / algorithm)))))
                  :ARG1 (e2 / equalize-01
                        :ARG1 (ii2 / impact-01)))
            :ARG1-of (g2 / general-02)))

# ::snt In other words,  the individuals responsible for designing  algorithms and weighting variables should  ask the question, “When this system fails,  who will it fail for, and how can we prevent  that failure?”64  Johndrow and Lum’s article, “An algorithm  for removing sensitive information:  application to race-independent recidivism  prediction,” provides a thorough analysis  of how machine learning algorithms can be  employed to augment fairness in AI-backed  decision making.65Businesses developing  ML systems- starting  with company leadership  that makes the strategic  decisions for how AI  should be developed/  deploye Include dynamic testing Create and integrate quality assessment  indicators that include fairness and  accountability66   Where appropriate, integrate dynamic testing  procedures to provide accountability either  by67: – Employing cryptographic  commitments (equivalents of sealed  documents held by third party or in  a safe place) – Fair random choices (a technique  allowing software to make fully  reproducible random choices) – Zero knowledge proofs  (cryptographic tools that allow a  decision-maker to prove that the  decision policy that was actually  used has a certain property without  revealing either how the property is  known or what the decision policy  is) ML development teams Teams tasked with  monitoring and evaluating  ML applications once they  are implemented 64 Interviews with Cathy O’Neil and Joshua Cohen  65 Johndrow and Lum 2017, An algorithm for removing sensitive information: application to race-independent recidivism prediction, https://arxiv.org/abs/1703.04957 66 Datta, Sen, and Zick “Algorithmic Transparency via Quantitiative Input Influence: Theory and Experiments with Learning Systems” ( http://www.fatml.org/ schedule/2016/presentation/algorithmic-transparency-quantitative-input )  67 All pulled from “Algorithmic Accountability” citing Kroll et al.
# File 186

(m / multi-sentence
      :snt1 (r / recommend-01
            :ARG1 (a / ask-01
                  :ARG0 (ii / individual
                        :ARG0-of (r2 / responsible-01
                              :ARG1 (a2 / and
                                    :op1 (d / design-01
                                          :ARG0 ii
                                          :ARG1 (a3 / algorithm))
                                    :op2 (w / weight-01
                                          :ARG0 ii
                                          :ARG1 (v / variable)))))
                  :ARG1 (a4 / and
                        :op1 (f / fail-01
                              :ARG1 (a5 / amr-unknown)
                              :ARG2 (s / system
                                    :mod (t / this)))
                        :op2 (p / possible-01
                              :ARG1 (p2 / prevent-01
                                    :ARG0 (w2 / we)
                                    :ARG1 (f2 / fail-01
                                          :ARG1 s))))))
      :snt2 (a6 / and
            :li 65
            :op1 (ii2 / interview-01
                  :ARG0 (a7 / and
                        :op1 (p3 / person
                              :name (n / name
                                    :op1 "Cathy"
                                    :op2 "O'Neil"))
                        :op2 (p4 / person
                              :name (n2 / name
                                    :op1 "Joshua"
                                    :op2 "Cohen")))
                  :ARG1 (p5 / publication
                        :name (n3 / name
                              :op1 "Algorithmic"
                              :op2 "Accountability")))
            :op2 (p6 / publication
                  :name (n4 / name
                        :op1 "Algorithmic"
                        :op2 "Transparency"
                        :op3 "and"
                        :op4 "Experiments"
                        :op5 "with"
                        :op6 "Learning"
                        :op7 "Systems")
                  :ARG1-of (c / cite-01
                        :ARG0 (a8 / and
                              :op1 (p7 / person
                                    :name (n5 / name
                                          :op1 "Kroll"))
                              :op2 (p8 / person
                                    :name (n6 / name
                                          :op1 "Lum"))))
                  :ARG1-of c
                  :ARG2 (p9 / publication
                        :name (n7 / name
                              :op1 "http://www.fatml.org/abs/1703.04957"))))
      :snt3 (a9 / and
            :li 67
            :op1 (c2 / create-01
                  :ARG1 (t2 / thing
                        :ARG0-of (ii3 / indicate-01
                              :ARG1 (a10 / and
                                    :op1 (f3 / fair-01)
                                    :op2 (a11 / accountable-02))))
                  :ARG1-of (ii4 / include-91
                        :ARG2 a10)))
      :op2 (ii5 / integrate-01
            :ARG1 t2)
      :location (a12 / area
            :ARG1-of (a13 / appropriate-02))
      :op2 (e / employ-02
            :ARG1 (t3 / thing
                  :ARG1-of (m2 / mean-01
                        :ARG2 (t4 / thing
                              :ARG2-of (c3 / commit-01
                                    :ARG1 (t5 / thing
                                          :ARG1-of (d2 / document-01)
                                          :ARG1-of (s2 / seal-01)
                                          :ARG1-of (h / hold-01
                                                :ARG0 (o / or
                                                      :op1 (t6 / third-party)
                                                      :op2 (p10 / place
                                                            :ARG1-of (s3 / safe-01))))))))
                  :mod (t7 / technique
                        :ARG0-of (a14 / allow-01
                              :ARG1 (c4 / choose-01
                                    :ARG0 (s4 / software)
                                    :ARG1-of (r3 / reproduce-01
                                          :ARG1-of (p11 / possible-01)))
                              :mod (r4 / random))))))

# ::snt Explainable AI, though it does not solv e all possible issues,  could be  used by law enforcement authorities  as part of  an increased use of innovative tools – including AI – in  analysis and prediction, while at the same time better  achieving the prerequisites of fairness,  accountability and transparency.
# File 92

(p / possible-01
      :ARG1 (u / use-01
            :ARG0 (a / authority
                  :ARG0-of (e / enforce-01
                        :ARG1 (l / law)))
            :ARG1 (ii / intelligent-01
                  :mod (a2 / artificial)
                  :ARG1-of (e2 / explain-01
                        :ARG1-of (p2 / possible-01)))
            :ARG2 (p3 / part
                  :part-of (u2 / use-01
                        :ARG1 (t / tool
                              :ARG1-of (ii2 / innovate-01)
                              :ARG2-of (ii3 / include-01
                                    :ARG1 (ii4 / intelligent-01
                                          :mod a2)))
                        :ARG2 (a3 / and
                              :op1 (a4 / analyze-01)
                              :op2 (p4 / predict-01))
                        :ARG1-of (ii5 / increase-01)
                        :time (a5 / achieve-01
                              :ARG1 (p5 / prerequisite
                                    :domain (a6 / and
                                          :op1 (f / fairness)
                                          :op2 (a7 / accountable-02)
                                          :op3 (t2 / transparency)))
                              :time (t3 / time
                                    :ARG1-of (s / same-01))
                              :ARG1-of (h / have-degree-91
                                    :ARG2 (g / good-02)
                                    :ARG3 (m / more))))))
      :concession (s2 / solve-01
            :polarity -
            :ARG0 ii
            :ARG1 (ii6 / issue-02
                  :mod (a8 / all)
                  :ARG1-of (p6 / possible-01))))

# ::snt For these reasons, the European Parliament  highlights the importance of having AI systems that are safe, robust, secure,  and fit for purpose, and  that respect the principles of fairness, data minimisation, accountability, transparency, non discrimination and explainability.
# File 92

(h / highlight-01
      :ARG0 (o / organization
            :name (n / name
                  :op1 "European"
                  :op2 "Parliament"))
      :ARG1 (ii / important-01
            :ARG1 (h2 / have-03
                  :ARG1 (s / system
                        :mod (ii2 / intelligent-01
                              :mod (a / artificial))
                        :ARG0-of (s2 / safe-01)
                        :mod (r / robust)
                        :mod (s3 / secure)
                        :ARG1-of (f / fit-03
                              :ARG2 (p / purpose))
                        :ARG0-of (r2 / respect-01
                              :ARG1 (p2 / principle
                                    :example (a2 / and
                                          :op1 (f2 / fairness)
                                          :op2 (m / minimize-01
                                                :ARG1 (d / data))
                                          :op3 (a3 / accountable-02)
                                          :op4 (t / transparency)
                                          :op5 (d2 / discriminate-01
                                                :polarity -)
                                          :op6 (e / explain-01
                                                :ARG1-of (p3 / possible-01))))))))
      :ARG1-of (c / cause-01
            :ARG0 (r3 / reason
                  :mod (t2 / this))))

# ::snt Furthermore, XAI helps to determin e a model’s precision, fairness, transparency,  and results in AI based decision making  (101).
# File 92

(a / and
      :op2 (a2 / and
            :op1 (h / help-01
                  :ARG0 (t / thing
                        :name (n / name
                              :op1 "XAI"))
                  :ARG1 (d / determine-01
                        :ARG0 t
                        :ARG1 (a3 / and
                              :op1 (p / precision
                                    :poss (m / model))
                              :op2 (f / fairness
                                    :poss m)
                              :op3 (t2 / transparency
                                    :poss m))))
            :op2 (r / result-01
                  :ARG1 t
                  :ARG2 (m2 / make-01
                        :ARG1 (d2 / decide-01)
                        :ARG1-of (b / base-02
                              :ARG2 t))))
      :ARG1-of (d3 / describe-01
            :ARG0 (p2 / publication
                  :ARG1-of (c / cite-01
                        :ARG2 101))))

# ::snt Explainable AI , although it does not solv e all possible issues,  could  be used by law enforcement authorities  to increase  the use of innovative tools – including AI – for  analysis and prediction, while at the same time helping to  achiev e the prerequisites of fairness,  accountability and transparency.
# File 92

(p / possible-01
      :ARG1 (u / use-01
            :ARG0 (a / authority
                  :ARG0-of (e / enforce-01
                        :ARG1 (l / law)))
            :ARG1 (ii / intelligent-01
                  :mod (a2 / artificial)
                  :ARG1-of (e2 / explain-01
                        :ARG1-of (p2 / possible-01)))
            :ARG2 (ii2 / increase-01
                  :ARG0 a
                  :ARG1 (u2 / use-01
                        :ARG1 (t / tool
                              :ARG1-of (ii3 / innovate-01)
                              :ARG2-of (ii4 / include-01
                                    :ARG1 ii))
                        :ARG2 (a3 / and
                              :op1 (a4 / analyze-01)
                              :op2 (p3 / predict-01)))
                  :time (h / help-01
                        :ARG0 ii
                        :ARG1 (a5 / achieve-01
                              :ARG1 (p4 / prerequisite
                                    :domain (a6 / and
                                          :op1 (f / fairness)
                                          :op2 (a7 / accountable-02)
                                          :op3 (t2 / transparency))))
                        :time (t3 / time
                              :ARG1-of (s / same-01)))))
      :concession (s2 / solve-01
            :polarity -
            :ARG0 ii
            :ARG1 (ii5 / issue-02
                  :mod (a8 / all)
                  :ARG1-of (p5 / possible-01))))

# ::snt Moreover , as is widely discussed at international level,  law enforcement authorities  and the criminal justice system should ensure fairness, accountability,  transparency and that the use of AI is effectively communicated to the publ ic.
# File 92

(a / and
      :op2 (r / recommend-01
            :ARG1 (e / ensure-01
                  :ARG0 (a2 / and
                        :op1 (a3 / authority
                              :ARG0-of (e2 / enforce-01
                                    :ARG1 (l / law)))
                        :op2 (s / system
                              :mod (j / justice
                                    :ARG0-of (c / criminal-03))))
                  :ARG1 (a4 / and
                        :op1 (f / fairness)
                        :op2 (a5 / accountable-02)
                        :op3 (t / transparency))
                  :op3 (c2 / communicate-01
                        :ARG1 (u / use-01
                              :ARG1 (ii / intelligent-01
                                    :mod (a6 / artificial)))
                        :ARG2 (g / government-organization
                              :ARG0-of (g2 / govern-01))
                        :ARG1-of (e3 / effective-04)))
            :ARG1-of (d / discuss-01
                  :manner (w / wide)
                  :location (l2 / level
                        :mod (ii2 / international)))))

# ::snt In this context , in December 2018 , the European Commission for the Efficiency of Justice (CEPEJ) of  the Council of Europe adopted the ‘Ethical Charter on the Use of Artificial Intelligence in Judicial  Systems and their environment ’ (296), which encompasses the following five principles:     1. principle of respect for fundamental rights : ensure that the design and implementation of  artificial intelligence tools and services a re compatible with fundamental rights ;    2. principle of non -discrimination : specifically prevent the development or intensification of any  discrimination among  individuals or groups of individuals ;    3. principle of quality and security : with regard to the proces sing of judicial decisions and data,  use certified sources and intangible data with models elaborated in a multi -disciplinary manner,  in a secure technological environment ;    4. principle of transparency, impartiality and fairness : make data processing methods   accessible and understandable, and authorise external audits ;    5. principle of ‘user control ’: eschew  a prescriptive approach and ensure that users are informed  actors and in control of the choices made  (297).
# File 92

(a / adopt-01
      :ARG0 (o / organization
            :name (n / name
                  :op1 "European"
                  :op2 "Commission"
                  :op3 "for"
                  :op4 "the"
                  :op5 "Efficiency"
                  :op6 "of"
                  :op7 "Justice")
            :part-of (o2 / organization
                  :name (n2 / name
                        :op1 "Council"
                        :op2 "of"
                        :op3 "Europe")))
      :ARG1 (l / law
            :name (n3 / name
                  :op1 "Ethical"
                  :op2 "Charter"
                  :op3 "on"
                  :op4 "the"
                  :op5 "Use"
                  :op6 "of"
                  :op7 "Artificial"
                  :op8 "Intelligence"
                  :op9 "in"
                  :op10 "Judicial"
                  :op11 "Systems"
                  :op12 "and"
                  :op13 "Their"
                  :op14 "Environments")
            :ARG0-of (e / encompass-01
                  :ARG1 (p / principle
                        :quant 5
                        :ARG1-of (f / follow-04)
                        :ARG1-of (m / mean-01
                              :ARG2 (a2 / and
                                    :op1 (p2 / principle
                                          :li 1
                                          :topic (r / respect-01
                                                :ARG1 (r2 / right-05
                                                      :mod (f2 / fundamental)))
                                          :ARG0-of (e2 / ensure-01
                                                :ARG1 (c / compatible
                                                      :domain (a3 / and
                                                            :op1 (d / design-01
                                                                  :ARG1 (a4 / and
                                                                        :op1 (t / tool
                                                                              :mod (a5 / artificial))
                                                                        :op2 (s / serve-01
                                                                              :mod (a6 / artificial))))
                                                            :op2 (ii / implement-01
                                                                  :ARG1 a4))
                                                      :mod (a7 / again)))
                                          :op2 (p3 / principle
                                                :topic (a8 / and
                                                      :op1 (p4 / possible-01
                                                            :ARG1 (a9 / access-01
                                                                  :ARG1 (m2 / method
                                                                        :mod (p5 / process-01
                                                                              :ARG1 (d2 / data)))))
                                                      :op2 (p6 / possible-01
                                                            :ARG1 (u / understand-01
                                                                  :ARG1 m2)))
                                                :op3 (a10 / audit-01
                                                      :mod (e3 / external)))))))
                  :ARG1-of (d3 / describe-01
                        :ARG0 (p7 / publication
                              :ARG1-of (c2 / cite-01
                                    :ARG2 297))))
            :time (d4 / date-entity
                  :month 12
                  :year 2018)
            :mod (c3 / context
                  :mod (t2 / this))))

# ::snt • Fairness : the use of technology  should not breach rights such as the right to due process, the  presumption of innocence, freedom of expression, and freedom from discr imination.
# File 92

(m / multi-sentence
      :snt1 (f / fairness
            :domain (r / recommend-01
                  :ARG1 (b / breach-01
                        :polarity -
                        :ARG0 (u / use-01
                              :ARG1 (t / technology))
                        :ARG1 (r2 / right-05
                              :example (a / and
                                    :op1 (r3 / right-05
                                          :ARG2 (d / due-process))
                                    :op2 (p / presume-01
                                          :ARG1 (ii / innocent-01))
                                    :op3 (f2 / free-04
                                          :ARG3 (e / express-01))
                                    :op4 (f3 / free-04
                                          :ARG3 (e2 / eliminate-01))))))))

# ::snt on fairness, accountability and transparency, that apply to all AI  systems .
# File 46

(a / apply-02
      :ARG1 (a2 / and
            :op1 (f / fairness)
            :op2 (a3 / accountable-02)
            :op3 (t / transparency))
      :ARG2 (s / system
            :mod (a4 / artificial)
            :mod (a5 / all)))

# ::snt transpare ncy,  fairness, non -discrimination).
# File 46

(a / and
      :op1 (e / equal-01)
      :op2 (f / fairness)
      :op3 (d / discriminate-01
            :polarity -)
      :ARG1-of (s / substitute-01))

# ::snt Fairness  ................................ ................................ ................................ ..21  7.4.
# File 46

(a / and
      :op1 (f / fairness)
      :op2 (a2 / age-01
            :ARG2 21)
      :op3 (s / score-on-scale-91
            :ARG1 7.4))

# ::snt transparency,  fairness, non -discrimination).
# File 46

(a / and
      :op1 (t / transparency)
      :op2 (f / fairness)
      :op3 (d / discriminate-01
            :polarity -))

# ::snt - Tiers other than high risk must also be subject to appropriate requirements, such  as complying  with the horizontal princip les that the AI Act should establish ( such  as transparency  and fairness)82 and maintaining an audit trail (documentation duty)  and reporting obligations for medium -risk systems to ensure a n adequate and  verifiable level of transparency.
# File 46

(o / obligate-01
      :ARG2 (s / subject-01
            :ARG1 (t / tier
                  :ARG2-of (e / except-01
                        :ARG1 (r / risk-01
                              :ARG1-of (h / high-02))))
            :ARG2 (t2 / thing
                  :ARG1-of (r2 / require-01)
                  :ARG1-of (a / appropriate-02)
                  :example (a2 / and
                        :li 82
                        :op1 (c / comply-01
                              :ARG1 (p / principle
                                    :mod (h2 / horizontal)
                                    :ARG1-of (e2 / establish-01
                                          :ARG0 (l / law
                                                :name (n / name
                                                      :op1 "Artificial"
                                                      :op2 "Intelligence"
                                                      :op3 "Act"))
                                          :ARG1-of (r3 / recommend-01))
                                    :example (a3 / and
                                          :op1 (t3 / transparency)
                                          :op2 (f / fairness))))
                        :op2 (m / maintain-01
                              :ARG1 (t4 / trail
                                    :mod (a4 / audit-01)
                                    :ARG1-of (m2 / mean-01
                                          :ARG2 (d / duty
                                                :mod (d2 / document-01)))))
                        :op3 (o2 / obligate-01
                              :ARG1 (s2 / system
                                    :ARG0-of (r4 / risk-01
                                          :mod (m3 / medium)))
                              :ARG2 (r5 / report-01))
                        :purpose (e3 / ensure-01
                              :ARG0 s2
                              :ARG1 (l2 / level
                                    :mod (t5 / transparency)
                                    :mod (a5 / adequate)
                                    :ARG1-of (v / verify-01))))))
      :mod (a6 / also))

# ::snt transparency, fairness, non -discrimination).
# File 46

(a / and
      :op1 (t / transparency)
      :op2 (f / fairness)
      :op3 (d / discriminate-01
            :polarity -))

# ::snt Fairness   AI systems  must be developed and used  in a fair and responsible way.
# File 46

(a / and
      :op1 (f / fairness)
      :op2 (o / obligate-01
            :ARG2 (a2 / and
                  :op1 (d / develop-02
                        :ARG1 (s / system
                              :mod (ii / intelligent-01
                                    :mod (a3 / artificial))))
                  :op2 (u / use-01
                        :ARG1 s)
                  :manner (a4 / and
                        :op1 (f2 / fair-01)
                        :op2 (r / responsible-02)))))

# ::snt Questions of fairness should also  be seen under the aspect of general welfare  considerations.
# File 46

(r / recommend-01
      :ARG1 (s / see-01
            :ARG1 (q / question-01
                  :ARG1 (f / fairness))
            :mod (a / also)
            :prep-under (a2 / aspect
                  :topic (c / consider-02
                        :ARG1 (w / welfare
                              :ARG1-of (g / general-02))))))

# ::snt A lack of fairness can lead to even  greater societal asymmetries, unequal  benefits for citizens /consumers , or could even lead to certain groups of people being  exposed to higher risks of poverty.
# File 46

(p / possible-01
      :ARG1 (o / or
            :op1 (l / lead-03
                  :ARG0 (l2 / lack-01
                        :ARG1 (f / fairness))
                  :ARG2 (a / and
                        :op1 (a2 / asymmetry
                              :mod (s / society)
                              :ARG1-of (h / have-degree-91
                                    :ARG2 (g / great)
                                    :ARG3 (m / more
                                          :mod (e / even))))
                        :op2 (b / benefit-01
                              :ARG1 (s2 / slash
                                    :op1 (c / citizen)
                                    :op2 (p2 / person
                                          :ARG0-of (c2 / consume-01)))
                              :ARG1-of (e2 / equal-01
                                    :polarity -))))
            :op2 (l3 / lead-03
                  :ARG0 l2
                  :ARG2 (e3 / expose-01
                        :ARG1 (g2 / group
                              :mod (c3 / certain)
                              :consist-of (p3 / person))
                        :ARG2 (r / risk-01
                              :ARG2 (p4 / poor)
                              :ARG1-of (h2 / have-degree-91
                                    :ARG2 (h3 / high-02
                                          :ARG1 r)
                                    :ARG3 (m2 / more))))
                  :mod (e4 / even))))

# ::snt Access to justice  and right to  redress , including collective redress    Greater protection in terms of transparency, safety, non -discrimination, or fairness are  vital before consumers can trust AI -powered products and services.
# File 46

(v / vital
      :domain (a / and
            :op1 (a2 / access-01
                  :ARG1 (j / justice))
            :op2 (r / right-05
                  :ARG2 (r2 / redress-01
                        :ARG2-of (ii / include-01
                              :ARG1 (r3 / redress-01
                                    :mod (c / collective)))))
            :op3 (p / protect-01
                  :topic (a3 / and
                        :op1 (t / transparency)
                        :op2 (s / safe-01)
                        :op3 (d / discriminate-02
                              :polarity -)
                        :op4 (f / fair-01))
                  :ARG1-of (h / have-degree-91
                        :ARG2 (g / great)
                        :ARG3 (m / more))))
      :time (b / before
            :op1 (p2 / possible-01
                  :ARG1 (t2 / trust-02
                        :ARG0 (p3 / person
                              :ARG0-of (c2 / consume-01))
                        :ARG1 (a4 / and
                              :op1 (p4 / product)
                              :op2 (s2 / serve-01)
                              :ARG1-of (p5 / power-01
                                    :ARG0 (ii2 / intelligent-01
                                          :mod (a5 / artificial))))))))

# ::snt A review must introduce new measures such as a modernisation of the concepts of  ‘fairness’ and ‘vulnerability’, the expansion of blacklisted practices to include ‘digital’  practices and the introduction of a reversal of the burden of proof, placing the onus on the  trader to prove their compliance wit h relevant legislation.113  12.5.
# File 46

(o / obligate-01
      :ARG2 (ii / introduce-02
            :ARG0 (r / review-01)
            :ARG1 (m / measure-02
                  :example (a / and
                        :op1 (m2 / modernize-01
                              :ARG1 (c / concept
                                    :topic (a2 / and
                                          :op1 (f / fairness)
                                          :op2 (v / vulnerable-01))))
                        :op2 (e / expand-01
                              :ARG1 (p / practice-01
                                    :ARG1-of (b / blacklist-01))
                              :ARG4 (ii2 / include-01
                                    :ARG1 (p2 / practice-01
                                          :mod (d / digital))))
                        :op3 (ii3 / introduce-02
                              :ARG1 (r2 / reverse-01
                                    :ARG1 (b2 / burden-01
                                          :ARG2 (p3 / prove-01))
                                    :ARG0-of (p4 / place-01
                                          :ARG1 (o2 / onus)
                                          :ARG2 (p5 / prove-01
                                                :ARG0 (p6 / person
                                                      :ARG0-of (t / trade-01))
                                                :ARG1 (c2 / comply-01
                                                      :ARG0 p6
                                                      :ARG1 (l / legislate-01
                                                            :ARG1-of (r3 / relevant-01)))))))))
            :ARG1-of (n / new-01)))

# ::snt ................................ ................................ ................................ ............................  6  The Current State of AI  ................................ ................................ ................................ ................................ ........  7  Public Outreach and Development of this Report  ................................ ................................ ................................ .. 12  Applications of AI for Public Good  ................................ ................................ ................................ ..........................  13  AI in the Federal G overnment  ................................ ................................ ................................ ................................ .. 15  AI and Regulation  ................................ ................................ ................................ ................................ ......................  17  Case Study: Autonomous Vehicles and Aircraft  ................................ ................................ ................................  18  Research and Workforce  ................................ ................................ ................................ ................................ ..........  23  Monitoring Progress in AI ................................ ................................ ................................ ................................ .. 23  Federal Support for AI Research  ................................ ................................ ................................ ........................  25  Workforce Development and Diversity  ................................ ................................ ................................ .............  26  AI, Automation, and the Economy  ................................ ................................ ................................ .......................  29  Fairness, Safety, and  Governance  ................................ ................................ ................................ ............................  30  Justice, Fairness, and Accountability  ................................ ................................ ................................ .................  30  Safety and Control ................................ ................................ ................................ ................................ ..............  32  Global Considerations and Security  ................................ ................................ ................................ ........................  35  International Coope ration  ................................ ................................ ................................ ................................ ... 35  AI and Cybersecurity  ................................ ................................ ................................ ................................ .........  36  AI in Weapon Systems  ................................ ................................ ................................ ................................ .......  37  Conclusion  ................................ ................................ ................................ ................................ ................................ .. 39  Recommendations in this Report  ................................ ................................ ................................ .............................  40  Acronyms ................................ ................................ ................................ ................................ ................................ .... 43  References  ................................ ................................ ................................ ................................ ................................ .. 45
# File 130

(m / multi-sentence
      :snt1 (s / state
            :mod (c / current)
            :mod (ii / intelligent-01
                  :mod (a / artificial))
            :example (a2 / and
                  :op1 (a3 / automate-01)
                  :op2 (e / economy)))
      :snt2 (a4 / and
            :op1 (f / fair-01)
            :op2 (s2 / safe-01)
            :op3 (g / govern-01))
      :snt3 (r / refer-01
            :ARG1 (r2 / report-01
                  :mod (t / this)))
      :snt4 (a5 / and
            :op1 (p / publication
                  :name (n / name
                        :op1 "Global"
                        :op2 "Considerations"))
            :op2 (p2 / publication
                  :name (n2 / name
                        :op1 "International"
                        :op2 "Coope"
                        :op3 "Rice"))
            :op3 (p3 / publication
                  :name (n3 / name
                        :op1 "Advanced"
                        :op2 "Integrated"
                        :op3 "Automated"
                        :op4 "Vehicle"))
            :op4 (p4 / publication
                  :name (n4 / name
                        :op1 "Advanced"
                        :op2 "Vehicle"
                        :op3 "and"
                        :op4 "Aerospace"
                        :op5 "Development"))
            :op5 (p5 / publication
                  :name (n5 / name
                        :op1 "Advanced"
                        :op2 "Vehicle"
                        :op3 "and"
                        :op4 "Aerospace"
                        :op5 "Development"))
            :op6 (p6 / publication
                  :name (n6 / name
                        :op1 "Advanced"
                        :op2 "Vehicle"
                        :op3 "and"
                        :op4 "Aerospace"
                        :op5 "Development"))
            :op7 (p7 / publication
                  :name (n7 / name
                        :op1 "Public"
                        :op2 "Outreach"))
            :op8 (p8 / publication
                  :name (n8 / name
                        :op1 "Public"
                        :op2 "Good"))
            :op9 (p9 / publication
                  :name (n9 / name
                        :op1 "Advanced"
                        :op2 "Vehicle"
                        :op3 "and"
                        :op4 "Aerospace"
                        :op5 "Development"))
            :op10 (p10 / publication
                  :name (n10 / name
                        :op1 "Public"
                        :op2 "Good"))
            :op11 (p11 / publication
                  :name (n11 / name
                        :op1 "Aeronomic"
                        :op2 "Vehicle"
                        :op3 "and"
                        :op4 "Aerospace"))
            :op12 (p12 / publication
                  :name (n12 / name
                        :op1 "Aeronomic"
                        :op2 "Vehicle"
                        :op3 "and"
                        :op4 "Control"))
            :op13 "and"
            :op14 "Aeronomic"
            :op15 "Vehicle"
            :op16 "and"
            :op17 "Aerospace"
            :op18 "Development"
            :op19 "and"
            :op20 "Aerospace"
            :op21 "and"
            :op21 "Regulations"))

# ::snt AI and Regulation   AI has applications in many products, such as cars and air craft, which  are subject to regulation designed  to protect the public from harm  and ensure fairness in economic competition .
# File 130

(m / multi-sentence
      :snt1 (a / and
            :op1 (ii / intelligent-01
                  :mod (a2 / artificial))
            :op2 (r / regulate-01))
      :snt2 (a3 / apply-02
            :ARG1 (ii2 / intelligent-01
                  :mod a2))
      :ARG2 (p / product
            :quant (m2 / many)
            :example (a4 / and
                  :op1 (c / car)
                  :op2 (c2 / craft
                        :mod (a5 / air))
                  :ARG1-of (s / subject-02
                        :ARG2 (r2 / regulate-01
                              :ARG1-of (d / design-01
                                    :ARG3 (a6 / and
                                          :op1 (p2 / protect-01
                                                :ARG0 r2
                                                :ARG1 (p3 / public)
                                                :ARG2 (h / harm-01
                                                      :ARG1 p3))
                                          :op2 (e / ensure-01
                                                :ARG0 r2
                                                :ARG1 (f / fair-01
                                                      :ARG1 (c3 / compete-01
                                                            :mod (e2 / economy)))))))))))

# ::snt Also , where regulatory responses to the ad dition of AI threaten to increase the cost  of compliance , or slow the development or adoption of beneficial innovations, policymakers should  consider how those responses could be adjusted to lower costs and barriers to innovation  without  adversely impactin g safety  or market fairness .
# File 130

(r / recommend-01
      :ARG1 (c / consider-02
            :ARG0 (p / person
                  :ARG0-of (l / legislate-01))
            :ARG1 (t / thing
                  :manner-of (a / adjust-01
                        :ARG1 (r2 / respond-01
                              :ARG0 (r3 / regulate-01)
                              :ARG1 (a2 / administer-01
                                    :ARG1 (a3 / artificial)))
                        :ARG2 (a4 / and
                              :op1 (c2 / cost-01)
                              :op2 (b / barrier
                                    :prep-to (ii / innovate-01))
                              :ARG1-of (h / have-degree-91
                                    :ARG2 (l2 / low-04
                                          :ARG1 a4)
                                    :ARG3 (m / more)))
                        :manner (ii2 / impact-01
                              :polarity -
                              :ARG1 (o / or
                                    :op1 (s / safe-01)
                                    :op2 (f / fair-01
                                          :ARG1 (m2 / market)))
                              :manner (a5 / adverse)))))
      :mod (a6 / also)
      :condition (t2 / threaten-01
            :ARG0 r2
            :ARG1 (o2 / or
                  :op1 (ii3 / increase-01
                        :ARG0 r2
                        :ARG1 (c3 / cost-01
                              :ARG1 (c4 / comply-01)))
                  :op2 (s2 / slow-01
                        :ARG0 r2
                        :ARG1 (o3 / or
                              :op1 (d / develop-02
                                    :ARG1 (ii4 / innovate-01
                                          :ARG1-of (b2 / benefit-01)))
                              :op2 (a7 / adopt-01
                                    :ARG1 ii4))))))

# ::snt Fairness, Safety, and Governance   As AI technologies move toward broader deployment, technical experts , policy analysts , and ethicists   have raised concerns about unintended consequences  of widespread adoption .
# File 130

(c / concern-01
      :ARG0 (c2 / consequence-03
            :ARG1 (a / adopt-01
                  :ARG1-of (s / spread-03
                        :ARG1-of (w / wide-02)))
            :ARG1-of (ii / intend-01
                  :polarity -))
      :ARG1 (a2 / and
            :op1 (f / fairness)
            :op2 (s2 / safe-01)
            :op3 (g / govern-01))
      :time (m / move-01
            :ARG0 (t / technology
                  :mod (a3 / artificial))
            :ARG2 (d / deploy-01
                  :ARG1 t
                  :ARG1-of (h / have-degree-91
                        :ARG2 (b / broad-02
                              :ARG1 d)
                        :ARG3 (m2 / more))))
      :ARG1-of (c3 / cause-01
            :ARG0 a2
            :op1 (p / person
                  :ARG1-of (e / expert-01
                        :ARG2 (t2 / technical)))
            :op2 (p2 / person
                  :ARG0-of (a4 / analyze-01
                        :ARG1 (p3 / policy-01)))
            :op3 (e2 / ethicist)))

# ::snt Use of AI to make  consequential decisions about people, often replacing decisions made by human -driven  bureaucra tic  processes , leads to concerns about how to ensure justice, fairness, and accountability —the same concerns  voiced previously in the Administration’s Big Data: Seizing Opportunities, Preserving Values  report of  2014,1 as well as the Report to the President on Big Data  and Privacy: A Technological Perspective  published by the President’s Council of Advisors on Science and Technology in 2014 .2 Transparency  concerns focus not only on the data and algorithms involved, but also on the potential to have some form  of explanat ion for any AI -based determination.
# File 130

(l / lead-03
      :ARG0 (u / use-01
            :ARG1 (ii / intelligent-01
                  :mod (a / artificial))
            :ARG2 (d / decide-01
                  :ARG3 (p / person)
                  :ARG1-of (c / consequential-01)
                  :ARG1-of (r / replace-01
                        :ARG2 (d2 / decide-01
                              :ARG0 (p2 / process-02
                                    :ARG0 (b / bureaucracy)
                                    :ARG1-of (d3 / drive-02
                                          :ARG0 (h / human))))
                        :frequency (o / often))))
      :ARG2 (c2 / concern-01
            :ARG0 (e / ensure-01
                  :ARG1 (a2 / and
                        :op1 (j / justice)
                        :op2 (f / fairness)
                        :op3 (a3 / accountable-02)))
            :ARG1-of (s / same-01
                  :ARG2 (c3 / concern-01
                        :ARG1-of (v / voice-01
                              :ARG0 (a4 / and
                                    :op1 (p3 / publication
                                          :name (n / name
                                                :op1 "Big"
                                                :op2 "Data"
                                                :op3 "Seizing"
                                                :op4 "Opportunities"
                                                :op5 ","
                                                :op6 "Preserving"
                                                :op7 "Value")
                                          :ARG1-of (r2 / report-01
                                                :ARG0 (g / government-organization
                                                      :ARG0-of (a5 / administrate-01))
                                                :time (d4 / date-entity
                                                      :year 2014)))
                                    :op2 (p4 / publication
                                          :name (n2 / name
                                                :op1 "Report"
                                                :op2 "to"
                                                :op3 "the"
                                                :op4 "President")
                                          :topic (a6 / and
                                                :op1 (d5 / data
                                                      :mod (b2 / big))
                                                :op2 (p5 / privacy)
                                                :op3 (p6 / perspective
                                                      :mod (t / technology)))
                                          :ARG1-of (p7 / publish-01
                                                :ARG0 (g2 / government-organization
                                                      :name (n3 / name
                                                            :op1 "Council"
                                                            :op2 "of"
                                                            :op3 "Advisors"
                                                            :op4 "on"
                                                            :op5 "Science"
                                                            :op6 "and"
                                                            :op7 "Technology"))
                                                :time (d6 / date-entity
                                                      :year 2014))))
                              :time (p8 / previous)))))
      :ARG2 (c4 / concern-01
            :ARG0 (t2 / transparency)
            :ARG1 (p9 / potential
                  :domain (h2 / have-03
                        :ARG1 (e2 / explain-01
                              :ARG1 (t3 / thing
                                    :ARG1-of (b3 / base-02
                                          :ARG2 ii)))
                        :mod (f2 / form
                              :mod (s2 / some))))))

# ::snt At a technical level, the challenges of fairness and safety are related.
# File 130

(r / relate-01
      :ARG1 (c / challenge-01
            :ARG0 (a / and
                  :op1 (f / fairness)
                  :op2 (s / safe-01)))
      :mod (l / level
            :mod (t / technical)))

# ::snt It can monitor the safety and fairness of applications as they  develop, and adapt regulatory frameworks to encourage innovation while protecting the public.
# File 130

(p / possible-01
      :ARG1 (m / monitor-01
            :ARG0 (ii / it)
            :ARG1 (a / and
                  :op1 (s / safe-01
                        :ARG1 (a2 / application))
                  :op2 (f / fair-01
                        :ARG1 a2))
            :time (a3 / and
                  :op1 (d / develop-02
                        :ARG0 a2
                        :ARG1 (f2 / framework
                              :ARG0-of (r / regulate-01)))
                  :op2 (a4 / adapt-01
                        :ARG0 a2
                        :ARG1 f2
                        :ARG3 (e / encourage-01
                              :ARG0 f2
                              :ARG1 (ii2 / innovate-01)
                              :time (p2 / protect-01
                                    :ARG0 f2
                                    :ARG1 (p3 / public)))))))

# ::snt PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE     17   AI and Regulation   AI has applications in many products, such as cars and aircraft, which  are subject to regulation designed  to protect the public from harm  and ensure fairness in economic competition .
# File 130

(m / multi-sentence
      :snt1 (p / prepare-02
            :ARG2 (f / future
                  :mod (a / artificial_instrument)))
      :snt2 (a2 / and
            :op1 (ii / intelligent-01
                  :mod (a3 / artificial))
            :op2 (r / regulate-01))
      :snt3 (a4 / apply-02
            :ARG1 (ii2 / intelligent-01
                  :mod (a5 / artificial))
            :ARG2 (p2 / product
                  :quant (m2 / many)
                  :example (a6 / and
                        :op1 (c / car)
                        :op2 (a7 / aircraft)
                        :ARG1-of (s / subject-02
                              :ARG2 (r2 / regulate-01
                                    :ARG1-of (d / design-01
                                          :ARG3 (a8 / and
                                                :op1 (p3 / protect-01
                                                      :ARG0 r2
                                                      :ARG1 (p4 / public)
                                                      :ARG2 (h / harm-01
                                                            :ARG1 p4))
                                                :op2 (e / ensure-01
                                                      :ARG0 r2
                                                      :ARG1 (f2 / fair-01
                                                            :ARG1 (c2 / compete-01
                                                                  :mod (e2 / economy))))))))))))

# ::snt Also, where regulatory responses to the addition of AI t hreaten to increase the cost  of compliance or slow the development or adoption of beneficial innovations, policymakers should  consider how those responses could be adjusted to lower costs and barriers to innovation without  adversely impacting safety  or mar ket fairness .
# File 130

(r / recommend-01
      :ARG1 (c / consider-02
            :ARG0 (p / person
                  :ARG0-of (l / legislate-01))
            :ARG1 (t / thing
                  :manner-of (a / adjust-01
                        :ARG1 (r2 / respond-01
                              :ARG1 (a2 / add-02
                                    :ARG1 (ii / intelligent-01
                                          :mod (a3 / artificial)))
                              :ARG0-of (r3 / regulate-01))
                        :ARG2 (a4 / and
                              :op1 (c2 / cost-01
                                    :ARG1 (c3 / comply-01))
                              :op2 (s / slow-01
                                    :ARG1 (o / or
                                          :op1 (d / develop-02
                                                :ARG1 (ii2 / innovate-01
                                                      :ARG1-of (b / benefit-01)))
                                          :op2 (a5 / adopt-01
                                                :ARG1 ii2))))
                        :ARG3 (a6 / and
                              :op1 (c4 / cost-01
                                    :ARG1-of (h / have-degree-91
                                          :ARG2 (l2 / low-04
                                                :ARG1 c4)
                                          :ARG3 (m / more)))
                              :op2 (b2 / barrier
                                    :prep-to (ii3 / innovate-01)))
                        :manner (o2 / or
                              :op1 (ii4 / impact-01
                                    :polarity -
                                    :ARG0 r2
                                    :ARG1 (s2 / safe-01)
                                    :manner (a7 / adverse))
                              :op2 (m2 / mar-02
                                    :polarity -
                                    :ARG0 r2
                                    :ARG1 (f / fairness))))))
      :mod (a8 / also))

# ::snt PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE     30   Fairness, Saf ety, and Governance   As AI technologies gain broader deployment, technical experts and policy analysts have raised concerns  about unintended consequences.
# File 130

(m / multi-sentence
      :snt1 (p / prepare-02
            :ARG2 (f / future
                  :mod (a / artificial)))
      :snt2 (c / concern-01
            :ARG0 (c2 / consequence-03
                  :ARG1-of (ii / intend-01
                        :polarity -))
            :ARG1 (a2 / and
                  :op1 (p2 / person
                        :ARG1-of (e / expert-01
                              :ARG2 (t / technical)))
                  :op2 (p3 / person
                        :ARG0-of (a3 / analyze-01
                              :ARG1 (p4 / policy-01))))
            :time (g / gain-02
                  :ARG0 (t2 / technology
                        :mod a))
            :ARG1 (d / deploy-01
                  :ARG1 t2
                  :ARG1-of (h / have-degree-91
                        :ARG2 (b / broad-02
                              :ARG1 d)
                        :ARG3 (m2 / more))))
      :snt3 (a4 / and
            :op1 (f2 / fairness)
            :op2 (s / safe-01)
            :op3 (e2 / ethics)
            :op4 (g2 / govern-01)))

# ::snt The u se of AI to make consequential decisions about people, often  replacing decisions made by human actors and institutions , leads to concerns about how to ensure justice,  fairness, and accountability —the same concerns voice d previously in the “ Big Data” context.62 The u se of  AI to control physical -world equipment leads to concerns about safety, especially as systems are exposed  to the full complexity of the human environment.
# File 130

(m / multi-sentence
      :li 62
      :snt1 (l / lead-03
            :ARG0 (ii / intelligent-01
                  :mod (a / artificial)
                  :ARG0-of (m2 / make-01
                        :ARG1 (d / decide-01
                              :ARG3 (p / person)
                              :ARG1-of (c / consequential-01))
                        :ARG1-of (r / replace-01
                              :ARG2 (d2 / decide-01
                                    :ARG0 (a2 / and
                                          :op1 p
                                          :ARG0-of (a3 / act-01))
                                    :op2 (ii2 / institution)
                                    :mod (h / human)))
                        :frequency (o / often))))
      :ARG2 (c2 / concern-01
            :ARG0 (e / ensure-01
                  :ARG1 (a4 / and
                        :op1 (j / justice)
                        :op2 (f / fairness)
                        :op3 (a5 / accountable-02)))
            :ARG1-of (s / same-01
                  :ARG2 (c3 / concern-01
                        :ARG1-of (v / voice-01
                              :location (c4 / context
                                    :mod (d3 / data
                                          :mod (b / big)))
                              :time (p2 / previous)))))
      :snt2 (l2 / lead-03
            :ARG0 (ii3 / intelligent-01
                  :mod a)
            :ARG0-of (c5 / control-01
                  :ARG1 (e2 / equipment
                        :mod (w / world
                              :mod (p3 / physical)))))
      :ARG2 (c6 / concern-01
            :ARG0 (s2 / safe-01)
            :ARG1-of (c7 / cause-01
                  :ARG0 (e3 / expose-01
                        :ARG1 (s3 / system)
                        :ARG2 (c8 / complexity
                              :mod (f2 / full)
                              :poss (e4 / environment
                                    :mod (h2 / human)))
                        :mod (e5 / especially)))))

# ::snt At a technical level, the challenges of fairness and safety are related.
# File 130

(r / relate-01
      :ARG1 (c / challenge-01
            :ARG0 (a / and
                  :op1 (f / fairness)
                  :op2 (s / safe-01)))
      :mod (l / level
            :mod (t / technical)))

# ::snt Justice, Fairness, and Accountability   A common theme in the Law and Governance, AI for Social Good, and Social and Economic Impac ts  workshops was the need to ensure that AI promotes justice  and fairness, and that AI -based processes are  accountab le to stakeholders .
# File 130

(n / need-01
      :ARG1 (e / ensure-01
            :ARG1 (a / and
                  :op1 (p / promote-02
                        :ARG0 (ii / intelligent-01
                              :mod (a2 / artificial))
                        :ARG1 (a3 / and
                              :op1 (j / justice)
                              :op2 (f / fairness)))
                  :op2 (a4 / account-01
                        :ARG0 (p2 / process-02
                              :ARG1-of (b / base-02
                                    :ARG2 ii))
                        :ARG1-of (p3 / possible-01)
                        :beneficiary (s / stake-01))))
      :mod (t / theme
            :mod (c / common)
            :location (a5 / and
                  :op1 (a6 / and
                        :op1 (l / law)
                        :op2 (g / govern-01))
                  :op2 (c2 / conference
                        :name (n2 / name
                              :op1 "AI"
                              :op2 "for"
                              :op3 "Social"
                              :op4 "Good"))
                  :op3 (c3 / conference
                        :name (n3 / name
                              :op1 "Social"
                              :op2 "Economic"
                              :op3 "Impac"
                              :op4 "TS"))
                  :op4 (w / workshop)))
      :example (a7 / and
            :op1 j
            :op2 f
            :op3 (a8 / accountable-02)))

# ::snt Justice, Fairness, and Accountability   A common theme in the Law and Governance, AI for Social Good, and Social and Economic Impac ts  workshops was the need to ensure that AI promotes justice  and fairness, and that AI -based processes are  accountab le to stakeholders .
# File 130

(n / need-01
      :ARG1 (e / ensure-01
            :ARG1 (a / and
                  :op1 (p / promote-02
                        :ARG0 (ii / intelligent-01
                              :mod (a2 / artificial))
                        :ARG1 (a3 / and
                              :op1 (j / justice)
                              :op2 (f / fairness)))
                  :op2 (a4 / account-01
                        :ARG0 (p2 / process-02
                              :ARG1-of (b / base-02
                                    :ARG2 ii))
                        :ARG1-of (p3 / possible-01)
                        :beneficiary (s / stake-01))))
      :mod (t / theme
            :mod (c / common)
            :location (a5 / and
                  :op1 (a6 / and
                        :op1 (l / law)
                        :op2 (g / govern-01))
                  :op2 (c2 / conference
                        :name (n2 / name
                              :op1 "AI"
                              :op2 "for"
                              :op3 "Social"
                              :op4 "Good"))
                  :op3 (c3 / conference
                        :name (n3 / name
                              :op1 "Social"
                              :op2 "Economic"
                              :op3 "Impac"
                              :op4 "TS"))
                  :op4 (w / workshop)))
      :example (a7 / and
            :op1 j
            :op2 f
            :op3 (a8 / accountable-02)))

# ::snt A separate report from Upturn question ed the fairness and efficacy of some  predictive  policing tools.67                                                               62 The White House, “Big Data: Seizing Opportunities, Preserving Values,” May 2014,  https://www.whitehouse.gov/sites/de fault/files/docs/big_data_privacy_report_may_1_2014.pdf; and The White  House, “Big Data: A Report on Algorithmic Systems, Opportunity, and Civil Rights,” May 2016,  https://www.whitehouse.gov/sites/default/files/microsites/ostp/2016_0504_data_discrimination .pdf.
# File 130

(a / and
      :op1 (p / publication
            :name (n / name
                  :op1 "Big"
                  :op2 "Data"
                  :op3 "A"
                  :op4 "Report"
                  :op5 "on"
                  :op6 "Algorithmic"
                  :op7 "Systems"
                  :op8 "Opportunities"
                  :op9 "and"
                  :op10 "Civil"
                  :op11 "Rights")
            :ARG1-of (s / separate-02)
            :time (d / date-entity
                  :month 5
                  :year 2016))
      :op2 (p2 / publication
            :name (n2 / name
                  :op1 "The"
                  :op2 "White"
                  :op3 "House")
            :ARG1-of (t / title-01
                  :ARG2 (a2 / and
                        :op1 (s2 / seize-01
                              :ARG1 (o / opportunity))
                        :op2 (p3 / preserve-01
                              :ARG1 (v / value))))
            :time (d2 / date-entity
                  :month 5
                  :year 2014)
            :medium (u / url-entity
                  :value "https://www.whitehouse.gov/sites/default/files/microsites/ostp/2016_0504_data_discrimination.pdf")))

# ::snt Recommendation 16: Federal agencies that use AI -based systems to make or provide decision  support for consequential decisions about individuals should take extra care to ensure the eff icacy  and fairness of those systems, based on evidence -based verification and validation.
# File 130

(r / recommend-01
      :ARG1 (c / care-03
            :ARG0 (a / agency
                  :mod (f / federal)
                  :ARG0-of (u / use-01
                        :ARG1 (s / system
                              :ARG1-of (b / base-02
                                    :ARG2 (ii / intelligent-01
                                          :mod (a2 / artificial))))
                        :ARG2 (o / or
                              :op1 (m / make-01
                                    :ARG0 a
                                    :ARG1 (d / decide-01
                                          :ARG3 (ii2 / individual)
                                          :ARG1-of (c2 / consequential-01)))
                              :op2 (p / provide-01
                                    :ARG0 a
                                    :ARG1 (s2 / support-01
                                          :ARG0 a
                                          :ARG1 (d2 / decide-01
                                                :ARG3 ii2))))))
            :ARG1 (e / ensure-01
                  :ARG0 a
                  :ARG1 (a3 / and
                        :op1 (ii3 / integrity
                              :polarity -
                              :poss (s3 / system
                                    :mod (t / that)))
                        :op2 (f2 / fair-01
                              :ARG1 s3)
                        :ARG1-of (b2 / base-02
                              :ARG2 (a4 / and
                                    :op1 (v / verify-01)
                                    :op2 (v2 / validate-01)
                                    :ARG1-of (b3 / base-02
                                          :ARG2 (e2 / evidence))))))
            :degree (e3 / extra))
      :ARG3 16)

# ::snt Recommendation 17: Federal agencies that make grants to state and local governments in support  of the use of AI -based systems to make consequential decisions about individuals should review the  terms of grants to ensure that AI -based products or services purchased with Federal grant funds  produce results in a sufficiently transparent fashion and are supported by evidence of efficacy and  fairness.
# File 130

(r / recommend-01
      :ARG1 (r2 / review-01
            :ARG0 (a / agency
                  :mod (f / federal)
                  :ARG0-of (g / grant-01
                        :ARG2 (a2 / and
                              :op1 (g2 / government-organization
                                    :ARG0-of (g3 / govern-01)
                                    :mod (s / state))
                              :op2 (g4 / government-organization
                                    :ARG0-of (g5 / govern-01)
                                    :ARG1-of (l / local-02)))
                        :purpose (s2 / support-01
                              :ARG0 a
                              :ARG1 (u / use-01
                                    :ARG1 (s3 / system
                                          :ARG1-of (b / base-02
                                                :ARG2 (ii / intelligent-01
                                                      :mod (a3 / artificial))))
                                    :ARG2 (d / decide-01
                                          :ARG3 (ii2 / individual)
                                          :ARG1-of (c / consequential-01))))))
            :ARG1 (t / term
                  :mod (g6 / grant-01))
            :purpose (e / ensure-01
                  :ARG0 a
                  :ARG1 (a4 / and
                        :op1 (p / produce-01
                              :ARG0 (o / or
                                    :op1 (p2 / product)
                                    :op2 (s4 / serve-01)
                                    :ARG1-of (b2 / base-02
                                          :ARG2 ii)
                                    :ARG1-of (p3 / purchase-01
                                          :ARG3 (f2 / fund
                                                :mod g6)))
                              :ARG1 (r3 / result-01
                                    :manner (t2 / transparent
                                          :ARG0-of (s5 / suffice-01))))
                        :op2 (s6 / support-01
                              :ARG0 (e2 / evidence-01
                                    :ARG1 (a5 / and
                                          :op1 (e3 / effective-04)
                                          :op2 (f3 / fair-01)))
                              :ARG1 o))))
      :ARG2 (p4 / publication
            :mod 17))

# ::snt PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE     35   Global Considerations and Security   In addition to the long -term challenges of AI and the specific issues relating to fairness and safety, AI  poses consequential policy questions in international relations, cybersecurity, and defense.
# File 130

(m / multi-sentence
      :snt1 (p / prepare-02
            :ARG2 (f / future
                  :mod (a / artificial_instrument)))
      :snt2 (a2 / and
            :li 35
            :op1 (c / consider-02
                  :ARG1 (g / globe))
            :op2 (s / security))
      :snt3 (p2 / pose-02
            :ARG0 (ii / intelligent-01
                  :mod (a3 / artificial))
            :ARG1 (q / question-01
                  :ARG1 (p3 / policy-01)
                  :ARG2 (a4 / and
                        :op1 (r / relation-03
                              :ARG1 (ii2 / international))
                        :op2 (c2 / cybersecurity)
                        :op3 (d / defend-01))
                  :ARG1-of (c3 / consequential-01))
            :ARG1-of (a5 / add-02
                  :ARG2 (a6 / and
                        :op1 (c4 / challenge-01
                              :ARG0 ii
                              :ARG1-of (l / long-03))
                        :op2 (ii3 / issue-02
                              :ARG1-of (s2 / specific-02)
                              :ARG1-of (r2 / relate-01
                                    :ARG2 (a7 / and
                                          :op1 (f2 / fairness)
                                          :op2 (s3 / safe-01))))))))

# ::snt It should monitor the safety and fairness of applications as they develop,  and adapt regulatory frameworks to encourage innovation while protecting the public.
# File 130

(r / recommend-01
      :ARG1 (m / monitor-01
            :ARG0 (ii / it)
            :ARG1 (a / and
                  :op1 (s / safe-01
                        :ARG1 (a2 / application))
                  :op2 (f / fair-01
                        :ARG1 a2))
            :time (a3 / and
                  :op1 (d / develop-02
                        :ARG0 a2
                        :ARG1 (f2 / framework
                              :ARG0-of (r2 / regulate-01)))
                  :op2 (a4 / adapt-01
                        :ARG0 a2
                        :ARG1 f2
                        :ARG3 (e / encourage-01
                              :ARG0 f2
                              :ARG1 (ii2 / innovate-01)
                              :time (p / protect-01
                                    :ARG0 f2
                                    :ARG1 (p2 / public)))))))

# ::snt Recommendation  16: Federal ag encies that use AI -based systems to make or provide decision support  for consequential decisions about individuals should take extra care to ensure the efficacy and fairness  of those systems, based on evidence -based verification and validation.
# File 130

(r / recommend-01
      :li 16
      :ARG1 (c / care-03
            :ARG0 (g / government-organization
                  :mod (f / federal)
                  :ARG0-of (a / administer-01)
                  :ARG0-of (u / use-01
                        :ARG1 (s / system
                              :ARG1-of (b / base-02
                                    :ARG2 (ii / intelligent-01
                                          :mod (a2 / artificial))))
                        :ARG2 (o / or
                              :op1 (m / make-01
                                    :ARG0 g
                                    :ARG1 (d / decide-01
                                          :ARG3 (ii2 / individual)
                                          :ARG1-of (c2 / consequential-01)))
                              :op2 (p / provide-01
                                    :ARG0 g
                                    :ARG1 (s2 / support-01
                                          :ARG0 g
                                          :ARG1 (d2 / decide-01
                                                :ARG3 ii2))))))
            :ARG1 (e / ensure-01
                  :ARG0 g
                  :ARG1 (a3 / and
                        :op1 (e2 / effective-04
                              :ARG0 (s3 / system
                                    :mod (t / that)))
                        :op2 (f2 / fair-01
                              :ARG1 s3)
                        :ARG1-of (b2 / base-02
                              :ARG2 (a4 / and
                                    :op1 (v / verify-01)
                                    :op2 (v2 / validate-01)
                                    :ARG1-of (b3 / base-02
                                          :ARG2 (e3 / evidence))))))
            :degree (e4 / extra)))

# ::snt Recommend ation  17: Federal agencies that make grants to state and local governments in support of  the use of AI -based systems to make consequential decisions about individuals should review the terms  of grants to ensure that AI -based products or services purchased with Federal grant funds produce  results in a sufficiently transparent fashion and are supported by evidence of efficacy and fairness.
# File 130

(r / recommend-01
      :ARG1 (r2 / review-01
            :ARG0 (a / agency
                  :mod (f / federal)
                  :ARG0-of (g / grant-01
                        :ARG2 (a2 / and
                              :op1 (g2 / government-organization
                                    :ARG0-of (g3 / govern-01)
                                    :mod (s / state))
                              :op2 (g4 / government-organization
                                    :ARG0-of (g5 / govern-01)
                                    :ARG1-of (l / local-02)))
                        :purpose (s2 / support-01
                              :ARG0 a
                              :ARG1 (u / use-01
                                    :ARG1 (s3 / system
                                          :ARG1-of (b / base-02
                                                :ARG2 (ii / intelligent-01
                                                      :mod (a3 / artificial))))
                                    :ARG2 (d / decide-01
                                          :ARG3 (ii2 / individual)
                                          :ARG1-of (c / consequential-01))))))
            :ARG1 (t / term-01
                  :ARG1 (g6 / grant-01))
            :purpose (e / ensure-01
                  :ARG0 a
                  :ARG1 (a4 / and
                        :op1 (p / produce-01
                              :ARG0 (o / or
                                    :op1 (p2 / product)
                                    :op2 (s4 / serve-01)
                                    :ARG1-of (b2 / base-02
                                          :ARG2 ii)
                                    :ARG1-of (p3 / purchase-01
                                          :ARG3 (f2 / fund-01
                                                :ARG0 g6)))
                              :ARG1 (r3 / result-01
                                    :manner (t2 / transparent
                                          :ARG0-of (s5 / suffice-01))))
                        :op2 (s6 / support-01
                              :ARG0 (e2 / evidence-01
                                    :ARG1 (a5 / and
                                          :op1 (e3 / effective-04)
                                          :op2 (f3 / fair-01)))
                              :ARG1 o))))
      :ARG2 (p4 / publication
            :name (n / name
                  :op1 "Ation"
                  :op2 17)))

# ::snt ............................  15    Chapter 2 – Data protection implications  ...........................  19  Fairness  ................................ ................................ .............  19  Effects of the processing  ................................ ....................  20  Expectations  ................................ ................................ .... 22  Transparency  ................................ ................................ ... 27  Conditions for p rocessing personal data  ................................ .. 29  Consent  ................................ ................................ ...........  29  Legitimate interests  ................................ ..........................  32  Contracts  ................................ ................................ .........  35  Public sector ................................ ................................ ..... 35  Purpose limita tion ................................ ................................  37  Data minimisation: collection and retention  ............................  40  Accuracy  ................................ ................................ ............  43  Rights of individuals  ................................ .............................  46  Subjec t access ................................ ................................ .. 46  Other rights  ................................ ................................ ..... 47  Security  ................................ ................................ .............  49  Accountability and governance  ................................ ..............  51  Data controllers and data processors  ................................ ...... 56    Chapter 3 – Compliance tools  ................................ .............  58  Anonymisation  ................................ ................................ .... 58  Privacy notice s ................................ ................................ .... 62  Privacy impact assessments  ................................ ..................  70  Privacy by design  ................................ ................................  72  Privacy seals and certification  ................................ ................  75  Ethical approaches  ................................ ...............................  77  Personal data stores  ................................ ............................  84  Algorithmic transparency  ................................ ......................  86    Chapter 4 – Discussion  ................................ .......................  90
# File 107

(m / multi-sentence
      :snt1 (a / and
            :op1 (p / publication
                  :name (n / name
                        :op1 "Chapter"
                        :op2 2))
            :op2 (ii / implicate-01
                  :ARG1 (p2 / protect-01
                        :ARG1 (d / data)))
            :op3 (p3 / publication
                  :name (n2 / name
                        :op1 "Privacy"
                        :op2 "By"
                        :op3 "Design"))
            :op4 (a2 / approach-02
                  :mod (e / ethics))
            :op5 (a3 / and
                  :op1 (a4 / accountable-02)
                  :op2 (g / govern-01))
            :op6 (c / contrast-01
                  :ARG2 (a5 / and
                        :op1 (p4 / person
                              :ARG0-of (c2 / control-01
                                    :ARG1 (d2 / data)))
                        :op2 (p5 / person
                              :ARG0-of (p6 / process-01
                                    :ARG1 d2))))
            :op7 (c3 / contrast-01
                  :ARG1 (p7 / percentage-entity
                        :value 20)
                  :ARG2 (p8 / percentage-entity
                        :value 22))
            :op8 (t / transparency)
            :op9 (p9 / percentage-entity
                  :value 27)
            :op10 (c4 / condition-01
                  :ARG1 p6
                  :ARG1 (d3 / data
                        :ARG1-of (p10 / personal-02))))
      :op11 (p11 / percentage-entity
            :value 40)
      :op12 (r / right-05
            :ARG1 (ii2 / individual))
      :op13 (p12 / percentage-entity
            :value 46)
      :op14 (p13 / percentage-entity
            :value 47)
      :op15 (s / security)
      :op16 (p14 / percentage-entity
            :value 32)
      :op17 (p15 / percentage-entity
            :value 50)
      :op18 (p16 / percentage-entity
            :value 35)
      :op19 (p17 / percentage-entity
            :value 84)
      :op20 t
      :mod (a6 / algorithm)
      :op21 (p18 / percentage-entity
            :value 90)
      :snt2 (a7 / and
            :op1 (p19 / publication
                  :name (n3 / name
                        :op1 "Chapter"
                        :op2 "3"))
            :op2 (p20 / publication
                  :name (n4 / name
                        :op1 "Clause"))
            :op3 (p21 / publication
                  :name (n5 / name
                        :op1 "Privacy"
                        :op2 "Notice"))
            :op4 "62")
      :snt3 (a8 / assess-01
            :ARG1 (ii3 / impact-01
                  :ARG0 (p22 / privacy))))

# ::snt     Big data, artificial intelligence, machine learning and data protection   20170904   Version : 2.2 19 Chapter 2 – Data protection implications     Fairness       In brief…      Some types of big data analytics, such as profiling, can have  intrusive effects  on individuals.
# File 107

(m / multi-sentence
      :snt1 (a / and
            :op1 (d / data
                  :mod (b / big))
            :op2 (ii / intelligent-01
                  :mod (a2 / artificial))
            :op3 (l / learn-01
                  :mod (m2 / machine))
            :op4 (p / protect-01
                  :ARG1 (d2 / data))
            :time (d3 / date-entity
                  :year 2007
                  :month 7
                  :day 4))
      :snt2 (c / chapter
            :mod 19
            :part-of (p2 / publication
                  :name (n / name
                        :op1 "Version"
                        :op2 2.2))
            :topic (ii2 / implicate-01
                  :ARG1 (p3 / protect-01
                        :ARG1 (d4 / data))))
      :snt3 (f / fairness)
      :snt4 (p4 / possible-01
            :ARG1 (a3 / affect-01
                  :ARG0 (t / type
                        :mod (s / some)
                        :mod (a4 / analyze-01
                              :ARG1 (d5 / data
                                    :mod b)
                              :example (p5 / profile-01)))
                  :ARG1 (ii3 / individual)
                  :ARG2 (ii4 / intrusive)))
      :snt5 (b2 / brief-01))

# ::snt The importance of fairness is preserved in the  GDPR: Article 5(1)(a) says personal data must be “processed fairly,  lawfully and  in a transparent manner in relation to the data subject”.
# File 107

(p / preserve-01
      :ARG0 (l / law
            :name (n / name
                  :op1 "GDPR")
            :ARG1-of (m / mean-01
                  :ARG2 (s / say-01
                        :ARG0 (l2 / law
                              :name (n2 / name
                                    :op1 "Article"
                                    :op2 "5"
                                    :op3 "part"
                                    :op4 "a"))
                        :ARG1 (o / obligate-01
                              :ARG2 (p2 / process-01
                                    :ARG1 (d / data
                                          :ARG1-of (p3 / personal-02))
                                    :manner (a / and
                                          :op1 (f / fair-01)
                                          :op2 (l3 / lawful)
                                          :op3 (t / transparent))
                                    :ARG1-of (r / relate-01
                                          :ARG2 (d2 / data
                                                :ARG1-of (s2 / subject-01))))))))
      :ARG1 (ii / important-01
            :ARG1 (f2 / fairness)))

# ::snt Fairness involves several  elements.
# File 107

(ii / involve-01
      :ARG1 (e / element
            :quant (s / several))
      :ARG2 (f / fairness))

# ::snt But assessing fairness also involves looking                                       34 For example, Naughton, John Why big data has made your privacy a thing of the past   Guardian online, 6 October 2013  http://www.theguardian.com/technology/2013/oct/06/big -data-predictiv e-analytics privacy ; Richards Neil M. and King, Jonathan H. Three paradoxes of big data  66 Stanford  Law Review Online, 41 3 September 2013  http://www.stanfordlawreview.org/online/privacy -and-big-data/three -paradoxes -bigdata; Leonard, Peter.
# File 107

(m / multi-sentence
      :snt1 (c / contrast-01
            :ARG2 (ii / involve-01
                  :ARG1 (l / look-01
                        :ARG1 (p / privacy))
                  :ARG2 (a / assess-01
                        :ARG1 (f / fairness))
                  :mod (a2 / also)))
      :snt2 (p2 / publication-91
            :ARG0 (a3 / and
                  :op1 (p3 / person
                        :name (n / name
                              :op1 "Neil"
                              :op2 "M."))
                  :op2 (p4 / person
                        :name (n2 / name
                              :op1 "King")))
            :ARG1 (p5 / publication
                  :name (n3 / name
                        :op1 "Three"
                        :op2 "Paradoxes"
                        :op3 "of"
                        :op4 "Big"
                        :op5 "Data"))
            :ARG4 (j / journal
                  :name (n4 / name
                        :op1 "Stanford"
                        :op2 "Law"
                        :op3 "Review"
                        :op4 "Online"))
            :time (d / date-entity
                  :day 41
                  :month 9
                  :year 2013)
            :medium (u / url-entity
                  :value "http://www.theguardian.com/technology/2013/oct/06/big-data-predictiv-e-analytics privacy"))
      :snt3 (p6 / publication
            :name (n5 / name
                  :op1 "Why"
                  :op2 "Big"
                  :op3 "Data"
                  :op4 "Made"
                  :op5 "A"
                  :op6 "Something"
                  :op7 "Of"
                  :op8 "the"
                  :op9 "Past"))
      :snt4 (p7 / publication
            :name (n6 / name
                  :op1 "Guardian")
            :time (d2 / date-entity
                  :day 6
                  :month 10
                  :year 2013)
            :medium (u2 / url-entity
                  :value "http://www.stanfordlawreview.org/online/privacy-and-big-data/three-paradoxes-bigdata"))
      :snt5 (p8 / publication
            :name (n7 / name
                  :op1 "Peter"))
      :snt6 (e / exemplify-01))

# ::snt How big data is used is an important factor in assessing fairness.
# File 107

(ii / important-01
      :ARG1 (t / thing
            :manner-of (u / use-01
                  :ARG1 (d / data
                        :mod (b / big))))
      :ARG2 (a / assess-01
            :ARG1 (f / fair-01)))

# ::snt This means that if big  data organisations are using personal  data, then as part of assessing fairness they need to be aware of  and factor in the effects of their processing on the individuals,  communities and societal groups concerned.
# File 107

(m / mean-01
      :ARG1 (t / this)
      :ARG2 (n / need-01
            :ARG0 (o / organization
                  :mod (d / data
                        :mod (b / big)))
            :ARG1 (a / and
                  :op1 (r / realize-01
                        :ARG0 o
                        :ARG1 (a2 / affect-01
                              :ARG0 (p / process-01
                                    :ARG1 (d2 / data
                                          :ARG1-of (p2 / personal-02)))
                              :ARG1 (a3 / and
                                    :op1 (ii / individual)
                                    :op2 (c / community)
                                    :op3 (g / group
                                          :mod (s / society))
                                    :ARG1-of (c2 / concern-02))))
                  :op2 (f / factor-01
                        :ARG0 o
                        :ARG1 a2))
            :subevent-of (a4 / assess-01
                  :ARG0 o
                  :ARG1 (f2 / fair-01))
            :condition (u / use-01
                  :ARG0 o
                  :ARG1 d2)))

# ::snt Fairness is also about expectations; would a particular use of  personal data be within the reasonable exp ectations of the  people concerned?
# File 107

(m / multi-sentence
      :snt1 (c / concern-02
            :ARG0 (f / fairness)
            :ARG1 (e / expect-01)
            :mod (a / also))
      :snt2 (h / have-mod-91
            :ARG1 (u / use-01
                  :ARG1 (d / data
                        :ARG1-of (p / personal-02))
                  :mod (p2 / particular))
            :ARG2 (r / reasonable-02
                  :ARG1 (e2 / expine-01
                        :ARG0 (p3 / person
                              :ARG1-of c))))
      :polarity (a2 / amr-unknown))

# ::snt While the use of big data has implications regarding  the  transparency of the processing of personal data, it is still a key  element of fairness.
# File 107

(c / contrast-01
      :ARG1 (ii / implicate-01
            :ARG0 (u / use-01
                  :ARG1 (d / data
                        :mod (b / big)))
            :ARG2 (t / transparent
                  :domain (p / process-01
                        :ARG1 (d2 / data
                              :ARG1-of (p2 / personal-02)))))
      :ARG2 (e / element
            :ARG1-of (k / key-02)
            :mod (s / still)
            :topic (f / fairness)
            :domain u))

# ::snt If an organisation is relying on it  to legitimise its big data processing, it need not seek the  consent of the individuals concerned, but it still has to tell them  what it is doing, in line with the fairness requirement.
# File 107

(c / contrast-01
      :ARG1 (n / need-01
            :polarity -
            :ARG0 (o / organization)
            :ARG1 (s / seek-01
                  :ARG0 o
                  :ARG1 (c2 / consent-01
                        :ARG0 (ii / individual
                              :ARG0-of (c3 / concern-02)))))
      :ARG2 (o2 / obligate-01
            :ARG1 o
            :ARG2 (t / tell-01
                  :ARG0 o
                  :ARG1 (t2 / thing
                        :ARG1-of (d / do-02
                              :ARG0 o))
                  :ARG2 ii
                  :ARG1-of (ii2 / in-line-04
                        :ARG2 (r / require-01
                              :ARG1 (f / fair-01))))
            :mod (s2 / still))
      :condition (r2 / rely-01
            :ARG0 o
            :ARG1 (ii3 / it)
            :ARG2 (l / legitimize-01
                  :ARG0 ii3
                  :ARG1 (p / process-01
                        :ARG0 o
                        :ARG1 (d2 / data
                              :mod (b / big))))))

# ::snt  Fairness  is a key factor in determining whether big data analysis is  incompatib le with the original processing purpose.
# File 107

(f / factor
      :ARG1-of (k / key-02)
      :domain (f2 / fairness)
      :ARG0-of (d / determine-01
            :ARG1 (t / truth-value
                  :polarity-of (c / compatible
                        :polarity -
                        :domain (a / analyze-01
                              :ARG1 (d2 / data
                                    :mod (b / big)))
                        :prep-with (p / purpose
                              :mod (p2 / process-01)
                              :mod (o / original))))))

# ::snt This also raises questions about the general fairness  of the p rocessing.
# File 107

(r / raise-01
      :ARG0 (t / this)
      :ARG1 (q / question-01
            :ARG1 (f / fair-01
                  :ARG1 (p / process-01)
                  :ARG1-of (g / general-02)))
      :mod (a / also))

# ::snt As regards discrimination, this is associated with issues relating to  the effects of the processing of personal data, as discussed in the  fairness  section above.
# File 107

(a / associate-01
      :ARG1 (t / this)
      :ARG2 (ii / issue-02
            :ARG1-of (r / relate-01
                  :ARG2 (a2 / affect-01
                        :ARG0 (p / process-01
                              :ARG1 (d / data
                                    :ARG1-of (p2 / personal-02)))))
            :ARG1-of (d2 / discuss-01
                  :location (s / section
                        :topic (f / fairness)
                        :location (a3 / above))))
      :topic (d3 / discriminate-02))

# ::snt As regards the justification of decisions based on machine learning  algorithms, and further to the issues of fairness  discussed above,  there are also i mplications for the new right under the GDPR to  obtain an explanation of a decision based on automated  processing120.
# File 107

(p / propose-01
      :li 120
      :ARG1 (r / right-05
            :ARG2 (o / obtain-01
                  :ARG1 (e / explain-01
                        :ARG1 (d / decide-01
                              :ARG1-of (b / base-02
                                    :ARG2 (p2 / process-01
                                          :ARG1-of (a / automate-01))))))
            :ARG1-of (n / new-01)
            :prep-under (l / law
                  :name (n2 / name
                        :op1 "GDPR")))
      :mod (a2 / also)
      :topic (a3 / and
            :op1 (j / justify-01
                  :ARG1 (d2 / decide-01
                        :ARG1-of (b2 / base-02
                              :ARG2 (a4 / algorithm
                                    :mod (m / machine
                                          :ARG0-of (l2 / learn-01))))))
            :op2 (ii / issue-02
                  :ARG0 (f / fairness)
                  :ARG1-of (d3 / discuss-01
                        :location (a5 / above))
                  :mod (f2 / further))))

# ::snt Anonymisation and definition of  personal data; Principle 1 –  fairness     Data lifecycle management:  archiving data    Principle 5 – retention     121.
# File 107

(a / and
      :op1 (a2 / and
            :op1 (a3 / anonymousize-00)
            :op2 (d / define-01
                  :ARG1 (d2 / data
                        :ARG1-of (p / personal-02))))
      :op2 (p2 / principle
            :mod 1
            :topic (f / fairness))
      :op3 (m / manage-01
            :ARG1 (l / lifecycle
                  :mod (d3 / data))
            :ARG1-of (m2 / mean-01
                  :ARG2 (a4 / archive-01
                        :ARG1 d3)))
      :op4 (p3 / principle
            :mod 5
            :topic (r / retain-01))
      :op5 121)

# ::snt They typically stress values of fairness  and  transparency.
# File 107

(s / stress-01
      :ARG0 (t / they)
      :ARG1 (v / value
            :mod (f / fairness)
            :mod (t2 / transparency))
      :ARG1-of (t3 / typical-02))

# ::snt This suggests  there is a business case for developing an approach that aims to  build trust and is based on transparency and fairness .
# File 107

(s / suggest-01
      :ARG0 (t / this)
      :ARG1 (c / case-03
            :ARG1 (d / develop-02
                  :ARG1 (a / approach-02
                        :ARG0-of (a2 / aim-01
                              :ARG1 (b / build-01
                                    :ARG1 (t2 / trust-01)))
                        :ARG1-of (b2 / base-02
                              :ARG2 (a3 / and
                                    :op1 (t3 / transparency)
                                    :op2 (f / fairness)))))
            :mod (b3 / business)))

# ::snt In particular, it helps to  meet what we see as the key issues of fairness and transparency.
# File 107

(h / help-01
      :ARG0 (m / meet-01
            :ARG1 (t / thing
                  :ARG1-of (s / see-01
                        :ARG0 (w / we)
                        :ARG2 (ii / issue-02
                              :ARG0 (a / and
                                    :op1 (f / fairness)
                                    :op2 (t2 / transparency))
                              :ARG1-of (k / key-02)))))
      :mod (p / particular))

# ::snt     Big data, artificial intelligence, machine learning and data protection   20170904   Version : 2.2 84 Personal data stores       In brief…      The use of personal data stores can address issues of fairness  and lack of transparency by giving individuals greater  control  over their personal data.
# File 107

(m / multi-sentence
      :snt1 (a / and
            :op1 (d / data
                  :mod (b / big))
            :op2 (ii / intelligent-01
                  :mod (a2 / artificial))
            :op3 (l / learn-01
                  :mod (m2 / machine))
            :op4 (p / protect-01
                  :ARG1 (d2 / data))
            :time (d3 / date-entity
                  :year 2007
                  :month 7
                  :day 4))
      :snt2 (s / store-01
            :ARG1 (d4 / data
                  :ARG1-of (p2 / personal-02)
                  :ARG1-of p2)
            :mod (v / version
                  :mod 2.2
                  :mod 84))
      :snt3 (p3 / possible-01
            :ARG1 (a3 / address-01
                  :ARG0 (u / use-01
                        :ARG1 (s2 / store-01
                              :ARG1 d4))
                  :ARG1 (ii2 / issue-02
                        :ARG0 (a4 / and
                              :op1 (f / fairness)
                              :op2 (l2 / lack-01
                                    :ARG1 (t / transparency))))
                  :ARG2 (g / give-01
                        :ARG1 (c / control-01
                              :ARG0 (ii3 / individual)
                              :ARG1 d4
                              :ARG1-of (h / have-degree-91
                                    :ARG2 (g2 / great)
                                    :ARG3 (m3 / more)))
                        :ARG2 ii3)))
      :snt4 (b2 / brief-01))

# ::snt This can at least help to address the issues  of fairness and lack of transparency that we have identified as  potentially problematic in big data.
# File 107

(p / possible-01
      :ARG1 (h / help-01
            :ARG0 (t / this)
            :ARG1 (a / address-02
                  :ARG0 t
                  :ARG1 (ii / issue-02
                        :ARG0 (a2 / and
                              :op1 (f / fairness)
                              :op2 (l / lack-01
                                    :ARG1 (t2 / transparency)))
                        :ARG1-of (ii2 / identify-01
                              :ARG0 (w / we)
                              :ARG2 (p2 / problem
                                    :mod (p3 / potential)
                                    :location (d / data
                                          :mod (b / big))))))
            :mod (a3 / at-least)))

# ::snt When processing personal data, according to Telefonica’s privacy  policy, we will at all times comply with the principles of lawfulness, fairness and  transparency, data minimisation, accuracy, storage limitation, integrity and confidentiality.
# File 13

(c / comply-01
      :ARG0 (w / we)
      :ARG1 (p / principle
            :example (a / and
                  :op1 (l / lawfulness)
                  :op2 (f / fairness)
                  :op3 (t / transparency)
                  :op4 (m / minimize-01
                        :ARG1 (d / data))
                  :op5 (a2 / accurate)
                  :op6 (l2 / limit-01
                        :ARG1 (s / store-01))
                  :op7 (ii / integrity)
                  :op8 (c2 / confidentiality)))
      :time (p2 / process-01
            :ARG0 w
            :ARG1 (d2 / data
                  :ARG1-of (p3 / personal-02)))
      :ARG1-of (s2 / say-01
            :ARG0 (p4 / policy-01
                  :ARG0 (c3 / company
                        :name (n / name
                              :op1 "Telefonica"))
                  :ARG2 (p5 / privacy)))
      :time (a3 / all))

# ::snt   Monetary Authority Of Singapore   1     Principles  to Promote Fairness, Ethics,  Accountability and Transparency  (FEAT) in the Use of Artificial  Intelligence and Data Analytics in  Singapore ’s Financial Sector
# File 24

(p / principle
      :li 1
      :topic (p2 / promote-02
            :ARG1 (a / and
                  :op1 (f / fairness)
                  :op2 (e / ethics)
                  :op3 (a2 / accountable-02)
                  :op4 (t / transparency))
            :ARG2 (u / use-01
                  :ARG1 (a3 / and
                        :op1 (ii / intelligent-01
                              :mod (a4 / artificial))
                        :op2 (a5 / analyze-01
                              :ARG1 (d / data)))
                  :location (s / sector
                        :mod (f2 / finance)
                        :poss (c / country
                              :name (n / name
                                    :op1 "Singapore")))))
      :domain (g / government-organization
            :name (n2 / name
                  :op1 "Monetary"
                  :op2 "Authority"
                  :op3 "of"
                  :op4 "Singapore")))

# ::snt Principles  to Promote  FEAT  in the Use of AI and Data Analytics in Singapore ’s Financial Sector     Monetary Authority of Singapore  2 Contents   1 Introduction  ................................ ................................ ...............................  3  2 Using This Document ................................ ................................ ..................  4  3 Scope and Definitions  ................................ ................................ .................  5  4 Summ ary of Principles  ................................ ................................ ................  6  5 Fairness  ................................ ................................ ................................ ...... 7  6 Ethics  ................................ ................................ ................................ .........  9  7 Accountability  ................................ ................................ ..........................  10  8 Transparency  ................................ ................................ ...........................  12  9 Acknowledgements  ................................ ................................ ..................  14
# File 24

(a / and
      :op1 (p / principle
            :purpose (p2 / promote-02
                  :ARG1 (f / feed-02
                        :ARG1 (u / use-01
                              :ARG1 (a2 / and
                                    :op1 (ii / intelligent-01
                                          :mod (a3 / artificial))
                                    :op2 (a4 / analyze-01
                                          :ARG1 (d / data)))
                              :ARG2 (s / sector
                                    :mod (f2 / finance)
                                    :poss (c / country
                                          :name (n / name
                                                :op1 "Singapore")))))))
      :op2 (p3 / publication
            :name (n2 / name
                  :op1 "Monetary"
                  :op2 "Authority"
                  :op3 "of"
                  :op4 "Singapore")
            :ARG1-of (c2 / cite-01
                  :ARG2 2))
      :op3 (c3 / constitute-01
            :ARG1 (p4 / principle))
      :op4 (s2 / scope)
      :op5 (d2 / define-01)
      :op6 (s3 / score-on-scale-91
            :ARG1 6
            :ARG3 7)
      :op7 (e / ethics)
      :op8 (s4 / score-on-scale-91
            :ARG1 9
            :ARG3 7)
      :op9 (a5 / accountability)
      :op10 (s5 / score-on-scale-91
            :ARG1 10
            :ARG3 7)
      :op11 (p5 / percentage-entity
            :value 10)
      :op12 (p6 / percentage-entity
            :value 8)
      :op13 (p7 / percentage-entity
            :value 12)
      :op14 (p8 / percentage-entity
            :value 9)
      :op15 (p9 / percentage-entity
            :value 14))

# ::snt In developing this set of Principles , MAS has worked closely with  key industry st akeholders through  the Fairness, Ethics, Accountability and Transparency   (FEAT) Committee.
# File 24

(w / work-01
      :ARG0 (o / organization
            :name (n / name
                  :op1 "MA"))
      :ARG3 (d / develop-02
            :ARG0 o
            :ARG1 (s / set
                  :consist-of (p / principle)
                  :mod (t / this)))
      :ARG1-of (c / close-10)
      :manner (o2 / organization
            :name (n2 / name
                  :op1 "FEAT"
                  :op2 "Committee")
            :consist-of (a / and
                  :op1 (f / fairness)
                  :op2 (e / ethics)
                  :op3 (a2 / accountable-02)
                  :op4 (t2 / transparency))
            :beneficiary (p2 / person
                  :ARG0-of (h / hold-01
                        :ARG1 (s2 / stake))
                  :ARG1-of (k / key-02)
                  :mod (ii / industry))))

# ::snt Principles  to Promote  FEAT  in the Use of AI and Data Analytics in Singapore ’s Financial Sector     Monetary Authority of Singapore  6 4 Summary of Principles   Fairness   Justifiability   1.
# File 24

(a / and
      :op1 (p / principle
            :purpose (p2 / promote-02
                  :ARG1 (f / feed-01
                        :ARG1 (a2 / and
                              :op1 (ii / intelligent-01
                                    :mod (a3 / artificial))
                              :op2 (a4 / analyze-01
                                    :ARG1 (d / data)))
                        :ARG2 (s / sector
                              :mod (f2 / finance)
                              :poss (c / country
                                    :name (n / name
                                          :op1 "Singapore"))))))
      :op2 (a5 / authority
            :mod (m / monetary)
            :mod c
            :li 6)
      :op3 (s2 / summarize-01
            :li 4
            :ARG1 (p3 / principle))
      :op4 (f3 / fairness)
      :op5 (p4 / possible-01
            :ARG1 (j / justify-01))
      :op6 (h / have-li-91
            :ARG2 1))

# ::snt Principles  to Promote  FEAT  in the Use of AI and Data Analytics in Singapore ’s Financial Sector     Monetary Authority of Singapore  7 5 Fairness   5.1 It is important that AIDA -driven decisions do not disadvantage any particular  indiv idual or groups of individuals  without justification .
# File 24

(m / multi-sentence
      :snt1 (p / principle
            :topic (p2 / promote-02
                  :ARG1 (f / feed-01
                        :ARG1 (a / and
                              :op1 (ii / intelligent-01
                                    :mod (a2 / artificial))
                              :op2 (a3 / analyze-01
                                    :ARG1 (d / data)))
                        :ARG2 (s / sector
                              :mod (f2 / finance)
                              :poss (c / country
                                    :name (n / name
                                          :op1 "Singapore"))))))
      :snt2 (a4 / and
            :op1 (p3 / publication
                  :name (n2 / name
                        :op1 "Monetary"
                        :op2 "Authority"
                        :op3 "of"
                        :op4 "Singapore"))
            :op2 (p4 / publication
                  :name (n3 / name
                        :op1 "Fairness"))
            :op3 (p5 / publication
                  :name (n4 / name
                        :op1 "5.1")))
      :snt3 (ii2 / important-01
            :ARG1 (d2 / disadvantage-01
                  :polarity -
                  :ARG0 (t / thing
                        :ARG1-of (d3 / decide-01)
                        :ARG1-of (d4 / drive-02
                              :ARG0 (a5 / act-02
                                    :name (n5 / name
                                          :op1 "AIDA"))))
                  :ARG1 (o / or
                        :op1 (ii3 / individual
                              :mod (p6 / particular))
                        :op2 (g / group
                              :consist-of ii3))
                  :manner (j / justify-01
                        :polarity -))))

# ::snt 5.3 The principle s of Fairness focus on two key aspects – firstly, the justifiability and  secondly, the accuracy and bias of AIDA -driven decision s.   Justifiability   1.
# File 24

(m / multi-sentence
      :snt1 (f / focus-01
            :li 5.3
            :ARG0 (p / principle
                  :mod (f2 / fairness))
            :ARG2 (a / aspect
                  :quant 2
                  :ARG1-of (k / key-02)
                  :ARG1-of (m2 / mean-01
                        :ARG2 (a2 / and
                              :op1 (p2 / possible-01
                                    :li 1
                                    :ARG1 (j / justify-01))
                              :op2 (a3 / and
                                    :li 2
                                    :op1 (a4 / accurate
                                          :domain (d / decide-01
                                                :ARG1-of (d2 / drive-02
                                                      :ARG0 (o / organization
                                                            :name (n / name
                                                                  :op1 "AIDA")))))
                                    :op2 (b / bias-01
                                          :ARG1 d))))))
      :snt2 (p3 / possible-01
            :li 1
            :ARG1 (j2 / justify-01)))

# ::snt Designers , developers and users of AI systems ( AI stakeholders ) must respect:   • Applicable laws in  New Zealand and other relevant jurisdictions   • Human rights  recognised under domestic and international law   • Rights of Māori  articulated in Te Tiriti o Waitangi    • Democratic values including the electoral process and informed public debate   • Principles of equality a nd fairness so that AI systems do not unjustly harm, exclude, disempower or  discriminate against individuals or particular groups.
# File 35

(o / obligate-01
      :ARG2 (r / respect-01
            :ARG0 (a / and
                  :op1 (p / person
                        :ARG0-of (d / design-01
                              :ARG1 (s / system
                                    :mod (a2 / artificial))))
                  :op2 (p2 / person
                        :ARG0-of (d2 / develop-02
                              :ARG1 s))
                  :op3 (p3 / person
                        :ARG0-of (u / use-01
                              :ARG1 s))
                  :domain (s2 / stake-01
                        :ARG2 s))
            :ARG1 (a3 / and
                  :op1 (l / law
                        :ARG1-of (a4 / apply-02
                              :location (a5 / and
                                    :op1 (c / country
                                          :name (n / name
                                                :op1 "New"
                                                :op2 "Zealand"))
                                    :op2 (j / jurisdiction
                                          :ARG1-of (r2 / relevant-01)
                                          :mod (o2 / other)))))
                  :op2 (r3 / right-05
                        :mod (h / human)
                        :ARG1-of (r4 / recognize-02
                              :ARG0 (a6 / and
                                    :op1 (l2 / law
                                          :mod (d3 / domestic))
                                    :op2 (l3 / law
                                          :mod (ii / international)))))
                  :op3 (r5 / right-05
                        :ARG1 (p4 / person
                              :mod (e / ethnic-group
                                    :name (n2 / name
                                          :op1 "Māori")))
                        :ARG1-of (a7 / articulate-01
                              :medium (w / work-of-art
                                    :name (n3 / name
                                          :op1 "Te"
                                          :op2 "Tiriti"
                                          :op3 "O"
                                          :op4 "Waitangi"))))
                  :op4 (v / value
                        :mod (d4 / democracy)
                        :ARG2-of (ii2 / include-01
                              :ARG1 (a8 / and
                                    :op1 (p5 / process-02
                                          :ARG1 (e2 / elect-01))
                                    :op2 (d5 / debate-01
                                          :ARG1-of (ii3 / inform-01)
                                          :ARG1-of (p6 / public-02)))))
                  :op5 (p7 / principle
                        :topic (a9 / and
                              :op1 (e3 / equal-01)
                              :op2 (f / fair-01)))
                  :purpose (o3 / or
                        :op1 (h2 / harm-01
                              :polarity -
                              :ARG0 s
                              :ARG1 o3
                              :op1 (ii4 / individual)
                              :op2 (g / group
                                    :mod (p8 / particular))))
                  :op2 (e4 / exclude-01
                        :ARG0 s
                        :ARG1 o3)
                  :op3 (d6 / disempower-01
                        :ARG0 s
                        :ARG1 o3)
                  :op4 (d7 / discriminate-02
                        :polarity -
                        :ARG0 s
                        :ARG1 o3))
            :ARG1-of (j2 / just-02
                  :polarity -)))

# ::snt FAIRNESS AND JUST ICE    2.
# File 35

(a / and
      :li 2
      :op1 (f / fairness)
      :op2 (ii / ice
            :mod (j / just)))

# ::snt 4 MACHINE LEARNING: THE POWER AND PROMISE OF COMPUTERS THAT LEARN BY EXAMPLEChapter five – Machine learning in society  83 5.1  Machine learning and the public  84 5.2  Social issues associated with machine learning applications  90 5.3  The implications of machine learning for governance of data use 98 5.4  Machine learning and the future of work 100 Chapter six – A new wave of machine learning research  109 6.1  Machine learning in society: key scientific and technical challenges  110 6.2  Interpretability and transparency  110 6.3  Verification and robustness  112 6.4  Privacy and sensitive data 113 6.5  Dealing with real-world data: fairness and the full analytics pipeline  114 6.6  Causality  115 6.7  Human-machine interaction  115 6.8  Security and control 116 6.9  Supporting a new wave of machine learning research 117 Annex / Glossary / Appendices  119 Canonical problems in machine learning  120 Glossary  122 Appendix  124
# File 168

(m / multi-sentence
      :snt1 (a / and
            :op1 (p / publication
                  :name (n / name
                        :op1 "Chapter"
                        :op2 "Five")
                  :topic (l / learn-01
                        :ARG1 (m2 / machine)))
            :op2 (p2 / publication
                  :name (n2 / name
                        :op1 "The"
                        :op2 "Power"
                        :op3 "and"
                        :op4 "Promise"
                        :op5 "of"
                        :op6 "Compute"))
            :snt2 (p3 / publication
                  :name (n3 / name
                        :op1 "Chapter"
                        :op2 "Six")
                  :topic (w / wave-04
                        :ARG1 (r / research-01
                              :ARG1 (l2 / learn-01
                                    :ARG1 (m3 / machine)))
                        :ARG1-of (n4 / new-01)))
            :snt3 (a2 / and
                  :op1 (p4 / publication
                        :name (n5 / name
                              :op1 "117"
                              :op2 "Annex"))
                  :op2 (p5 / publication
                        :name (n6 / name
                              :op1 "122"
                              :op2 "Glossary"))
                  :snt4 (a3 / and
                        :op1 (p6 / publication
                              :name (n7 / name
                                    :op1 "88"
                                    :op2 "5.1")
                              :topic (l3 / learn-01
                                    :ARG1 (m4 / machine)
                                    :location (s / society)))
                        :op2 (p7 / publication
                              :name (n8 / name
                                    :op1 "110"
                                    :op2 "6.3")
                              :topic (a4 / and
                                    :op1 (v / verify-01)
                                    :op2 (t / transparency)))
                        :snt5 (p8 / publication
                              :name (n9 / name
                                    :op1 "90"
                                    :op2 "5.3")
                              :topic (ii / issue-02
                                    :ARG0 (s2 / social-03)
                                    :ARG1-of (a5 / associate-01
                                          :ARG2 (a6 / application
                                                :mod (m5 / machine)))))
                        :snt6 (d / deal-01
                              :ARG2 (d2 / data
                                    :mod (w2 / world
                                          :ARG1-of (r2 / real-04)))
                              :manner (a7 / and
                                    :op1 (f / fairness)
                                    :op2 (p9 / pipeline
                                          :mod (a8 / analyze-01)
                                          :mod (f2 / full))))
                        :snt7 (p10 / publication
                              :name (n10 / name
                                    :op1 "116"
                                    :op2 "6.8")
                              :topic (a9 / and
                                    :op1 (s3 / security)
                                    :op2 (c / control-01)))
                        :snt8 (p11 / publication
                              :name (n11 / name
                                    :op1 "108"
                                    :op2 "6.4")
                              :topic (f3 / future
                                    :poss (w3 / work-01)))
                        :snt9 (p12 / publication
                              :name (n12 / name
                                    :op1 "108"
                                    :op2 "6.4"))))))

# ::snt These areas include algorithmic interpretability, robustness, privacy, fairness, inference of causality, human-machine interaction, and security.
# File 168

(ii / include-01
      :ARG1 (a / and
            :op1 (c / capable-01
                  :ARG1 (a2 / algorithm)
                  :ARG2 (ii2 / interpret-01))
            :op2 (r / robustness)
            :op3 (p / privacy)
            :op4 (f / fairness)
            :op5 (ii3 / infer-01
                  :ARG1 (c2 / causality))
            :op6 (ii4 / interact-01
                  :ARG0 (h / human)
                  :ARG1 (m / machine))
            :op7 (s / security))
      :ARG2 (a3 / area
            :mod (t / this)))

# ::snt These areas include algorithm interpretability, robustness, privacy, fairness, inference of causality, human-machine interactions, and security.
# File 168

(ii / include-01
      :ARG1 (a / and
            :op1 (p / possible-01
                  :ARG1 (ii2 / interpret-01
                        :ARG1 (a2 / algorithm)))
            :op2 (r / robustness)
            :op3 (p2 / private-02)
            :op4 (f / fairness)
            :op5 (ii3 / infer-01
                  :ARG1 (c / causality))
            :op6 (ii4 / interact-01
                  :ARG0 (h / human)
                  :ARG1 (m / machine))
            :op7 (s / security))
      :ARG2 (a3 / area
            :mod (t / this)))

# ::snt  CHAPTER FIVE92 MACHINE LEARNING: THE POWER AND PROMISE OF COMPUTERS THAT LEARN BY EXAMPLEFairness and statistical stereotyping Statistical profiling is already used in marketing, insurance, and assessment of threats for policing, so the need to carefully manage biases in data is not in itself new.
# File 168

(m / multi-sentence
      :snt1 (c / chapter
            :mod 592
            :part-of (p / publication
                  :name (n / name
                        :op1 "Machine"
                        :op2 "Learning"))
            :ARG1-of (m2 / mean-01
                  :ARG2 (a / and
                        :op1 (p2 / power-01
                              :ARG0 (c2 / computer
                                    :ARG0-of (l / learn-01
                                          :manner (e / example))))
                        :op2 (p3 / promise-01
                              :ARG0 c2))))
      :snt2 (c3 / cause-01
            :ARG0 (u / use-01
                  :ARG1 (p4 / profile-01
                        :mod (s / statistics))
                  :ARG2 (a2 / and
                        :op1 (m3 / market-01)
                        :op2 (ii / insure-02)
                        :op3 (a3 / assess-01
                              :ARG1 (t / threaten-01
                                    :ARG2 (p5 / police-01))))
                  :time (a4 / already))
            :ARG1 (n2 / new-01
                  :polarity -
                  :ARG1 (n3 / need-01
                        :ARG1 (m4 / manage-01
                              :ARG1 (b / bias-01
                                    :ARG1 (d / data))
                              :ARG1-of (c4 / care-04))))))

# ::snt There are two different ways in which machine learning applications may give rise to biases or lack of fairness.
# File 168

(w / way
      :quant 2
      :ARG1-of (d / differ-02)
      :manner-of (p / possible-01
            :ARG1 (r / rise-01
                  :ARG0 (a / apply-02
                        :ARG1 (l / learn-01
                              :ARG1 (m / machine)))
                  :ARG1 (o / or
                        :op1 (b / bias-01)
                        :op2 (l2 / lack-01
                              :ARG1 (f / fair-01))))))

# ::snt A different source of bias or unfairness can arise  when a machine learning algorithm correctly finds that a particular attribute of individuals is valuable in predicting outcomes, in contexts where society may deem use of such an attribute inappropriate.
# File 168

(p / possible-01
      :ARG1 (a / arise-02
            :ARG1 (s / source-02
                  :ARG1 (o / or
                        :op1 (b / bias-01)
                        :op2 (f / fair-01
                              :polarity -))
                  :ARG1-of (d / differ-02))
            :time (f2 / find-02
                  :ARG0 (a2 / algorithm
                        :instrument-of (l / learn-01
                              :mod (m / machine)))
                  :ARG1 (v / value-02
                        :ARG1 (a3 / attribute-01
                              :ARG0 (ii / individual)
                              :mod (p2 / particular))
                        :ARG2 (p3 / predict-01
                              :ARG1 (o2 / outcome)))
                  :ARG1-of (c / correct-02)
                  :location (c2 / context
                        :location-of (d2 / deem-01
                              :ARG0 (s2 / society)
                              :ARG1 (u / use-01
                                    :ARG1 a3
                                    :ARG1-of (a4 / appropriate-02
                                          :polarity -))
                              :ARG1-of (p4 / possible-01))))))

# ::snt Transparency can also help in detecting instances of bias or unfairness.Second, increased transparency – that is knowing when and why a system performs well or badly – may be directly helpful in the development of better algorithms.
# File 168

(p / possible-01
      :li 2
      :ARG1 (h / help-01
            :ARG0 (t / transparency
                  :ARG1-of (ii / increase-01)
                  :ARG1-of (m / mean-01
                        :ARG2 (k / know-01
                              :ARG1 (a / and
                                    :op1 (t2 / time
                                          :time-of (p2 / perform-02
                                                :ARG0 (s / system)
                                                :ARG1 (o / or
                                                      :op1 (w / well-09)
                                                      :op2 (b / bad-07))))
                                    :op2 (t3 / thing
                                          :ARG0-of (c / cause-01
                                                :ARG1 p2))))))
            :ARG1 (d / develop-02
                  :ARG1 (a2 / algorithm
                        :ARG1-of (h2 / have-degree-91
                              :ARG2 (g / good-02
                                    :ARG1 a2)
                              :ARG3 (m2 / more))))
            :ARG1-of (d2 / direct-02))
      :mod (a3 / also)
      :ARG1-of (p3 / possible-01
            :ARG2 (h3 / help-01
                  :ARG0 (t4 / transparency)
                  :ARG1 (d3 / detect-01
                        :ARG1 (ii2 / instance
                              :mod (o2 / or
                                    :op1 (b2 / bias-01)
                                    :op2 (f / fairness
                                          :polarity -)))))))

# ::snt Third, there may be situations in which society deems that principles of fairness require that an individual be given reasons when an important decision is made against them 152.
# File 168

(p / possible-01
      :li 3
      :ARG1 (s / situation
            :subevent (d / deem-01
                  :ARG0 (s2 / society)
                  :ARG1 (r / require-01
                        :ARG0 (p2 / principle
                              :topic (f / fairness))
                        :ARG1 (g / give-01
                              :ARG1 (r2 / reason)
                              :ARG2 (ii / individual)
                              :time (d2 / decide-01
                                    :ARG1 (t / thing
                                          :ARG1-of (ii2 / important-01))
                                    :prep-against ii))))))

# ::snt  CHAPTER SIX114 MACHINE LEARNING: THE POWER AND PROMISE OF COMPUTERS THAT LEARN BY EXAMPLE6.5 Dealing with real-world data: fairness  and the full analytics pipelineHow can real world data be curated into machine-usable forms, addressing ‘real-world’ messiness, and potential systemic – or social – biases?Machine learning systems need to contend with the realities of real-world data: data sets often have missing entries and outliers, they come in different formats, and suffer from various forms of data corruption.
# File 168

(m / multi-sentence
      :snt1 (c / chapter
            :mod 114
            :part-of (b / book
                  :name (n / name
                        :op1 "Machine"
                        :op2 "Learning")))
      :snt2 (a / and
            :op1 (p / power
                  :poss (c2 / computer
                        :ARG0-of (l / learn-01
                              :manner (e / example
                                    :li 6.5))))
            :op2 (p2 / promise-01
                  :ARG0 c2))
      :snt3 (d / deal-01
            :ARG2 (d2 / data
                  :mod (w / world
                        :ARG1-of (r / real-04)))
            :snt4 (a2 / and
                  :op1 (f / fairness)
                  :op2 (p3 / pipeline
                        :mod (a3 / analytics)
                        :mod (f2 / full))
                  :polarity (a4 / amr-unknown))
            :snt4 (p4 / possible-01
                  :ARG1 (a5 / and
                        :op1 (c3 / curate-01
                              :ARG1 (d3 / data
                                    :mod w)
                              :ARG3 (f3 / form
                                    :ARG1-of (u / use-01
                                          :ARG0 (m2 / machine))))
                        :op2 (a6 / address-02
                              :ARG1 (a7 / and
                                    :op1 (m3 / messiness
                                          :mod w)
                                    :op2 (b2 / bias-01
                                          :mod (s / systemic)
                                          :mod (s2 / social)
                                          :mod (p5 / potential)))))
                  :polarity (a8 / amr-unknown))
            :snt5 (c4 / contend-01
                  :ARG0 (s3 / system
                        :ARG0-of (l2 / learn-01
                              :manner m2)))
            :ARG1 (r2 / reality
                  :poss d3)
            :example (a9 / and
                  :op1 (m4 / miss-01
                        :ARG0 (s4 / set
                              :consist-of (d4 / data))
                        :ARG1 (a10 / and
                              :op1 (e2 / entry)
                              :op2 (o / outlier))
                        :frequency (o2 / often))
                  :op2 (c5 / come-01
                        :ARG1 s4
                        :manner (f4 / format
                              :ARG1-of (d5 / differ-02)))
                  :op3 (s5 / suffer-01
                        :ARG0 s4
                        :ARG1 (c6 / corrupt-01
                              :ARG1 d4
                              :mod (f5 / form
                                    :mod (v / various)))))))

# ::snt These areas include algorithm  interpretability, robustness,  privacy, fairness, inference  of causality, human-machine interactions, and security.
# File 168

(ii / include-01
      :ARG1 (a / and
            :op1 (p / possible-01
                  :ARG1 (ii2 / interpret-01
                        :ARG1 (a2 / algorithm)))
            :op2 (r / robustness)
            :op3 (p2 / privacy)
            :op4 (f / fairness)
            :op5 (ii3 / infer-01
                  :ARG1 (c / causality))
            :op6 (ii4 / interact-01
                  :ARG0 (h / human)
                  :ARG1 (m / machine))
            :op7 (s / security))
      :ARG2 (a3 / area
            :mod (t / this)))

# ::snt The principl es to be respected include  fairness  and non- discrimination,  and the  right to privacy .
# File 83

(ii / include-91
      :ARG1 (a / and
            :op1 (f / fairness)
            :op2 (d / discriminate-02
                  :polarity -)
            :op3 (r / right-05
                  :ARG2 (p / privacy)))
      :ARG2 (d2 / discipline
            :ARG1-of (r2 / respect-01)))

# ::snt Some 40 countries   subscribed to  these principles  – 36 OECD member countries  (including all 22  countries that  are  members of both the EU and the OECD) , and six non- member countries  (including two EU  countries ).11 One of the five principles , 'Human -centred values and fairness ( Principle 1.2 )' states that   'AI actors should respect the rule of law, human rights and democratic values, throughout the AI  system lifecycle.
# File 83

(m / multi-sentence
      :snt1 (s / subscribe-01
            :ARG0 (c / country
                  :quant (s2 / some
                        :op1 40)
                  :ARG2-of (ii / include-91
                        :ARG1 (a / and
                              :op1 (c2 / country
                                    :quant 36
                                    :ARG0-of (h / have-org-role-91
                                          :ARG1 (o / organization
                                                :name (n / name
                                                      :op1 "OECD"))
                                          :ARG2 (m2 / member))
                                    :ARG2-of (ii2 / include-91
                                          :ARG1 (c3 / country
                                                :quant 22
                                                :mod (a2 / all)
                                                :ARG0-of (h2 / have-org-role-91
                                                      :ARG1 (a3 / and
                                                            :op1 (o2 / organization
                                                                  :name (n2 / name
                                                                        :op1 "EU"))
                                                            :op2 o)
                                                      :ARG2 (m3 / member))))))
                        :op2 (c4 / country
                              :quant 6
                              :ARG0-of (h3 / have-org-role-91
                                    :polarity -
                                    :ARG1 o
                                    :ARG2 (m4 / member))
                              :ARG2-of (ii3 / include-91
                                    :ARG1 (c5 / country
                                          :quant 2
                                          :ARG0-of (h4 / have-org-role-91
                                                :ARG1 o2
                                                :ARG2 (m5 / member)))))))
            :ARG1 (p / principle
                  :mod (t / this)))
      :snt2 (s3 / state-01
            :ARG0 (p2 / principle
                  :mod 1.2
                  :ARG1-of (ii4 / include-91
                        :ARG2 (p3 / principle
                              :quant 5))
                  :ARG1-of (m6 / mean-01
                        :ARG2 (a4 / and
                              :op1 (v / value
                                    :ARG1-of (c6 / center-01
                                          :ARG2 (h5 / human)))
                              :op2 (f / fair-01))))
            :ARG1 (r / recommend-01
                  :ARG1 (r2 / respect-01
                        :ARG0 (p4 / person
                              :ARG0-of (a5 / act-01
                                    :mod (a6 / artificial)))
                        :ARG1 (a7 / and
                              :op1 (r3 / rule-03
                                    :ARG1 (l / law))
                              :op2 (r4 / right-05
                                    :ARG1 h5)
                              :op3 (v2 / value
                                    :mod (d / democracy))))
                  :duration (l2 / lifecycle
                        :mod (s4 / system
                              :mod a6)))))

# ::snt These include freedom, dignity and autonomy, privacy  and data protection, non discrimination and equality, diversity, fairness, social justice, and internationally recognised labour rights'.
# File 83

(ii / include-01
      :ARG1 (a / and
            :op1 (f / free-04)
            :op2 (d / dignity)
            :op3 (a2 / autonomy)
            :op4 (p / private-02)
            :op5 (p2 / protect-01
                  :ARG1 (d2 / data))
            :op6 (a3 / and
                  :op1 (d3 / discriminate-02
                        :polarity -)
                  :op2 (e / equal-01))
            :op7 (d4 / diversity)
            :op8 (f2 / fairness)
            :op9 (j / justice
                  :mod (s / social))
            :op10 (r / right-05
                  :ARG2 (l / labor-01)
                  :ARG1-of (r2 / recognize-01
                        :location (ii2 / international))))
      :ARG2 (t / this))

# ::snt 24  https://en.oxforddictionaries.com/definition/bias 25  For a deeper discussion on statistical bias and fairness issues in AI, see talk by Princeton Computer Scientist Arving Narayanan: https://www.youtube.
# File 30

(s / see-01
      :li 24
      :ARG0 (y / you)
      :ARG1 (t / talk-01
            :ARG0 (p / person
                  :name (n / name
                        :op1 "Arving"
                        :op2 "Narayanan")
                  :ARG0-of (h / have-org-role-91
                        :ARG1 (u / university
                              :name (n2 / name
                                    :op1 "Princeton"))
                        :ARG2 (s2 / scientist
                              :mod (c / computer)))))
      :medium (u2 / url-entity
            :value "https://en.oxforddictionaries.com/definition/bias-25")
      :purpose (d / discuss-01
            :ARG1 (a / and
                  :op1 (b / bias-01
                        :mod (s3 / statistics))
                  :op2 (ii / issue-02
                        :ARG0 (f / fairness))
                  :topic (ii2 / intelligent-01
                        :mod (a2 / artificial)))
            :ARG1-of (h2 / have-degree-91
                  :ARG2 (d2 / deep-03
                        :ARG1 d)
                  :ARG3 (m / more))))

# ::snt 28 This is broadly known at the FATML community, “Fairness, Accountability and Transparency for Machine Learning.” See https://www.fatml.org/ for              more info.
# File 30

(m / multi-sentence
      :snt1 (k / know-02
            :li 28
            :ARG0 (c / community
                  :mod (o / organization
                        :name (n / name
                              :op1 "FATML")))
            :ARG1 (t / this)
            :ARG2 (a / and
                  :op1 (f / fairness)
                  :op2 (a2 / accountable-02)
                  :op3 (t2 / transparency)
                  :topic (l / learn-01
                        :manner (m2 / machine)))
            :manner (b / broad))
      :snt2 (s / see-01
            :mode imperative
            :ARG0 (y / you)
            :ARG1 (u / url-entity
                  :value "https://www.fatml.org/")
            :ARG2 (ii / information
                  :mod (m3 / more))))

# ::snt Considering ethical  concepts such as justice, fairness, transparency, and accountability allows for valuable debate about the  societal impacts of AI, and the role of AI in our lives.52  There is also an academic research community  devoted to addressing ethical issues.53  Ethics have helped those researching and developing AI to define  boundaries for themselves.
# File 30

(m / multi-sentence
      :snt1 (a / allow-01
            :li 52
            :ARG0 (c / consider-02
                  :ARG1 (c2 / concept
                        :mod (e / ethics)
                        :example (a2 / and
                              :op1 (j / justice)
                              :op2 (f / fairness)
                              :op3 (t / transparency)
                              :op4 (a3 / accountable-02))))
            :ARG1 (d / debate-01
                  :ARG1 (a4 / and
                        :op1 (ii / impact-01
                              :ARG0 (ii2 / intelligent-01
                                    :mod (a5 / artificial))
                              :ARG1 (s / society))
                        :op2 (r / role
                              :poss ii2
                              :topic (l / live-01
                                    :ARG0 (w / we))))
                  :ARG1-of (v / value-02)))
      :snt2 (d2 / devote-01
            :li 53
            :ARG1 (c3 / community
                  :mod (r2 / research-01
                        :mod (a6 / academia)))
            :ARG2 (a7 / address-02
                  :ARG0 c3
                  :ARG1 (ii3 / issue-02
                        :ARG0 (e2 / ethics)))
            :mod (a8 / also))
      :snt3 (h / help-01
            :li 53
            :ARG0 (e3 / ethics)
            :ARG1 (d3 / define-01
                  :ARG0 (p / person
                        :ARG0-of (r3 / research-01
                              :ARG1 (ii4 / intelligent-01
                                    :mod a5)))
                  :ARG0-of (d4 / develop-02
                        :ARG1 ii4))
            :ARG1 (b / boundary)
            :beneficiary p)
      :ARG2 p)

# ::snt 52  https://www.considerati.com/publications/blog/marrying-ethics-human-rights-ai-scrutiny/ 53  The Fairness, Accountability and Transparency in Machine Learning initiative: https://www.fatml.org/ 54  For each policy see -- Microsoft: https://www.microsoft.com/en-us/ai/our-approach-to-ai, Google: https://www.blog.google/technology/ai/aiprinciples/, DeepMind: https://deepmind.com/applied/deepmind-ethics-society/principles/
# File 30

(m / multi-sentence
      :snt1 (u / url-entity
            :value "https://www.considerati.com/publications/blog/marrying-ethics-human-rights-ai-scrutiny/"
            :li 53)
      :snt2 (a / and
            :op1 (o / organization
                  :name (n / name
                        :op1 "The"
                        :op2 "Fairness"
                        :op3 ","
                        :op4 "Accountability"
                        :op5 "and"
                        :op6 "Transparency"
                        :op7 "in"
                        :op8 "Machine"
                        :op9 "Learning"
                        :op10 "Initiative")
                  :medium (u2 / url-entity
                        :value "https://www.microsoft.com/en-us/ai/our-approach-to-ai"))
            :op2 (o2 / organization
                  :name (n2 / name
                        :op1 "DeepMind")
                  :medium (u3 / url-entity
                        :value "https://deepmind.blog.google/technology/ai/aiprinciples/")))
      :snt3 (s / see-01
            :mode imperative
            :li 54
            :ARG0 (y / you)
            :ARG1 (a2 / and
                  :op1 (c / company
                        :name (n3 / name
                              :op1 "Microsoft")
                        :medium (u4 / url-entity
                              :value "https://www.fatml.com/applied/deepmind-ethics-society/principles/58673/"))
                  :op2 c
                  :name (n4 / name
                        :op1 "Google")
                  :medium u4))
      :topic (p / policy-01
            :mod (e / each)))

# ::snt PE650.527v02-00 4/31 RR\1214925EN.docx EN– having regard to Regulation (EU) 2018/1807 of the European Parliament and of the  Council of 14 November 2018 on a framework for the free flow of non-personal data in  the European Union8,  – having regard to Regulation (EU) 2019/1150 of the European Parliament and of the  Council of 20 June 2019 on promoting fairness and transparency for business users of  online intermediation services9,  – having regard to the Commission White Paper of 19 February 2020 entitled ‘Artificial  Intelligence - A European approach to excellence and trust’ (COM(2020)0065), – having regard to the work of the High-Level Expert Group on Artificial Intelligence set  up by the Commission, – having regard to the Commission communications entitled ‘A European Data Strategy’  (COM(2020)0066) and ‘A New Industrial Strategy for Europe’ (COM(2020)0102), – having regard to the Guidelines for Examination in the European Patent Office of  November 2019, – having regard to the digital economy working paper 2016/05 of the Commission’s Joint  Research Centre and its Institute for Prospective Technological Studies entitled ‘An  Economic Policy Perspective on Online Platforms’, – having regard to the political guidelines for the next European Commission 2019-2024  entitled ‘A Union that strives for more: my agenda for Europe’, – having regard to its resolution of 16 February 2017 with recommendations to the  Commission on Civil Law Rules on Robotics10, – having regard to Rule 54 of its Rules of Procedure,  – having regard to the opinions of the Committee on the Internal Market and Consumer  Protection, the Committee on Transport and Tourism and the Committee on Culture and  Education, – having regard to the report of the Committee on Legal Affairs (A9-0176/2020), A. whereas the Union’s legal framework for intellectual property aims to promote  innovation, creativity and access to knowledge and information; B. whereas Article 118 of the TFEU stipulates that the Union legislator must establish  measures for the creation of European intellectual property rights (IPRs) to provide  uniform protection of those rights throughout the Union; whereas the single market is  conducive to the stronger economic growth needed to ensure the prosperity of Union  citizens; 8 OJ L 303, 28.11.2018, p. 59.
# File 86

(m / multi-sentence
      :snt1 (a / and
            :op1 (p / publication
                  :name (n / name
                        :op1 "PE650.527v02-00")
                  :time (d / date-entity
                        :month 6
                        :day 31
                        :year 2019))
            :op2 (p2 / publication
                  :name (n2 / name
                        :op1 "A"
                        :op2 "European"
                        :op3 "Data"
                        :op4 "Strategy"
                        :op5 "on"
                        :op6 "Online"
                        :op7 "Platforms")
                  :ARG1-of (e / entitle-02
                        :ARG2 (w / work-01
                              :ARG0 (o / organization
                                    :name (n3 / name
                                          :op1 "High-Level"
                                          :op2 "Expert"
                                          :op3 "Group"
                                          :op4 "on"
                                          :op5 "Artificial"
                                          :op6 "Intelligence")
                                    :ARG1-of (s / set-up-03
                                          :ARG0 (o2 / organization
                                                :name (n4 / name
                                                      :op1 "European"
                                                      :op2 "Union")))))))
            :op3 (p3 / publication
                  :name (n5 / name
                        :op1 "A"
                        :op2 "European"
                        :op3 "Parliament")
                  :time (d2 / date-entity
                        :year 2019
                        :month 6
                        :day 9)
                  :ARG0-of (r / regard-01
                        :ARG1 (p4 / publication
                              :name (n6 / name
                                    :op1 "A"
                                    :op2 "New"
                                    :op3 "Industrial"
                                    :op4 "Strategy"
                                    :op5 "for"
                                    :op6 "Europe")))
                  :op4 (p5 / publication
                        :name (n7 / name
                              :op1 "Guidelines"
                              :op2 "for"
                              :op3 "Examination")
                        :time (d3 / date-entity
                              :year 2019
                              :month 11
                              :day 11))
                  :ARG0-of (r2 / regard-01
                        :ARG1 (p6 / publication
                              :name (n8 / name
                                    :op1 "A"
                                    :op2 "Civil"
                                    :op3 "Law"
                                    :op4 "Rules"
                                    :op5 "on"
                                    :op6 "Robotics"))))
            :op5 (p7 / publication
                  :name (n9 / name
                        :op1 "OJ"
                        :op2 "L"
                        :op3 "303")
                  :time (d4 / date-entity
                        :year 2019
                        :month 11
                        :day 11))
            :op6 (p8 / publication
                  :name (n10 / name
                        :op1 "A"
                        :op2 "Committee"
                        :op3 "on"
                        :op4 "Cultural"
                        :op5 "Affairs")
                  :time (d5 / date-entity
                        :year 2020))
            :ARG0-of (r3 / regard-01
                  :ARG1 (t / thing
                        :ARG1-of (r4 / recommend-01
                              :ARG2 (o3 / organization
                                    :name (n11 / name
                                          :op1 "European"
                                          :op2 "Parliament"))))))
      :op7 (p9 / publication
            :name (n12 / name
                  :op1 "Rule"
                  :op2 "54")
            :part-of (r5 / rule
                  :mod (p10 / procedure)
                  :poss o3))
      :snt2 (c / contrast-01
            :ARG2 (s2 / stipulate-01
                  :ARG0 (l / law
                        :name (n13 / name
                              :op1 "Article"
                              :op2 "118")
                        :part-of (t2 / treaty
                              :name (n14 / name
                                    :op1 "TFEU")))
                  :ARG1 (o4 / obligate-01
                        :ARG1 (o5 / organization
                              :name (n15 / name
                                    :op1 "European"
                                    :op2 "Union"))
                        :ARG2 (e2 / establish-01
                              :ARG0 o5
                              :ARG1 (m2 / measure-02
                                    :ARG1 (p11 / protect-01
                                          :ARG1 (r6 / right-05
                                                :ARG2 (p12 / property
                                                      :mod (ii / intellectual)))
                                          :mod (c2 / continent
                                                :name (n16 / name
                                                      :op1 "Europe")))
                                    :ARG1-of (u / uniform-02)))))))

# ::snt Notes that AI makes it possible to process a large quantity of data relating to the state of  the art or the existence of IPRs; notes, at the same time, that AI or related technologies  used for the registration procedure to grant IPRs and for the determination of liability  for infringements of IPRs cannot be a substitute for human review carried out on a caseby-case basis, in order to ensure the quality and fairness of decisions; notes that AI is  progressively gaining the ability to perform tasks typically carried out by humans and  stresses, therefore, the need to establish adequate safeguards, including design systems  with human-in-the-loop control and review processes, transparency, accountability and  verification of AI decision-making; 18.
# File 86

(a / and
      :li 18
      :op1 (n / note-01
            :ARG1 (m / make-02
                  :ARG0 (ii / intelligent-01
                        :mod (a2 / artificial))
                  :ARG1 (p / possible-01
                        :ARG1 (p2 / process-01
                              :ARG1 (d / data
                                    :quant (l / large)
                                    :ARG1-of (r / relate-01
                                          :ARG2 (o / or
                                                :op1 (s / state
                                                      :mod (a3 / art))
                                                :op2 (e / exist-01
                                                      :ARG1 (p3 / product
                                                            :name (n2 / name
                                                                  :op1 "IPR"))))))))))
      :op2 (n3 / note-01
            :ARG1 (g / gain-02
                  :ARG0 ii
                  :ARG1 (c / capable-01
                        :ARG1 ii
                        :ARG2 (p4 / perform-02
                              :ARG0 ii
                              :ARG1 (t / task
                                    :ARG1-of (c2 / carry-out-03
                                          :ARG0 (h / human)
                                          :ARG1-of (t2 / typical-02)))))
                  :ARG0-of (c3 / cause-01
                        :ARG1 (s2 / stress-02
                              :ARG1 (n4 / need-01
                                    :ARG1 (e2 / establish-01
                                          :ARG1 (s3 / safeguard
                                                :mod (a4 / adequate)
                                                :ARG2-of (ii2 / include-01
                                                      :ARG1 (a5 / and
                                                            :op1 (s4 / system
                                                                  :mod (d2 / design)
                                                                  :ARG0-of (h2 / have-03
                                                                        :ARG1 (a6 / and
                                                                              :op1 (c4 / control-01
                                                                                    :ARG0 (h3 / human
                                                                                          :location (l2 / loop))
                                                                                    :ARG1 (p5 / process-02
                                                                                          :ARG1 (r2 / review-01)))
                                                                              :op2 (t3 / transparency)
                                                                              :op3 (a7 / accountable-02)
                                                                              :op4 (v / verify-01
                                                                                    :ARG1 (m2 / make-01
                                                                                          :ARG0 ii
                                                                                          :ARG1 (d3 / decide-01)))))))))))
                              :ARG1-of (p6 / possible-01
                                    :polarity -)
                              :purpose (e3 / ensure-01
                                    :ARG1 (a8 / and
                                          :op1 (q / quality
                                                :poss (d4 / decide-01))
                                          :op2 (f / fair-01
                                                :ARG1 d4))))))
            :time (t4 / time
                  :ARG1-of (s5 / same-01))))

# ::snt Introduce	a	new	‘Certificate	of	Fairness	for	AI	systems’	alongside	a	‘kite	mark’	type	scheme	to	display	it.
# File 7

(ii / introduce-01
      :ARG1 (a / and
            :op1 (c / certificate
                  :ARG1-of (n / new-01)
                  :topic (f / fairness))
            :op2 (o / organization
                  :name (n2 / name
                        :op1 "AI"
                        :op2 "systems"))
            :op3 (k / kite-mark)
            :op4 (s / schedule-01
                  :ARG1 (d / display-01
                        :ARG1 (ii2 / it)))))

# ::snt Introduce	a	‘reduced	liability’	incentive	for	companies	that	have	obtained	a	Certificate	of	Fairness	to	foster	innovation	and	competitiveness.
# File 7

(ii / introduce-01
      :ARG1 (a / and
            :op1 (r / reduce-01
                  :ARG1 (l / liable-01))
            :op2 (ii2 / incentivize-01
                  :ARG1 (c / company
                        :ARG0-of (o / obtain-01
                              :ARG1 (c2 / certificate
                                    :topic (f / fairness)))))
            :op3 (f2 / foster-01
                  :ARG0 c
                  :ARG1 a
                  :op1 (ii3 / innovate-01
                        :ARG0 c)
                  :op2 (c3 / competitiveness))))

# ::snt Now	more	than	ever,	ethics	and	fairness	have	become	key	for	policy	makers	and	citizens.
# File 7

(h / have-degree-91
      :ARG1 (a / and
            :op1 (e / ethics)
            :op2 (f / fairness))
      :ARG2 (a2 / and
            :op1 (k / key-02
                  :ARG1 a
                  :ARG2 (p / policy-01))
            :op2 (k2 / key-02
                  :ARG1 a
                  :ARG2 (a3 / and
                        :op1 (p2 / person
                              :ARG0-of (m / make-01
                                    :ARG1 p))
                        :op2 (c / citizen))))
      :ARG3 (m2 / more)
      :ARG4 (e2 / ever))

# ::snt The	WLinAI	Network	was	established	in	May	2018	to	achieve	the	following	objectives:	Equality	o Bring	more	women	into	the	tech	field	by	providing	role	models	and	champions;	o Foster	a	space	for	women	to	proactively	share	ideas;	o Encourage	women	in	tech	to	grow	both	professionally	and	personally;	o Create	alliances	between	BAME	and	other	minority	tech	groups	and	forward	thinking	leaders	to	ensure	AI	works	for	all;		Policy		o Create	cutting	edge	policy	proposals	regarding	the	increased	use	of	AI	in	society;	o To	move	Ethics	well	beyond	just	fixing	algorithms,	to	define	what	AI	should	and	should	not	be	used	for	in	the	bigger	picture;	o Investigate	governance	models	for	the	deployment	of	AI			Fairness		o Ensure	AI	does	not	amplify	stereotypes	and	reinforce	prejudices;	o Define	design	values	to	avoid	AI	mirroring	existing	power	imbalances;	o Evaluate	and	develop	policies	to	mitigate	the	impact	of	AI	on	jobs,	especially	in	areas	that	harm	women	the	most.
# File 7

(m / multi-sentence
      :snt1 (e / establish-01
            :ARG1 (o / organization
                  :name (n / name
                        :op1 "The"
                        :op2 "WLinAI"))
            :time (d / date-entity
                  :month 5
                  :year 2018))
      :snt2 (a / and
            :op1 (e2 / encourage-01
                  :ARG1 (w / woman)
                  :ARG2 (g / grow-01
                        :ARG0 w
                        :ARG1 (a2 / and
                              :op1 (p / professional)
                              :op2 (ii / individual))))
            :op2 (d2 / define-01
                  :ARG1 (v / value)
                  :purpose (a3 / avoid-01
                        :ARG1 (ii2 / imbalance
                              :ARG1-of (e3 / exist-01))))
            :op3 (a4 / and
                  :op1 (e4 / evaluate-01)
                  :op2 (d3 / develop-02
                        :ARG1 (p2 / policy-01)
                        :purpose (m2 / mitigate-01
                              :ARG0 p2
                              :ARG1 (ii3 / impact-01
                                    :ARG0 (a5 / and
                                          :op1 (p3 / person)
                                          :op2 (p4 / person
                                                :ARG0-of (h / have-org-role-91
                                                      :ARG2 (c / champion))))
                                    :ARG1 (j / job)))))))

# ::snt We	therefore	call	for	the	regulation	of	AI	comprising	of,	but	not	limited	to:	● The	establishment	of	a	regulatory	function	to	support	and	work	alongside	the	Information	Commissioner	Officer	(ICO)	and	the	Centre	of	Data	Ethics	to		o oversee	complaints	around	significant	effect	of	algorithms	on	individuals;		o perform	ethics	audits	on	companies	using	algorithms	for	their	decision	making	as	well	as	digital	advertising	and	any	process	which	has	significant	effect	on	citizens,	including	price	discrimination;	● The	establishment	of	‘certificates	of	fairness’9	to	be	issued	to	companies	that	undertake	an	audit	and	follow	the	processes	set	up	at	industry	level.
# File 7

(c / cause-01
      :ARG1 (c2 / contrast-01
            :ARG1 (c3 / call-03
                  :ARG0 (w / we)
                  :ARG1 (r / regulate-01
                        :ARG1 (ii / intelligent-01
                              :mod (a / artificial))))
            :ARG2 (a2 / and
                  :op1 (o / oversee-01
                        :ARG0 w
                        :ARG1 (c4 / complain-01
                              :ARG0 (c5 / company
                                    :ARG0-of (u / use-01
                                          :ARG1 (a3 / algorithm)
                                          :ARG2 (d / decide-01
                                                :ARG0 c5
                                                :ARG3 (a4 / and
                                                      :op1 (a5 / advertise-01
                                                            :mod (d2 / digital))
                                                      :op2 (p / process-02
                                                            :mod (a6 / any)
                                                            :ARG0-of (a7 / affect-01
                                                                  :ARG1 (c6 / citizen)
                                                                  :ARG1-of (s / significant-02))
                                                            :ARG2-of (ii2 / include-01
                                                                  :ARG1 (p2 / price-01
                                                                        :ARG1 (d3 / discriminate-02))))))))))
                  :op2 (f / follow-02
                        :ARG0 w
                        :ARG1 p))))

# ::snt ● In	view	of	the	need	to	grow	AI	and	invest	in	its	development,	we	recommend	that	the	certificate	of	fairness	grants	companies	a	‘reduced	liability’	incentive	in	relation	to	liability	for	inadvertent	errors	within	the	system.
# File 7

(r / recommend-01
      :ARG0 (w / we)
      :ARG1 (g / grant-01
            :ARG0 (c / certificate
                  :topic (f / fairness))
            :ARG1 (l / liable-01
                  :ARG1 (c2 / company)
                  :ARG1-of (r2 / reduce-01)
                  :ARG0-of (ii / incentivize-01
                        :ARG2 (l2 / liable-01
                              :ARG1 c2
                              :ARG1-of (c3 / cause-01
                                    :ARG0 (e / err-01
                                          :ARG0 c2
                                          :ARG1-of (a / advertise-01
                                                :polarity -)
                                          :location (s / system))))))
            :ARG2 c2))

# ::snt As	AI	is	becoming	ubiquitous,	it	is	important	that	safeguards	are	in	place	to	ensure	fairness,	transparency	and	the	ability	to	challenge	a	machine	decision.
# File 7

(c / cause-01
      :ARG0 (b / become-01
            :ARG1 (p / publication
                  :name (n / name
                        :op1 "The"
                        :op2 "Independent"
                        :op3 "Student"
                        :op4 "Room"))
            :ARG2 (u / unique-01
                  :ARG1 p))
      :ARG1 (ii / important-01
            :ARG1 (s / safeguard
                  :location (p2 / place
                        :purpose (e / ensure-01
                              :ARG0 s
                              :ARG1 (a / and
                                    :op1 (f / fairness)
                                    :op2 (t / transparency)
                                    :op3 (p3 / possible-01
                                          :ARG1 (c2 / challenge-01
                                                :ARG0 s
                                                :ARG2 (d / decide-01
                                                      :ARG0 (m / machine))))))))))

# ::snt These	two	requirements	are	important	in	order	to	avoid	“drift”	in	use	that	could	reduce	the	accuracy	and	fairness	of	the	algorithm.
# File 7

(ii / important-01
      :ARG1 (t / thing
            :quant 2
            :ARG1-of (r / require-01)
            :mod (t2 / this))
      :purpose (a / avoid-01
            :ARG1 (d / drift-01))
      :purpose (u / use-01
            :ARG1 t
            :ARG2 (r2 / reduce-01
                  :ARG1 (a2 / and
                        :op1 (a3 / accuracy)
                        :op2 (f / fairness)
                        :poss (a4 / algorithm))
                  :ARG1-of (p / possible-01))))

# ::snt Therefore,	we	recommend:	● Approval	must	be	sought	from	a	regulator	prior	to	deployment	should	the	AIA	identify	an	area	of	risk;	● Risk	to	individuals	or	groups	should	be	determined	within	the	UN	Universal	Declaration	of	Human	Rights	(UDHR)	to	balance	any	variance	in	cultural	norms	with	regards	to	fairness	and	bias;				● Involvement	of	an	automated	system	in	the	decision-making	process	should	be	clearly	highlighted	to	the	user;	● Data	subjects	must	be	informed	about	what	would	need	to	change	to	obtain	a	different	outcome	or	a	different	decision;	● Guidance	and	specific	criteria	must	be	developed	at	sector	level	as	we	recognise	that	a	one	size	fits	all	approach	will	be	detrimental	to	innovation.
# File 7

(c / cause-01
      :ARG1 (r / recommend-01
            :ARG0 (w / we)
            :ARG1 (a / and
                  :op1 (o / obligate-01
                        :ARG1 (a2 / approve-01
                              :ARG0 (p / person
                                    :ARG0-of (r2 / regulate-01))
                              :time (p2 / prior
                                    :op1 (d / deploy-01))))
                  :op2 (o2 / obligate-01
                        :ARG1 (d2 / develop-02
                              :ARG1 a2
                              :manner (l / level
                                    :mod (s / sector))))
                  :op3 (r3 / recommend-01
                        :ARG1 (d3 / determine-01
                              :ARG1 (r4 / risk-01
                                    :ARG0 (o3 / or
                                          :op1 (ii / individual)
                                          :op2 (g / group))
                                    :ARG1-of (m / mean-01
                                          :ARG2 (d4 / declare-02
                                                :ARG0 (o4 / organization
                                                      :name (n / name
                                                            :op1 "Universal"
                                                            :op2 "Declaration"
                                                            :op3 "of"
                                                            :op4 "Human"
                                                            :op5 "Rights")))))))
                  :op4 (o5 / obligate-01
                        :ARG1 (ii2 / inform-01
                              :ARG1 (s2 / subject
                                    :mod (a3 / all))
                              :ARG2 (t / thing
                                    :ARG1-of (n2 / need-01
                                          :ARG0 o3)))))))

# ::snt ● Responsibility	and	Fairness:	are	values	which	may	need	to	be	embedded	in	the	machine,	depending	on	the	degree	of	machine	autonomy.
# File 7

(a / and
      :op1 (r / responsible-01)
      :op2 (f / fairness)
      :domain (v / value
            :ARG0-of (n / need-01
                  :ARG1 (e / embed-01
                        :ARG1 v
                        :ARG2 (m / machine))
                  :ARG1-of (p / possible-01))
            :ARG0-of (d / depend-01
                  :ARG1 (d2 / degree
                        :degree-of (a2 / autonomy
                              :poss m)))))

# ::snt This	is	why	we	are	recommending	the	issuing	of	certificates	of	fairness	for	organisations	to	adopt	and	display	to	increase	transparency	and	reliability.
# File 7

(c / cause-01
      :ARG0 (t / this)
      :ARG1 (r / recommend-01
            :ARG0 (w / we)
            :ARG1 (a / and
                  :op1 (ii / issue-01
                        :ARG1 (c2 / certificate
                              :topic (f / fairness)))
                  :op2 (d / display-01
                        :ARG1 c2
                        :purpose (a2 / and
                              :op1 (ii2 / increase-01
                                    :ARG1 (t2 / transparency))
                              :op2 (r2 / rely-01
                                    :ARG1-of (p / possible-01)))))
            :ARG2 (o / organization)))

# ::snt Introduce	a	‘certificate	of	fairness’	for	AI	systems	that	are	audited	for	risks	concerning	discrimination,	unfairness	and	privacy.
# File 7

(ii / introduce-01
      :ARG1 (c / certify-01
            :ARG2 (f / fairness))
      :ARG2 (a / audit-01
            :ARG1 (s / system
                  :ARG0-of (c2 / concern-02
                        :ARG1 (a2 / and
                              :op1 (d / discriminate-02)
                              :op2 (f2 / fairness
                                    :polarity -)
                              :op3 (p / privacy))))))

# ::snt Introduce	a	‘reduced	liability’	incentive	for	companies	that	have	obtained	a	Certificate	of	Fairness.
# File 7

(ii / introduce-01
      :ARG1 (a / and
            :op1 (r / reduce-01
                  :ARG1 (l / liable-01))
            :op2 (ii2 / incentivize-01
                  :ARG1 (c / company
                        :ARG0-of (o / obtain-01
                              :ARG1 (c2 / certificate
                                    :topic (f / fair-01)))))))

# ::snt Such	companies	may	also	publish	a	kitemark	to	showcase	their	commitment	to	fairness	and	equality.
# File 7

(p / possible-01
      :ARG1 (p2 / publish-01
            :ARG0 (c / company
                  :mod (s / such))
            :ARG1 (t / thing
                  :ARG1-of (m / mark-01))
            :purpose (s2 / showcase-01
                  :ARG0 c
                  :ARG1 (c2 / commit-01
                        :ARG1 c
                        :ARG2 (a / and
                              :op1 (f / fairness)
                              :op2 (e / equal-01))))
            :mod (a2 / also)))

# ::snt 35AI Fairness 360 (AIF360)  IBM has released this open source.
# File 129

(m / multi-sentence
      :snt1 (p / publication
            :name (n / name
                  :op1 "35AI"
                  :op2 "Fairness"
                  :op3 360))
      :snt2 (r / release-01
            :ARG0 (c / company
                  :name (n2 / name
                        :op1 "IBM"))
            :ARG1 (t / thing
                  :ARG1-of (o / open-04)
                  :mod (t2 / this))))

# ::snt AIF360 implements more than ten bias  mitigation algorithms and seventy state-of-the-art metrics related to fairness in a common software  framework.
# File 129

(ii / implement-01
      :ARG0 (p / product
            :name (n / name
                  :op1 "AIF360"))
      :ARG1 (a / and
            :op1 (a2 / algorithm
                  :quant (m / more-than
                        :op1 10)
                  :ARG0-of (m2 / mitigate-01
                        :ARG1 (b / bias-01)))
            :op2 (m3 / metric
                  :quant 70
                  :mod (s / state-of-the-art)
                  :ARG1-of (r / relate-01
                        :ARG2 (f / fairness))))
      :location (f2 / framework
            :mod (s2 / software)
            :ARG1-of (s3 / share-01)))

# ::snt 2 Regulation (EU) 2019/1150 of 20 June 2019 on promoting fairness and transparency for business users of online intermediation services [2019] OJ  L186/57.
# File 74

(p / publication-91
      :ARG1 (r / regulate-01
            :li 2
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "EU"))
            :ARG1 (p2 / promote-02
                  :ARG1 (a / and
                        :op1 (f / fairness)
                        :op2 (t / transparency)
                        :beneficiary (p3 / person
                              :ARG0-of (u / use-01
                                    :ARG1 (s / service
                                          :mod (ii / intermediation
                                                :mod (o2 / online))))
                              :mod (b / business))))
            :time (d / date-entity
                  :year 2019
                  :month 6
                  :day 20))
      :ARG4 (j / journal
            :name (n2 / name
                  :op1 "OJ"))
      :ARG1-of (c / cite-01
            :ARG2 (l / law
                  :name (n3 / name
                        :op1 "L186/57"))))

# ::snt An ethical  platform for the responsible delivery of an AI p roject   Preliminary considerations  about the ethical pl atform    Three building -blocks of a responsible AI project delivery ecosystem   The SUM Values    The FAST Track Principles    Fairness     Data fairness     Design fairness     Outcome fairness     Implementation fairness     Putting the principle of discriminatory non -harm into action    Accountability     Accountability deserves consideration both before and after model completion    Sustainability     Stakeholder Impact Assessment    Safety     Accuracy, reliability, s ecurity, and r obustness     Risks posed to accura cy and reliability     Risks posed to security and robustness    Transparency     Defining transparent AI     Three critical tasks for designing and implementing transparent AI     Map ping AI t ransparency   Process t ransparency: Establishing a Process -Based Governance F ramework     Outcome transparency : Explaining outcomes, clarifyin g content , implementing responsibly    Defining i nterpretable AI    Technical aspects of choosing, designing, and using an interpretable AI system    Guide lines for designing  and delivering  a sufficiently interpretable AI system     Guideline 1: Look first to context, potential impact, and domain -specific need     Guideline 2: Draw on standard interpretable techniques when possible     Guideline 3: Considerations  for ‘black box’ AI systems     Guideline 4: Think about interpretability in terms of capacities for understanding   Securing  responsible delivery through  human -centred implementation protocols and practices    Step 1: Consider aspects of application type and domain context to define roles    Step 2: Define delivery relations and map delivery processes    Step 3: Build an ethical implementation platform   Conclusion    Bibliography
# File 157

(m / multi-sentence
      :snt1 (a / and
            :op1 (c / consider-02
                  :ARG1 (p / platform
                        :mod (e / ethics)
                        :purpose (d / deliver-01
                              :ARG1 (ii / intelligent-01
                                    :mod (a2 / artificial))))
                  :mod (p2 / preliminary))
            :op2 (p3 / put-03
                  :ARG1 (p4 / principle
                        :topic (h / harm-01
                              :polarity -
                              :ARG0-of (d2 / discriminate-01)))
                  :ARG2 (a3 / act-02))
            :op3 (d3 / deserve-01
                  :ARG0 (a4 / accountable-02)
                  :ARG1 (c2 / consider-02
                        :ARG1 (a5 / aspect
                              :mod (t / technical)
                              :topic (a6 / and
                                    :op1 (d4 / design-01
                                          :ARG1 (s / system
                                                :mod ii
                                                :ARG1-of (ii2 / interpret-01
                                                      :ARG1-of (p5 / possible-01))))
                                    :op2 (d5 / deliver-01
                                          :ARG1 s))))))
      :snt2 (a7 / and
            :op1 (t2 / task
                  :quant 3
                  :ARG1-of (c3 / critical-02)
                  :purpose (a8 / and
                        :op1 (d6 / design-01
                              :ARG1 (s2 / system
                                    :mod ii))
                        :op2 (ii3 / implement-01
                              :ARG1 s2)))
            :op2 (e2 / establish-01
                  :ARG1 (g / government-organization
                        :ARG0-of (g2 / govern-01)
                        :ARG1-of (b / base-02
                              :ARG2 (p6 / process-02)))))
      :snt3 (a9 / and
            :op1 (p7 / publication
                  :name (n / name
                        :op1 "The"
                        :op2 "SUM"
                        :op3 "Value"))
            :op2 (p8 / publication
                  :name (n2 / name
                        :op1 "FAST"
                        :op2 "Track"
                        :op3 "Principles"))
            :op3 (f / fairness
                  :mod (d7 / data))
            :op4 (d8 / design-01
                  :ARG1 (f2 / fair-01))
            :op5 (ii4 / implement-01))
      :snt4 (a10 / and
            :op1 (p9 / publication
                  :name (n3 / name
                        :op1 "Guarding"
                        :op2 "1"))
            :op2 (p10 / publication
                  :name (n4 / name
                        :op1 "Step"
                        :op2 "2"))
            :op3 "3")
      :op4 (c4 / conclude-01)
      :op5 (p11 / publication
            :name (n5 / name
                  :op1 "Bibliography"))
      :snt6 (a11 / and
            :op1 (l / look-01
                  :ARG0 (y / you)
                  :ARG1 (a12 / and
                        :op1 (c5 / context
                              :mod (a13 / application))
                        :op2 (c6 / context
                              :mod (d9 / domain)))
                  :ARG2 (d10 / define-01
                        :ARG0 y
                        :ARG1 (r / role))
                  :time (f3 / first)))
      :op2 (s3 / sustain-01
            :ARG0 y)
      :op3 (a14 / assess-01
            :ARG1 (ii5 / impact-01
                  :ARG0 (p12 / person
                        :ARG0-of (h2 / hold-01
                              :ARG1 (s4 / stake)))))
      :op4 (s5 / safe-01)
      :snt7 (p13 / pose-02
            :ARG0 (a15 / and
                  :op1 (a16 / accurate)
                  :op2 (r2 / reliability))
            :ARG1 (a17 / and
                  :op1 (s6 / security)
                  :op2 (r3 / robustness))))

# ::snt An ethical  platform for the responsible delivery of an AI p roject   Preliminary considerations  about the ethical pl atform    Three building -blocks of a responsible AI project delivery ecosystem   The SUM Values    The FAST Track Principles    Fairness     Data fairness     Design fairness     Outcome fairness     Implementation fairness     Putting the principle of discriminatory non -harm into action    Accountability     Accountability deserves consideration both before and after model completion    Sustainability     Stakeholder Impact Assessment    Safety     Accuracy, reliability, s ecurity, and r obustness     Risks posed to accura cy and reliability     Risks posed to security and robustness    Transparency     Defining transparent AI     Three critical tasks for designing and implementing transparent AI     Map ping AI t ransparency   Process t ransparency: Establishing a Process -Based Governance F ramework     Outcome transparency : Explaining outcomes, clarifyin g content , implementing responsibly    Defining i nterpretable AI    Technical aspects of choosing, designing, and using an interpretable AI system    Guide lines for designing  and delivering  a sufficiently interpretable AI system     Guideline 1: Look first to context, potential impact, and domain -specific need     Guideline 2: Draw on standard interpretable techniques when possible     Guideline 3: Considerations  for ‘black box’ AI systems     Guideline 4: Think about interpretability in terms of capacities for understanding   Securing  responsible delivery through  human -centred implementation protocols and practices    Step 1: Consider aspects of application type and domain context to define roles    Step 2: Define delivery relations and map delivery processes    Step 3: Build an ethical implementation platform   Conclusion    Bibliography
# File 157

(m / multi-sentence
      :snt1 (a / and
            :op1 (c / consider-02
                  :ARG1 (p / platform
                        :mod (e / ethics)
                        :purpose (d / deliver-01
                              :ARG1 (ii / intelligent-01
                                    :mod (a2 / artificial))))
                  :mod (p2 / preliminary))
            :op2 (p3 / put-03
                  :ARG1 (p4 / principle
                        :topic (h / harm-01
                              :polarity -
                              :ARG0-of (d2 / discriminate-01)))
                  :ARG2 (a3 / act-02))
            :op3 (d3 / deserve-01
                  :ARG0 (a4 / accountable-02)
                  :ARG1 (c2 / consider-02
                        :ARG1 (a5 / aspect
                              :mod (t / technical)
                              :topic (a6 / and
                                    :op1 (d4 / design-01
                                          :ARG1 (s / system
                                                :mod ii
                                                :ARG1-of (ii2 / interpret-01
                                                      :ARG1-of (p5 / possible-01))))
                                    :op2 (d5 / deliver-01
                                          :ARG1 s))))))
      :snt2 (a7 / and
            :op1 (t2 / task
                  :quant 3
                  :ARG1-of (c3 / critical-02)
                  :purpose (a8 / and
                        :op1 (d6 / design-01
                              :ARG1 (s2 / system
                                    :mod ii))
                        :op2 (ii3 / implement-01
                              :ARG1 s2)))
            :op2 (e2 / establish-01
                  :ARG1 (g / government-organization
                        :ARG0-of (g2 / govern-01)
                        :ARG1-of (b / base-02
                              :ARG2 (p6 / process-02)))))
      :snt3 (a9 / and
            :op1 (p7 / publication
                  :name (n / name
                        :op1 "The"
                        :op2 "SUM"
                        :op3 "Value"))
            :op2 (p8 / publication
                  :name (n2 / name
                        :op1 "FAST"
                        :op2 "Track"
                        :op3 "Principles"))
            :op3 (f / fairness
                  :mod (d7 / data))
            :op4 (d8 / design-01
                  :ARG1 (f2 / fair-01))
            :op5 (ii4 / implement-01))
      :snt4 (a10 / and
            :op1 (p9 / publication
                  :name (n3 / name
                        :op1 "Guarding"
                        :op2 "1"))
            :op2 (p10 / publication
                  :name (n4 / name
                        :op1 "Step"
                        :op2 "2"))
            :op3 "3")
      :op4 (c4 / conclude-01)
      :op5 (p11 / publication
            :name (n5 / name
                  :op1 "Bibliography"))
      :snt6 (a11 / and
            :op1 (l / look-01
                  :ARG0 (y / you)
                  :ARG1 (a12 / and
                        :op1 (c5 / context
                              :mod (a13 / application))
                        :op2 (c6 / context
                              :mod (d9 / domain)))
                  :ARG2 (d10 / define-01
                        :ARG0 y
                        :ARG1 (r / role))
                  :time (f3 / first)))
      :op2 (s3 / sustain-01
            :ARG0 y)
      :op3 (a14 / assess-01
            :ARG1 (ii5 / impact-01
                  :ARG0 (p12 / person
                        :ARG0-of (h2 / hold-01
                              :ARG1 (s4 / stake)))))
      :op4 (s5 / safe-01)
      :snt7 (p13 / pose-02
            :ARG0 (a15 / and
                  :op1 (a16 / accurate)
                  :op2 (r2 / reliability))
            :ARG1 (a17 / and
                  :op1 (s6 / security)
                  :op2 (r3 / robustness))))

# ::snt                                                                              Understanding Artificial Intelligence Ethics and Safety  5 harbour traces of discrimination, bias, inequity,  or unfairness, the opaqueness of the model may be deeply  problematic .
# File 157

(a / and
      :op1 (h / harbor-01
            :ARG0 (m / model)
            :ARG1 (t / trace
                  :mod (o / or
                        :op1 (d / discriminate-02)
                        :op2 (b / bias-01)
                        :op3 (e / equity
                              :polarity -)
                        :op4 (f / fair-01
                              :polarity -))))
      :op2 (p / possible-01
            :ARG1 (p2 / problematic-02
                  :ARG0 (o2 / opaqueness
                        :poss m)
                  :ARG1-of (d2 / deep-02)))
      :op3 (u / understand-01
            :ARG1 (a2 / and
                  :op1 (e2 / ethics
                        :mod (a3 / artificial))
                  :op2 (s / safe-01))))

# ::snt • You will have to ensure that  your AI project  is fair and non -discriminatory  by accounti ng for  its potential to have discriminat ory e ffects on individuals and social groups, by mitigating  biases  that ma y influence your model’s outputs , and by  being aware of the issues  surrounding  fairness  that come into play at every phase  of the design and implementation   pipeline.
# File 157

(o / obligate-01
      :ARG1 (y / you)
      :ARG2 (e / ensure-01
            :ARG0 y
            :ARG1 (a / and
                  :op1 (f / fair-01
                        :ARG1 (p / project
                              :mod (ii / intelligent-01
                                    :mod (a2 / artificial))
                              :poss y))
                  :op2 (d / discriminate-02
                        :polarity -
                        :ARG0 p))
            :manner (a3 / and
                  :op1 (a4 / account-01
                        :ARG0 y
                        :ARG1 (p2 / potential
                              :domain (d2 / discriminate-02
                                    :ARG0 p
                                    :ARG1 (a5 / and
                                          :op1 (ii2 / individual)
                                          :op2 (g / group
                                                :mod (s / society))))))
                  :op2 (m / mitigate-01
                        :ARG0 y
                        :ARG1 (b / bias-01
                              :ARG0-of (ii3 / influence-01
                                    :ARG1 (o2 / output
                                          :poss (m2 / model
                                                :poss y)))))
                  :op3 (r / realize-01
                        :ARG0 y
                        :ARG1 (ii4 / issue-02
                              :ARG0-of (s2 / surround-01
                                    :ARG1 (f2 / fairness))
                              :ARG0-of (c / come-about-06
                                    :time (p3 / phase
                                          :mod (e2 / every)
                                          :subevent-of (a6 / and
                                                :op1 (d3 / design-01
                                                      :ARG1 (p4 / pipeline))
                                                :op2 (ii5 / implement-01
                                                      :ARG1 p4)))))))))

# ::snt                                                                              Understanding Artificial Intelligence Ethics and Safety  7   Three building -blocks  of a responsible AI project delivery  ecosystem     Setting up an ethical platform for responsible AI project delivery involves  not only  building from the  cultural ground up ; it involves providing you r team  with the means to accomplish the goals of  establishing the ethical permissibility, fairness, trustworthiness, and justifiability of your project.
# File 157

(m / multi-sentence
      :snt1 (a / and
            :op1 (u / understand-01
                  :ARG1 (a2 / and
                        :op1 (e / ethics
                              :mod (a3 / artificial))
                        :op2 (s / safe-01)))
            :op2 (b / block
                  :quant 3
                  :ARG2-of (b2 / build-01)
                  :part-of (e2 / ecosystem
                        :mod (d / deliver-01
                              :ARG1 (p / project
                                    :mod (ii / intelligent-01
                                          :mod (a4 / artificial)))))))
      :snt2 (a5 / and
            :op1 (ii2 / involve-01
                  :ARG0 (s2 / set-up-03
                        :ARG1 (p2 / platform
                              :mod (e3 / ethics))
                        :purpose d)
                  :ARG1 (b3 / build-01
                        :source (g / ground-up
                              :mod (c / culture))))
            :op2 (ii3 / involve-01
                  :ARG0 s2
                  :ARG1 (p3 / provide-01
                        :ARG1 (m2 / means)
                        :ARG2 (t / team
                              :poss (y / you))
                        :purpose (a6 / accomplish-01
                              :ARG0 t
                              :ARG1 (g2 / goal
                                    :topic (e4 / establish-01
                                          :ARG0 t
                                          :ARG1 (a7 / and
                                                :op1 (p4 / possible-01
                                                      :ARG1 (p5 / permit-01
                                                            :ARG1 (e5 / ethics)))
                                                :op2 (f / fair-01)
                                                :op3 (p6 / possible-01
                                                      :ARG1 (t2 / trust-01))
                                                :op4 (j / justifiability)
                                                :poss p
                                                :poss y))))))))

# ::snt These  will be called  FAST Track Principles , and they will be  composed  of four key notions: Fairness, Accountability,  Sustainability , and Transparency .
# File 157

(a / and
      :op1 (c / call-01
            :ARG1 (t / this)
            :ARG2 (t2 / thing
                  :name (n / name
                        :op1 "FAST"
                        :op2 "Track"
                        :op3 "Principles")))
      :op2 (c2 / compose-01
            :ARG1 t
            :ARG2 (n2 / notion
                  :quant 4
                  :ARG1-of (k / key-02)
                  :domain (a2 / and
                        :op1 (f / fairness)
                        :op2 (a3 / accountable-02)
                        :op3 (s / sustain-01
                              :ARG1-of (p / possible-01))
                        :op4 (t3 / transparency)))))

# ::snt Moreover, w e demand of them that  their actions and  decisi ons be supported by good reasons, and we hold them  accountable for the fairness, equity, and  reasonableness  of how they treat  others.
# File 157

(a / and
      :op2 (a2 / and
            :op1 (d / demand-01
                  :ARG0 (w / we)
                  :ARG1 (s / support-01
                        :ARG0 (r / reason
                              :ARG1-of (g / good-02))
                        :ARG1 (a3 / and
                              :op1 (a4 / act-02
                                    :ARG0 (t / they))
                              :op2 (d2 / decide-01
                                    :ARG0 t)))
                  :ARG2 t)
            :op2 (h / hold-02
                  :ARG0 w
                  :ARG1 (a5 / accountable-02
                        :ARG0 t
                        :ARG1 (a6 / and
                              :op1 (f / fairness)
                              :op2 (e / equity)
                              :op3 (r2 / reasonableness)
                              :domain (t2 / thing
                                    :manner-of (t3 / treat-01
                                          :ARG0 t
                                          :ARG1 (p / person
                                                :mod (o / other))))))
                  :ARG2 t)))

# ::snt Targeted principles such as fairness,  accountability, sustainability , and transparency are meant to ‘ fill the gap ’ between the new ‘smart  agency’ of machines and their fundamental lack of moral responsibility.
# File 157

(m / mean-02
      :ARG1 (p / principle
            :example (a / and
                  :op1 (f / fairness)
                  :op2 (a2 / accountable-02)
                  :op3 (s / sustain-01
                        :ARG1-of (p2 / possible-01))
                  :op4 (t / transparency))
            :ARG1-of (t2 / target-01))
      :ARG2 (f2 / fill-01
            :ARG0 p
            :ARG1 (g / gap
                  :mod (b / between
                        :op1 (a3 / agency
                              :ARG1-of (s2 / smart-06)
                              :ARG1-of (n / new-01)
                              :poss (m2 / machine))
                        :op2 (l / lack-01
                              :ARG0 m2
                              :ARG1 (r / responsible-02
                                    :ARG0 m2
                                    :ARG1-of (m3 / moral-02))
                              :mod (f3 / fundamental))))))

# ::snt The FAST Track Principles : Fairness, Accountability, Sustainability, and Transparency     By becoming well -acquainted with the FA ST Track Principles, all members  of your project delivery  team will be better able to support a responsible environment for data innovation.
# File 157

(m / multi-sentence
      :snt1 (a / and
            :op1 (f / fairness)
            :op2 (a2 / accountable-02)
            :op3 (s / sustain-01)
            :op4 (t / transparency)
            :domain (p / principle
                  :name (n / name
                        :op1 "FAST"
                        :op2 "Track")))
      :snt2 (p2 / possible-01
            :ARG1 (s2 / support-01
                  :ARG0 (p3 / person
                        :mod (a3 / all)
                        :ARG0-of (h / have-org-role-91
                              :ARG1 (t2 / team
                                    :ARG0-of (d / deliver-01
                                          :ARG1 (p4 / project))
                                    :poss (y / you))
                              :ARG2 (m2 / member)))
                  :ARG1 (e / environment
                        :ARG1-of (r / responsible-02
                              :ARG2 (ii / innovate-01
                                    :ARG1 (d2 / data)))))
            :ARG1-of (h2 / have-degree-91
                  :ARG2 (g / good-02)
                  :ARG3 (m3 / more))
            :ARG1-of (c / cause-01
                  :ARG0 (b / become-01
                        :ARG1 p3
                        :ARG2 (a4 / acquaint-01
                              :ARG1 p3
                              :ARG2 (p5 / principle
                                    :name (n2 / name
                                          :op1 "FA"
                                          :op2 "ST"
                                          :op3 "Track"
                                          :op4 "Principles"))
                              :ARG1-of (w / well-09))))))

# ::snt Issues of fairness, accountability, sustainability,  and transparency operate at every juncture and at  every level of the AI project delivery work flow and demand the cooperative attention and  deliberative involvement of those with technical expertise, domain knowledge, project/product  management skill, and policy competence.
# File 157

(a / and
      :op1 (o / operate-01
            :ARG0 (ii / issue-02
                  :ARG0 (a2 / and
                        :op1 (f / fairness)
                        :op2 (a3 / accountable-02)
                        :op3 (s / sustain-01
                              :ARG1-of (p / possible-01))
                        :op4 (t / transparency)))
            :location (a4 / and
                  :op1 (j / juncture
                        :mod (e / every))
                  :op2 (l / level
                        :mod (e2 / every)
                        :mod (f2 / flow-01
                              :ARG1 (d / deliver-01
                                    :ARG1 (w / work-01
                                          :mod (p2 / project
                                                :ARG1-of (ii2 / intelligent-01
                                                      :mod (a5 / artificial)))))))))
      :op2 (d2 / demand-01
            :ARG0 ii
            :ARG1 (a6 / and
                  :op1 (a7 / attend-02
                        :ARG0 (p3 / person
                              :mod (t2 / that)
                              :ARG0-of (h / have-03
                                    :ARG1 (a8 / and
                                          :op1 (e3 / expertise
                                                :mod (t3 / technical))
                                          :op2 (k / know-01
                                                :mod (d3 / domain))
                                          :op3 (s2 / skill
                                                :topic (m / manage-01
                                                      :ARG1 (s3 / slash
                                                            :op1 (p4 / project)
                                                            :op2 (p5 / product))))
                                          :op4 (c / competent-01
                                                :ARG2 (p6 / policy-01)))))
                        :ARG1 ii
                        :ARG0-of (c2 / cooperate-01))
                  :op2 (ii3 / involve-01
                        :ARG1 p3
                        :ARG2 (d4 / deliberate-01
                              :ARG0 p3)))))

# ::snt                                                                              Understanding Artificial Intelligence Ethics and Safety  13   You should keep in mind , initially, that while fairness, accountability, sustainability, and transparency  are grouped together in the FAST acronym, they do not nece ssarily relate to each other on the same  plane or as equivalents.
# File 157

(r / recommend-01
      :ARG1 (k / keep-in-mind-08
            :ARG1 (y / you)
            :ARG2 (r2 / relate-01
                  :polarity -
                  :ARG1 (a / and
                        :op1 (f / fairness)
                        :op2 (a2 / accountable-02)
                        :op3 (s / sustain-01)
                        :op4 (t / transparency))
                  :ARG2 (o / other
                        :mod (e / each))
                  :manner (o2 / or
                        :op1 (p / plane
                              :ARG1-of (s2 / same-01))
                        :op2 (e2 / equivalent)))
            :time (ii / initial))
      :ARG2 y
      :ARG1-of (d / describe-01
            :ARG0 (p2 / publication
                  :ARG1-of (c / cite-01
                        :ARG2 13)
                  :topic a
                  :op1 (e3 / ethics
                        :mod (a3 / artificial))
                  :op2 (s3 / safe-01))))

# ::snt The governing roles of accountability and transparency are very different f rom the more dependent  roles  of fairness  and sustainability.
# File 157

(d / differ-02
      :ARG1 (r / role
            :ARG0-of (g / govern-01)
            :consist-of (a / and
                  :op1 (a2 / accountable-02)
                  :op2 (t / transparency)))
      :ARG2 (r2 / role
            :ARG0-of (d2 / depend-01
                  :ARG2-of (h / have-degree-91
                        :ARG1 r2
                        :ARG3 (m / more)))
            :consist-of (a3 / and
                  :op1 (f / fairness)
                  :op2 (s / sustain-01
                        :ARG1-of (p / possible-01))))
      :degree (v / very))

# ::snt According to the principle of fairness,  desig ners and implementers are held accountable for being equitable and  for not harming anyone  through bias or discriminat ion.
# File 157

(h / hold-02
      :ARG1 (a / accountable-02
            :ARG0 (a2 / and
                  :op1 (p / person
                        :ARG0-of (d / distribute-01))
                  :op2 (p2 / person
                        :ARG0-of (ii / implement-01)))
            :ARG1 (a3 / and
                  :op1 (e / equitable
                        :domain a2)
                  :op2 (h2 / harm-01
                        :polarity -
                        :ARG0 a2
                        :ARG1 (a4 / anyone)
                        :manner (o / or
                              :op1 (b / bias-01)
                              :op2 (d2 / discriminate-01)))))
      :ARG1-of (c / conform-01
            :ARG2 (p3 / principle
                  :topic (f / fairness))))

# ::snt Whereas the principles of transparency and accountability  thus  provide the procedural mechanisms  and means  through which AI systems  can be justified  and by which their producer and implementers   can be hel d responsible,  fairness and sustainability are  the crucial aspects of the design,  implementation, and outcomes of these systems  which  establish the normative criteria fo r such  governing constraints .
# File 157

(c / contrast-01
      :ARG1 (p / provide-01
            :ARG0 (p2 / principle
                  :topic (a / and
                        :op1 (t / transparency)
                        :op2 (a2 / accountable-02)))
            :ARG1 (a3 / and
                  :op1 (m / mechanism
                        :mod (p3 / procedure))
                  :op2 (m2 / means)
                  :instrument-of (p4 / possible-01
                        :ARG1 (j / justify-01
                              :ARG1 (s / system
                                    :mod (a4 / artificial))))
                  :instrument-of (p5 / possible-01
                        :ARG1 (r / responsible-01
                              :ARG0 (a5 / and
                                    :op1 (p6 / person
                                          :ARG0-of (p7 / produce-01
                                                :ARG1 s))
                                    :op2 (p8 / person
                                          :ARG0-of (ii / implement-01
                                                :ARG1 s)))))))
      :ARG2 (a6 / aspect
            :mod (c2 / crucial)
            :poss (a7 / and
                  :op1 (d / design-01
                        :ARG1 (s2 / system
                              :mod (t2 / this)))
                  :op2 (ii2 / implement-01
                        :ARG1 s2)
                  :op3 (s3 / sustain-01
                        :ARG1 s2
                        :ARG1-of (p9 / possible-01)))
            :ARG0-of (e / establish-01
                  :ARG1 (c3 / criteria
                        :ARG1-of (n / norm-02)
                        :purpose (c4 / constrain-01
                              :ARG0 (t3 / thing)
                              :ARG1-of (g / govern-01)
                              :mod (s4 / such))))))

# ::snt Transparency, accountability, and fairness are also data prote ction principles , and w here  algorithmic processing involves personal data, complying with them is not simply a matter of ethics  or good pr actice, but a legal requirement, which is enshrined in the General Data Protection  Regulation (GDPR) and the Data Protection Act of 2018 (DPA 2018 ).
# File 157

(a / and
      :op1 (p / principle
            :ARG0-of (p2 / protect-01
                  :ARG1 (d / data))
            :domain (a2 / and
                  :op1 (t / transparency)
                  :op2 (a3 / accountable-02)
                  :op3 (f / fairness))
            :mod (a4 / also))
      :op2 (ii / involve-01
            :ARG1 (d2 / data
                  :ARG1-of (p3 / personal-02))
            :ARG2 (p4 / process-01
                  :manner (a5 / algorithm)))
      :op3 (m / matter
            :polarity -
            :domain (c / comply-01
                  :ARG1 a2)
            :topic (o / or
                  :op1 (e / ethics)
                  :op2 (a6 / act-02
                        :ARG1-of (g / good-02)))
            :ARG1-of (s / simple-02)
            :ARG1-of (c2 / contrast-01
                  :ARG2 (r / require-01
                        :ARG1 c
                        :ARG1-of (l / legal-02)
                        :ARG1-of (e2 / enshrine-01
                              :ARG0 (a7 / and
                                    :op1 (l2 / law
                                          :name (n / name
                                                :op1 "General"
                                                :op2 "Data"
                                                :op3 "Protection"
                                                :op4 "Regulation"))
                                    :op2 (l3 / law
                                          :name (n2 / name
                                                :op1 "Data"
                                                :op2 "Protection"
                                                :op3 "Act"
                                                :op4 "of"
                                                :op5 "2018"))))))))

# ::snt For more detailed information  about the specific meanings of transparency, accountability, and fairness as data protection  principles in the context of the GDPR and the DPA 2018, please refer to the   Guide to Data Protection   produced by the Information Commissioner’s Office.
# File 157

(r / refer-03
      :mode imperative
      :polite +
      :ARG0 (y / you)
      :ARG1 (p / publication
            :name (n / name
                  :op1 "Guide"
                  :op2 "to"
                  :op3 "Data"
                  :op4 "Protection")
            :ARG1-of (p2 / produce-01
                  :ARG0 (o / organization
                        :name (n2 / name
                              :op1 "Information"
                              :op2 "Commissioner's"
                              :op3 "Office"))))
      :purpose (ii / information
            :ARG1-of (d / detail-01)
            :topic (m / mean-01
                  :ARG1 (p3 / principle
                        :topic (p4 / protect-01
                              :ARG1 (d2 / data))
                        :example (a / and
                              :op1 (t / transparency)
                              :op2 (a2 / accountable-02)
                              :op3 (f / fairness)))
                  :ARG1-of (s / specific-02))
            :topic (a3 / and
                  :op1 (o2 / organization
                        :name (n3 / name
                              :op1 "General"
                              :op2 "Certificate"
                              :op3 "of"
                              :op4 "Secondary"
                              :op5 "Education"))
                  :op2 (o3 / organization
                        :name (n4 / name
                              :op1 "DPA")
                        :time (d3 / date-entity
                              :year 2018)))))

# ::snt Fairness     When thinking about fairness in the design  and deployment of AI systems, it is important to always  keep in mind that these technologies, no matter how neutral they may seem, are designed and  produced  by human beings, who are bound by the limitations of their contexts and biases.
# File 157

(ii / important-01
      :ARG1 (k / keep-in-mind-08
            :ARG1 (y / you)
            :ARG2 (a / and
                  :op1 (d / design-01
                        :ARG0 (b / being
                              :mod (h / human)
                              :ARG1-of (b2 / bind-01
                                    :ARG0 (l / limit-01
                                          :ARG0 (a2 / and
                                                :op1 (c / context
                                                      :poss b)
                                                :op2 (b3 / bias-01
                                                      :ARG1 b)))))
                        :ARG1 (t / technology
                              :mod (t2 / this)))
                  :op2 (p / produce-01
                        :ARG0 b
                        :ARG1 t))
            :time (a3 / always))
      :time (t3 / think-01
            :ARG0 y
            :ARG1 (f / fairness
                  :topic (a4 / and
                        :op1 (d2 / design-01
                              :ARG1 (s / system
                                    :mod (ii2 / intelligent-01
                                          :mod (a5 / artificial))))
                        :op2 (d3 / deploy-01
                              :ARG1 s)))))

# ::snt Fairness     When thinking about fairness in the design  and deployment of AI systems, it is important to always  keep in mind that these technologies, no matter how neutral they may seem, are designed and  produced  by human beings, who are bound by the limitations of their contexts and biases.
# File 157

(ii / important-01
      :ARG1 (k / keep-in-mind-08
            :ARG1 (y / you)
            :ARG2 (a / and
                  :op1 (d / design-01
                        :ARG0 (b / being
                              :mod (h / human)
                              :ARG1-of (b2 / bind-01
                                    :ARG0 (l / limit-01
                                          :ARG0 (a2 / and
                                                :op1 (c / context
                                                      :poss b)
                                                :op2 (b3 / bias-01
                                                      :ARG1 b)))))
                        :ARG1 (t / technology
                              :mod (t2 / this)))
                  :op2 (p / produce-01
                        :ARG0 b
                        :ARG1 t))
            :time (a3 / always))
      :time (t3 / think-01
            :ARG0 y
            :ARG1 (f / fairness
                  :topic (a4 / and
                        :op1 (d2 / design-01
                              :ARG1 (s / system
                                    :mod (ii2 / intelligent-01
                                          :mod (a5 / artificial))))
                        :op2 (d3 / deploy-01
                              :ARG1 s)))))

# ::snt There is no silver bullet when it comes to remediating  the dangers of discrimination and unfairness in AI systems.
# File 157

(b / bullet
      :polarity -
      :mod (s / silver)
      :time (c / come-12
            :ARG1 (r / remedy-01
                  :ARG1 (e / endanger-01
                        :ARG0 (a / and
                              :op1 (d / discriminate-02)
                              :op2 (f / fairness
                                    :polarity -)
                              :location (s2 / system
                                    :mod (a2 / artificial)))))))

# ::snt The problem of fairness and bias  mitigation in algorithmic design and use therefore has no simple or strictly technical solution.
# File 157

(c / cause-01
      :ARG1 (s / solve-01
            :polarity -
            :ARG1 (p / problem
                  :topic (a / and
                        :op1 (f / fairness)
                        :op2 (b / bias-01)
                        :ARG0-of (m / mitigate-01
                              :ARG1 (a2 / and
                                    :op1 (d / design-01
                                          :ARG1 (a3 / algorithm))
                                    :op2 (u / use-01
                                          :ARG1 a3)))))
            :ARG2 (o / or
                  :op1 (s2 / simple-02)
                  :op2 (t / technical
                        :mod (s3 / strict)))))

# ::snt That said, best practices of fairness -aware design  and implementation  (both at the level of non technical self -assessment and at the level of technical control s and means of evaluation) hold great  promise in terms of securing just , morally acceptable , and beneficial  outcomes that  treat  affected  stakeholders fairly and equitably.
# File 157

(s / say-01
      :ARG1 (h / hold-01
            :ARG0 (a / and
                  :op1 (p / practice-01
                        :ARG1 (d / design-01
                              :ARG1-of (r / realize-01
                                    :ARG0 (f / fairness))))
                  :op2 (p2 / practice-01
                        :ARG1 (ii / implement-01))
                  :location (a2 / and
                        :op1 (a3 / assess-01
                              :ARG1 (s2 / self)
                              :mod (t / technical
                                    :polarity -))
                        :op2 (a4 / and
                              :op1 (a5 / assess-01
                                    :ARG1 (c / control-01
                                          :mod (t2 / technical)))
                              :op2 (m / means
                                    :instrument-of (e / evaluate-01)))))
            :ARG1 (p3 / promise-01
                  :ARG0 a
                  :topic (s3 / secure-01
                        :ARG0 a
                        :ARG1 (o / outcome
                              :ARG1-of (j / just-02)
                              :ARG1-of (a6 / accept-01
                                    :ARG1-of (p4 / possible-01)
                                    :ARG1-of (m2 / moral-02))
                              :ARG0-of (b / benefit-01)
                              :ARG0-of (t3 / treat-01
                                    :ARG1 (s4 / stake
                                          :ARG1-of (a7 / affect-01))
                                    :ARG2 (a8 / and
                                          :op1 (f2 / fair-01)
                                          :op2 (e2 / equitable)))))
                  :mod (g / great))))

# ::snt While there are different ways to characterise or define fairness in the design and use of AI systems,  you should consider the principle of discriminatory non -harm  as a minimum required threshold of  fairnes s. This principle directs us to do no harm to others through the biased or discriminatory  outcomes that may result from practices of AI innovation :                                                  Data f airness     Responsible data acquisition, handling, and management is a necessary component of algorithmic  fairness.
# File 157

(m / multi-sentence
      :snt1 (h / have-concession-91
            :ARG1 (r / recommend-01
                  :ARG1 (c / consider-01
                        :ARG0 (y / you)
                        :ARG1 (p / principle
                              :topic (h2 / harm-01
                                    :polarity -
                                    :ARG0 (d / discriminate-02)))
                        :ARG2 (t / threshold
                              :ARG1-of (r2 / require-01)
                              :mod (m2 / minimum)
                              :mod (f / fairness))))
            :ARG2 (w / way
                  :ARG1-of (d2 / differ-02)
                  :manner-of (o / or
                        :op1 (c2 / characterize-01
                              :ARG1 (f2 / fairness))
                        :op2 (d3 / define-01
                              :ARG1 f2)
                        :topic (a / and
                              :op1 (d4 / design-01
                                    :ARG1 (s / system
                                          :mod (ii / intelligent-01
                                                :mod (a2 / artificial))))
                              :op2 (u / use-01
                                    :ARG1 s)))))
      :snt2 (d5 / direct-01
            :ARG0 (p2 / principle
                  :mod (t2 / this))
            :ARG1 (d6 / do-02
                  :polarity -
                  :ARG0 (w2 / we)
                  :ARG1 (h3 / harm-01
                        :ARG0 w2
                        :ARG1 (p3 / person
                              :mod (o2 / other)))
                  :manner (o3 / outcome
                        :ARG1-of (r3 / result-01
                              :ARG2 (p4 / practice-01
                                    :ARG1 (ii2 / innovate-01
                                          :ARG1 (ii3 / intelligent-01
                                                :mod a2))))
                        :ARG1-of (p5 / possible-01))
                  :ARG1-of (d7 / discriminate-02)))
      :snt3 (c3 / component
            :ARG1-of (n / need-01
                  :ARG0 (f3 / fairness
                        :mod (a3 / algorithmic)))
            :domain (a4 / and
                  :op1 (a5 / acquire-01
                        :ARG1 (d8 / data)
                        :ARG1-of (r4 / responsible-02))
                  :op2 (h4 / handle-01
                        :ARG1 d8)
                  :op3 (m3 / manage-01
                        :ARG1 d8))))

# ::snt Your project team  should keep in mind the following key elements  of data fairness :   Principle of Discriminatory Non -Harm:  The designers and users of AI systems, which  process social or demographic data pertaining to features of human subjects, societal  patterns , or cultural formations , should prioritise the mitigation of bias and the  exclusion of discriminatory influences on the  outputs and implementations of their  models.
# File 157

(r / recommend-01
      :ARG1 (k / keep-in-mind-08
            :ARG1 (t / team
                  :mod (p / project)
                  :poss (y / you))
            :ARG2 (e / element
                  :ARG1-of (k2 / key-02)
                  :ARG1-of (f / follow-01)
                  :mod (f2 / fairness
                        :mod (d / data))
                  :ARG1-of (m / mean-01
                        :ARG2 (p2 / principle
                              :topic (h / harm-01
                                    :polarity -
                                    :ARG0 (d2 / discriminate-02))))))
      :ARG2 (r2 / recommend-01
            :ARG1 (p3 / prioritize-01
                  :ARG0 (a / and
                        :op1 (p4 / person
                              :ARG0-of (d3 / design-01
                                    :ARG1 (s / system
                                          :mod (ii / intelligent-01
                                                :mod (a2 / artificial))
                                          :ARG0-of (p5 / process-01
                                                :ARG1 (d4 / data
                                                      :mod (o / or
                                                            :op1 (s2 / society)
                                                            :op2 (d5 / demography))
                                                      :ARG0-of (p6 / pertain-01
                                                            :ARG1 (a3 / and
                                                                  :op1 (f3 / feature
                                                                        :poss (s3 / subject
                                                                              :mod (h2 / human)))
                                                                  :op2 (p7 / pattern
                                                                        :mod (s4 / society))
                                                                  :op3 (f4 / form-01
                                                                        :ARG1 (c / culture))))))))
                              :op2 (p8 / person
                                    :ARG0-of (u / use-01
                                          :ARG1 s)))
                        :ARG1 (a4 / and
                              :op1 (m2 / mitigate-01
                                    :ARG0 a
                                    :ARG1 (b / bias-01))
                              :op2 (e2 / exclude-01
                                    :ARG0 a
                                    :ARG1 (ii2 / influence-01
                                          :ARG0 (d6 / discriminate-02))
                                    :ARG2 (a5 / and
                                          :op1 (o2 / output)
                                          :op2 (ii3 / implement-01
                                                :ARG1 (m3 / model-01
                                                      :ARG0 a)))))))))

# ::snt Are trained  and tested  on properly representative, relevant, accurate, and  generalisable data sets ( Data Fairness )  2.
# File 157

(a / and
      :li 2
      :op1 (t / train-01
            :ARG1 (s / set
                  :consist-of (d / data)
                  :ARG0-of (r / represent-01
                        :manner (p / proper))
                  :ARG1-of (r2 / relevant-01)
                  :mod (a2 / accurate)
                  :ARG1-of (g / generalize-01)
                  :ARG2-of t))
      :op2 (t2 / test-01
            :ARG1 s
            :ARG2 s)
      :ARG1-of (m / mean-01
            :ARG2 (f / fairness
                  :mod (d2 / data))))

# ::snt Have model architectures that do not include target variables, features,   processes, or analytical structures ( correlations, interactions,  and inferences)  which are unreasonable , morally objectionable,  or unjust ifiable ( Design  Fairness )  3.
# File 157

(h / have-03
      :mode imperative
      :li 3
      :ARG0 (y / you)
      :ARG1 (a / architect
            :mod (m / model)
            :ARG2-of (ii / include-01
                  :polarity -
                  :ARG1 (o / or
                        :op1 (v / variable
                              :ARG1-of (t / target-01))
                        :op2 (f / feature)
                        :op3 (p / process-02)
                        :op4 (s / structure
                              :mod (a2 / analyze-01)
                              :example (a3 / and
                                    :op1 (c / correlate-01)
                                    :op2 (ii2 / interact-01)
                                    :op3 (ii3 / infer-01))
                              :ARG1-of (r / reasonable-02
                                    :polarity -)
                              :ARG1-of (o2 / objectionable-02
                                    :ARG1-of (m2 / moral-02))
                              :ARG1-of (f2 / fair-01
                                    :polarity -))
                        :op2 (p2 / possible-01
                              :polarity -
                              :ARG1 (f3 / fair-01))))))

# ::snt Do not have discriminator y or inequitable impacts on the lives of the people  they affect  (Outcome Fairness)   4.
# File 157

(h / have-03
      :polarity -
      :ARG0 (y / you)
      :ARG1 (o / or
            :op1 (ii / impact-01
                  :ARG0 y
                  :ARG1 (l / life
                        :poss (p / person
                              :ARG1-of (a / affect-01
                                    :ARG0 y)))
                  :ARG0-of (d / discriminate-02))
            :op2 (ii2 / impact-01
                  :ARG0 y
                  :ARG1 l
                  :ARG0-of (f / fair-01
                        :polarity -)))
      :ARG1-of (m / mean-01
            :ARG2 (f2 / fair-01
                  :ARG1 (o2 / outcome)))
      :li 4)

# ::snt Are deployed by users sufficiently trained to implement them responsibly and  without bias  (Implementation Fairness )
# File 157

(d / deploy-01
      :ARG0 (p / person
            :ARG0-of (u / use-01)
            :ARG2-of (t / train-01
                  :ARG1 (ii / implement-01
                        :ARG0 p
                        :ARG1 (t2 / they)
                        :ARG1-of (r / responsible-02)
                        :manner (b / bias-01
                              :polarity -)
                        :ARG1-of (m / mean-01
                              :ARG2 (ii2 / implement-01)))
                  :ARG0-of (s / suffice-01))))

# ::snt Design  Fairness     Because human beings have a hand in all stages of the construction of AI systems, fairness -aware  design must take precautions across the AI project workflow to prevent  bias from having a  discriminatory influence:     • Problem Formulation: At the initial stage of problem formulation and outcome definition ,  technical and non -technical members of your team should work together to translate project  goals into measurable targets .
# File 157

(m / multi-sentence
      :snt1 (d / design-01
            :ARG1 (f / fairness))
      :snt2 (c / cause-01
            :ARG0 (h / have-hand-in-17
                  :ARG0 (b / being
                        :mod (h2 / human))
                  :ARG1 (c2 / construct-01
                        :ARG1 (s / system
                              :mod (ii / intelligent-01
                                    :mod (a / artificial)))
                        :mod (s2 / stage
                              :mod (a2 / all))))
            :ARG1 (o / obligate-01
                  :ARG1 (d2 / design-01
                        :ARG0-of (r / realize-01
                              :ARG1 (f2 / fairness)))
                  :ARG2 (p / precaution-02
                        :ARG1 d2
                        :purpose (p2 / prevent-01
                              :ARG0 d2
                              :ARG1 (ii2 / influence-01
                                    :ARG0 (b2 / bias-01)
                                    :ARG1 d2
                                    :ARG0-of (d3 / discriminate-02)))
                        :location (a3 / across
                              :op1 (w / workflow
                                    :mod (p3 / project
                                          :mod (ii3 / intelligent-01)))))))
      :snt3 (f3 / form-01
            :ARG1 (p4 / problem))
      :snt4 (r2 / recommend-01
            :ARG1 (w2 / work-01
                  :ARG0 (a4 / and
                        :op1 (p5 / person
                              :ARG0-of (h3 / have-org-role-91
                                    :ARG1 (t / team
                                          :poss (y / you))
                                    :ARG2 (m2 / member
                                          :mod (t2 / technical))))
                        :op2 (p6 / person
                              :ARG0-of (h4 / have-org-role-91
                                    :ARG1 t
                                    :ARG2 (m3 / member
                                          :mod (t3 / technical
                                                :polarity -)))))
                  :ARG1 (t4 / translate-01
                        :ARG0 a4
                        :ARG1 (g / goal
                              :mod p3))
                  :ARG2 (t5 / target
                        :ARG1-of (m4 / measure-01
                              :ARG1-of (p7 / possible-01))))
            :mod (t6 / together)
            :time (s3 / stage
                  :mod (ii4 / initial)
                  :subevent-of (a5 / and
                        :op1 (f4 / form-01
                              :ARG1 (p8 / problem))
                        :op2 (d4 / define-01
                              :ARG1 (o2 / outcome))))))

# ::snt Design  Fairness     Because human beings have a hand in all stages of the construction of AI systems, fairness -aware  design must take precautions across the AI project workflow to prevent  bias from having a  discriminatory influence:     • Problem Formulation: At the initial stage of problem formulation and outcome definition ,  technical and non -technical members of your team should work together to translate project  goals into measurable targets .
# File 157

(m / multi-sentence
      :snt1 (d / design-01
            :ARG1 (f / fairness))
      :snt2 (c / cause-01
            :ARG0 (h / have-hand-in-17
                  :ARG0 (b / being
                        :mod (h2 / human))
                  :ARG1 (c2 / construct-01
                        :ARG1 (s / system
                              :mod (ii / intelligent-01
                                    :mod (a / artificial)))
                        :mod (s2 / stage
                              :mod (a2 / all))))
            :ARG1 (o / obligate-01
                  :ARG1 (d2 / design-01
                        :ARG0-of (r / realize-01
                              :ARG1 (f2 / fairness)))
                  :ARG2 (p / precaution-02
                        :ARG1 d2
                        :purpose (p2 / prevent-01
                              :ARG0 d2
                              :ARG1 (ii2 / influence-01
                                    :ARG0 (b2 / bias-01)
                                    :ARG1 d2
                                    :ARG0-of (d3 / discriminate-02)))
                        :location (a3 / across
                              :op1 (w / workflow
                                    :mod (p3 / project
                                          :mod (ii3 / intelligent-01)))))))
      :snt3 (f3 / form-01
            :ARG1 (p4 / problem))
      :snt4 (r2 / recommend-01
            :ARG1 (w2 / work-01
                  :ARG0 (a4 / and
                        :op1 (p5 / person
                              :ARG0-of (h3 / have-org-role-91
                                    :ARG1 (t / team
                                          :poss (y / you))
                                    :ARG2 (m2 / member
                                          :mod (t2 / technical))))
                        :op2 (p6 / person
                              :ARG0-of (h4 / have-org-role-91
                                    :ARG1 t
                                    :ARG2 (m3 / member
                                          :mod (t3 / technical
                                                :polarity -)))))
                  :ARG1 (t4 / translate-01
                        :ARG0 a4
                        :ARG1 (g / goal
                              :mod p3))
                  :ARG2 (t5 / target
                        :ARG1-of (m4 / measure-01
                              :ARG1-of (p7 / possible-01))))
            :mod (t6 / together)
            :time (s3 / stage
                  :mod (ii4 / initial)
                  :subevent-of (a5 / and
                        :op1 (f4 / form-01
                              :ARG1 (p8 / problem))
                        :op2 (d4 / define-01
                              :ARG1 (o2 / outcome))))))

# ::snt These challenges of fairness aware design at the problem formulation stage show the need  for making  diversity and inclusive participation  a priority  from the start  of the AI project  lifecycle .
# File 157

(s / show-01
      :ARG0 (c / challenge-01
            :ARG2 (d / design-01
                  :ARG0-of (r / realize-01
                        :ARG1 (f / fairness)))
            :mod (t / this)
            :time (s2 / stage
                  :time-of (f2 / formulate-01
                        :ARG1 (p / problem))))
      :ARG1 (n / need-01
            :ARG1 (p2 / prioritize-01
                  :ARG1 (m / make-02
                        :ARG1 (a / and
                              :op1 (d2 / diversity)
                              :op2 (p3 / participate-01
                                    :ARG0-of (ii / include-91))))
                  :time (f3 / from
                        :op1 (s3 / start-01
                              :ARG1 (l / lifecycle
                                    :mod (p4 / project
                                          :mod (ii2 / intelligent-01
                                                :mod (a2 / artificial)))))))))

# ::snt Choices made about how to classify and structure raw inputs  must be taken  in a fairness aware manner with due consideration given to the sensitive social  contexts that may introduce bias into such acts of classificati on.
# File 157

(o / obligate-01
      :ARG2 (t / take-01
            :ARG1 (c / choose-01
                  :ARG2 (a / and
                        :op1 (c2 / classify-01
                              :ARG1 (ii / input
                                    :mod (r / raw)))
                        :op2 (s / structure-01
                              :ARG1 ii)))
            :manner a
            :op1 (r2 / realize-01
                  :ARG1 (f / fairness))
            :op2 (c3 / consider-02
                  :ARG1 (c4 / context
                        :ARG0-of (s2 / sensitive-03)
                        :mod (s3 / society)
                        :ARG0-of (ii2 / introduce-02
                              :ARG1 (b / bias)
                              :ARG2 (a2 / act-02
                                    :ARG1 (c5 / classify-01)
                                    :mod (s4 / such))
                              :ARG1-of (p / possible-01)))
                  :mod (d / due))))

# ::snt Similar fairness aware  processes should be put in place  to review automated or outsourced classifications .
# File 157

(r / recommend-01
      :ARG1 (ii / in-place
            :domain (p / process-02
                  :ARG0-of (r2 / realize-01
                        :ARG1 (f / fairness))
                  :ARG1-of (r3 / resemble-01))
            :purpose (r4 / review-01
                  :ARG0 p
                  :ARG1 (c / classify-01
                        :manner (o / or
                              :op1 (a / automate-01)
                              :op2 (o2 / outsource-01))))))

# ::snt • Evaluating Analytical Structures: Design fairness also demands close assessment of the  existence in the trained model of lurking or hidden proxies for discriminatory features that  may act as significant factors  in its output.
# File 157

(m / multi-sentence
      :snt1 (e / evaluate-01
            :ARG1 (s / structure
                  :mod (a / analyze-01)))
      :snt2 (d / demand-01
            :ARG0 (f / fairness
                  :mod (d2 / design-01))
            :ARG1 (a2 / assess-01
                  :ARG1 (e2 / exist-01
                        :ARG1 (o / or
                              :op1 (t / thing
                                    :ARG0-of (l / lurk-01))
                              :op2 (t2 / thing
                                    :ARG1-of (h / hide-01))
                              :domain (p / proxy
                                    :purpose (f2 / feature
                                          :ARG0-of (d3 / discriminate-02)
                                          :ARG0-of (a3 / act-01
                                                :ARG1 (t3 / thing
                                                      :ARG1-of (f3 / factor-01)
                                                      :ARG1-of (s2 / significant-02))
                                                :ARG1-of (p2 / possible-01)))))
                        :location (m2 / model
                              :ARG1-of (t4 / train-01)))
                  :ARG1-of (c / close-10))
            :mod (a4 / also)))

# ::snt Outcome  fairness     As part of this minimum safeguarding of discriminatory non -harm, forethought and well -informed  consideration must be put into how you are going to define and measure the fairness of the impacts  and outcomes of the AI system you are developing .
# File 157

(m / multi-sentence
      :snt1 (f / fairness
            :mod (o / outcome))
      :snt2 (o2 / obligate-01
            :ARG2 (p / put-01
                  :ARG1 (a / and
                        :op1 (f2 / forethought)
                        :op2 (c / consider-02
                              :ARG1-of (ii / inform-01
                                    :ARG1-of (w / well-09))))
                  :ARG2 (t / thing
                        :manner-of (d / define-01
                              :ARG0 (y / you)
                              :ARG1 (f3 / fair-01
                                    :ARG1 (a2 / and
                                          :op1 (ii2 / impact-01
                                                :ARG0 (s / system
                                                      :mod (ii3 / intelligent-01
                                                            :mod (a3 / artificial))
                                                      :ARG1-of (d2 / develop-02
                                                            :ARG0 y)))
                                          :op2 (o3 / outcome
                                                :mod s))))
                        :manner-of (m2 / measure-01
                              :ARG0 y
                              :ARG1 f3))
                  :part-of (s2 / safeguard-01
                        :ARG1 (h / harm-01
                              :polarity -
                              :ARG0-of (d3 / discriminate-01))
                        :mod (m3 / minimum)
                        :mod (t2 / this)))))

# ::snt There is a  great diversity of beliefs in the  area of outcome fairness as to how to properly classify  what  makes the consequences of an algorithmic ally supported  decision equitable, fair, and allocatively  just.
# File 157

(d / diversity
      :mod (g / great)
      :domain (t / thing
            :ARG1-of (b / believe-01)
            :topic (t2 / thing
                  :manner-of (c / classify-01
                        :ARG1 (t3 / thing
                              :ARG0-of (m / make-02
                                    :ARG1 (a / and
                                          :op1 (e / equitable
                                                :domain (t4 / thing
                                                      :ARG1-of (d2 / decide-01)
                                                      :ARG1-of (s / support-01
                                                            :ARG0 (p / person
                                                                  :ARG1-of (a2 / ally-01
                                                                        :mod (a3 / algorithm))))))
                                          :op2 (f / fair-01
                                                :ARG1 t4)
                                          :op3 (j / just-02
                                                :ARG1 t4
                                                :mod (a4 / allocate-01)))))
                        :manner (p2 / proper))))
      :topic (a5 / area
            :mod (f2 / fair-01
                  :ARG1 (o / outcome))))

# ::snt Different approaches —detailed below —stress different pri nciples:  some  focus on  demographic  parity, some on individual fairness , others  on error rates  equitably distributed across subpopulations .
# File 157

(s / stress-01
      :ARG0 (a / approach-02
            :ARG1-of (d / differ-02
                  :ARG1 (p / principle
                        :example (a2 / and
                              :op1 (f / focus-01
                                    :ARG1 (s2 / some)
                                    :ARG2 (p2 / parity
                                          :mod (d2 / demography)))
                              :op2 (f2 / focus-01
                                    :ARG1 s2
                                    :ARG2 (f3 / fairness
                                          :mod (ii / individual)))
                              :op3 (f4 / focus-01
                                    :ARG1 (o / other)
                                    :ARG2 (r / rate
                                          :mod (e / error)
                                          :ARG1-of (d3 / distribute-01
                                                :ARG2 (p3 / population)
                                                :manner (e2 / equitable)))))))
            :ARG1-of (d4 / detail-01
                  :location (b / below)))
      :ARG1 p)

# ::snt Your  determination  of outcome fairness should  heavily depend both on the specific use case for  which the fairness of outcome is being considered  and the technical feasibility of incorporating your  chosen criteria into the  construction of the AI  system .
# File 157

(r / recommend-01
      :ARG1 (d / depend-01
            :ARG0 (d2 / determine-01
                  :ARG0 (y / you)
                  :ARG1 (f / fair-01
                        :ARG1 (o / outcome)))
            :ARG1 (a / and
                  :op1 (c / case-04
                        :ARG1 (u / use-01)
                        :ARG1-of (s / specific-02)
                        :ARG2-of (c2 / consider-02
                              :ARG1 (f2 / fair-01
                                    :ARG1 o)))
                  :op2 (f3 / feasibility
                        :mod (t / technical)
                        :domain (ii / incorporate-02
                              :ARG1 (c3 / criteria
                                    :ARG1-of (c4 / choose-01
                                          :ARG0 y))
                              :ARG2 (c5 / construct-01
                                    :ARG1 (s2 / system
                                          :mod (ii2 / intelligent-01
                                                :mod (a2 / artificial)))))))
            :manner (h / heavy)))

# ::snt (Note that diffe rent fairness -aware methods  involve  different types  of technical intervention s at the pre -processing, modelling, or post processing stages  of production ).
# File 157

(n / note-01
      :mode imperative
      :ARG0 (y / you)
      :ARG1 (ii / involve-01
            :ARG1 (t / type
                  :ARG1-of (d / differ-02)
                  :mod (ii2 / intervene-01
                        :mod (t2 / technical)
                        :time (s / stage
                              :subevent-of (p / produce-01)
                              :subevent (o / or
                                    :op1 (p2 / process-01
                                          :time (b / before
                                                :op1 p))
                                    :op2 (m / model-01
                                          :time s)
                                    :op3 (p3 / process-01
                                          :time (a / after
                                                :op1 p))))))
            :ARG2 (m2 / method
                  :ARG0-of (r / realize-01
                        :ARG1 (f / fairness))
                  :ARG1-of d)))

# ::snt Again, this means that  determining  your  fairness definition should  be a cooperative and multidisciplinary effort across the project team .
# File 157

(m / mean-01
      :ARG1 (t / this)
      :ARG2 (r / recommend-01
            :ARG1 (e / effort-01
                  :ARG1 (d / determine-01
                        :ARG1 (d2 / define-01
                              :ARG0 (y / you)
                              :ARG1 (f / fair-01)))
                  :ARG0-of (c / cooperate-01)
                  :mod (m2 / multidisciplinary)
                  :location (a / across
                        :op1 (t2 / team
                              :mod (p / project)))))
      :mod (a2 / again))

# ::snt You will find below a summary table of some of the main definitions of outcome fairness that have  been integrated by researchers into formal models  as well as a list of current articles and technical  resource s, which should be consulted to orient your team to the relevant knowledge base .
# File 157

(f / find-01
      :ARG0 (y / you)
      :ARG1 (a / and
            :op1 (t / table
                  :ARG2-of (s / summarize-01
                        :ARG1 (d / define-01
                              :ARG1 (f2 / fairness
                                    :mod (o / outcome))
                              :mod (m / main)
                              :quant (s2 / some)
                              :ARG1-of (ii / integrate-01
                                    :ARG0 (p / person
                                          :ARG0-of (r / research-01))
                                    :ARG2 (m2 / model
                                          :mod (f3 / formal))))))
            :op2 (l / list
                  :consist-of (a2 / and
                        :op1 (a3 / article
                              :time (c / current))
                        :op2 (r2 / resource
                              :mod (t2 / technical))
                        :ARG1-of (c2 / consult-01
                              :ARG2 (o2 / orient-01
                                    :ARG0 (t3 / team
                                          :poss y
                                          :ARG1-of o2)
                                    :ARG2 (b / base
                                          :mod (k / know-01)
                                          :ARG1-of (r3 / relevant-01)))
                              :ARG1-of (r4 / recommend-01)))))
      :location (b2 / below))

# ::snt The first four  fairness types fall under the category of group fairness and allow for  comparative criteria of non -discrimination to be considered in model construction and evaluation.
# File 157

(a / and
      :op1 (f / fall-04
            :ARG1 (t / type
                  :quant 4
                  :mod (f2 / fairness)
                  :ord (o / ordinal-entity
                        :value 1))
            :ARG2 (c / category
                  :mod (f3 / fairness
                        :mod (g / group))))
      :op2 (a2 / allow-01
            :ARG0 t
            :ARG1 (c2 / consider-02
                  :ARG1 (c3 / criteria
                        :ARG1-of (c4 / compare-01)
                        :topic (d / discriminate-01
                              :polarity -))
                  :ARG2 (a3 / and
                        :op1 (c5 / construct-01
                              :ARG1 (m / model))
                        :op2 (e / evaluate-01
                              :ARG1 m)))))

# ::snt The final two fairness types focus instead on cases of individual fairness, where cont ext-specific  issues of effective bias are considered and assessed at the level of the individual agent.
# File 157

(ii / instead-of-91
      :ARG1 (f / focus-01
            :ARG0 (t / type
                  :quant 2
                  :mod (f2 / fairness)
                  :mod (f3 / final))
            :ARG2 (c / case-04
                  :ARG1 (f4 / fairness
                        :mod (ii2 / individual))
                  :location-of (a / and
                        :op1 (c2 / consider-02
                              :ARG1 (ii3 / issue-02
                                    :ARG0 (b / bias-01
                                          :ARG0-of (e / effective-04))
                                    :ARG1-of (s / specific-02
                                          :ARG2 (c3 / control-01
                                                :ARG1 c3)
                                          :ARG1-of (e2 / extend-01))))
                        :op2 (a2 / assess-01
                              :ARG1 ii3)
                        :manner (l / level
                              :poss (a3 / agent
                                    :mod (ii4 / individual)))))))

# ::snt Take note, though, that these technical approaches have limited scope in terms of the bigger picture  issues of algorithmic fairness that we have alre ady stressed .
# File 157

(h / have-concession-91
      :ARG1 (n / note-01
            :mode imperative
            :ARG0 (y / you)
            :ARG1 (s / scope
                  :ARG1-of (l / limit-01)
                  :topic (ii / issue-02
                        :ARG0 (f / fairness
                              :mod (a / algorithm))
                        :ARG1-of (s2 / stress-01
                              :ARG0 (w / we)
                              :mod (a2 / again))
                        :mod (p / picture
                              :ARG1-of (h2 / have-degree-91
                                    :ARG2 (b / big)
                                    :ARG3 (m / more))))
                  :domain (a3 / approach-02
                        :mod (t / technical)
                        :mod (t2 / this)))))

# ::snt                                                                              Understanding Artificial Intelligence Ethics and Safety  19 Some Formalis able  Definitions of Outcome Fairness   Type of Fairness  Definition   Demographic/   Statistical Parit y        Group Fairness  An outcome is fair if each group in the selected set receives benefit in equal or  similar proportions, i.e.
# File 157

(m / multi-sentence
      :snt1 (a / and
            :op1 (e / ethics
                  :mod (a2 / artificial))
            :op2 (s / safe-01))
      :snt2 (p / possible-01
            :li 19
            :ARG1 (a3 / and
                  :op1 (d / define-01
                        :ARG1 (f / fairness
                              :mod (o / outcome)))
                  :op2 d
                  :ARG1 (d2 / demography))
            :op3 (s2 / statistic)
            :op4 (f2 / fairness
                  :mod (g / group)))
      :snt3 (f3 / fair-01
            :ARG1 o)
      :condition (r / receive-01
            :ARG0 g
            :mod (e2 / each)
            :part-of (s3 / set
                  :ARG1-of (s4 / select-01)))
      :ARG1 (b / benefit-01
            :ARG1 g
            :manner (o2 / or
                  :op1 (p2 / proportion
                        :ARG1-of (e3 / equal-01))
                  :op2 (p3 / proportion
                        :ARG1-of (r2 / resemble-01)))))

# ::snt True Positive Rate  Parity             Group Fairness  An outcome is fair if the ‘true positive’ rates of an algorithmic prediction or  classification are equal across groups.
# File 157

(m / multi-sentence
      :snt1 (r / rate
            :ARG1-of (t / true-01)
            :mod (p / positive))
      :snt2 (p2 / parity)
      :snt3 (f / fair-01
            :ARG1 (g / group))
      :snt4 (f2 / fair-01
            :ARG1 (o / outcome)
            :condition (e / equal-01
                  :ARG1 (r2 / rate
                        :mod p
                        :poss (o2 / or
                              :op1 (p3 / predict-01
                                    :manner (a / algorithm))
                              :op2 (c / classify-01
                                    :manner a)))
                  :ARG3 (a2 / across
                        :op1 (g2 / group)))))

# ::snt This method  is  also referred to as ‘equal opportunity ’ fairness because it aims to secure  equalised odds of an advantageous outcome for qualified individuals  in a given  population regardless of the protected or disadvantaged  groups of which they  are members.
# File 157

(r / refer-01
      :ARG1 (m / method
            :mod (t / this))
      :ARG2 (f / fairness
            :ARG1-of (e / equal-01))
      :mod (a / also)
      :ARG1-of (c / cause-01
            :ARG0 (a2 / aim-01
                  :ARG0 m
                  :ARG1 (s / secure-01
                        :ARG0 m
                        :ARG1 (o / odds
                              :ARG1-of (e2 / equal-01)
                              :topic (o2 / outcome
                                    :ARG1-of (a3 / advantage-01))
                              :beneficiary (ii / individual
                                    :ARG1-of (q / qualify-02)
                                    :location (p / population
                                          :ARG1-of (g / give-14))))
                        :ARG1-of (r2 / regardless-91
                              :ARG2 (o3 / or
                                    :op1 (g2 / group
                                          :ARG1-of (p2 / protect-01))
                                    :op2 (g3 / group
                                          :ARG2-of a3
                                          :polarity -))
                              :ARG1-of (ii2 / include-91
                                    :ARG2 g2))))))

# ::snt False Positive Rate  Parity         Group Fairness  An outcome is fair if it does not disparately mistreat people belonging to a  given social group by misc lassifying them at a higher rate than the members of  a second social group, for this would place the members of the first group at an  unfair disadvantage.
# File 157

(m / multi-sentence
      :snt1 (r / rate
            :mod (p / positive)
            :mod (f / false))
      :snt2 (p2 / parity)
      :snt3 (f2 / fair-01
            :ARG1 (g / group))
      :snt4 (f3 / fair-01
            :ARG1 (o / outcome)
            :condition (m2 / mistreat-01
                  :polarity -
                  :ARG0 o
                  :ARG1 (p3 / person
                        :ARG0-of (b / belong-01
                              :ARG1 (g2 / group
                                    :ARG1-of (s / social-03)
                                    :ARG1-of (g3 / give-01))))
                  :manner m2
                  :ARG0 o
                  :ARG1 p3
                  :manner (m3 / mismanage-01)
                  :ARG0-of (c / cause-01
                        :ARG1 (p4 / place-01
                              :ARG0 m2
                              :ARG1 (p5 / person
                                    :ARG0-of (h / have-org-role-91
                                          :ARG1 (g4 / group
                                                :ord (o2 / ordinal-entity
                                                      :value 2)
                                                :ARG1-of (s2 / social-03))
                                          :ARG2 (m4 / member)))
                              :ARG2 (d / disadvantage
                                    :ARG1-of (f4 / fair-01
                                          :polarity -)))))))

# ::snt Positive Predictive  Value Parity         Group Fairness  An outcome is fair if the rates of positive predictive value (the fraction of  correctly predicted positive cases out of all predicted positive cases) are equal  across sensitive and advantaged groups.
# File 157

(m / multi-sentence
      :snt1 (p / parity
            :mod (v / value
                  :ARG1-of (p2 / predict-01))
            :mod (p3 / positive))
      :snt2 (f / fairness
            :mod (g / group))
      :snt3 (f2 / fair-01
            :ARG1 (o / outcome)
            :condition (e / equal-01
                  :ARG1 (r / rate
                        :mod (v2 / value
                              :mod (p4 / positive)
                              :ARG1-of (p5 / predict-01)
                              :ARG1-of (m2 / mean-01
                                    :ARG2 (f3 / fraction
                                          :ARG1-of (ii / include-91
                                                :ARG2 (c / case
                                                      :mod (p6 / positive)
                                                      :ARG1-of (p7 / predict-01
                                                            :ARG1-of (c2 / correct-02))
                                                      :mod (a / all)
                                                      :mod (p8 / positive)))))))
                  :ARG3 (a2 / across
                        :op1 (g2 / group
                              :ARG0-of (s / sensitive-03)
                              :ARG1-of (a3 / advantage-01))))))

# ::snt Outcome fairness is defined here in  terms of a parity of precision, where the probability of members from different  groups actually having the quality they are predicted to have is the same  across  groups .
# File 157

(d / define-01
      :ARG0 (h / here)
      :ARG1 (f / fairness
            :mod (o / outcome))
      :ARG2 (p / parity
            :mod (p2 / precision)
            :ARG1-of (m / mean-01
                  :ARG2 (s / same-01
                        :ARG1 (p3 / probability
                              :mod (h2 / have-03
                                    :ARG0 (m2 / member
                                          :source (g / group
                                                :ARG1-of (d2 / differ-02)))
                                    :ARG1 (q / quality
                                          :ARG1-of (h3 / have-03
                                                :ARG0 m2
                                                :ARG1-of (p4 / predict-01)))
                                    :ARG1-of (a / actual-02)))
                        :ARG3 (a2 / across
                              :op1 (g2 / group))))))

# ::snt Individual Fairness       Individual  Fairness  An outcome is fair if it treats individuals with similar relevant qualification s  similarly.
# File 157

(m / multi-sentence
      :snt1 (f / fairness
            :mod (ii / individual))
      :snt2 (f2 / fairness
            :mod (ii2 / individual))
      :snt3 (f3 / fair-01
            :ARG1 (o / outcome)
            :condition (t / treat-01
                  :ARG0 o
                  :ARG1 (ii3 / individual
                        :ARG0-of (q / qualify-02
                              :ARG1-of (r / relevant-01)
                              :ARG1-of (r2 / resemble-01)))
                  :ARG2 (r3 / resemble-01))))

# ::snt Counterfactual  Fairness                   Individual  Fairness  An outcome is fair if  an automa ted decision made about  an indiv idual  belonging to a sen sitive group would have been the same were that individual  a member of a different group in a closest possible alternative (or  counterfactual) world.
# File 157

(m / multi-sentence
      :snt1 (f / fairness
            :mod (c / counterfactual))
      :snt2 (f2 / fairness
            :mod (ii / individual))
      :snt3 (f3 / fair-01
            :ARG1 (o / outcome)
            :condition (s / same-01
                  :ARG1 (d / decide-01
                        :ARG1 (b / belong-01
                              :ARG0 (ii2 / individual)
                              :ARG1 (g / group
                                    :mod (c2 / collective)))
                        :mod (a / automatic))
                  :ARG2 (ii3 / individual
                        :ARG0-of (h / have-org-role-91
                              :ARG1 (g2 / group
                                    :ARG1-of (d2 / differ-02))
                              :ARG2 (m2 / member)))
                  :condition (b2 / be-located-at-91
                        :ARG1 ii2
                        :ARG2 (o2 / or
                              :op1 (w / world
                                    :mod (a2 / alternative)
                                    :ARG1-of (p / possible-01)
                                    :ARG1-of (h2 / have-degree-91
                                          :ARG2 (c3 / close-10
                                                :ARG1 w)
                                          :ARG3 (m3 / most)))
                              :op2 (w2 / world
                                    :mod c)
                              :ARG1-of (p2 / possible-01))))))

# ::snt Like the individual fairness approach, this method of  defining fairnes s focu ses on the specific circumstan ces of an affected decision  subject, but, by using the tools  of contrastive explanation , it moves beyond  individual fairness insofar as it brings out  the causal influences behind the  algorithmic output.
# File 157

(c / contrast-01
      :ARG1 (f / focus-01
            :ARG0 (m / method
                  :mod (d / define-01
                        :ARG1 (f2 / fairness))
                  :ARG1-of (r / resemble-01
                        :ARG2 (a / approach-02
                              :ARG1 (f3 / fairness
                                    :mod (ii / individual))))
                  :mod (t / this))
            :ARG1 (c2 / coefficient
                  :ARG1-of (s / specific-02)
                  :mod (c3 / circumstantial)
                  :poss (s2 / subject
                        :topic (d2 / decide-01)
                        :ARG1-of (a2 / affect-01))))
      :ARG2 (m2 / move-01
            :ARG1 m
            :ARG2 (b / beyond
                  :op1 f3)
            :manner (u / use-01
                  :ARG0 m
                  :ARG1 (t2 / tool
                        :instrument-of (e / explain-01
                              :ARG0-of c))))
      :ARG1-of (c4 / cause-01
            :ARG0 (b2 / bring-01
                  :ARG0 m
                  :ARG1 (ii2 / influence-01
                        :ARG0 (b3 / behind
                              :op1 (o / output
                                    :mod (a3 / algorithm)))
                        :ARG0-of (c5 / cause-01))
                  :ARG2 (o2 / out))))

# ::snt Fairness through awareness.
# File 157

(f / fairness
      :manner (a / awareness))

# ::snt (Statistical Parity and Individual Fairness)   Zemel, R. , Wu, Y. , Swersky, K. , Pitassi, T. , & Dwork, C. (2013 ).
# File 157

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Zemel"))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "Wu"))
            :op3 (p4 / person
                  :name (n3 / name
                        :op1 "Y."))
            :op4 (p5 / person
                  :name (n4 / name
                        :op1 "Swersky"))
            :op5 (p6 / person
                  :name (n5 / name
                        :op1 "Pitassi"))
            :op6 (p7 / person
                  :name (n6 / name
                        :op1 "T."))
            :op7 (p8 / person
                  :name (n7 / name
                        :op1 "Dwork")))
      :ARG1 (p9 / publication
            :name (n8 / name
                  :op1 "Statistical"
                  :op2 "Parity"
                  :op3 "and"
                  :op4 "Individual"
                  :op5 "Fairness"))
      :time (d / date-entity
            :year 2013))

# ::snt Fairness beyond disparate treatment & dispar ate  impact: Learning classification without disparate mistreatment.
# File 157

(a / and
      :op1 (b / beyond
            :op1 (a2 / and
                  :op1 (t / treat-01
                        :mod (d / disparate))
                  :op2 (t2 / treat-01
                        :ARG0-of (d2 / disparage-01))))
      :op2 (t3 / thing
            :ARG1-of (m / mean-01
                  :ARG2 (c / classify-01
                        :manner (l / learn-01)
                        :manner (m2 / mistreat-01
                              :polarity -
                              :mod (d3 / disparate))))))

# ::snt Fairness definitions explained.
# File 157

(e / explain-01
      :ARG1 (t / thing
            :ARG2-of (d / define-01
                  :ARG1 (f / fairness))))

# ::snt In Proceedings of the International Workshop on Software  Fairness , 1-7.
# File 157

(p / publication-91
      :ARG7 (v / value-interval
            :op1 1
            :op2 7)
      :ARG4 (p2 / Proceedings
            :part-of (c / conference
                  :name (n / name
                        :op1 "International"
                        :op2 "Workshop"
                        :op3 "on"
                        :op4 "Software"
                        :op5 "Fairness"))))

# ::snt Counterfactual fairness.
# File 157

(f / fairness
      :mod (f2 / fact
            :polarity -))

# ::snt (Counterfactual Fairness)   Ustun, B. , Spangher, A ., & Liu, Y.
# File 157

(a / and
      :op1 (p / publication
            :name (n / name
                  :op1 "Counterfactual"
                  :op2 "Fairness"))
      :op2 (p2 / publication
            :name (n2 / name
                  :op1 "B."
                  :op2 "Ustun"))
      :op3 (p3 / publication
            :name (n3 / name
                  :op1 "Spangher"
                  :op2 "A"))
      :op4 (p4 / publication
            :name (n4 / name
                  :op1 "Liu"
                  :op2 "Y.")))

# ::snt In Proceedings of the Conference on  Fairness, Acc ountability, and Transparency , 10-19.
# File 157

(b / be-located-at-91
      :ARG2 (p / publication-91
            :ARG1 (c / conference
                  :name (n / name
                        :op1 "Conference"
                        :op2 "on"
                        :op3 ""
                        :op4 ""
                        :op5 "Fairness"
                        :op6 "Accuntability"
                        :op7 "and"
                        :op8 "Transparency"))
            :ARG4 (v / value-interval
                  :op1 10
                  :op2 19)))

# ::snt ( Extension of Counterfactual Fairness)   Technical Resources for Exploring Fairness Tools:   https://dsapp.uchicago.edu/projects/aequitas/   (University of Chicago’s open source bias audit toolkit for machine  learning developers)   http://www.fairness -measures.org/  and https://github.com/megantosh/fairness_measures_code/   (Datasets and  software for detecting algorithmic discrimination from TU Berlin and Eur ecat)  https://github.com/c olumbia/fairtest  (Fairtest unwarranted association discovery platform from Columbia  University)   http://aif360.mybluemix.net/#  (IBM’s Fairness 360 open source toolkit)         Fairness Posi tion Statement :     Once you and your project team have thoroughly consider ed the use case appropriateness as well as   technical feasibility of the formal models of fairness most relevant for your system and have  incorporated the model into your application , you should  prepare  a Fairness Posi tion Statement  (FPS)  in which the fairness criteria being employed in the AI system is made explicit and explained in plain  and non -technical language.
# File 157

(r / recommend-01
      :ARG1 (p / prepare-01
            :ARG0 (y / you)
            :ARG1 (t / thing
                  :name (n / name
                        :op1 "Fairness"
                        :op2 "Posi"
                        :op3 "Statement")
                  :medium-of (a / and
                        :op1 (e / explicit-03
                              :ARG1 (c / criteria
                                    :mod (f / fairness)
                                    :ARG1-of (e2 / employ-02
                                          :ARG2 (s / system
                                                :mod (ii / intelligent-01
                                                      :mod (a2 / artificial))))))
                        :op2 (e3 / explain-01
                              :ARG1 c
                              :medium (l / language
                                    :mod (t2 / technical
                                          :polarity -))))))
      :ARG2 y
      :time (a3 / and
            :op1 (c2 / consider-02
                  :ARG0 (a4 / and
                        :op1 y
                        :op2 (t3 / team
                              :mod (p2 / project)
                              :poss y))
                  :ARG1 (a5 / appropriate-02
                        :ARG1 (a6 / and
                              :op1 (u / use-01)
                              :op2 (f2 / feasibility
                                    :mod (t4 / technical)
                                    :poss (m / model
                                          :mod (f3 / fairness)
                                          :ARG1-of (h / have-degree-91
                                                :ARG2 (r2 / relevant-01
                                                      :ARG1 m
                                                      :ARG2 s
                                                      :poss y))
                                          :ARG3 (m2 / most))))))
            :degree (t5 / thorough))
      :op2 (p3 / platform
            :name (n2 / name
                  :op1 "Fairtest")
            :ARG0-of (d / discover-01
                  :ARG1 (a7 / association))
            :source (u2 / university
                  :name (n3 / name
                        :op1 "University"
                        :op2 "of"
                        :op3 "Chicago"))
            :mod (t6 / toolkit
                  :mod (s2 / source
                        :ARG1-of (o / open-04))
                  :poss (c3 / company
                        :name (n4 / name
                              :op1 "IBM"))))
      :medium (a8 / and
            :op1 (u3 / url-entity
                  :value "http://www.mybluemix.uchicago.edu/projects/aequitas/"))
      :op2 (u4 / url-entity
            :value "https://github.com/megantosh/fairness_measures_code/"))

# ::snt ( Extension of Counterfactual Fairness)   Technical Resources for Exploring Fairness Tools:   https://dsapp.uchicago.edu/projects/aequitas/   (University of Chicago’s open source bias audit toolkit for machine  learning developers)   http://www.fairness -measures.org/  and https://github.com/megantosh/fairness_measures_code/   (Datasets and  software for detecting algorithmic discrimination from TU Berlin and Eur ecat)  https://github.com/c olumbia/fairtest  (Fairtest unwarranted association discovery platform from Columbia  University)   http://aif360.mybluemix.net/#  (IBM’s Fairness 360 open source toolkit)         Fairness Posi tion Statement :     Once you and your project team have thoroughly consider ed the use case appropriateness as well as   technical feasibility of the formal models of fairness most relevant for your system and have  incorporated the model into your application , you should  prepare  a Fairness Posi tion Statement  (FPS)  in which the fairness criteria being employed in the AI system is made explicit and explained in plain  and non -technical language.
# File 157

(r / recommend-01
      :ARG1 (p / prepare-01
            :ARG0 (y / you)
            :ARG1 (t / thing
                  :name (n / name
                        :op1 "Fairness"
                        :op2 "Posi"
                        :op3 "Statement")
                  :medium-of (a / and
                        :op1 (e / explicit-03
                              :ARG1 (c / criteria
                                    :mod (f / fairness)
                                    :ARG1-of (e2 / employ-02
                                          :ARG2 (s / system
                                                :mod (ii / intelligent-01
                                                      :mod (a2 / artificial))))))
                        :op2 (e3 / explain-01
                              :ARG1 c
                              :medium (l / language
                                    :mod (t2 / technical
                                          :polarity -))))))
      :ARG2 y
      :time (a3 / and
            :op1 (c2 / consider-02
                  :ARG0 (a4 / and
                        :op1 y
                        :op2 (t3 / team
                              :mod (p2 / project)
                              :poss y))
                  :ARG1 (a5 / appropriate-02
                        :ARG1 (a6 / and
                              :op1 (u / use-01)
                              :op2 (f2 / feasibility
                                    :mod (t4 / technical)
                                    :poss (m / model
                                          :mod (f3 / fairness)
                                          :ARG1-of (h / have-degree-91
                                                :ARG2 (r2 / relevant-01
                                                      :ARG1 m
                                                      :ARG2 s
                                                      :poss y))
                                          :ARG3 (m2 / most))))))
            :degree (t5 / thorough))
      :op2 (p3 / platform
            :name (n2 / name
                  :op1 "Fairtest")
            :ARG0-of (d / discover-01
                  :ARG1 (a7 / association))
            :source (u2 / university
                  :name (n3 / name
                        :op1 "University"
                        :op2 "of"
                        :op3 "Chicago"))
            :mod (t6 / toolkit
                  :mod (s2 / source
                        :ARG1-of (o / open-04))
                  :poss (c3 / company
                        :name (n4 / name
                              :op1 "IBM"))))
      :medium (a8 / and
            :op1 (u3 / url-entity
                  :value "http://www.mybluemix.uchicago.edu/projects/aequitas/"))
      :op2 (u4 / url-entity
            :value "https://github.com/megantosh/fairness_measures_code/"))

# ::snt The interface  between the user and the system should be designed to make clear and accessible to the  user the system’s rationale, compliance to fairness standards, and confidence level.
# File 157

(r / recommend-01
      :ARG1 (d / design-01
            :ARG1 (t / thing
                  :instrument-of (ii / interact-01
                        :ARG0 (p / person
                              :ARG0-of (u / use-01))
                        :ARG1 (s / system)))
            :ARG3 (m / make-02
                  :ARG0 t
                  :ARG1 (a / and
                        :op1 (c / clear-06
                              :ARG0 t
                              :ARG1 (r2 / rationale
                                    :poss s))
                        :op2 (c2 / comply-01
                              :ARG0 s
                              :ARG1 (s2 / standard
                                    :topic (f / fairness)))
                        :op3 (l / level
                              :mod (c3 / confidence)))
                  :ARG2 p)))

# ::snt Considering  fairness  aware design and implementation from a workflow perspective will allow you, as a team,  to  concretis e and make explicit end -to-end paths of accountability in a clear and peer -reviewable   manner.
# File 157

(a / allow-01
      :ARG0 (c / consider-02
            :ARG1 (a2 / and
                  :op1 (d / design-01)
                  :op2 (ii / implement-01)
                  :ARG0-of (r / realize-01
                        :ARG1 (f / fairness)))
            :manner (p / perspective
                  :mod (w / work-01
                        :ARG1 (p2 / process-01))))
      :ARG1 (a3 / and
            :op1 (c2 / concretize-01
                  :ARG0 (y / you
                        :mod (t / team)))
            :op2 (m / make-01
                  :ARG0 y
                  :ARG1 (p3 / path
                        :path-of (a4 / accountable-02)
                        :mod (e / end-to-end)
                        :ARG1-of (e2 / explicit-03)))
            :manner (a5 / and
                  :op1 (c3 / clear-06)
                  :op2 (r2 / review-01
                        :ARG0 (p4 / peer)
                        :ARG1 p3
                        :ARG1-of (p5 / possible-01)))))

# ::snt Here is a schematic  representation of the fairness aware workflow .
# File 157

(r / represent-01
      :ARG0 (s / schematic)
      :ARG1 (w / work-01
            :ARG0-of (r2 / realize-01
                  :ARG1 (f / fairness)))
      :location (h / here))

# ::snt                                                                              Understanding Artificial Intelligence Ethics and Safety  23   Considering fairness aware design and implementation from such a workflow perspective will also  assist you in pinpoint ing risks  of bias or downstream discrimination and streamlining  possible solutions  in a proactive, pre -emptive, and anticipatory way .
# File 157

(a / and
      :op1 (u / understand-01
            :ARG1 (a2 / and
                  :op1 (e / ethics
                        :mod (ii / intelligent-01
                              :mod (a3 / artificial)))
                  :op2 (s / safe-01))
            :mod (p / publication
                  :ARG1-of (c / cite-01
                        :ARG2 23)))
      :op2 (a4 / assist-01
            :ARG0 (c2 / consider-02
                  :ARG1 (a5 / and
                        :op1 (d / design-01
                              :ARG0-of (r / realize-01
                                    :ARG1 (f / fairness)))
                        :op2 (ii2 / implement-01
                              :ARG0-of (f2 / facilitate-01
                                    :ARG1 (f3 / fair-01)))
                        :manner (p2 / perspective
                              :mod (w / work-01)
                              :mod (s2 / such)))
                  :ARG1 (y / you)
                  :ARG2 (a6 / and
                        :op1 (p3 / pinpoint-01
                              :ARG0 y
                              :ARG1 (r2 / risk-01
                                    :ARG1 (o / or
                                          :op1 (b / bias-01)
                                          :op2 (d2 / discriminate-02
                                                :mod (d3 / downstream)))))
                        :op2 (s3 / streamline-01
                              :ARG0 y
                              :ARG1 (s4 / solution
                                    :ARG1-of (p4 / possible-01)))
                        :manner (w2 / way
                              :mod (p5 / proactive)
                              :mod (p6 / preempt-01)
                              :mod (a7 / anticipate-01)))
                  :mod (a8 / also))))

# ::snt at each  column of the above table), you and the relevant members of your team should carry out a  collaborative self -assessment with regard to  the applicable dimension of fairness .
# File 157

(r / recommend-01
      :ARG1 (c / carry-out-03
            :ARG0 (a / and
                  :op1 (y / you)
                  :op2 (p / person
                        :ARG1-of (r2 / relevant-01)
                        :ARG0-of (h / have-org-role-91
                              :ARG1 (t / team
                                    :poss y)
                              :ARG2 (m / member))))
            :ARG1 (a2 / assess-01
                  :ARG0 a
                  :ARG1 a
                  :ARG2 (d / dimension
                        :ARG1-of (a3 / apply-02
                              :ARG1-of (p2 / possible-01))
                        :topic (f / fairness))
                  :manner (c2 / collaborate-01)))
      :location (c3 / column
            :mod (e / each)
            :part-of (t2 / table
                  :location (a4 / above))))

# ::snt Typically, AI project delivery workflows include department and delivery leads, technical Discriminatory Non -Harm  Self-Assessment     Step 1:  Identify the fairness and bias mitigation dimensions  that apply to the specific  stage under consideration (for example, at the data pre -processing  stage , dimensions of  data fairness , design fa irness, and outcome fairness may be  at issue).
# File 157

(m / multi-sentence
      :snt1 (ii / include-01
            :ARG1 (a / and
                  :op1 (p / person
                        :ARG0-of (l / lead-02
                              :ARG1 (a2 / and
                                    :op1 (d / department)
                                    :op2 (d2 / deliver-01))))
                  :op2 (p2 / person
                        :ARG0-of l
                        :ARG1 (d3 / deliver-01)))
            :op3 (a3 / assess-01
                  :ARG0 (p3 / person)
                  :ARG1 p3
                  :ARG2 (h / harm-01
                        :polarity -
                        :mod (t / technical))))
      :ARG2 (f / flow-01
            :ARG1 (d4 / deliver-01
                  :ARG1 (ii2 / intelligent-01
                        :mod (a4 / artificial)))
            :ARG1-of (t2 / typical-02))
      :snt2 (s / step-01
            :mod 1
            :ARG2 (ii3 / identify-01
                  :ARG1 (d5 / dimension
                        :ARG1-of (a5 / apply-02
                              :ARG2 (s2 / stage
                                    :ARG1-of (s3 / specific-02)
                                    :ARG1-of (c / consider-02)
                                    :example (p4 / possible-01
                                          :ARG1 (ii4 / issue-02
                                                :ARG0 (a6 / and
                                                      :op1 (d6 / dimension
                                                            :topic (f2 / fairness
                                                                  :mod (d7 / data)))
                                                      :op2 (f3 / fairness
                                                            :mod (d8 / design-01))
                                                      :op3 (f4 / fairness
                                                            :mod (o / outcome)))))))))))

# ::snt It also involves furnishing the decision  subject  and other interested parties  with an explanation of the ethical permissibility , the  fairness, and the safety  of the  use of the  AI system.
# File 157

(ii / involve-01
      :ARG1 (f / furnish-01
            :ARG1 (a / and
                  :op1 (s / subject
                        :ARG2-of (d / decide-01))
                  :op2 (p / party
                        :ARG1-of (ii2 / interest-01)
                        :mod (o / other)))
            :ARG2 (e / explain-01
                  :ARG1 (a2 / and
                        :op1 (p2 / permit-01
                              :mod (e2 / ethics))
                        :op2 (f2 / fairness)
                        :op3 (s2 / safe-01
                              :ARG0 (u / use-01
                                    :ARG1 (s3 / system
                                          :mod (ii3 / intelligent-01
                                                :mod (a3 / artificial))))))))
      :ARG2 (ii4 / it)
      :mod (a4 / also))

# ::snt In offering an explanation to affected  stake holders, y ou should be able to demonstrate that considerations of ethical  permissibility,  non-discrimination /fairness , and safety/ public trustworthiness were operative end -to-end in  the design and implementation processes that lead to  an automated decision  or behaviour .
# File 157

(r / recommend-01
      :ARG1 (p / possible-01
            :ARG1 (d / demonstrate-01
                  :ARG0 (y / you)
                  :ARG1 (o / operate-01
                        :ARG0 (c / consider-02
                              :ARG1 (a / and
                                    :op1 (p2 / permit-01
                                          :mod (e / ethics))
                                    :op2 (d2 / discriminate-02
                                          :polarity -)
                                    :op3 (f / fair-01)
                                    :op4 (s / slash
                                          :op1 (s2 / safe-01)
                                          :op2 (t / trust-01
                                                :ARG1 (p3 / public)))))
                        :location (a2 / and
                              :op1 (p4 / process-02
                                    :ARG1 (d3 / design-01))
                              :op2 (p5 / process-02
                                    :ARG1 (ii / implement-01))
                              :ARG0-of (l / lead-03
                                    :ARG2 (o2 / or
                                          :op1 (d4 / decide-01)
                                          :op2 (b / behave-01)
                                          :ARG1-of (a3 / automate-01))))
                        :manner (e2 / end-to-end))))
      :topic (o3 / offer-01
            :ARG0 y
            :ARG1 (e3 / explain-01
                  :ARG0 y
                  :ARG2 (p6 / person
                        :ARG0-of (h / hold-01
                              :ARG1 (s3 / stake))
                        :ARG1-of (a4 / affect-01)))))

# ::snt This outcome justification should take the content clarification /explicated outcome  from task 2  as its starting point and weigh that explanation against the justifiability criteria  adhered to throughout the design and use pipeline: ethical  permissibility,  nondiscrimination /fairness , and safety/ public trustworthiness .
# File 157

(r / recommend-01
      :ARG1 (a / and
            :op1 (t / take-01
                  :ARG0 (j / justify-01
                        :ARG1 (o / outcome)
                        :mod (t2 / this))
                  :ARG1 (a2 / and
                        :op1 (c / clarify-10
                              :ARG1 (c2 / content))
                        :op2 (o2 / outcome
                              :ARG1-of (e / explain-01))
                        :source (t3 / task
                              :mod 2))
                  :ARG2 (p / point
                        :mod (s / start-01
                              :ARG0 j)))
            :op2 (w / weigh-01
                  :ARG0 j
                  :ARG1 o2
                  :ARG3 (c3 / criteria
                        :ARG1-of (a3 / adhere-02
                              :location (p2 / pipeline
                                    :mod (d / design-01)
                                    :mod (u / use-01)))
                        :ARG2-of (j2 / justify-01
                              :ARG1-of (p3 / possible-01))
                        :ARG1-of (m / mean-01
                              :ARG2 (a4 / and
                                    :op1 (p4 / permit-01
                                          :mod (e2 / ethics))
                                    :op2 (d2 / discriminate-01
                                          :polarity -)
                                    :op3 (f / fairness)
                                    :op4 (s2 / slash
                                          :op1 (s3 / safe-01)
                                          :op2 (t4 / trust-01
                                                :ARG0 (p5 / public)))))))))

# ::snt semantic content) of th ese systems is a precondition for   ensuring  their safety and fairness .
# File 157

(p / precondition-01
      :ARG1 (e / ensure-01
            :ARG0 (s / system
                  :mod (t / this))
            :ARG1 (a / and
                  :op1 (s2 / safe-01
                        :ARG1 s)
                  :op2 (f / fair-01
                        :ARG1 s)))
      :ARG2 (c / content
            :mod (s3 / semantics)
            :poss s))

# ::snt Where possible, explanatory demonstrations of technical concepts  (like performance  metrics, formal fairness criteria, confidence intervals, etc.)
# File 157

(d / demonstrate-01
      :ARG1 (c / concept
            :mod (t / technical)
            :example (a / and
                  :op1 (m / metric
                        :mod (p / perform-02))
                  :op2 (c2 / criteria
                        :mod (f / fairness)
                        :mod (f2 / formal))
                  :op3 (ii / interval
                        :mod (c3 / confidence))
                  :op4 (e / et-cetera)))
      :ARG0-of (e2 / explain-01)
      :location (l / location
            :ARG1-of (p2 / possible-01)))

# ::snt • Each explanation should provide confirmatory information that the formal fairness criter ia  specified in your project’s Fairness Policy Statement has been met.
# File 157

(r / recommend-01
      :ARG1 (p / provide-01
            :ARG0 (e / explain-01
                  :mod (e2 / each))
            :ARG1 (ii / information
                  :ARG0-of (c / confirm-01
                        :ARG1 (m / meet-01
                              :ARG0 (c2 / criter
                                    :mod (f / fairness)
                                    :mod (f2 / formal)
                                    :ARG1-of (s / specify-01
                                          :ARG0 (s2 / state-01
                                                :ARG0 (p2 / project
                                                      :poss (y / you))
                                                :ARG1 (p3 / policy-01
                                                      :ARG2 (f3 / fairness))))))))))

# ::snt • Each explanation should provide confirmatory information that the formal fairness criter ia  specified in your project’s Fairness Policy Statement has been met.
# File 157

(r / recommend-01
      :ARG1 (p / provide-01
            :ARG0 (e / explain-01
                  :mod (e2 / each))
            :ARG1 (ii / information
                  :ARG0-of (c / confirm-01
                        :ARG1 (m / meet-01
                              :ARG0 (c2 / criter
                                    :mod (f / fairness)
                                    :mod (f2 / formal)
                                    :ARG1-of (s / specify-01
                                          :ARG0 (s2 / state-01
                                                :ARG0 (p2 / project
                                                      :poss (y / you))
                                                :ARG1 (p3 / policy-01
                                                      :ARG2 (f3 / fairness))))))))))

# ::snt This should include relevant information about performance  metrics, formal fairness criteria and validation, the implementation disclaimer, links or  summaries to the relevant information from the process logs of your P BG Framework,  and  links or summary information from th e Stakeholder Impact Assessment.
# File 157

(r / recommend-01
      :ARG1 (ii / include-01
            :ARG1 (a / and
                  :op1 (ii2 / information
                        :ARG1-of (r2 / relevant-01)
                        :topic (a2 / and
                              :op1 (m / metric
                                    :mod (p / perform-02))
                              :op2 (c / criteria
                                    :mod (f / fairness)
                                    :mod (f2 / formal))
                              :op3 (v / validate-01)))
                  :op2 (d / disclaim-01
                        :ARG1 (ii3 / implement-01))
                  :op3 (l / link-01
                        :ARG2 (ii4 / information
                              :ARG1-of (r3 / relevant-01)
                              :source (l2 / log
                                    :mod (p2 / process-01)
                                    :part-of (f3 / framework
                                          :name (n / name
                                                :op1 "PBG"
                                                :op2 "Framework")
                                          :poss (y / you)))))
                  :op4 (l3 / link-01
                        :ARG2 (ii5 / information
                              :ARG1-of (r4 / relevant-01)
                              :source (a3 / assess-01
                                    :ARG1 (ii6 / impact-01
                                          :ARG1 (s / stakeholder))
                                    :mod (t / this))))
                  :op5 (ii7 / information
                        :ARG1-of (s2 / summarize-01)
                        :source a3))
            :ARG2 t))

# ::snt Last, but not least, our ongoing partnership with the Information Commissioner’s Office on Project  ExplAIn—and, in particular, with ICO colleagues Carl Wiper and Alex Hubbard —has been a key  contributor to this guide’s focus on fairness, transparency, and accountability.
# File 157

(c / contribute-01
      :li -1
      :ARG0 (p / partner-01
            :ARG0 (w / we)
            :ARG1 (a / and
                  :op1 (o / organization
                        :name (n / name
                              :op1 "Information"
                              :op2 "Commissioner's"
                              :op3 "Office"))
                  :op2 (o2 / organization
                        :name (n2 / name
                              :op1 "ExplAIn"))
                  :op3 (a2 / and
                        :op1 (p2 / person
                              :name (n3 / name
                                    :op1 "Carl"
                                    :op2 "Wiper"))
                        :op2 (p3 / person
                              :name (n4 / name
                                    :op1 "Alex"
                                    :op2 "Hubbard"))
                        :ARG0-of (h / have-org-role-91
                              :ARG1 (o3 / organization
                                    :name (n5 / name
                                          :op1 "ICO"))
                              :ARG2 (c2 / colleague))
                        :mod (p4 / particular)))
            :ARG1-of (g / go-on-15))
      :ARG2 (f / focus-01
            :ARG0 (g2 / guide
                  :mod (t / this))
            :ARG2 (a3 / and
                  :op1 (f2 / fairness)
                  :op2 (t2 / transparency)
                  :op3 (a4 / accountable-02)))
      :ARG1-of (k / key-02))

# ::snt The SUM Values    General fairness    Data fairness   Design fairness   Outcome fairness   Implementation fairness   Accountability   Stakeholder Impact Assessment   Safety:  Accuracy, reliability, security, and robustness   Transparency   Process -Based Governance   Interpretable AI   Responsible delivery through human -centred implementation protocols and practices   Individual and societal impacts of machine learning and algorithm ic systems         The SUM Values     Access Now.
# File 157

(m / multi-sentence
      :snt1 (v / value
            :name (n / name
                  :op1 "The"
                  :op2 "Sum"
                  :op3 "Value"))
      :snt2 (a / and
            :op1 (f / fairness
                  :ARG1-of (g / general-02))
            :op2 (f2 / fairness
                  :mod (d / data))
            :op3 (f3 / fairness
                  :mod (d2 / design-01))
            :op4 (f4 / fairness
                  :mod (o / outcome))
            :op5 (f5 / fairness
                  :mod (ii / implement-01))
            :op6 (a2 / accountable-02)
            :op7 (a3 / assess-01
                  :ARG1 (ii2 / impact-01
                        :ARG0 (p / person
                              :ARG0-of (h / hold-01
                                    :ARG1 (s / stake)))))
            :op8 (s2 / safe-01)
            :op9 (a4 / and
                  :op1 (a5 / accuracy)
                  :op2 (r / reliability)
                  :op3 (s3 / security)
                  :op4 (r2 / robustness))
            :op10 (t / transparency)
            :op11 (g2 / govern-01
                  :ARG1-of (b / base-02
                        :ARG2 (p2 / process)))
            :op12 (ii3 / interpret-01
                  :ARG1 (ii4 / intelligent-01
                        :mod (a6 / artificial)))
            :op13 (d3 / deliver-01
                  :ARG1-of (r3 / responsible-02)
                  :instrument (a7 / and
                        :op1 (p3 / protocol)
                        :op2 (p4 / practice-01)
                        :ARG1-of (c / center-01
                              :ARG2 (h2 / human))))
            :op14 (ii5 / impact-01
                  :ARG0 (a8 / and
                        :op1 (l / learn-01
                              :mod (m2 / machine))
                        :op2 (s4 / system
                              :mod (a9 / algorithm)))
                  :ARG1 (a10 / and
                        :op1 (ii6 / individual)
                        :op2 (s5 / society)))
            :snt3 (p5 / publication
                  :name (n2 / name
                        :op1 "The"
                        :op2 "Sum"
                        :op3 "Value"))
            :snt4 p5
            :name (n3 / name
                  :op1 "Access"
                  :op2 "Now")))

# ::snt Retrieved  from  https://www.nature.com/news/four -ethical -priori ties-for-neurotechnologies -and-ai-1.22960       General fairness     Binns, R. (2017).
# File 157

(r / retrieve-01
      :ARG2 (p / publication-91
            :ARG0 (p2 / person
                  :name (n / name
                        :op1 "R."
                        :op2 "Binns"))
            :ARG1 (f / fairness
                  :ARG1-of (g / general-02))
            :time (d / date-entity
                  :year 2017))
      :medium (u / url-entity
            :value "https://www.nature.com/news/four-ethical-priori-ties-for-neurotechnologies-and-ai-1.22960"))

# ::snt Fairness in machine learning: Lessons from political philosophy.
# File 157

(l / lesson
      :source (p / philosophy
            :topic (p2 / politics))
      :domain (f / fairness
            :topic (l2 / learn-01
                  :manner (m / machine))))

# ::snt Improving fairness in machine  learning systems: What do industry practitioners need?
# File 157

(m / multi-sentence
      :snt1 (ii / improve-01
            :ARG1 (f / fair-01
                  :ARG1 (s / system
                        :mod (l / learn-01
                              :manner (m2 / machine)))))
      :snt2 (n / need-01
            :ARG0 (p / person
                  :ARG0-of (p2 / practice-01
                        :ARG1 (ii2 / industry)))
            :ARG1 (a / amr-unknown)))

# ::snt Fairness and abstraction in  sociotechnical systems.
# File 157

(a / and
      :op1 (f / fairness)
      :op2 (a2 / abstract-02)
      :location (s / system
            :mod (s2 / society)))

# ::snt In  Proceedings of the Conference on Fairness, Accountability, and  Transparency  (pp.
# File 157

(b / be-located-at-91
      :ARG2 (p / publication-91
            :ARG1 (c / conference
                  :name (n / name
                        :op1 "Conference"
                        :op2 "on"
                        :op3 "Fairness"
                        :op4 "Accountability"
                        :op5 "and"
                        :op6 "Transparency"))
            :ARG7 (v / value-interval
                  :op1 1
                  :op2 2)))

# ::snt Fairness and accountability design needs for algorithmic support  in high -stakes public sector decision -making.
# File 157

(n / need-01
      :ARG0 (d / design-01
            :ARG1 (a / and
                  :op1 (f / fairness)
                  :op2 (a2 / accountable-02)))
      :ARG1 (s / support-01
            :ARG0 (a3 / algorithm)
            :ARG1 (m / make-18
                  :ARG0 (s2 / sector
                        :ARG1-of (p / public-02))
                  :ARG1 (d2 / decide-01)
                  :mod (s3 / stake
                        :ARG1-of (h / high-02)))))

# ::snt                                                                              Understanding Artificial Intelligence Ethics and Safety  78 Data fairness     Abadi, D., Agrawal, R., Ailamaki, A., Balazinska, M., Bernstein, P. A., Carey, M. J., ... & Gehrke, J.
# File 157

(a / and
      :op1 (u / understand-01
            :ARG1 (a2 / and
                  :op1 (e / ethics
                        :mod (ii / intelligent-01
                              :mod (a3 / artificial)))
                  :op2 (s / safe-01)))
      :op2 (f / fairness
            :mod (d / data))
      :op3 (a4 / and
            :op1 (p / person
                  :name (n / name
                        :op1 "Abadi"))
            :op2 (p2 / person
                  :name (n2 / name
                        :op1 "Agrawal"))
            :op3 (p3 / person
                  :name (n3 / name
                        :op1 "Ailamaki"))
            :op4 (p4 / person
                  :name (n4 / name
                        :op1 "Balazinska"))
            :op5 (p5 / person
                  :name (n5 / name
                        :op1 "Bernstein"))
            :op6 (p6 / person
                  :name (n6 / name
                        :op1 "M.J."))
            :op7 (p7 / person
                  :name (n7 / name
                        :op1 "Carey"))
            :op8 (p8 / person
                  :name (n8 / name
                        :op1 "Gehrke"))))

# ::snt Retrieved from https://www.mdpi.com/1424 -8220/18/7/2146       Design fairness     Barocas, S., & Selbst, A. D. (2016).
# File 157

(r / retrieve-01
      :ARG2 (p / publication-91
            :ARG0 (a / and
                  :op1 (p2 / person
                        :name (n / name
                              :op1 "Barocas"))
                  :op2 (p3 / person
                        :name (n2 / name
                              :op1 "Selbst"))
                  :op3 (p4 / person
                        :name (n3 / name
                              :op1 "A."
                              :op2 "D.")))
            :ARG1 (p5 / publication
                  :name (n4 / name
                        :op1 "Design"
                        :op2 "Fair"))
            :time (d / date-entity
                  :year 2016))
      :medium (u / url-entity
            :value "https://www.mdpi.com/1424-8220/18/7/2146"))

# ::snt Algorithmic bias: From discrimination discovery to fairness -aware  data mining.
# File 157

(b / bias-01
      :mod (a / algorithm)
      :ARG1-of (r / range-01
            :ARG3 (d / discover-01
                  :ARG1 (d2 / discriminate-02))
            :ARG4 (m / mine-01
                  :ARG1 (d3 / data)
                  :ARG0-of (r2 / realize-01
                        :ARG1 (f / fairness)))))

# ::snt Problem formulation and fairness.
# File 157

(a / and
      :op1 (f / formulate-01
            :ARG1 (p / problem))
      :op2 (f2 / fair-01))

# ::snt In  Proceedings of the Conference on Fairness,  Accountability, and Transparency  (pp.
# File 157

(b / be-located-at-91
      :ARG2 (p / publication-91
            :ARG1 (c / conference
                  :name (n / name
                        :op1 "Conference"
                        :op2 "on"
                        :op3 "Fairness"
                        :op4 "and"
                        :op5 "Accountability"
                        :op6 "and"
                        :op7 "Transparency"))
            :ARG7 (v / value-interval
                  :op1 1
                  :op2 2)))

# ::snt https://doi.org/10.1007/s12599 -017-0487 -z      Outcome fairness
# File 157

(f / fairness
      :domain (o / outcome)
      :ARG1-of (d / describe-01
            :ARG0 (u / url-entity
                  :value "https://doi.org/10.1007/s12599 -017-0487 -z")))

# ::snt Fairness -aware programming.
# File 157

(p / program-01
      :ARG0-of (r / realize-01
            :ARG1 (f / fairness)))

# ::snt In  Proceedings of the Conference on  Fairness, Accountability, and Transparency  (pp.
# File 157

(b / be-located-at-91
      :ARG2 (p / publication-91
            :ARG1 (c / conference
                  :name (n / name
                        :op1 "Conference"
                        :op2 "on"
                        :op3 "Fairness"
                        :op4 "and"
                        :op5 "Accountability"
                        :op6 "and"
                        :op7 "Transparency"))
            :ARG7 (v / value-interval
                  :op1 1
                  :op2 2)))

# ::snt Path -specific counterfactual fairness.
# File 157

(f / fairness
      :ARG1-of (s / specific-02
            :ARG2 (p / path))
      :mod (c / counterfactual))

# ::snt Algorithmic decision making and the cost  of fairness.
# File 157

(a / and
      :op1 (m / make-01
            :ARG1 (d / decide-01
                  :manner (a2 / algorithm)))
      :op2 (c / cost-01
            :ARG1 (f / fairness)))

# ::snt Fairness through awareness.
# File 157

(f / fairness
      :manner (a / awareness))

# ::snt A  comparative study of fairness -enhancing interventions in machine learning.
# File 157

(s / study-01
      :ARG1 (ii / intervene-01
            :ARG0-of (e / enhance-01
                  :ARG1 (f / fairness))
            :instrument (l / learn-01
                  :mod (m / machine)))
      :manner (c / compare-01))

# ::snt In  Proceedings of the  Conference on Fairness,  Accountability, and Transparency  (pp.
# File 157

(b / be-located-at-91
      :ARG2 (p / publication-91
            :ARG1 (c / conference
                  :name (n / name
                        :op1 "Conference"
                        :op2 "on"
                        :op3 "Fairness"
                        :op4 "and"
                        :op5 "Accountability"
                        :op6 "and"
                        :op7 "Transparency"))
            :ARG7 (v / value-interval
                  :op1 1
                  :op2 2)))

# ::snt The case for proc ess fairness in learning:  Feature selection for fair decision making.
# File 157

(c / case-03
      :ARG1 (f / fairness
            :topic (l / learn-01)
            :ARG1-of (m / mean-01
                  :ARG2 (s / select-01
                        :ARG1 (f2 / feature)
                        :purpose (m2 / make-18
                              :ARG1 (d / decide-01
                                    :ARG1-of (f3 / fair-01)))))))

# ::snt On Fairness, Diversity and Randomness in  Algorithmic Decision Making.
# File 157

(a / and
      :op1 (f / fairness)
      :op2 (d / diversity)
      :op3 (r / randomness)
      :topic (m / make-01
            :ARG1 (d2 / decide-01
                  :manner (a2 / algorithm))))

# ::snt Beyond distributive fairness in algorithmic  decision making: Feature selection for procedurally fair learning.
# File 157

(b / beyond
      :op1 (f / fairness
            :mod (d / distribute-01)
            :topic (m / make-01
                  :ARG1 (d2 / decide-01)
                  :manner (a / algorithm)))
      :domain (s / select-01
            :ARG1 (f2 / feature)
            :purpose (l / learn-01
                  :ARG1-of (f3 / fair-01
                        :manner (p / procedure)))))

# ::snt Retrieved from http://mlg.eng.cam.ac.uk/adrian/AAAI18 BeyondDistributiveFairness.pdf   Hardt, M., Price, E., & Srebro, N. (2016).
# File 157

(r / retrieve-01
      :ARG2 (u / url-entity
            :value "http://mlg.eng.cam.ac.uk/adrian/AAAI18 BeyondDistributiveFairness.pdf")
      :source (p / publication-91
            :ARG0 (a / and
                  :op1 (p2 / person
                        :name (n / name
                              :op1 "Hardt"))
                  :op2 (p3 / person
                        :name (n2 / name
                              :op1 "Price"))
                  :op3 (p4 / person
                        :name (n3 / name
                              :op1 "E."))
                  :op4 (p5 / person
                        :name (n4 / name
                              :op1 "Srebro")))
            :time (d / date-entity
                  :year 2016)))

# ::snt Fairness -aware classifier with prejudice remover  regularizer.
# File 157

(a / and
      :op1 (p / person
            :ARG0-of (c / classify-01)
            :ARG0-of (r / realize-01
                  :ARG1 (f / fairness)))
      :op2 (p2 / person
            :ARG0-of (r2 / remove-01
                  :ARG1 (p3 / prejudice-01)))
      :op3 (p4 / person
            :ARG0-of (r3 / regularize-01)))

# ::snt Counterfactual fairness.
# File 157

(f / fairness
      :mod (f2 / fact
            :polarity -))

# ::snt Retrieved from http://papers.nips.cc/paper   /6995 -counterfactual -fairness   Russell, C., Kusner, M. J., Loftus, J., & Silva, R. (2017).
# File 157

(r / retrieve-01
      :ARG2 (p / publication-91
            :ARG0 (a / and
                  :op1 (p2 / person
                        :name (n / name
                              :op1 "Russell"))
                  :op2 (p3 / person
                        :name (n2 / name
                              :op1 "Kusner"))
                  :op3 (p4 / person
                        :name (n3 / name
                              :op1 "M.J."))
                  :op4 (p5 / person
                        :name (n4 / name
                              :op1 "Loftus"))
                  :op5 (p6 / person
                        :name (n5 / name
                              :op1 "Silva")))
            :ARG1 (p7 / publication)
            :time (d / date-entity
                  :year 2017))
      :medium (u / url-entity
            :value "http://papers.nips.cc/paper/6995 -counterfactual -fairness"))

# ::snt When worlds collide: Integrating different counterfactual  assumptio ns in fairness.
# File 157

(m / multi-sentence
      :snt1 (b / be-temporally-at-91
            :ARG2 (c / collide-01
                  :ARG0 (w / world)))
      :snt2 (ii / integrate-01
            :ARG1 (a / assume-02
                  :ARG1 (t / thing
                        :ARG1-of (d / differ-02)
                        :mod (c2 / counterfactual)))
            :manner (f / fairness)))

# ::snt Retrieved  from http://papers.nips.cc/paper/7220 -when -worlds -collide -integrating -different -counterfactual assumptions -in-fairness.pdf
# File 157

(r / retrieve-01
      :ARG2 (u / url-entity))

# ::snt In  Proceedings of the  Conference on Fairness, Accountability, and Transparency  (pp.
# File 157

(b / be-located-at-91
      :ARG2 (p / publication-91
            :ARG1 (c / conference
                  :name (n / name
                        :op1 "Conference"
                        :op2 "on"
                        :op3 "Fairness"
                        :op4 "Accountability"
                        :op5 "and"
                        :op6 "Transparency"))
            :ARG7 (v / value-interval
                  :op1 1
                  :op2 2)))

# ::snt Fairness definitions explained.
# File 157

(e / explain-01
      :ARG1 (t / thing
            :ARG2-of (d / define-01
                  :ARG1 (f / fairness))))

# ::snt In  2018 IEEE/ACM International Workshop on  Software Fairness (FairWare)  (pp.
# File 157

(p / publication-91
      :ARG4 (c / conference
            :name (n / name
                  :op1 "IEEE/ACM"
                  :op2 "International"
                  :op3 "Workshop"
                  :op4 "on"
                  :op5 "Software"
                  :op6 "Fairness"
                  :op7 "(FairWare)"))
      :ARG7 (v / value-interval
            :op1 1
            :op2 2)
      :time (d / date-entity
            :year 2018))

# ::snt Fairness constraints: Mechanisms f or fair  classification.
# File 157

(c / constraint
      :topic (f / fair-01)
      :ARG1-of (m / mean-01
            :ARG2 (c2 / classify-01
                  :ARG2 (o / or
                        :op1 (m2 / mechanism
                              :mod (s / string-entity
                                    :value "f"))
                        :op2 (m3 / mechanism
                              :ARG1-of (f2 / fair-01))))))

# ::snt Fairness beyond disparate treatment &  disparate impact: Learning classification without disparate mistreatment.
# File 157

(f / fairness
      :location (b / beyond
            :op1 (a / and
                  :op1 (t / treat-01
                        :mod (d / disparate))
                  :op2 (ii / impact-01
                        :mod (d2 / disparate))))
      :example (l / learn-01
            :ARG1 (c / classify-01)
            :manner (m / mistreat-01
                  :polarity -
                  :mod (d3 / disparate))))

# ::snt Fairness in decision -making the causal explanation formula.
# File 157

(f / fairness
      :domain (f2 / formula
            :mod (m / make-18
                  :ARG1 (d / decide-01))
            :mod (e / explain-01
                  :ARG1 (e2 / event
                        :ARG0-of (c / cause-01)))))

# ::snt Retrieved from https://link.springer.com/article/10.100 7/s10618 -0170506 -1      Implementation fairness     Alexander, V., Blinder, C., & Zak, P. J.
# File 157

(r / retrieve-01
      :ARG2 (u / url-entity
            :value "https://link.springer.com/article/10.100 7/s10618 -0170506 -1"
            :ARG3 (f / fairness
                  :ARG1-of (ii / implement-01))
            :ARG4 (a / and
                  :op1 (p / person
                        :name (n / name
                              :op1 "Alexander"))
                  :op2 (p2 / person
                        :name (n2 / name
                              :op1 "Blinder"))
                  :op3 (p3 / person
                        :name (n3 / name
                              :op1 "Zak"))
                  :op4 (p4 / person
                        :name (n4 / name
                              :op1 "P."
                              :op2 "J.")))))

# ::snt Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response  to algorithmic management.
# File 157

(u / understand-01
      :ARG1 (t / thing
            :ARG2-of (p / perceive-01
                  :ARG1 (t2 / thing
                        :ARG1-of (d / decide-01)
                        :mod (a / algorithm)))
            :ARG2-of (ii / include-91
                  :ARG1 (a2 / and
                        :op1 (f / fairness)
                        :op2 (t3 / trust-01)
                        :op3 (e / emotion)
                        :ARG2-of (r / respond-01
                              :ARG1 (m / manage-01
                                    :ARG0 a))))))

# ::snt Fairness, Accountability, and  Transparency in Machine Learning.
# File 157

(a / and
      :op1 (f / fairness)
      :op2 (a2 / accountable-02)
      :op3 (t / transparency)
      :topic (l / learn-01
            :mod (m / machine)))

# ::snt Fairness and transparency  of machine learning for trustworthy cloud services.
# File 157

(a / and
      :op1 (f / fairness)
      :op2 (t / transparency)
      :domain (l / learn-01
            :mod (m / machine)
            :purpose (s / service
                  :mod (c / cloud)
                  :mod (t2 / trustworthy))))

# ::snt In  Proceeding s of the Conference on Fairness, Accountability, and  Transparency  (pp.
# File 157

(b / be-located-at-91
      :ARG2 (p / publication-91
            :ARG1 (p2 / proceed-01
                  :ARG1 (c / conference
                        :name (n / name
                              :op1 "Conference"
                              :op2 "on"
                              :op3 "Fairness,"
                              :op4 "Accountability"
                              :op5 "and"
                              :op6 "Transparency")))
            :ARG7 (v / value-interval
                  :op1 1
                  :op2 2)))

# ::snt In  Proceedings of the  conference on fairness, accountability, and transparency  (pp.
# File 157

(b / be-located-at-91
      :ARG1 (p / publication-91
            :ARG1 (c / conference
                  :topic (a / and
                        :op1 (f / fairness)
                        :op2 (a2 / accountable-02)
                        :op3 (t / transparency)))
            :ARG7 (c2 / chapter
                  :mod (v / value-interval)))
      :ARG2 c)

# ::snt The trouble with algorithmic decisions: An analytic road map to examine efficiency and  fairness in automated and opaque decision making.
# File 157

(m / multi-sentence
      :snt1 (t / trouble-01
            :ARG0 (d / decide-01
                  :manner (a / algorithm)))
      :snt2 (m2 / map
            :mod (r / road)
            :mod (a2 / analyze-01)
            :purpose (e / examine-01
                  :ARG1 (a3 / and
                        :op1 (e2 / efficient-01
                              :ARG1 (m3 / make-01
                                    :ARG1 (d2 / decide-01)
                                    :ARG1-of (a4 / automate-01)
                                    :mod (o / opaque)))
                        :op2 (f / fair-01
                              :ARG1 m3)))))

# ::snt From ethical thinking to algorithmic regulationWhat the law already says about algorithms and artificial intelligenceThe limits of  the current legal frameworkShould algorithms and artificial intelligence be banned in certain sectors?Two founding principles for the development of algorithms and   artificial intelligence: fairness and continued attention and vigilanceEngineering principles: intelligibility, accountability, human interventionFrom principles to policy recommendationsCONCLUSIONACKNOWLEDGEMENTSLIST OF EVENTS ORGANISED FOR THE PUBLIC DEBATEGLOSSARY57 1011 13 141516 19 21 23 24263134383941 43 4445464748 51 5361626366CONTENTS
# File 21

(m / multi-sentence
      :snt1 (r / range-01
            :ARG3 (t / think-01
                  :mod (e / ethics))
            :ARG4 (r2 / regulate-01
                  :ARG1 (a / algorithm)))
      :snt2 (s / say-01
            :ARG0 (l / law)
            :ARG1 (a2 / amr-unknown)
            :ARG3 (a3 / and
                  :op1 (a4 / algorithm)
                  :op2 (ii / intelligent-01
                        :mod (a5 / artificial))))
      :snt3 (r3 / range-01
            :ARG3 (t2 / thing
                  :ARG2-of (l2 / limit-01
                        :ARG1 (f / framework
                              :mod (l3 / law)
                              :time (c / current))))
            :ARG4 (a6 / and
                  :op1 (f2 / fairness)
                  :op2 (a7 / and
                        :op1 (a8 / attend-02
                              :ARG1-of (c2 / continue-01))
                        :op2 (v / vigilant-01))
                  :ARG2-of (f3 / found-01
                        :ARG1 (d / develop-02
                              :ARG1 (a9 / and
                                    :op1 (a10 / algorithm)
                                    :op2 (ii2 / intelligent-01
                                          :mod a5)))))
            :ARG5 (r4 / recommend-01
                  :ARG3 (p / policy-01)))
      :snt4 (s2 / summarize-01
            :ARG1 (e2 / event)
            :ARG2 (p2 / publication
                  :name (n / name
                        :op1 "Public"
                        :op2 "Debate"
                        :op3 "Glossary"))))

# ::snt The first, substantial one, is the principle of fairness.
# File 21

(p / principle
      :topic (f / fair-01)
      :ord (o / ordinal-entity
            :value 1)
      :mod (s / substantial))

# ::snt P .47 Two founding principles for the development of algorithms and artificial intelligence:  fairness and continued attention and vigilance P .48 Engineering principles: intelligibility, accountability, human intervention P .51 From principles to policy recommendations P .53How can   we respond?43HOW CAN HUMANS KEEP THE UPPER HAND?
# File 21

(m / multi-sentence
      :snt1 (p / principle
            :quant 2
            :ARG2-of (f / found-01)
            :purpose (d / develop-02
                  :ARG1 (a / and
                        :op1 (a2 / algorithm)
                        :op2 (ii / intelligent-01
                              :mod (a3 / artificial))))
            :ARG1-of (m2 / mean-01
                  :ARG2 (a4 / and
                        :op1 (f2 / fairness)
                        :op2 (a5 / attend-02
                              :ARG1-of (c / continue-01))
                        :op3 (v / vigilant-01)))
            :ARG1-of (m3 / mean-01
                  :ARG2 (p2 / principle
                        :mod (e / engineer-01)
                        :ARG1-of (m4 / mean-01
                              :ARG2 (a6 / and
                                    :op1 (ii2 / intelligibility)
                                    :op2 (a7 / accountable-02)
                                    :op3 (ii3 / intervene-01
                                          :ARG0 (h / human))))))
            :ARG1-of (c2 / cite-01
                  :ARG2 47))
      :snt2 (r / range-01
            :ARG3 (p3 / principle)
            :ARG4 (r2 / recommend-01
                  :ARG1 (p4 / policy-01))
            :ARG1-of (c3 / cite-01
                  :ARG2 51))
      :snt3 (p5 / possible-01
            :ARG1 (r3 / respond-01
                  :ARG0 (w / we)
                  :ARG2 (a8 / amr-unknown)))
      :snt4 (p6 / possible-01
            :ARG1 (k / keep-01
                  :ARG0 (h2 / human
                        :part (h3 / hand
                              :ARG1-of (u / up-03)
                              :ARG1-of k)))
            :polarity (a9 / amr-unknown)))

# ::snt 51 Le Numérique et les droits fondamentaux, 2014, p.273 and 278-28148 Two founding principles for   the development of algorithms   and artificial intelligence: fairness   and continued attention and vigilance There are two distinct, albeit linked, intended outcomes to  the discussions on algorithms and AI: the principles and  the concrete means for putting these into practice.
# File 21

(m / multi-sentence
      :snt1 (p / publication-91
            :ARG7 51
            :ARG1 (a / and
                  :op1 (p2 / publication
                        :name (n / name
                              :op1 "Le"
                              :op2 "Numérique"
                              :op3 "and"
                              :op4 "Les"
                              :op5 "Droits"
                              :op6 "Fondamentaux"))
                  :op2 (p3 / publication
                        :name (n2 / name
                              :op1 "Le"
                              :op2 "Universite"
                              :op3 "de"
                              :op4 "Sante")))
            :ARG4 (p4 / publication
                  :name (n3 / name
                        :op1 "Polarity"
                        :op2 "and"
                        :op3 "Les"
                        :op4 "Droits"
                        :op5 "Fondamentaux"))
            :time (d / date-entity
                  :year 2014)
            :ARG7 (a2 / and
                  :op1 273
                  :op2 278
                  :op3 28148))
      :snt2 (p5 / principle
            :ARG0-of (f / found-01
                  :ARG1 (a3 / and
                        :op1 (d2 / develop-02
                              :ARG1 (a4 / algorithm))
                        :op2 (ii / intelligent-01
                              :mod (a5 / artificial))))
            :domain (a6 / and
                  :op1 (f2 / fairness)
                  :op2 (a7 / attend-02
                        :ARG1-of (c / continue-01))
                  :op3 (v / vigilant-01)))
      :snt3 (o / outcome
            :quant 2
            :ARG1-of (ii2 / intend-01
                  :concession (l / link-01
                        :polarity -))
            :topic (d3 / discuss-01
                  :ARG1 a3)
            :domain (a8 / and
                  :op1 (p6 / principle)
                  :op2 (m2 / means
                        :ARG1-of (c2 / concrete-02)
                        :instrument-of (p7 / put-03
                              :ARG1 a8
                              :ARG2 (p8 / practice-01
                                    :ARG1 a8))))))

# ::snt Beyond the observation that these principles do not cover the full  range of algorithmic and AI uses in practice, numerous  requirements regarding algorithms raised in the public  debate (fairness, accountability, intelligibility, explicability,  transparency, etc.
# File 21

(r / require-01
      :ARG1 (t / thing
            :ARG1-of (ii / include-91
                  :ARG2 (a / and
                        :op1 (f / fairness)
                        :op2 (a2 / accountable-02)
                        :op3 (ii2 / intelligibility)
                        :op4 (e / explicate-01)
                        :op5 (t2 / transparency)
                        :op6 (e2 / et-cetera)))
            :quant (n / numerous))
      :topic (a3 / algorithm
            :ARG1-of (r2 / raise-01
                  :location (d / debate-01
                        :ARG1-of (p / public-02))))
      :mod (b / beyond
            :op1 (o / observe-01
                  :ARG1 (c / cover-01
                        :polarity -
                        :ARG0 (p2 / principle
                              :mod (t3 / this))
                        :ARG1 (r3 / range-01
                              :ARG1 (u / use-01
                                    :ARG1 (a4 / and
                                          :op1 (a5 / algorithm)
                                          :op2 (ii3 / intelligent-01
                                                :mod (a6 / artificial))))
                              :ARG1-of (f2 / full-09))
                        :ARG1-of (p3 / practice-01)))))

# ::snt Two of these, bearing on fairness and continued  attention and vigilance, stand out as particularly founding  principles.
# File 21

(s / stand-out-06
      :ARG1 (t / thing
            :quant 2
            :ARG1-of (ii / include-91
                  :ARG2 (t2 / this))
            :ARG0-of (b / bear-01
                  :ARG1 (a / and
                        :op1 (f / fairness)
                        :op2 (a2 / attend-02
                              :ARG1-of (c / continue-01))
                        :op3 (v / vigilant-01
                              :ARG1-of (c2 / continue-01)))))
      :ARG2 (p / principle
            :ARG0-of (f2 / found-01)
            :mod (p2 / particular)))

# ::snt The principle of fairness A principle formulated by the French Council of State In its 2014 annual report on digital technology and fun damental rights, the Council of State outlined three  recommendations calling for a “rethink of the principles  underpinning the protection of fundamental rights”.
# File 21

(o / outline-01
      :ARG0 (g / government-organization
            :name (n / name
                  :op1 "Council"
                  :op2 "of"
                  :op3 "State")
            :mod (c / country
                  :name (n2 / name
                        :op1 "France")))
      :ARG1 (r / recommend-01
            :quant 3
            :ARG0 g
            :ARG0-of (c2 / call-03
                  :ARG1 (r2 / rethink-01
                        :ARG1 (p / principle
                              :ARG0-of (u / underpin-01
                                    :ARG1 (p2 / protect-01
                                          :ARG1 (r3 / right-05
                                                :mod (f / fundamental))))))))
      :medium (r4 / report-01
            :ARG0 g
            :ARG1 (a / and
                  :op1 (t / technology
                        :mod (d / digital))
                  :op2 (r5 / right-05
                        :mod (m / mental)
                        :ARG1-of (f2 / fun-01)))
            :time (d2 / date-entity
                  :year 2014)
            :frequency (r6 / rate-entity-91
                  :ARG3 (t2 / temporal-quantity
                        :quant 1
                        :unit (y / year))))
      :mod (p3 / principle
            :mod (f3 / fairness)
            :ARG1-of (f4 / formulate-01
                  :ARG0 g)))

# ::snt The third had to do with the principle of “fairness” applied,  not to all algorithms, but in a more restricted manner to  “platforms”50.
# File 21

(h / have-to-do-with-04
      :li 50
      :ARG0 (o / ordinal-entity
            :value 3)
      :ARG1 (p / principle
            :topic (f / fairness
                  :ARG1-of (a / apply-01
                        :ARG2 (p2 / platform)
                        :ARG1-of (c / contrast-01
                              :ARG2 (a2 / algorithm
                                    :mod (a3 / all
                                          :polarity -)))
                        :manner (h2 / have-degree-91
                              :ARG2 (r / restrict-01
                                    :ARG1 a)
                              :ARG3 (m / more))
                        :ARG1-of h2))))

# ::snt According to the French Council of State, “fairness consists of ensuring, in good faith, the search  engine optimisation (SEO) or ranking service, without  seeking to alter or manipulate it for purposes that are not in the users’ interest 51”.
# File 21

(s / say-01
      :ARG0 (g / government-organization
            :name (n / name
                  :op1 "Council"
                  :op2 "of"
                  :op3 "State")
            :mod (c / country
                  :name (n2 / name
                        :op1 "France")))
      :ARG1 (c2 / consist-01
            :ARG1 (f / fairness)
            :ARG2 (e / ensure-01
                  :ARG1 (o / or
                        :op1 (o2 / optimize-01
                              :ARG1 (s2 / search-engine))
                        :op2 (s3 / serve-01
                              :ARG1 (r / rank-01)))
                  :manner (f2 / faith
                        :ARG1-of (g2 / good-02))
                  :manner (s4 / seek-01
                        :polarity -
                        :ARG1 o
                        :op1 (a / alter-01
                              :ARG1 o
                              :purpose (p / purpose
                                    :ARG2-of (ii / interest-01
                                          :polarity -
                                          :ARG1 (p2 / person
                                                :ARG0-of (u / use-01)))))
                        :op2 (m / manipulate-01
                              :ARG1 o
                              :purpose p)))))

# ::snt Platforms’ obligations towards their users in terms of the fairness principle as defined by the Council of State par ticularly include, on the one hand, the relevance of SEO  and ranking criteria used by the platform with a view to  providing users with the best possible service and, on the  other, information about these criteria.
# File 21

(ii / include-01
      :ARG1 (a / and
            :op1 (r / relevant-01
                  :ARG1 (c / company
                        :name (n / name
                              :op1 "SEO")))
            :op2 (c2 / criteria
                  :topic (r2 / rank-01)
                  :ARG1-of (u / use-01
                        :ARG0 (p / platform)
                        :purpose (p2 / provide-01
                              :ARG0 p
                              :ARG1 (a2 / and
                                    :op1 (s / service
                                          :ARG1-of (p3 / possible-01)
                                          :ARG1-of (h / have-degree-91
                                                :ARG2 (g / good-02
                                                      :ARG1 s)
                                                :ARG3 (m / most)))
                                    :op2 (ii2 / information
                                          :topic (c3 / criteria
                                                :mod r2)))
                              :ARG2 (p4 / person
                                    :ARG0-of u)))))
      :ARG2 (o / obligate-01
            :ARG1 p
            :ARG2 p4
            :topic (p5 / principle
                  :topic (f / fairness)
                  :ARG1-of (d / define-01
                        :ARG0 (g2 / government-organization
                              :name (n2 / name
                                    :op1 "Council"
                                    :op2 "of"
                                    :op3 "State")))))
      :mod (p6 / particular))

# ::snt This definition of fairness does not so much grant a  right to users as it lays down an obligation with regard  to controllers.
# File 21

(c / contrast-01
      :ARG1 (g / grant-01
            :polarity -
            :ARG0 (d / define-01
                  :ARG1 (f / fair-01)
                  :mod (t / this))
            :ARG1 (r / right-05)
            :ARG2 (p / person
                  :ARG0-of (u / use-01))
            :ARG1-of (h / have-quant-91
                  :ARG2 (m / much)
                  :ARG3 (s / so)))
      :ARG2 (l / lay-01
            :ARG0 d
            :ARG1 (o / obligate-01
                  :topic (p2 / person
                        :ARG0-of (c2 / control-01)))
            :ARG2 (d2 / down)))

# ::snt In a way, the beginnings of a principle of fairness can be  found in the 1978 French Data Protection Act.
# File 21

(p / possible-01
      :ARG1 (f / find-01
            :ARG1 (t / thing
                  :ARG2-of (b / begin-01
                        :ARG1 (p2 / principle
                              :topic (f2 / fairness))))
            :location (l / law
                  :name (n / name
                        :op1 "French"
                        :op2 "Data"
                        :op3 "Protection"
                        :op4 "Act")
                  :time (d / date-entity
                        :year 1978)))
      :manner (w / way))

# ::snt For the right  of information it upholds appears as a primary requirement  in terms of fairness towards the data subject where an  algorithm is processing his or her data.
# File 21

(a / appear-02
      :ARG1 (r / require-01
            :ARG1 (r2 / right-05
                  :ARG2 (ii / information)
                  :ARG1-of (u / uphold-01
                        :ARG0 (ii2 / it)))
            :mod (p / primary)
            :topic (f / fair-01
                  :ARG2 (s / subject
                        :mod (d / data)
                        :location-of (p2 / process-01
                              :ARG0 (a2 / algorithm)
                              :ARG1 (d2 / data
                                    :poss (o / or
                                          :op1 (h / he)
                                          :op2 (s2 / she))))))))

# ::snt French Council of State’s principle of fairness appears as  particularly interesting as it mentions the notion of “users’  interest”.
# File 21

(a / appear-02
      :ARG1 (ii / interest-01
            :ARG1 (p / principle
                  :topic (f / fair-01)
                  :poss (g / government-organization
                        :name (n / name
                              :op1 "French"
                              :op2 "Council"
                              :op3 "of"
                              :op4 "State")))
            :degree (p2 / particular))
      :ARG1-of (c / cause-01
            :ARG0 (m / mention-01
                  :ARG0 p
                  :ARG1 (n2 / notion
                        :topic (ii2 / interest-01
                              :ARG1 (p3 / person
                                    :ARG0-of (u / use-01)))))))

# ::snt Indeed, it is not simply a question of the algorithm  saying what it does and doing what it says: the principle of  fairness also limits the extent to which the controller can  determine the criteria by which the algorithm operates.
# File 21

(m / multi-sentence
      :snt1 (q / question-01
            :polarity -
            :ARG1 (a / and
                  :op1 (s / say-01
                        :ARG0 (a2 / algorithm)
                        :ARG1 (t / thing))
                  :op2 (d / do-02
                        :ARG0 a2
                        :ARG1 (t2 / thing
                              :ARG1-of s
                              :ARG0 a2))))
      :ARG1-of (s2 / simple-02)
      :mod (ii / indeed)
      :snt2 (l / limit-01
            :ARG0 (p / principle
                  :topic (f / fairness))
            :ARG1 (e / extent
                  :extent-of (p2 / possible-01
                        :ARG1 (d2 / determine-01
                              :ARG0 (p3 / person
                                    :ARG0-of (c / control-01))
                              :ARG1 (c2 / criteria
                                    :ARG0-of (o / operate-01
                                          :ARG1 a2)))))
            :mod (a3 / also)))

# ::snt 52  “Without ignoring trade secrecy, platforms would have to explain the general logic involved in their algorithms to users as well as, where applicable, the way in which users can  change their settings.” 53  For the sake of settling any semantic quibbles, let us be clear that use of the expression “fairness of algorithms”, rather than amounting to anthropomorphising a technical  object (algorithm), is a handy shortcut for talking about the fairness of algorithm designers and processors.
# File 21

(m / multi-sentence
      :snt1 (q / quote-01
            :ARG2 53)
      :snt2 (o / obligate-01
            :ARG1 (p / platform)
            :ARG2 (e / explain-01
                  :ARG0 p
                  :ARG1 (a / and
                        :op1 (l / logic
                              :ARG1-of (g / general-02)
                              :ARG1-of (ii / involve-01
                                    :ARG2 (a2 / algorithm
                                          :poss p)))
                        :op2 (w / way
                              :manner-of (p2 / possible-01
                                    :ARG1 (c / change-01
                                          :ARG0 (p3 / person
                                                :ARG0-of (u / use-01))
                                          :ARG1 (s / set-02
                                                :ARG0 p3)))))
                  :ARG2 p3)
            :manner (ii2 / ignore-01
                  :polarity -
                  :ARG1 (s2 / secrecy
                        :mod (t / trade-01))))
      :snt3 (l2 / let-01
            :mode imperative
            :ARG0 (w2 / we)
            :ARG1 (c2 / clear-06
                  :ARG0 w2
                  :ARG1 (s3 / shortcut
                        :ARG1-of (h / handy-02)
                        :purpose (t2 / talk-01
                              :ARG1 (f / fairness
                                    :poss (a3 / and
                                          :op1 (p4 / person
                                                :ARG0-of (d / design-01
                                                      :ARG1 (a4 / algorithm)))
                                          :op2 (p5 / person
                                                :ARG0-of (p6 / process-01
                                                      :ARG1 a4)))))
                        :ARG1-of (ii3 / instead-of-91
                              :ARG2 (a5 / amount-02
                                    :ARG1 (a6 / anthropomorphize-01
                                          :ARG1 (o2 / object
                                                :mod (t3 / technical)
                                                :domain a4))))))
            :purpose (s4 / settle-02
                  :ARG0 w2
                  :ARG1 (q2 / quibble-01
                        :mod (s5 / semantics)
                        :mod (a7 / any)))))

# ::snt With the principle of fairness, it is quite  different since such information must be provided to the  community of users from the outset52.
# File 21

(d / differ-02
      :li 52
      :ARG1 (ii / it)
      :ARG1-of (c / cause-01
            :ARG0 (o / obligate-01
                  :ARG2 (p / provide-01
                        :ARG1 (ii2 / information
                              :mod (s / such))
                        :ARG2 (c2 / community
                              :consist-of (p2 / person
                                    :ARG0-of (u / use-01)))
                        :time (f / from
                              :op1 (o2 / outset)))))
      :topic (p3 / principle
            :mod (f2 / fairness))
      :degree (q / quite))

# ::snt In this respect, fairness could well represent a solution to the problem of unbalanced relations between  controllers of algorithms and users.
# File 21

(p / possible-01
      :ARG1 (r / represent-01
            :ARG0 (f / fairness)
            :ARG1 (s / solve-01
                  :ARG1 (p2 / problem
                        :topic (r2 / relation-03
                              :ARG0 (p3 / person
                                    :ARG0-of (c / control-01
                                          :ARG1 (a / algorithm)))
                              :ARG1 (p4 / person
                                    :ARG0-of (u / use-01
                                          :ARG1 a))
                              :ARG1-of (b / balance-01
                                    :polarity -)))))
      :mod (w / well)
      :mod (r3 / respect
            :mod (t / this)))

# ::snt The notion of fairness has also been on the agenda of  additional talks led by the French Digital Council (CNNum).
# File 21

(ii / include-91
      :ARG1 (n / notion
            :topic (f / fairness))
      :ARG2 (a / agenda
            :poss (t / talk-01
                  :mod (a2 / additional)
                  :ARG1-of (l / lead-02
                        :ARG0 (o / organization
                              :name (n2 / name
                                    :op1 "French"
                                    :op2 "Digital"
                                    :op3 "Council")))))
      :mod (a3 / also))

# ::snt In its report entitled Ambition numérique (Digital Ambition,  2015), it made a proposal aimed at setting up an “algorithm  fairness rating agency” which could rely on an open network  of contributors.
# File 21

(p / propose-01
      :ARG0 (ii / it)
      :ARG1 (s / set-up-03
            :ARG0 ii
            :ARG1 (a / agency
                  :mod (a2 / algorithm)
                  :ARG0-of (r / rate-01
                        :ARG1 (f / fairness))
                  :ARG0-of (r2 / rely-01
                        :ARG1 (n / network
                              :ARG1-of (o / open-04)
                              :consist-of (p2 / person
                                    :ARG0-of (c / contribute-01)))
                        :ARG1-of (p3 / possible-01))))
      :ARG1-of (a3 / aim-02)
      :location (r3 / report
            :name (n2 / name
                  :op1 "Ambition"
                  :op2 "nova")
            :poss ii
            :ARG1-of (t / title-01
                  :ARG2 (p4 / publication-91
                        :ARG4 (p5 / publication
                              :name n2
                              :op1 "Digital"
                              :op2 "Ambition"))
                  :time (d / date-entity
                        :year 2015))))

# ::snt In light of this, there would also be merits in the principle  of fairness of algorithms being applied to algorithms or  issues not dealt with by the legislation on personal data  protection.
# File 21

(c / cause-01
      :ARG0 (t / this)
      :ARG1 (m / merit-01
            :ARG1 (p / principle
                  :topic (f / fair-01
                        :ARG1 (a / apply-02
                              :ARG1 (a2 / algorithm)
                              :ARG2 (o / or
                                    :op1 a2)
                              :op2 (ii / issue-02
                                    :ARG1-of (d / deal-01
                                          :polarity -
                                          :ARG0 (l / legislate-01
                                                :ARG1 (p2 / protect-01
                                                      :ARG1 (d2 / data
                                                            :ARG1-of (p3 / personal-02))))))))))
      :mod (a3 / also))

# ::snt With the rise of machine learning algorithms, the principle  of fairness of algorithms – whilst evidently representing a solution as far as some major issues are concerned –  comes up against a substantial stumbling block.
# File 21

(c / come-up-13
      :ARG1 (p / principle
            :topic (f / fair-01
                  :ARG1 (a / algorithm)))
      :ARG2 (b / block
            :ARG0-of (s / stumble-01)
            :mod (s2 / substantial))
      :time (r / rise-01
            :ARG1 (a2 / algorithm
                  :instrument-of (l / learn-01
                        :mod (m / machine))))
      :concession (r2 / represent-01
            :ARG0 p
            :ARG1 (s3 / solve-01
                  :topic (ii / issue-02
                        :ARG1-of (m2 / major-02)
                        :mod (s4 / some)))
            :manner (e / evident)))

# ::snt The notion of fairness on the part of algorithm designers  (which is what we are actually, usually, referring to when we  speak of “fairness of algorithms”) loses some of its scope  the moment an algorithm behaves in a way which remains  inscrutable even to its very designers.
# File 21

(l / lose-02
      :ARG0 (n / notion
            :topic (f / fairness
                  :prep-on (p / part
                        :poss (p2 / person
                              :ARG0-of (d / design-01
                                    :ARG1 (a / algorithm)))))
            :ARG1-of (r / refer-01
                  :ARG0 (w / we)
                  :ARG1-of (a2 / actual-02)
                  :time (s / speak-01
                        :ARG0 w
                        :ARG1 (f2 / fairness
                              :poss (a3 / algorithm)))
                  :mod (u / usual)))
      :ARG1 (s2 / scope
            :poss a
            :quant (s3 / some))
      :time (m / moment
            :time-of (b / behave-01
                  :ARG0 (a4 / algorithm)
                  :ARG1 (w2 / way
                        :ARG1-of (r2 / remain-01
                              :ARG3 (ii / inscrutable
                                    :beneficiary (p3 / person
                                          :ARG0-of (d2 / design-01
                                                :ARG1 a4)
                                          :mod (e / even))))))))

# ::snt It must be possible  either to speak of fairness of algorithms in the strict sense  (but does this actually mean anything?
# File 21

(c / contrast-01
      :ARG1 (o / obligate-01
            :ARG2 (p / possible-01
                  :ARG1 (s / speak-01
                        :ARG1 (f / fair-01
                              :ARG1 (a / algorithm))
                        :manner (s2 / sense
                              :mod (s3 / strict)))))
      :ARG2 (m / mean-01
            :ARG1 s
            :ARG2 (a2 / anything)
            :polarity (a3 / amr-unknown)
            :ARG1-of (a4 / actual-02)))

# ::snt This last idea is thus much broader than the initial consi derations raised earlier on the notion of fairness, which  were focused on commercial and competitive concerns  amid the development of decidedly unfair practices aimed  at obtaining an advantage by manipulating the algorithm.
# File 21

(c / cause-01
      :ARG1 (h / have-degree-91
            :ARG1 (ii / idea
                  :mod (l / last)
                  :mod (t / this))
            :ARG2 (b / broad-02
                  :ARG1 ii)
            :ARG3 (m / more
                  :quant (m2 / much))
            :ARG4 (c2 / criticism
                  :mod (ii2 / initial)
                  :ARG1-of (r / raise-01
                        :time (b2 / before))
                  :topic (n / notion
                        :topic (f / fairness))
                  :ARG1-of (f2 / focus-01
                        :ARG2 (c3 / concern-01
                              :ARG0 (a / and
                                    :op1 (c4 / commerce)
                                    :op2 (c5 / compete-01)))
                        :time (d / develop-02
                              :ARG1 (p / practice-01
                                    :ARG1-of (f3 / fair-01
                                          :polarity -
                                          :degree (d2 / decide-01))
                                    :ARG1-of (a2 / aim-02
                                          :ARG2 (o / obtain-01
                                                :ARG1 (a3 / advantage-01)
                                                :manner (m3 / manipulate-01
                                                      :ARG1 (a4 / algorithm))))))))))

# ::snt 50 The principle of continued  attention and vigilance While the principle of fairness appears to be a substantial  founding principle, the one of continued attention and vigi lance is more methodological, and must guide the way in which our societies model algorithmic systems.
# File 21

(m / multi-sentence
      :li 50
      :snt1 (p / principle
            :topic (a / and
                  :op1 (a2 / attend-02
                        :ARG1-of (c / continue-01))
                  :op2 (v / vigilant-01)))
      :snt2 (a3 / and
            :op1 (h / have-degree-91
                  :ARG1 (p2 / principle
                        :topic (a4 / and
                              :op1 a2
                              :op2 (v2 / vigi
                                    :mod (l / lance)))
                        :ARG1-of (c2 / continue-01))
                  :ARG2 (m2 / method)
                  :ARG3 (m3 / more))
            :op2 (o / obligate-01
                  :ARG1 p2
                  :ARG2 (g / guide-01
                        :ARG0 p2
                        :ARG1 (w / way
                              :manner-of (m4 / model-01
                                    :ARG0 (s / society
                                          :poss (w2 / we))
                                    :ARG1 (s2 / system
                                          :mod (a5 / algorithm))))))
            :concession (a6 / appear-02
                  :ARG1 (p3 / principle
                        :topic (f / fair-01)
                        :mod (s3 / substantial)
                        :domain (p4 / principle
                              :topic (f2 / found-01))))))

# ::snt 55 https://cnnumerique.fr/wp-content/uploads/2015/11/CNNum_Fiche_Loyaute-des-plateformes.pdf51 Engineering principles: intelligibility,  accountability, human intervention Intelligibility, transparency,  accountability Given the opacity of algorithmic systems,  transparency  is an oft-cited requirement, with the idea that it could be  a condition for fairness.
# File 21

(m / multi-sentence
      :snt1 (u / url-entity
            :value "https://cnnumerique.fr/wp-content/uploads/2015/11/CNNum_Fiche_Loyaute-des-plateformes.pdf51")
      :snt2 (p / principle
            :mod (e / engineer-01)
            :domain (a / and
                  :op1 (ii / intelligible)
                  :op2 (a2 / accountable-02)
                  :op3 (ii2 / intervene-01
                        :ARG0 (h / human))
                  :op4 (t / transparent)
                  :op5 (a3 / accountable-02)))
      :snt3 (r / require-01
            :ARG1 (t2 / transparency)
            :ARG1-of (c / cite-01
                  :frequency (o / oft))
            :prep-with (ii3 / idea
                  :domain (p2 / possible-01
                        :ARG1 (h2 / have-condition-91
                              :ARG1 (f / fairness)
                              :ARG2 t2)))
            :ARG1-of (c2 / cause-01
                  :ARG0 (o2 / opacity
                        :poss (s / system
                              :mod (a4 / algorithm))))))

# ::snt The idea of intelligibility (or explicability), in the same way  as that of transparency, in any case ties in with the prin-ciple of fairness, as we might ultimately consider it to be  a condition for the latter’s implementation.
# File 21

(t / tie-in-02
      :ARG1 (ii / idea
            :topic (o / or
                  :op1 (ii2 / intelligible)
                  :op2 (e / explicate-01)))
      :ARG2 (p / principle
            :topic (f / fairness))
      :mod (c / case
            :mod (a / any))
      :ARG1-of (c2 / cause-01
            :ARG0 (c3 / consider-01
                  :ARG0 (w / we)
                  :ARG1 (h / have-condition-91
                        :ARG1 (ii3 / implement-01
                              :ARG1 (l / latter))
                        :ARG2 (ii4 / it))
                  :mod (u / ultimate)
                  :ARG1-of (p2 / possible-01)))
      :manner (w2 / way
            :ARG1-of (s / same-01
                  :ARG2 (w3 / way
                        :topic (t2 / transparency)))))

# ::snt However, many analyses agree that these provisions are  insufficient to effectively demystify algorithm-driven sys tems and ensure intelligibility, transparency and fairness.
# File 21

(c / contrast-01
      :ARG2 (a / agree-01
            :ARG0 (a2 / analyze-01
                  :quant (m / many))
            :ARG1 (s / suffice-01
                  :polarity -
                  :ARG0 (p / provision
                        :mod (t / this))
                  :ARG1 (a3 / and
                        :op1 (d / demystify-01
                              :ARG0 p
                              :ARG1 (s2 / system
                                    :ARG1-of (a4 / automate-01)
                                    :ARG1-of (d2 / drive-02
                                          :ARG0 (a5 / algorithm)))
                              :ARG1-of (e / effective-04))
                        :op2 (e2 / ensure-01
                              :ARG0 p
                              :ARG1 (a6 / and
                                    :op1 (ii / intelligibility)
                                    :op2 (t2 / transparency)
                                    :op3 (f / fairness)))))))

# ::snt It also seems entirely relevant for this requirement (whether  determined by the law or freely adopted by the stakehol ders) to concern algorithms that do not process the personal data of their users too, insofar as they are likely to  have significant collective impacts – regardless of the fact  that these are not direct impacts on individuals themselves  (see, in particular, “The limits of the current legal framework”  and “The principle of fairness”).
# File 21

(s / seem-01
      :ARG1 (r / relevant-01
            :ARG1 (r2 / require-01
                  :ARG1 (c / concern-02
                        :ARG0 (a / algorithm
                              :ARG0-of (p / process-01
                                    :polarity -
                                    :ARG1 (d / data
                                          :ARG1-of (p2 / personal-02)
                                          :poss (p3 / person
                                                :ARG0-of (u / use-01
                                                      :ARG1 a)))
                                    :mod (t / too)))
                        :ARG1 (ii / impact-01
                              :ARG0 a
                              :ARG1 (c2 / collective)
                              :ARG1-of (s2 / significant-02)
                              :ARG1-of (l / likely-01)
                              :concession (f / fact
                                    :topic (ii2 / impact-01
                                          :polarity -
                                          :ARG0 a
                                          :ARG1 (ii3 / individual)
                                          :ARG1-of (d2 / direct-02)))))
                  :mod (t2 / this))
            :degree (e / entire)
            :ARG1-of (r3 / regardless-91
                  :ARG2 (o / or
                        :op1 (d3 / determine-01
                              :ARG0 (l2 / law)
                              :ARG1 r2)
                        :op2 (a2 / adopt-01
                              :ARG0 (s3 / stakeholder)
                              :ARG1 r2
                              :ARG1-of (f2 / free-04)))))
      :mod (a3 / also)
      :example (a4 / and
            :op1 (l3 / limit-01
                  :ARG1 (f3 / framework
                        :time (c3 / current)
                        :ARG1-of (l4 / legal-02)))
            :op2 (p4 / principle
                  :topic (f4 / fair-01))))

# ::snt RECOMMENDATION 4 Set up a national platform for auditing algorithms Developing algorithmic auditing to check their compliance  with the law and fairness is often billed as a solution to  ensure their fairness, accountability and, more broadly,  their compliance with the law.Through design,   the whole relationship   between humans and machines  can be adjusted, to empower us and increase   our ability to make   informed decisions HOW CAN HUMANS KEEP THE UPPER HAND?
# File 21

(m / multi-sentence
      :snt1 (r / recommend-01
            :li 4
            :ARG1 (s / set-up-03
                  :ARG1 (p / platform
                        :mod (n / nation)
                        :purpose (a / audit-01
                              :ARG1 (a2 / algorithm)))))
      :snt2 (a3 / and
            :op1 (d / develop-02
                  :ARG1 (a4 / audit-01
                        :mod a2)
                  :purpose (c / check-01
                        :ARG1 (c2 / comply-01
                              :ARG0 (t / they)
                              :ARG1 (l / law)))))
      :op2 (b / bill-01
            :ARG1 (f / fairness)
            :ARG2 (s2 / solve-01
                  :ARG2 (e / ensure-01
                        :ARG0 (f2 / fairness)
                        :ARG1 (a5 / and
                              :op1 (f3 / fairness
                                    :poss t)
                              :op2 (a6 / accountable-02
                                    :ARG0 t)
                              :op3 (c3 / comply-01
                                    :ARG0 t
                                    :ARG1 l
                                    :ARG1-of (h / have-degree-91
                                          :ARG2 (b2 / broad-02
                                                :ARG1 c3)
                                          :ARG3 (m2 / more))))))
            :frequency (o / often))
      :snt3 (p2 / possible-01
            :ARG1 (a7 / adjust-01
                  :ARG1 (r2 / relation-03
                        :ARG0 (h2 / human)
                        :ARG2 (m3 / machine)
                        :mod (w / whole))
                  :manner (d2 / design-01)
                  :purpose (a8 / and
                        :op1 (e2 / empower-01
                              :ARG0 a7
                              :ARG1 (w2 / we))
                        :op2 (ii / increase-01
                              :ARG0 a7
                              :ARG1 (p3 / possible-01
                                    :ARG1 (d3 / decide-01
                                          :ARG0 w2
                                          :ARG1-of (ii2 / inform-01
                                                :ARG2-of h
                                                :ARG1 d3
                                                :ARG3 m2)))))))
      :manner (a9 / amr-unknown))

# ::snt On the one hand,  they would guarantee that algorithms practise fairness and  non-discrimination.
# File 21

(c / contrast-01
      :ARG1 (g / guarantee-01
            :ARG0 (t / they)
            :ARG1 (p / practice-01
                  :ARG0 (a / algorithm)
                  :ARG1 (a2 / and
                        :op1 (f / fairness)
                        :op2 (d / discriminate-01
                              :polarity -)))))

# ::snt First, the substantial principle of fairness of algorithms,  which builds on the principle already proposed by the  French Council of State (see the section “The principle  of fairness”).
# File 21

(m / multi-sentence
      :snt1 (p / principle
            :li 1
            :topic (f / fairness
                  :mod (a / algorithm))
            :mod (s / substantial)
            :ARG1-of (b / build-02
                  :ARG2 (p2 / principle
                        :ARG1-of (p3 / propose-01
                              :ARG0 (g / government-organization
                                    :name (n / name
                                          :op1 "Council"
                                          :op2 "of"
                                          :op3 "State")
                                    :mod (c / country
                                          :name (n2 / name
                                                :op1 "France")))
                              :time (a2 / already)))))
      :snt2 (s2 / see-01
            :mode imperative
            :ARG0 (y / you)
            :ARG1 (s3 / section
                  :topic (p4 / principle
                        :topic (f2 / fairness)))))

# ::snt This version factors in the idea of fairness  towards users, not only as consumers but also as ci-tizens, and even towards communities whose lifestyles  could be affected by algorithms, whether or not these  process personal data.
# File 21

(f / factor-01
      :ARG0 (v / version
            :mod (t / this))
      :ARG1 (ii / idea
            :topic (f2 / fairness
                  :beneficiary (a / and
                        :op1 (p / person
                              :ARG0-of (u / use-01))
                        :op2 (p2 / person
                              :ARG0-of (c / consume-01)
                              :mod (o / only
                                    :polarity -))
                        :op3 (p3 / person
                              :ARG0-of (g / google-01)
                              :mod (a2 / also))
                        :op4 (c2 / community
                              :mod (e / even)
                              :ARG1-of (a3 / affect-01
                                    :ARG0 (a4 / algorithm)
                                    :ARG2 (l / lifestyle
                                          :poss c2)
                                    :ARG1-of (p4 / possible-01)
                                    :ARG1-of (r / regardless-91
                                          :ARG2 (p5 / process-01
                                                :ARG0 a4
                                                :ARG1 (d / data
                                                      :ARG1-of (p6 / personal-02))))))))))

# ::snt At a time when France and Europe are  setting out their positions regarding artificial intelligence,  the question is an entirely relevant one.CONCLUSION The principles of fairness   and continued attention and  vigilance could form part of a  new generation of principles  and human rights in the digital  age: system-rights organising  the dimension underpinning  our digital world
# File 21

(m / multi-sentence
      :snt1 (r / relevant-01
            :ARG1 (q / question-01)
            :degree (e / entire)
            :time (s / set-out-06
                  :ARG0 (a / and
                        :op1 (c / country
                              :name (n / name
                                    :op1 "France"))
                        :op2 (c2 / continent
                              :name (n2 / name
                                    :op1 "Europe")))
                  :ARG1 (p / position-02
                        :ARG0 a
                        :ARG2 (ii / intelligent-01
                              :mod (a2 / artificial)))))
      :snt2 (p2 / possible-01
            :ARG1 (f / form-01
                  :ARG0 (a3 / and
                        :op1 (p3 / principle
                              :topic (f2 / fairness))
                        :op2 (a4 / and
                              :op1 (a5 / attend-02
                                    :ARG1-of (c3 / continue-01))
                              :op2 (v / vigilant-01)))
                  :ARG1 (p4 / part
                        :part-of (g / generation
                              :ARG1-of (n3 / new-01)
                              :consist-of (a6 / and
                                    :op1 (p5 / principle)
                                    :op2 (r2 / right-05
                                          :ARG1 (h / human)))
                              :time (a7 / age
                                    :mod (d / digital))
                              :ARG1-of (m2 / mean-01
                                    :ARG2 (o / organize-01
                                          :ARG0 (r3 / right-05
                                                :mod (s2 / system))
                                          :ARG1 (d2 / dimension
                                                :ARG0-of (u / underpin-01
                                                      :ARG1 (w / world
                                                            :mod d
                                                            :poss (w2 / we)))))))))))

# ::snt LAUNCH EVENT ROUNDTABLE SESSIONS  “Algorithms and humans” and “Fairness, transparency and plurality of algorithms” > CNIL SYMPOSIUM  “Towards new forms of humanity?” > Universcience CONFERENCE   “Algorithms and law” > Lille II University CONFERENCE   “The choice in the age of Big Data” > Sciences Po Lille and Visions d’Europe DEBATE  “The governance of emerging technosciences” > German American Conference at Harvard University DEBATE  “Transatlantic perspectives on: AI in the age of social media; privacy,  security and the future of political campaigning” > The Future Society at Harvard Kennedy School ROUNDTABLE SESSIONS  “Big Data, human resources:  algorithms on the agenda” > FO-Cadres CONFERENCE  “Fairness of algorithmic decision-making” > Toulouse III – Paul Sabatier University DEBATE  “Will digital technology spell the end of the rule of law?” > Collège des Bernadins SYMPOSIUM  “Predictive justice” >   Douai Court of Appeal, Lille Association of Lawyers and Law Department of Université Catholique de Lille WORKSHOPS  “Fairness of algorithmic decision-making and processing” > LabEx International Centre for Mathematics and Computer Science in Toulouse23/01/2017 23/03/2017  25/03/2017 31/03/2017 06/04/201708/04/201718/04/2017 18/04/2017 04/05/201716/05/201719/05/201702/06/2017
# File 21

(m / multi-sentence
      :snt1 (p / publication
            :name (n / name
                  :op1 "LAUNCH"
                  :op2 "Event")
            :mod (r / roundtable))
      :snt2 (p2 / publication
            :name (n2 / name
                  :op1 "Lille"
                  :op2 "II"
                  :op3 "University"
                  :op4 "Conference"))
      :snt3 (p3 / publication
            :name (n3 / name
                  :op1 "The"
                  :op2 "Future"
                  :op3 "Society")
            :mod (s / school
                  :name (n4 / name
                        :op1 "Harvard"
                        :op2 "Kennedy"
                        :op3 "School")))
      :snt4 (p4 / publication
            :name (n5 / name
                  :op1 "F-Cadres"
                  :op2 "Conference"))
      :snt5 (p5 / publication
            :name (n6 / name
                  :op1 "The"
                  :op2 "Governorship"
                  :op3 "of"
                  :op4 "Technosciences")
            :mod (c / country
                  :name (n7 / name
                        :op1 "Germany")))
      :snt6 (p6 / publication
            :name (n8 / name
                  :op1 "Towards"
                  :op2 "Form"
                  :op3 "of"
                  :op4 "Humanity")
            :polarity (a / amr-unknown))
      :snt7 (p7 / publication
            :name (n9 / name
                  :op1 "Collège"
                  :op2 "des"
                  :op3 "Bernadins"
                  :op4 "SymposIUM"))
      :snt8 (p8 / publication
            :name (n10 / name
                  :op1 "Predictive"
                  :op2 "Justice")
            :location (c2 / city
                  :name (n11 / name
                        :op1 "Lille")))
      :snt9 (p9 / publication
            :name (n12 / name
                  :op1 "Big"
                  :op2 "Data")
            :topic (a2 / and
                  :op1 (m2 / make-01
                        :ARG1 (t / thing
                              :ARG1-of (d / decide-01)
                              :mod (a3 / algorithm)))
                  :op2 (p10 / process-01
                        :ARG1 t)))
      :snt8 (p11 / publication
            :name (n13 / name
                  :op1 "F-Cadres"
                  :op2 "Conference"))
      :snt9 (p12 / publication
            :name (n14 / name
                  :op1 "The"
                  :op2 "Fairness"
                  :op3 "of"
                  :op4 "Algorithms"))
      :snt10 (p13 / publication
            :name (n15 / name
                  :op1 "Sciences"
                  :op2 "Po"
                  :op3 "Lille"
                  :op4 "and"
                  :op5 "Visions"
                  :op6 "d'Europe")))

# ::snt Key guidance derived from Chapter I:    Develop , deploy and use AI systems  in a way  that adhere s to the ethical principles of : respect for h uman  autonomy, prevention of h arm, fairness and  explicability .
# File 16

(g / guide-01
      :ARG2 (a / and
            :op1 (d / develop-02
                  :ARG1 (s / system
                        :mod (a2 / artificial)))
            :op2 (d2 / deploy-01
                  :ARG1 s)
            :op3 (u / use-01
                  :ARG1 s)
            :manner (w / way
                  :ARG1-of (a3 / adhere-02
                        :ARG2 (p / principle
                              :mod (e / ethics)
                              :example (a4 / and
                                    :op1 (r / respect-01
                                          :ARG1 (a5 / autonomy
                                                :mod (m / man
                                                      :part (a6 / arm))))
                                    :op2 (p2 / prevent-01
                                          :ARG1 a6)
                                    :op3 (f / fairness)
                                    :op4 (e2 / explain-01
                                          :ARG1-of (p3 / possible-01)))))))
      :ARG1-of (d3 / derive-01
            :ARG2 (c / chapter
                  :mod 1))
      :ARG1-of (k / key-02))

# ::snt 12   These are the principles of:   (i) Respect for human a utonomy   (ii) Prevention of harm   (iii) Fairness   (iv) Explicability   Many of the se are to a large extent  already reflected in existing legal requirements  for which mandatory compli ance  is required  and hence also fall  within  the scope of lawful AI, which is  Trustworthy  AI’s first component.26 Yet, as set  out above, while many legal obligations reflect ethical principles, adherence to ethical principles goes beyond formal  compliance with existing laws.27     The p rinciple of respect for human autonomy   The fundamental rights  upon which the EU is founded are directed towards ensuring respect for the freedom and  autonomy of human beings.
# File 16

(m / multi-sentence
      :snt1 (p / principle
            :li 12
            :domain (t / this)
            :example (a / and
                  :op1 (r / respect-01
                        :li "i"
                        :ARG1 (a2 / autonomy
                              :mod (h / human)))
                  :op2 (p2 / prevent-01
                        :li "ii"
                        :ARG1 (h2 / harm-01))
                  :op3 (f / fairness
                        :li "iii")
                  :op4 (p3 / possible-01
                        :li "iv"
                        :ARG1 (e / explain-01))
                  :op5 (e2 / exemplify-01
                        :li 27
                        :ARG1 (p4 / principle
                              :topic (r2 / respect-01
                                    :ARG1 (a3 / autonomy
                                          :mod (h3 / human)))
                              :ARG1-of (m2 / mean-01
                                    :ARG2 (d / direct-01
                                          :ARG1 (r3 / right-05
                                                :mod (f2 / fundamental)
                                                :ARG2-of (f3 / found-01
                                                      :ARG1 (o / organization
                                                            :name (n / name
                                                                  :op1 "EU"))))
                                          :ARG2 (e3 / ensure-01
                                                :ARG1 (r4 / respect-01
                                                      :ARG1 (a4 / and
                                                            :op1 (f4 / free-04
                                                                  :ARG1 (h4 / human))
                                                            :op2 (a5 / autonomy
                                                                  :poss h4))))))))))
      :snt2 (c / contrast-01
            :li 26
            :ARG1 (r5 / reflect-01
                  :ARG1 (o2 / obligate-01
                        :quant (m3 / many))
                  :ARG2 (p5 / principle
                        :mod (e4 / ethics))
                  :degree (e5 / extent
                        :mod (l / large))
                  :time (a6 / already))
            :ARG2 (r6 / reflect-01
                  :ARG1 (o3 / obligate-01
                        :quant (m4 / many))
                  :ARG2 (c2 / comply-01
                        :ARG1 (l2 / law
                              :ARG1-of (e6 / exist-01))
                        :mod (f5 / formal)))
            :ARG0-of (c3 / cause-01
                  :ARG1 (f6 / fall-01
                        :ARG1 o3
                        :ARG4 (s / scope
                              :poss (ii / intelligent-01
                                    :mod (a7 / artificial)
                                    :mod (l3 / lawful)
                                    :ARG1-of (w / worth-02
                                          :ARG2 (t2 / trustworthy))))
                        :mod (a8 / also))))
      :ARG1-of (s2 / set-out-06
            :location (a9 / above)))

# ::snt  The p rinciple of fairness   The development, deployment and use of AI systems must be fair .
# File 16

(p / principle
      :topic (f / fairness)
      :domain (o / obligate-01
            :ARG2 (f2 / fair-01
                  :ARG1 (a / and
                        :op1 (d / develop-02
                              :ARG1 (s / system
                                    :mod (ii / intelligent-01
                                          :mod (a2 / artificial))))
                        :op2 (d2 / deploy-01
                              :ARG1 s)
                        :op3 (u / use-01
                              :ARG1 s)))))

# ::snt While we acknowledge  that there are many  different interpretations of fairness, we believe that f airness has both a substantive and a procedural dimension.
# File 16

(c / contrast-01
      :ARG1 (a / acknowledge-01
            :ARG0 (w / we)
            :ARG1 (ii / interpret-01
                  :ARG1 (f / fairness)
                  :ARG1-of (d / differ-02)
                  :quant (m / many)))
      :ARG2 (b / believe-01
            :ARG0 w
            :ARG1 (h / have-03
                  :ARG0 f
                  :ARG1 (a2 / and
                        :op1 (d2 / dimension
                              :mod (s / substantive))
                        :op2 (d3 / dimension
                              :mod (p / procedure))
                        :mod (b2 / both)))))

# ::snt Additionally, fairness implies that AI  practitioners should respect the principle of proportionality between means and ends, and consider carefully how to                                                                                                                                                                                                                       Fairness is closel y linked to the rights to Non -discrimination, Solidarity and Justice (reflected in Articles 21 and following).
# File 16

(ii / imply-01
      :ARG0 (f / fairness)
      :ARG1 (r / recommend-01
            :ARG1 (a / and
                  :op1 (r2 / respect-01
                        :ARG0 (p / person
                              :ARG0-of (p2 / practice-01
                                    :ARG1 (ii2 / intelligent-01
                                          :mod (a2 / artificial))))
                        :ARG1 (p3 / principle
                              :topic (p4 / proportionality
                                    :mod (b / between
                                          :op1 (m / means)
                                          :op2 (e / end)))))
                  :op2 (c / consider-02
                        :ARG0 p
                        :ARG1 (t / thing
                              :manner-of (r3 / right-05
                                    :ARG2 (a3 / and
                                          :op1 (d / discriminate-02
                                                :polarity -)
                                          :op2 (s / solidarity)
                                          :op3 (j / justice))))
                        :manner (c2 / careful)))
            :ARG1-of (r4 / reflect-01
                  :ARG2 (a4 / and
                        :op1 (a5 / article
                              :mod 21)
                        :op2 (a6 / article
                              :mod 21))))
      :mod (a7 / additional))

# ::snt Additionally, fairness implies that AI  practitioners should respect the principle of proportionality between means and ends, and consider carefully how to                                                                                                                                                                                                                       Fairness is closel y linked to the rights to Non -discrimination, Solidarity and Justice (reflected in Articles 21 and following).
# File 16

(ii / imply-01
      :ARG0 (f / fairness)
      :ARG1 (r / recommend-01
            :ARG1 (a / and
                  :op1 (r2 / respect-01
                        :ARG0 (p / person
                              :ARG0-of (p2 / practice-01
                                    :ARG1 (ii2 / intelligent-01
                                          :mod (a2 / artificial))))
                        :ARG1 (p3 / principle
                              :topic (p4 / proportionality
                                    :mod (b / between
                                          :op1 (m / means)
                                          :op2 (e / end)))))
                  :op2 (c / consider-02
                        :ARG0 p
                        :ARG1 (t / thing
                              :manner-of (r3 / right-05
                                    :ARG2 (a3 / and
                                          :op1 (d / discriminate-02
                                                :polarity -)
                                          :op2 (s / solidarity)
                                          :op3 (j / justice))))
                        :manner (c2 / careful)))
            :ARG1-of (r4 / reflect-01
                  :ARG2 (a4 / and
                        :op1 (a5 / article
                              :mod 21)
                        :op2 (a6 / article
                              :mod 21))))
      :mod (a7 / additional))

# ::snt 13   balance competing interests and objectives.31 The procedural dimension of fairness entails the ability to contest and  seek effective redress against decisions made by AI systems and by the humans operating them.32 In order to do so,  the entity accountable for the decision must be identifiable, and the  decision -making processes should  be  explicable.
# File 16

(m / multi-sentence
      :snt1 (b / balance-01
            :li 13
            :ARG1 (a / and
                  :op1 (ii / interest-01
                        :ARG0-of (c / compete-01))
                  :op2 (o / objective
                        :ARG0-of (c2 / compete-01))))
      :snt2 (e / entail-01
            :li 31
            :ARG0 (d / dimension
                  :mod (p / procedure)
                  :mod (f / fairness))
            :ARG1 (c3 / capable-01
                  :ARG2 (a2 / and
                        :op1 (c4 / contest-01
                              :ARG1 (d2 / decide-01
                                    :ARG0 (a3 / and
                                          :op1 (s / system
                                                :ARG1-of (ii2 / intelligent-01
                                                      :mod (a4 / artificial)))
                                          :op2 (h / human
                                                :ARG0-of (o2 / operate-01
                                                      :ARG1 s)))))
                        :op2 (s2 / seek-01
                              :ARG1 (r / redress-01
                                    :ARG1 d2
                                    :ARG0-of (e2 / effective-04)))))
            :snt3 (o3 / obligate-01
                  :li 32
                  :ARG2 (a5 / and
                        :op1 (ii3 / identify-01
                              :ARG1 (e3 / entity
                                    :ARG0-of (a6 / accountable-02
                                          :ARG1 (d3 / decide-01))))
                        :op2 (e4 / explicate-01
                              :ARG1 (p2 / process-02
                                    :ARG1 (d4 / decide-01))))
                  :purpose (d5 / do-02
                        :ARG1 (s3 / so)))))

# ::snt Key gui dance derived from Chapter I:    Develop, deploy and use AI systems in a way that adheres to  the ethical principles of : respect for human  autonomy, prevention of harm, fairness and explicability.
# File 16

(m / multi-sentence
      :snt1 (d / dance-01
            :ARG1 (g / gui)
            :ARG1-of (d2 / derive-01
                  :ARG2 (c / chapter
                        :mod 1))
            :ARG1-of (k / key-02))
      :snt2 (a / and
            :op1 (d3 / develop-02
                  :ARG1 (s / system
                        :mod (ii / intelligent-01
                              :mod (a2 / artificial))))
            :op2 (d4 / deploy-01
                  :ARG1 s)
            :op3 (u / use-01
                  :ARG1 s)
            :manner (a3 / adhere-02
                  :ARG1 (p / principle
                        :mod (e / ethics)
                        :example (a4 / and
                              :op1 (r / respect-01
                                    :ARG1 (a5 / autonomy
                                          :mod (h / human)))
                              :op2 (p2 / prevent-01
                                    :ARG1 (h2 / harm-01))
                              :op3 (f / fairness)
                              :op4 (p3 / possible-01
                                    :ARG1 (e2 / explain-01)))))))

# ::snt 1.5 Diversity , non -discrimination  and fairness   In order to achieve Trustworthy  AI, we must enable in clusion and diversity throughout the entire AI system’s life  cycle .
# File 16

(m / multi-sentence
      :snt1 (a / and
            :li 1.5
            :op1 (d / diversity)
            :op2 (d2 / discriminate-01
                  :polarity -)
            :op3 (f / fairness))
      :snt2 (o / obligate-01
            :ARG1 (w / we)
            :ARG2 (e / enable-01
                  :ARG0 w
                  :ARG1 (a2 / and
                        :op1 (c / clump-01)
                        :op2 (d3 / diversity))
                  :duration (c2 / cycle-02
                        :ARG1 (l / live-01
                              :ARG0 (s / system
                                    :mod (ii / intelligent-01
                                          :mod (a3 / artificial))))
                        :mod (e2 / entire)))
            :purpose (a4 / achieve-01
                  :ARG0 w
                  :ARG1 (t / trustworthy
                        :domain ii))))

# ::snt 1.6 Societal  and environmental w ell-being   In line with the principles  of fairness and prevention of h arm, the broader society, other sentient beings and the  environment  should be also considered as stakeholders throughout the AI system’s life cycle.
# File 16

(r / recommend-01
      :li 1.6
      :ARG1 (c / consider-02
            :ARG1 (s / stake-01
                  :ARG0 (a / and
                        :op1 (s2 / society)
                        :op2 (b / being
                              :ARG0-of (e / exist-01)
                              :mod (o / other))
                        :op3 (e2 / environment)))
            :ARG2 (p / principle
                  :topic (a2 / and
                        :op1 (f / fairness)
                        :op2 (p2 / prevent-01
                              :ARG1 (a3 / arm))))
            :mod (a4 / also)
            :duration (c2 / cycle
                  :mod (l / life)
                  :poss (s3 / system
                        :ARG1-of (ii / intelligent-01
                              :mod (a5 / artificial))))))

# ::snt 1.7 Accountability    The requirement of  accountability complements the above requirements , and is closely linked to the principle  of  fairness .
# File 16

(a / and
      :li 1.7
      :op1 (c / complement-01
            :ARG0 (r / require-01
                  :ARG1 (a2 / accountable-02))
            :ARG1 (r2 / require-01
                  :location (a3 / above)))
      :op2 (l / link-01
            :ARG1 r
            :ARG2 (p / principle
                  :topic (f / fair-01))
            :ARG1-of (c2 / close-10)))

# ::snt 24   Key guidance derived from Chapter II:    Ensure that the AI system’s entire life cycle meets the seven key requirements for Trustworthy  AI: (1)  human agency and oversight, (2) technical robustness and safety, (3) privacy and data g overnance, (4)  transparency , (5) d iversity , non-discrimination and fairness, (6) environmental and s ocietal well -being and  (7) accountability.
# File 16

(e / ensure-01
      :li 24
      :ARG1 (m / meet-01
            :ARG0 (c / cycle
                  :mod (l / life)
                  :mod (e2 / entire)
                  :poss (s / system
                        :mod (ii / intelligent-01
                              :mod (a / artificial))))
            :ARG1 (r / require-01
                  :quant 7
                  :ARG0 s
                  :ARG1 (a2 / and
                        :op1 (a3 / and
                              :li 1
                              :op1 (a4 / agency
                                    :mod (h / human))
                              :op2 (o / oversee-01
                                    :ARG0 h))
                        :op2 (r2 / robustness
                              :mod (t / technical))
                        :op3 (s2 / safe-01)
                        :op4 (p / privacy
                              :li 3)
                        :op5 (ii2 / integrity
                              :mod (d / data))
                        :op6 (t2 / transparency
                              :li 4)
                        :op7 (a5 / and
                              :li 5
                              :op1 (d2 / discriminate-02
                                    :polarity -)
                              :op2 (f / fairness))
                        :op8 (a6 / and
                              :li 6
                              :op1 (e3 / environment)
                              :op2 (w / well-09
                                    :mod (e4 / ethnicity)))
                        :op9 (a7 / accountable-02
                              :li 7))
                  :ARG1-of (k / key-02)))
      :ARG1-of (d3 / derive-01
            :ARG2 (c2 / chapter
                  :mod 2)))

# ::snt Diversity, non -discrimination and fairness   Unfair bias  avoidance:    Did you establish a strategy or a set of procedures to avoid creating or reinforcing unfair bias in the AI  system, both regarding the use of input data as well as for the algorithm design?
# File 16

(m / multi-sentence
      :snt1 (a / and
            :op1 (d / diversity)
            :op2 (d2 / discriminate-01
                  :polarity -)
            :op3 (f / fairness))
      :snt2 (a2 / avoid-01
            :ARG1 (b / bias-01
                  :ARG1-of (f2 / fair-01
                        :polarity -)))
      :snt3 (e / establish-01
            :ARG0 (y / you)
            :ARG1 (o / or
                  :op1 (s / strategy)
                  :op2 (s2 / set
                        :consist-of (p / procedure)))
            :polarity (a3 / amr-unknown)
            :purpose (a4 / avoid-01
                  :ARG1 (o2 / or
                        :op1 (c / create-01
                              :ARG1 (b2 / bias-01
                                    :ARG1-of (f3 / fair-01
                                          :polarity -))
                              :location (s3 / system
                                    :mod (ii / intelligent-01
                                          :mod (a5 / artificial))))
                        :op2 (r / reinforce-01
                              :ARG1 b2)
                        :topic (a6 / and
                              :op1 (u / use-01
                                    :ARG1 (d3 / data
                                          :mod (ii2 / input)))
                              :op2 (d4 / design-01
                                    :ARG1 (a7 / algorithm)))))))

# ::snt  Did you ensure an adequate working definition of “fairness” that you apply in designing A I systems?
# File 16

(e / ensure-01
      :ARG0 (y / you)
      :ARG1 (t / thing
            :ARG2-of (d / define-01
                  :ARG1 (f / fairness))
            :mod (a / adequate)
            :ARG1-of (w / work-01)
            :ARG1-of (a2 / apply-01
                  :ARG0 y
                  :ARG2 (d2 / design-01
                        :ARG0 y
                        :ARG1 (s / system
                              :mod t
                              :name (n / name
                                    :op1 "A"
                                    :op2 "I")))))
      :polarity (a3 / amr-unknown))

# ::snt  Did you ensure a quantitative analysis or metrics to measure and test the applied definition of  fairness?
# File 16

(e / ensure-01
      :polarity (a / amr-unknown)
      :ARG0 (y / you)
      :ARG1 (o / or
            :op1 (a2 / analyze-01
                  :mod (q / quantitative))
            :op2 (m / metric))
      :purpose (a3 / and
            :op1 (m2 / measure-01
                  :ARG0 y
                  :ARG1 (d / define-01
                        :ARG1 (f / fair-01)
                        :ARG1-of (a4 / apply-02)))
            :op2 (t / test-01
                  :ARG0 y
                  :ARG1 d)))

# ::snt Note that transparency cannot prevent non -discrimination or ensure fairness , and is  not the panacea against  the problem of scoring .
# File 16

(n / note-01
      :mode imperative
      :ARG0 (y / you)
      :ARG1 (a / and
            :op1 (p / possible-01
                  :polarity -
                  :ARG1 (o / or
                        :op1 (p2 / prevent-01
                              :ARG0 (t / transparency)
                              :ARG1 (d / discriminate-02
                                    :polarity -))
                        :op2 (e / ensure-01
                              :ARG0 t
                              :ARG1 (f / fair-01))))
            :op2 (p3 / panacea
                  :polarity -
                  :domain t
                  :prep-against (p4 / problem
                        :topic (s / score-01)))))

# ::snt Now  is the time to establish effective frameworks that embody the technology, practices,  values, and governance of responsible AI, because AI’s wide-ranging impact naturally  raises new questions about AI’s governance, safety, fairness, and effect on equitable  economic opportunities.
# File 102

(c / cause-01
      :ARG0 (r / raise-01
            :ARG0 (ii / impact-01
                  :ARG0 (ii2 / intelligent-01
                        :mod (a / artificial))
                  :ARG1-of (r2 / range-01
                        :ARG2 (w / wide-02)))
            :ARG1 (q / question-01
                  :ARG1 (a2 / and
                        :op1 (g / govern-01
                              :ARG0 ii2)
                        :op2 (s / safe-01)
                        :op3 (f / fairness)
                        :op4 (a3 / affect-01
                              :ARG0 ii2
                              :ARG1 (o / opportunity
                                    :mod (e / economy)
                                    :mod (e2 / equitable))))
                  :ARG1-of (n / new-01))
            :ARG1-of (n2 / natural-03))
      :ARG1 (t / time
            :mod (n3 / now)
            :time-of (e3 / establish-01
                  :ARG1 (f2 / framework
                        :ARG0-of (e4 / effective-04)
                        :ARG0-of (e5 / embody-01
                              :ARG1 (a4 / and
                                    :op1 (t2 / technology)
                                    :op2 (p / practice-01)
                                    :op3 (v / value)
                                    :op4 (g2 / govern-01
                                          :ARG0 ii2)))))))

# ::snt We do so by incorporating responsible practices for fairness, safety, privacy, and  transparency early in developers’ machine learning workflow and throughout the  product development lifecycle.
# File 102

(ii / incorporate-02
      :ARG0 (w / we)
      :ARG1 (p / practice-01
            :ARG1 (a / and
                  :op1 (f / fairness)
                  :op2 (s / safe-01)
                  :op3 (p2 / privacy)
                  :op4 (t / transparency))
            :ARG1-of (r / responsible-02))
      :time a
      :op1 (e / early
            :op1 (w2 / workflow
                  :mod (l / learn-01
                        :ARG0 (p3 / person
                              :ARG0-of (d / develop-02))
                        :instrument (m / machine))))
      :op2 (t2 / throughout
            :op1 (l2 / lifecycle
                  :mod (d2 / develop-02
                        :ARG1 (p4 / product))))
      :manner (s2 / so))

# ::snt They identify global fairness, harms, and human rights related concerns while stress  testing AI-enabled products.
# File 102

(ii / identify-01
      :ARG0 (t / they)
      :ARG1 (c / concern-01
            :ARG1-of (r / relate-01
                  :ARG2 (a / and
                        :op1 (f / fairness
                              :mod (g / globe))
                        :op2 (h / harm-01)
                        :op3 (r2 / right-05
                              :ARG1 (h2 / human)))))
      :time (s / stress-02
            :ARG0 (t2 / test-01
                  :ARG1 (p / product
                        :ARG1-of (e / enable-01
                              :ARG0 (ii2 / intelligent-01
                                    :mod (a2 / artificial)))))))

# ::snt They also supplement the work of the ProFair (“product  fairness ”) team,20 which also sits within our central AI Principles operations team.
# File 102

(s / supplement-01
      :li 20
      :ARG0 (t / they)
      :ARG1 (w / work-01
            :ARG0 (t2 / team
                  :name (n / name
                        :op1 "ProFair")
                  :ARG1-of (m / mean-01
                        :ARG2 (f / fairness
                              :mod (p / product)))
                  :ARG1-of (s2 / sit-01
                        :ARG2 (t3 / team
                              :mod (c / central)
                              :ARG0-of (o / operate-01)
                              :poss (w2 / we)
                              :poss (p2 / principle
                                    :name (n2 / name
                                          :op1 "AI")))
                        :mod (a / also))))
      :mod (a2 / also))

# ::snt 11 2022 AI Principles Progress UpdateThe Approach The researchers applied for an AI Principles review of their dataset and proactively  requested fairness testing.
# File 102

(m / multi-sentence
      :snt1 (u / update-02
            :ARG1 (t / thing
                  :name (n / name
                        :op1 "AI"
                        :op2 "Principles"))
            :time (d / date-entity
                  :year 2022
                  :month 11)
            :ARG1-of (p / progress-01))
      :snt2 (a / approach-02)
      :snt3 (a2 / and
            :op1 (a3 / apply-01
                  :ARG0 (p2 / person
                        :ARG0-of (r / research-01))
                  :ARG1 (r2 / review-01
                        :ARG1 (d2 / dataset
                              :poss p2)
                        :mod (p3 / principle
                              :mod (ii / intelligent-01
                                    :mod (a4 / artificial)))))
            :op2 (r3 / request-01
                  :ARG0 p2
                  :ARG1 (t2 / test-01
                        :ARG1 (f / fairness))
                  :manner (p4 / proactive))))

# ::snt The Approach But how do we categorize the continuous spectrum of skin tones from all around the  world into meaningful categories that work for evaluating and addressing fairness
# File 102

(c / contrast-01
      :ARG2 (c2 / categorize-01
            :ARG0 (w / we)
            :ARG1 (s / spectrum
                  :consist-of (t / tone
                        :mod (s2 / skin))
                  :ARG1-of (c3 / continue-01)
                  :source (a / around
                        :op1 (w2 / world)
                        :mod (a2 / all)))
            :ARG2 (c4 / category
                  :ARG0-of (w3 / work-01
                        :ARG1 (a3 / and
                              :op1 (e / evaluate-01
                                    :ARG1 (f / fairness))
                              :op2 (a4 / address-02
                                    :ARG1 f)))
                  :ARG0-of (m / meaningful-05))
            :manner (a5 / amr-unknown))
      :topic (a6 / approach-02))

# ::snt In order to validate the Monk Skin Tone Scale for ML purposes, researchers working on  skin tone fairness in Google Research launched a study within the U.S. that’s now under  peer review.
# File 102

(l / launch-01
      :ARG0 (p / person
            :ARG0-of (r / research-01
                  :ARG1 (f / fair-01
                        :ARG1 (t / tone
                              :mod (s / skin)))
                  :location (c / company
                        :name (n / name
                              :op1 "Google"
                              :op2 "Research"))))
      :ARG1 (s2 / study-01
            :location (c2 / country
                  :name (n2 / name
                        :op1 "U.S."))
            :ARG1-of (r2 / review-01
                  :ARG0 (p2 / peer)
                  :time (n3 / now)))
      :purpose (v / validate-01
            :ARG0 p
            :ARG1 (s3 / scale
                  :name (n4 / name
                        :op1 "Monk"
                        :op2 "Skin"
                        :op3 "Tone"
                        :op4 "Scale"))
            :purpose (t2 / thing
                  :name (n5 / name
                        :op1 "ML"))))

# ::snt The study’s goal was to understand how well participants across diverse  communities felt their own skin tone was represented within the scale, helping to identify  whether ML fairness efforts with this categorization could uncover and address potential  biases faced across populations.
# File 102

(a / and
      :op1 (h / have-purpose-91
            :ARG1 (s / study-01)
            :ARG2 (u / understand-01
                  :ARG0 s
                  :ARG1 (t / thing
                        :manner-of (f / feel-01
                              :ARG0 (p / person
                                    :ARG0-of (p2 / participate-01)
                                    :location (a2 / across
                                          :op1 (c / community
                                                :mod (d / diverse)))
                                    :part (t2 / tone
                                          :mod (s2 / skin)))
                              :ARG1 (r / represent-01
                                    :ARG1 t2
                                    :ARG2 (s3 / scale))))))
      :op2 (h2 / help-01
            :ARG0 s
            :ARG1 (ii / identify-01
                  :ARG0 s
                  :ARG1 (t3 / truth-value
                        :polarity-of (p3 / possible-01
                              :ARG1 (a3 / and
                                    :op1 (u2 / uncover-01
                                          :ARG0 (e / effort-01
                                                :ARG1 (f2 / fair-01
                                                      :ARG1 p
                                                      :ARG0-of (h3 / have-org-role-91
                                                            :ARG2 (d2 / doctor
                                                                  :mod (m / medicine)))))
                                          :instrument (c2 / categorize-01
                                                :mod (t4 / this)))
                                    :ARG1 (b / bias-01
                                          :mod (p4 / potential)
                                          :ARG1-of (f3 / face-01
                                                :ARG0 (p5 / population))))
                              :op2 (a4 / address-02
                                    :ARG0 e
                                    :ARG1 b))))))

# ::snt ML fairness40 evaluations prevent common human  biases from inadvertently getting reproduced by ML algorithms.
# File 102

(p / prevent-01
      :ARG0 (e / evaluate-01
            :ARG1 (f / fairness
                  :mod (p2 / product
                        :name (n / name
                              :op1 "ML"))))
      :ARG1 (r / reproduce-01
            :ARG0 (a / algorithm
                  :mod p2)
            :ARG1 (b / bias-01
                  :ARG1 (h / human)
                  :mod (c / common))
            :manner (ii / inadvertent)))

# ::snt To improve CV systems’ understanding of skin tones  and improve ML fairness evaluation, we’re open-sourcing the MST.
# File 102

(s / source-01
      :ARG0 (w / we)
      :ARG1 (t / thing
            :name (n / name
                  :op1 "MST"))
      :ARG1-of (o / open-04)
      :purpose (a / and
            :op1 (ii / improve-01
                  :ARG0 w
                  :ARG1 (u / understand-01
                        :ARG0 (s2 / system
                              :mod (t2 / thing
                                    :name (n2 / name
                                          :op1 "CV")))
                        :ARG1 (t3 / tone
                              :mod (s3 / skin))))
            :op2 (ii2 / improve-01
                  :ARG0 w
                  :ARG1 (e / evaluate-01
                        :ARG1 (f / fairness
                              :mod (t4 / thing
                                    :name (n3 / name
                                          :op1 "ML")))))))

# ::snt We encourage ML fairness  researchers, developers, and our users to offer feedback41 on how we can improve the  scale and develop our ML models responsibly, in line with Google’s AI Principles.
# File 102

(e / encourage-01
      :li 41
      :ARG0 (w / we)
      :ARG1 (a / and
            :op1 (p / person
                  :ARG0-of (r / research-01
                        :ARG1 (f / fairness
                              :mod (m / machine
                                    :ARG1-of (ii / intelligent-01)))))
            :op2 (p2 / person
                  :ARG0-of (d / develop-02))
            :op3 (p3 / person
                  :ARG0-of (u / use-01)
                  :poss w))
      :ARG2 (o / offer-01
            :ARG0 a
            :ARG1 (f2 / feedback
                  :topic (a2 / and
                        :op1 (p4 / possible-01
                              :ARG1 (ii2 / improve-01
                                    :ARG0 w
                                    :ARG1 (s / scale-01
                                          :ARG1 (m2 / model
                                                :mod (m3 / machine
                                                      :ARG1-of (ii3 / intelligent-01))
                                                :poss w))))
                        :op2 (d2 / develop-02
                              :ARG0 w
                              :ARG1 m2
                              :ARG1-of (ii4 / in-line-04
                                    :ARG2 (p5 / principle
                                          :poss (c / company
                                                :name (n / name
                                                      :op1 "Google"))
                                          :topic (ii5 / intelligent-01
                                                :mod (a3 / artificial)))))
                        :ARG1-of (r2 / responsible-02)))))

# ::snt We’ve found that creating this space can help engineers and product managers create  a mental model for how, when, and why other AI ethics resources, such as technical  tools or consultations on fairness, can help, and to support a team culture of ethical  decision making.
# File 102

(f / find-01
      :ARG0 (w / we)
      :ARG1 (p / possible-01
            :ARG1 (h / help-01
                  :ARG0 (c / create-01
                        :ARG1 (s / space
                              :mod (t / this)))
                  :ARG1 (c2 / create-01
                        :ARG0 (a / and
                              :op1 (p2 / person
                                    :ARG0-of (e / engineer-01))
                              :op2 (p3 / person
                                    :ARG0-of (m / manage-01
                                          :ARG1 (p4 / product))))
                        :ARG1 (m2 / model
                              :mod (m3 / mind)
                              :topic (a2 / and
                                    :op1 (t2 / thing
                                          :manner-of (p5 / possible-01
                                                :ARG1 (h2 / help-01
                                                      :ARG0 (r / resource
                                                            :mod (e2 / ethics)
                                                            :mod (o / other)
                                                            :mod (a3 / artificial)
                                                            :example (o2 / or
                                                                  :op1 (t3 / tool
                                                                        :mod (t4 / technical))
                                                                  :op2 (c3 / consult-01
                                                                        :ARG2 (f2 / fairness)))))))
                                    :op2 (t5 / thing
                                          :time-of p5)
                                    :op3 (t6 / thing
                                          :ARG0-of (c4 / cause-01
                                                :ARG1 p5))
                                    :op4 (s2 / support-01
                                          :ARG0 r
                                          :ARG1 (c5 / culture
                                                :mod (t7 / team)
                                                :topic (m4 / make-01
                                                      :ARG1 (d / decide-01
                                                            :mod (e3 / ethics))))))))
                  :ARG2 a)))

# ::snt For example, health-related AI  applications, such as those that help medical specialists in diagnosing disease, might  raise questions of potential fairness, privacy, or other concerns.
# File 102

(e / exemplify-01
      :ARG0 (p / possible-01
            :ARG1 (r / raise-01
                  :ARG0 (a / application
                        :ARG1-of (r2 / relate-01
                              :ARG2 (h / health))
                        :mod (ii / intelligent-01
                              :mod (a2 / artificial))
                        :example (t / that
                              :ARG0-of (h2 / help-01
                                    :ARG1 (d / diagnose-01
                                          :ARG0 (p2 / person
                                                :ARG0-of (s / specialize-01
                                                      :mod (m / medicine)))
                                          :ARG1 (d2 / disease))
                                    :ARG2 p2)))
                  :ARG1 (q / question-01
                        :ARG1 (o / or
                              :op1 (f / fairness)
                              :op2 (p3 / privacy)
                              :op3 (c / concern-01
                                    :mod (o2 / other))
                              :mod (p4 / potential))))))

# ::snt Reviews spanned across large language models, datasets, community  responsibility, content quality, and region-specific fairness issues in India, among other  topics.
# File 102

(s / span-01
      :ARG0 (r / review-01)
      :ARG1 (a / and
            :op1 (m / model
                  :mod (l / language
                        :mod (l2 / large)))
            :op2 (d / dataset)
            :op3 (r2 / responsible-03
                  :ARG1 (c / community))
            :op4 (q / quality
                  :mod (c2 / content))
            :op5 (ii / issue-02
                  :ARG0 (f / fairness)
                  :ARG1-of (s2 / specific-02
                        :ARG2 (r3 / region))
                  :location (c3 / country
                        :name (n / name
                              :op1 "India")))
            :op6 (t / topic
                  :mod (o / other))))

# ::snt ProFair’s AI Principles consultations with product teams this year have explored  potential fairness issues in models and products that utilize text and image generation,  person and object detection, and classification functions for teams across Google.
# File 102

(e / explore-01
      :ARG0 (c / consult-01
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "ProFair"))
            :ARG1 (t / team
                  :mod (p / product))
            :ARG2 (p2 / principle
                  :mod (ii / intelligent-01
                        :mod (a / artificial)))
            :time (y / year
                  :mod (t2 / this)))
      :ARG1 (ii2 / issue-02
            :ARG0 (f / fair-01)
            :ARG1 (a2 / and
                  :op1 (m / model)
                  :op2 (p3 / product)
                  :ARG0-of (u / utilize-01
                        :ARG1 (a3 / and
                              :op1 (g / generate-01
                                    :ARG1 (a4 / and
                                          :op1 (t3 / text)
                                          :op2 (ii3 / image)))
                              :op2 (d / detect-01
                                    :ARG1 (a5 / and
                                          :op1 (p4 / person)
                                          :op2 (o2 / object)))
                              :op3 (f2 / function-01
                                    :ARG1 (c2 / classify-01)))
                        :beneficiary (t4 / team
                              :location (a6 / across
                                    :op1 (c3 / company
                                          :name (n2 / name
                                                :op1 "Google"))))))
            :mod (p5 / potential)))

# ::snt For datasets and models, the consistent outcome is to create and publish detailed  documentation of datasets and models in the form of structured transparency artifacts  known as data and model cards (see the following section for details), which function  like nutrition labels, providing information such as the provenance of the data (if a data  card) and model performance when tested for fairness (if a model card).
# File 102

(o / outcome
      :ARG1-of (c / consistent-02)
      :topic (a / and
            :op1 (d / dataset)
            :op2 (m / model))
      :domain (a2 / and
            :op1 (c2 / create-01
                  :ARG1 (d2 / document-01
                        :ARG1 (a3 / and
                              :op1 (d3 / dataset)
                              :op2 (m2 / model))
                        :ARG1-of (d4 / detail-01)))
            :op2 (p / publish-01
                  :ARG1 d2)
            :mod (f / form
                  :mod (a4 / artifact
                        :mod (t / transparency)
                        :ARG1-of (s / structure-01)
                        :ARG1-of (k / know-02
                              :ARG2 (a5 / and
                                    :op1 (c3 / card
                                          :mod (d5 / data))
                                    :op2 (c4 / card
                                          :mod (m3 / model))))
                        :ARG0-of (f2 / function-01
                              :ARG1 (p2 / provide-01
                                    :ARG0 a4
                                    :ARG1 (ii / information
                                          :example (a6 / and
                                                :op1 (p3 / prove-01
                                                      :ARG1 (h / history
                                                            :poss (d6 / data))
                                                      :condition (c5 / card
                                                            :mod (d7 / data)))
                                                :op2 (p4 / perform-02
                                                      :ARG0 (m4 / model)
                                                      :time (t2 / test-01
                                                            :ARG2 (f3 / fair-01)
                                                            :condition c5))))))))
            :ARG1-of (s2 / see-01
                  :mode imperative
                  :ARG0 (y / you)
                  :ARG2 (s3 / section
                        :ARG1-of (f4 / follow-01))
                  :purpose (d8 / detail-01))))

# ::snt We are taking a careful  approach with LaMDA to consider valid concerns about fairness, factuality, and  anthropomorphization  (the tendency for humans to see human traits in inanimate
# File 102

(a / approach-02
      :ARG0 (w / we)
      :ARG1 (c / consider-02
            :ARG0 w
            :ARG1 (c2 / concern-01
                  :ARG0 (a2 / and
                        :op1 (f / fairness)
                        :op2 (f2 / factuality)
                        :op3 (a3 / anthropomorphize-01
                              :ARG1-of (m / mean-01
                                    :ARG2 (t / tend-02
                                          :ARG1 (h / human)
                                          :ARG2 (s / see-01
                                                :ARG0 h
                                                :ARG1 (t2 / trait
                                                      :mod (h2 / human))
                                                :location (a4 / animate
                                                      :polarity -))))))
                  :ARG1-of (v / valid-02)))
      :ARG1-of (c3 / care-04)
      :accompanier (o / organization
            :name (n / name
                  :op1 "LaMDA")))

# ::snt Responsible AI Research Our researchers continue to present at leading conferences around the world, including  the Computer Vision and Pattern Recognition conference ( CVPR), the Association for  Computing Machinery Fairness, Accountability, and Transparency ( FAccT) conference,  the Conference on Neural Information and Processing Systems ( NeurIPS ), and more.
# File 102

(c / continue-01
      :ARG0 (p / person
            :ARG0-of (r / research-01
                  :ARG1 (ii / intelligent-01
                        :mod (a / artificial))
                  :ARG1-of (r2 / responsible-01))
            :poss (w / we))
      :ARG1 (p2 / present-01
            :ARG0 p
            :ARG2 (c2 / conference
                  :ARG0-of (l / lead-01)
                  :location (a2 / around
                        :op1 (w2 / world))
                  :ARG2-of (ii2 / include-91
                        :ARG1 (a3 / and
                              :op1 (c3 / conference
                                    :name (n / name
                                          :op1 "Computer"
                                          :op2 "Vision"
                                          :op3 "and"
                                          :op4 "Pattern"
                                          :op5 " Recognition"
                                          :op6 "Conference"))
                              :op2 (c4 / conference
                                    :name (n2 / name
                                          :op1 "Association"
                                          :op2 "for"
                                          :op3 "Computer"
                                          :op4 "Machinery"
                                          :op5 "Fairness"
                                          :op6 ","
                                          :op7 "Accountability"
                                          :op8 "and"
                                          :op9 "Transparency"))
                              :op3 (c5 / conference
                                    :name (n3 / name
                                          :op1 "Conference"
                                          :op2 "on"
                                          :op3 "Neural"
                                          :op4 "Information"
                                          :op5 "and"
                                          :op6 "Processing"
                                          :op7 "Systems"))
                              :op4 (m / more))))))

# ::snt In 2022, we published 166 papers, on notable topics such as achieving robustness48  and trustworthiness in large-scale ML models,49 maintaining fairness in real-world uses  of ML,50 bringing impacted communities into AI research and development,51 ensuring  that AI is culturally competent,52 and enabling new approaches to prototyping humancentered AI.53 Adversarial testing In lockstep with Google’s central operations team and processes for AI Principles  reviews and governance as described in the previous section, our research teams  often begin the RAI evaluation process of their technical work early in the product  development lifecycle and the ML workflow, using adversarial testing — stress testing a  model or product to probe it for errors and harms.
# File 102

(m / multi-sentence
      :snt1 (p / publish-01
            :ARG0 (w / we)
            :ARG1 (p2 / paper
                  :quant 166
                  :topic (t / topic
                        :ARG1-of (n / notable-04)
                        :example (a / and
                              :op1 (a2 / achieve-01
                                    :li 48
                                    :ARG1 (a3 / and
                                          :op1 (r / robustness)
                                          :op2 (w2 / worth-02
                                                :ARG1 (m2 / model
                                                      :mod (l / large-scale)
                                                      :mod (t2 / thing
                                                            :name (n2 / name
                                                                  :op1 "ML"))))))
                              :op2 (m3 / maintain-01
                                    :li 49
                                    :ARG1 (f / fairness)
                                    :topic (u / use-01
                                          :ARG1 t2
                                          :mod (w3 / world
                                                :ARG1-of (r2 / real-04))))
                              :op3 (b / bring-01
                                    :li 50
                                    :ARG1 (c / community
                                          :ARG1-of (ii / impact-01))
                                    :ARG2 (a4 / and
                                          :op1 (r3 / research-01
                                                :ARG1 t2)
                                          :op2 (d / develop-02
                                                :ARG1 t2)))
                              :op4 (e / ensure-01
                                    :li 51
                                    :ARG1 (c2 / competent-01
                                          :ARG1 t2
                                          :mod (c3 / culture)))
                              :op5 (e2 / enable-01
                                    :li 53
                                    :ARG1 (a5 / approach-02
                                          :ARG1 (p3 / prototype-01
                                                :ARG1 t2)))))))
      :time (d2 / date-entity
            :year 2022)
      :snt2 (b2 / begin-01
            :li 53
            :ARG0 (t3 / team
                  :ARG0-of (r4 / research-01)
                  :poss (w4 / we))
            :ARG1 (p4 / process-02
                  :ARG1 (e3 / evaluate-01
                        :ARG0 t3
                        :ARG1 (w5 / work-01
                              :ARG0 t3
                              :mod (t4 / technical)))
                  :ARG1-of (r5 / resemble-01
                        :ARG2 (a6 / and
                              :op1 (p5 / process-02
                                    :ARG1 (r6 / review-01
                                          :ARG1 (t5 / thing
                                                :name (n3 / name
                                                      :op1 "AI"
                                                      :op2 "Principles"))))
                              :op2 (p6 / process-02
                                    :ARG1 (g / govern-01
                                          :ARG1 t5))
                              :ARG1-of (d3 / describe-01
                                    :ARG0 (s / section
                                          :time (p7 / previous)))))))
      :frequency (o / often)
      :manner u
      :ARG0 t3
      :ARG1 (t6 / test-01
            :manner (a7 / adversarial)
            :ARG1-of (m4 / mean-01
                  :ARG2 (t7 / test-01
                        :ARG1 (o2 / or
                              :op1 (m5 / model)
                              :op2 (p8 / product)))
                  :ARG2 (p9 / probe-01
                        :ARG1 o2
                        :ARG2 (a8 / and
                              :op1 (e4 / err-01)
                              :op2 (h / harm-01))))))

# ::snt This year, we integrated the Model Remediation library ,55 which provides techniques  for addressing bias and fairness issues in models, into our internal ML platform for  automating common ML workflows across the company; it is also available publicly.
# File 102

(m / multi-sentence
      :snt1 (ii / integrate-01
            :ARG0 (w / we)
            :ARG1 (l / library
                  :mod 55
                  :name (n / name
                        :op1 "Model"
                        :op2 "Remediation")
                  :ARG0-of (p / provide-01
                        :ARG1 (t / technique
                              :instrument-of (a / address-02
                                    :ARG1 (ii2 / issue-02
                                          :ARG0 (a2 / and
                                                :op1 (b / bias-01)
                                                :op2 (f / fairness)))
                                    :ARG2 (m2 / model)))))
            :ARG2 (p2 / platform
                  :mod (t2 / thing
                        :name (n2 / name
                              :op1 "ML"))
                  :ARG1-of (ii3 / internal-02)
                  :poss w
                  :purpose (a3 / automate-01
                        :ARG0 w
                        :ARG1 (f2 / flow-01
                              :ARG1 t2
                              :ARG1-of (s / share-01
                                    :ARG0 (c / company)))))
            :time (y / year
                  :mod (t3 / this)))
      :snt2 (a4 / available-02
            :ARG2 (ii4 / it)
            :ARG1-of (p3 / public-02)
            :mod (a5 / also)))

# ::snt Our dataset generation projects include: • Building a new image dataset centering on a diverse representation of subjects for  internal product fairness testing and development • Creating internal synthetic datasets, built with privacy top of mind and with an  emphasis on photographs that are inclusive • Creating an externally available Wikipedia dataset to help avoid unfair gender bias Understanding context Our emerging best practices for responsible AI require a clear articulation of the broader  societal context into which the technology may be deployed.
# File 102

(m / multi-sentence
      :snt1 (ii / include-01
            :ARG1 (a / and
                  :op1 (b / build-01
                        :ARG1 (d / dataset
                              :mod (ii2 / image)
                              :ARG1-of (n / new-01)
                              :ARG0-of (c / center-01
                                    :ARG2 (r / representation-02
                                          :ARG1 (s / subject)
                                          :mod (d2 / diverse))
                                    :purpose (a2 / and
                                          :op1 (t / test-01
                                                :ARG1 (f / fair-01
                                                      :ARG1 (p / product)))
                                          :op2 (d3 / develop-02
                                                :ARG1 p)
                                          :ARG1-of (ii3 / internal-02)))))
                  :op2 (c2 / create-01
                        :ARG1 (d4 / dataset
                              :mod (s2 / synthetic)
                              :ARG1-of (ii4 / internal-02)
                              :ARG1-of (b2 / build-01
                                    :manner (t2 / top-of-mind))
                              :ARG0-of (e / emphasize-01
                                    :ARG1 (p2 / photograph-01
                                          :ARG0-of ii
                                          :ARG2 p2))))))
      :op3 (c3 / create-01
            :ARG1 (d5 / dataset
                  :ARG2-of (a3 / available-02
                        :mod (e2 / external))
                  :mod (p3 / publication
                        :name (n2 / name
                              :op1 "Wikipedia")))
            :purpose (h / help-01
                  :ARG0 d5
                  :ARG1 (a4 / avoid-01
                        :ARG1 (b3 / bias-01
                              :ARG1 (g / gender)
                              :ARG1-of (f2 / fair-01
                                    :polarity -)))))
      :snt2 (u / understand-01
            :ARG1 (c4 / context))
      :snt3 (r2 / require-01
            :ARG0 (p4 / practice-01
                  :ARG0 (w / we)
                  :ARG1 (ii5 / intelligent-01
                        :mod (a5 / artificial)
                        :ARG1-of (r3 / responsible-02))
                  :ARG0-of (e3 / emerge-02))
            :ARG1 (a6 / articulate-01
                  :ARG1 (c5 / context
                        :mod (s3 / society)
                        :ARG1-of (h2 / have-degree-91
                              :ARG2 (b4 / broad-02
                                    :ARG1 c5)
                              :ARG3 (m2 / more)))
                  :ARG1-of (c6 / clear-06))
            :ARG1-of (p5 / possible-01)))

# ::snt We continue to create new programs to address emerging challenges in fairness.
# File 102

(c / continue-01
      :ARG0 (w / we)
      :ARG1 (c2 / create-01
            :ARG0 w
            :ARG1 (p / program
                  :ARG1-of (n / new-01))
            :purpose (a / address-02
                  :ARG0 p
                  :ARG1 (c3 / challenge-01
                        :ARG0-of (e / emerge-02))
                  :manner (f / fairness))))

# ::snt We expressed our support  for the initiative and shared recommendations, including to clarify the roles of different  stakeholders in the AI value chain, expand on the distinction between fairness and unfair  bias, and determine how the NIST framework can be integrated with other standards and  frameworks.
# File 102

(e / express-01
      :ARG0 (w / we)
      :ARG1 (s / support-01
            :ARG0 w
            :ARG1 (a / and
                  :op1 (ii / initiative)
                  :op2 (r / recommend-01
                        :ARG1-of (s2 / share-01)
                        :ARG2-of (ii2 / include-01
                              :ARG1 (a2 / and
                                    :op1 (c / clarify-10
                                          :ARG1 (r2 / role
                                                :poss (s3 / stake-01
                                                      :ARG2 (c2 / chain
                                                            :mod (v / value
                                                                  :mod (a3 / artificial)))
                                                      :ARG1-of (d / differ-02))))
                                    :op2 (e2 / expand-01
                                          :ARG1 (d2 / distinguish-01
                                                :ARG1 (f / fairness)
                                                :ARG2 (b / bias-01
                                                      :ARG1-of (f2 / fair-01
                                                            :polarity -))))
                                    :op3 (d3 / determine-01
                                          :ARG1 (t / thing
                                                :manner-of (p / possible-01
                                                      :ARG1 (ii3 / integrate-01
                                                            :ARG1 (f3 / framework
                                                                  :mod (o / organization
                                                                        :name (n / name
                                                                              :op1 "NIST")))
                                                            :ARG2 (a4 / and
                                                                  :op1 (s4 / standard)
                                                                  :op2 (f4 / framework)
                                                                  :mod (o2 / other))))))))))))

# ::snt For example, to identify potential fairness  considerations, the Photos and Assistant product teams, and researchers working on  generative AI including Imagen, Parti, and the AI Test Kitchen, have participated in  the Equitable AI Research Roundtable  (EARR).119 This program offers the opportunity  to identify potential fairness considerations with a group of experts from the Othering  and Belonging Institute at UC Berkeley; PolicyLink; Ed Trust West; University of Texas,  Austin; and Emory University School of Law early in the product development lifecycle.
# File 102

(p / participate-01
      :li 119
      :ARG0 (a / and
            :op1 (t / team
                  :name (n / name
                        :op1 "Photos"
                        :op2 "and"
                        :op3 "Assistant")
                  :mod (p2 / product))
            :op2 (p3 / person
                  :ARG0-of (r / research-01
                        :ARG1 (ii / intelligent-01
                              :mod (a2 / artificial)
                              :mod (g / generative)))
                  :ARG2-of (ii2 / include-91
                        :ARG1 (a3 / and
                              :op1 (c / company
                                    :name (n2 / name
                                          :op1 "Imagen"))
                              :op2 (c2 / company
                                    :name (n3 / name
                                          :op1 "Parti"))
                              :op3 (o / organization
                                    :name (n4 / name
                                          :op1 "AI"
                                          :op2 "Test"
                                          :op3 "Kitchen"))))))
      :ARG1 (o2 / organization
            :name (n5 / name
                  :op1 "Equitable"
                  :op2 "AI"
                  :op3 "Research"
                  :op4 "Roundtable"))
      :purpose (ii3 / identify-01
            :ARG0 a
            :ARG1 (c3 / consider-02
                  :ARG1 (f / fairness)
                  :mod (p4 / potential))
            :accompanier (g2 / group
                  :consist-of (p5 / person
                        :ARG0-of (h / have-org-role-91
                              :ARG1 (a4 / and
                                    :op1 (r2 / research-institute
                                          :name (n6 / name
                                                :op1 "Othering"
                                                :op2 "and"
                                                :op3 "Belonging"
                                                :op4 "Institute")
                                          :location (u / university
                                                :name (n7 / name
                                                      :op1 "UC"
                                                      :op2 "Berkeley")))
                                    :op2 (r3 / research-institute
                                          :name (n8 / name
                                                :op1 "PolicyLink"))
                                    :op3 (o3 / organization
                                          :name (n9 / name
                                                :op1 "Ed"
                                                :op2 "Trust"
                                                :op3 "West"))
                                    :op4 (u2 / university
                                          :name (n10 / name
                                                :op1 "University"
                                                :op2 "of"
                                                :op3 "Texas")
                                          :location (c4 / city
                                                :name (n11 / name
                                                      :op1 "Austin")))
                                    :op5 (s / school
                                          :name (n12 / name
                                                :op1 "Emory"
                                                :op2 "University"
                                                :op3 "School"
                                                :op4 "of"
                                                :op5 "Law"))))))
            :time (e / early
                  :op1 (l / lifecycle
                        :mod (d / develop-02
                              :ARG1 (p6 / product)))))
      :ARG1-of (e2 / exemplify-01))

# ::snt 39 2022 AI Principles Progress UpdateEnd Notes 1. https://blog.google/technology/ai/join-us-in-the-ai-test-kitchen/ 2. https://blog.google/products/translate/24-new-languages/ 3. https://blog.google/technology/health/advancing-genomics-better-understand-and-treatdisease/ 4. https://blog.google/technology/health/check-up-ai-developments-2022/ 5. https://www.wired.com/story/hurricane-ian-destroyed-homes-google-algorithms-sent-money/ 6. https://www.iso.org/committee/6794475.html 7. https://www.nist.gov/itl/ai-risk-management-framework 8. https://www.pdpc.gov.sg/Help-and-Resources/2020/01/Model-AI-Governance-Framework 9. https://www.mas.gov.sg/schemes-and-initiatives/veritas 10. https://www.niti.gov.in/sites/default/files/2022-11/Ai_for_All_2022_02112022_0.pdf 11. https://www.justice.gc.ca/eng/csj-sjc/pl/charter-charte/c27_1.html#:~:text=In%20 addition%2C%20the%20Artificial%20Intelligence,with%20other%20government%20 entities%20specified 12. https://www.camara.leg.br/proposicoesWeb/prop_ mostrarintegra?codteor=1853928&filename=PL-21-2020 13. https://www.msit.go.kr/bbs/view.do?sCode=eng&mId=10&mPid=9&bbsSeqNo=46&nttSeqNo=9 14. https://www.whitehouse.gov/ostp/news-updates/2021/10/22/icymi-wired-opinion-americansneed-a-bill-of-rights-for-an-ai-powered-world/ 15. https://www.gov.uk/guidance/data-ethics-and-ai-guidance-landscape 16. https://www.gov.il/en/departments/news/most-news20221117 17. https://www.ft.com/content/3467659a-386d-11ea-ac3c-f68c10993b04 18. https://blog.google/technology/ai/crossword-puzzle-big-purpose/ 19. https://blog.google/technology/ai/an-update-on-our-work-in-responsibleinnovation/#:~:text=moral%20imagination%20workshop 20. https://blog.google/inside-google/googlers/meet-3-women-who-test-google-productsfairness/ 21. https://parti.research.google/ 22. https://imagen.research.google/
# File 102

(m / multi-sentence
      :snt1 (u / url-entity
            :value "https://www.whitehouse.gov/technology/ai/join-us-in-the-ai-test-kitchen/.html")
      :snt2 (u2 / url-entity
            :value "https://www.google/technology/ai/crossword-puzzle-big-purpose/.html")
      :snt3 (u3 / url-entity
            :value "https://www.google/inside-google/googlers/meet-3-women-who-test-google-products.html")
      :snt4 (u4 / url-entity
            :value "https://www.google/ostp/news-updates/2021/10/22/icymi-wired-opinion-americans.html")
      :snt5 (u5 / url-entity
            :value "https://www.msit.gov/committee/6794475.html")
      :snt6 (u6 / url-entity
            :value "https://www.google/technology/ai/an-update-on-our-work-in-responsibleinnovation.html")
      :snt7 (u7 / url-entity
            :value "https://www.google/wordpress.com/content/3467659a-386d-11ea-charter-charte/c27_1.html")
      :snt8 (u8 / url-entity
            :value "https://www.google/wordpress.com/sites/default/files/2022-11/Ai_for_All_2022_0.html")
      :snt9 (u9 / url-entity
            :value "https://www.google/wordpress.com/sites/default/files/2022-11/Ai_for_most-news.html"))

# ::snt https://translate.google.com/ 24. https://storage.googleapis.com/gresearch/translate-gender-challenge-sets/Readme.html 25. https://ai.google/principles/ 26. https://en.wikipedia.org/wiki/Wikipedia:Biographies_of_living_persons 27. https://storage.googleapis.com/gresearch/translate-gender-challenge-sets/Readme.html 28. https://ai.googleblog.com/2021/06/a-dataset-for-studying-gender-bias-in.html 29. https://storage.googleapis.com/gresearch/translate-gender-challenge-sets/Data%20Card.pdf 30. https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf 31. http://gendershades.org/ 32. https://openaccess.thecvf.com/content/CVPR2021W/RCV/papers/Hazirbas_Casual_ Conversations_A_Dataset_for_Measuring_Fairness_in_AI_CVPRW_2021_paper.pdf 33. https://www.ncbi.nlm.nih.gov/books/NBK481857/table/chapter6.t1/ 34. https://ieeexplore.ieee.org/abstract/document/9590512 35. https://direct.mit.edu/daed/article/150/2/76/98313/The-Unceasing-Significance-of-ColorismSkin-Tone 36. https://www.journals.uchicago.edu/doi/abs/10.1086/682162 37. https://scholar.harvard.edu/files/monk/files/monk_-_the_consequences_of_race_and_color_in_ brazil_-_sp.pdf 38. https://www.norc.org/Pages/default.aspx 39. https://skintone.google/get-started 40. https://developers.google.com/machine-learning/crash-course/fairness/video-lecture 41. https://google.qualtrics.com/jfe/form/SV_eFJF7qguvcWvdFs 42. https://blog.google/technology/ai/join-us-in-the-ai-test-kitchen/l 43. https://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html 44. https://arxiv.org/abs/2201.08239 45. https://dynamicworld.app/explore/ 46. https://io.google/2022/program/385b422e-3a08-4372-8ed3-4e79bafb779a/ 47. https://www.bsr.org/en/ 48. https://arxiv.org/abs/2110.07858
# File 102

(h / hyperlink-91
      :ARG3 (u / url-entity
            :value "https://www.google.com/2022/01/lamda-towards-safe-grounded-and-high.html")
      :ARG4 (u2 / url-entity
            :value "https://www.google.com/2021/06/a-dataset-for-studying-gender-bias-in.html"))

# ::snt https://translate.google.com/ 24. https://storage.googleapis.com/gresearch/translate-gender-challenge-sets/Readme.html 25. https://ai.google/principles/ 26. https://en.wikipedia.org/wiki/Wikipedia:Biographies_of_living_persons 27. https://storage.googleapis.com/gresearch/translate-gender-challenge-sets/Readme.html 28. https://ai.googleblog.com/2021/06/a-dataset-for-studying-gender-bias-in.html 29. https://storage.googleapis.com/gresearch/translate-gender-challenge-sets/Data%20Card.pdf 30. https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf 31. http://gendershades.org/ 32. https://openaccess.thecvf.com/content/CVPR2021W/RCV/papers/Hazirbas_Casual_ Conversations_A_Dataset_for_Measuring_Fairness_in_AI_CVPRW_2021_paper.pdf 33. https://www.ncbi.nlm.nih.gov/books/NBK481857/table/chapter6.t1/ 34. https://ieeexplore.ieee.org/abstract/document/9590512 35. https://direct.mit.edu/daed/article/150/2/76/98313/The-Unceasing-Significance-of-ColorismSkin-Tone 36. https://www.journals.uchicago.edu/doi/abs/10.1086/682162 37. https://scholar.harvard.edu/files/monk/files/monk_-_the_consequences_of_race_and_color_in_ brazil_-_sp.pdf 38. https://www.norc.org/Pages/default.aspx 39. https://skintone.google/get-started 40. https://developers.google.com/machine-learning/crash-course/fairness/video-lecture 41. https://google.qualtrics.com/jfe/form/SV_eFJF7qguvcWvdFs 42. https://blog.google/technology/ai/join-us-in-the-ai-test-kitchen/l 43. https://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html 44. https://arxiv.org/abs/2201.08239 45. https://dynamicworld.app/explore/ 46. https://io.google/2022/program/385b422e-3a08-4372-8ed3-4e79bafb779a/ 47. https://www.bsr.org/en/ 48. https://arxiv.org/abs/2110.07858
# File 102

(h / hyperlink-91
      :ARG3 (u / url-entity
            :value "https://www.google.com/2022/01/lamda-towards-safe-grounded-and-high.html")
      :ARG4 (u2 / url-entity
            :value "https://www.google.com/2021/06/a-dataset-for-studying-gender-bias-in.html"))

# ::snt https://arxiv.org/pdf/2205.05256.pdf 50. https://arxiv.org/pdf/2202.01034.pdf 51. https://dl.acm.org/doi/abs/10.1145/3491102.3517716 52. https://ai-cultures.github.io/ 53. https://dl.acm.org/doi/abs/10.1145/3491101.3503564 54. https://www.deepmind.com/publications/red-teaming-language-models-with-language-models 55. https://www.tensorflow.org/responsible_ai/model_remediation 56. https://pair-code.github.io/lit/ 57. https://knowyourdata.withgoogle.com/ 58. https://arxiv.org/abs/2204.02311 59. https://sites.research.google/scouts/ 60. https://jigsaw.google.com/ 61. https://perspectiveapi.com/ 62. https://medium.com/jigsaw/scaling-machine-learning-fairness-with-societal-contextbe73d4ad38e2 63. https://arxiv.org/abs/2202.13028 64. https://github.com/google-research/parti/blob/main/data_cards/fit400m_data_card.pdf 65. https://arxiv.org/abs/2204.02311 66. https://pair-code.github.io/datacardsplaybook/ 67. https://arxiv.org/abs/2201.11903 68. https://aclanthology.org/D19-1221.pdf 69. https://arxiv.org/abs/2205.05638 70. https://arxiv.org/abs/2009.06367 71. https://aclanthology.org/2022.acl-long.72.pdf 72. https://blog.google/technology/ai/an-update-on-our-work-in-responsibleinnovation/#:~:text=an%20internal%20tool%20to%20help%20teams%20assess%20how%20 ml%20models%20were%20developed 73. https://blog.youtube/inside-youtube/inside-responsibility-whats-next-on-our-misinfo-efforts/ 74. https://blog.google/outreach-initiatives/accessibility/look-to-speak-launches-in-ukraine/
# File 102

(m / multi-sentence
      :snt1 (u / url-entity
            :value "https://www.arxiv.org/dot/abs/2202.05256.html")
      :snt2 (u2 / url-entity
            :value "https://arxiv.org/dot/abs/2205.html")
      :snt3 (u3 / url-entity
            :value "https://www.youtube/inside-youtube/inside-responsibility-whats-next-on-our-misinfo-efforts/")
      :snt4 (u4 / url-entity
            :value "https://pair-code.com/58.1145/3491101.pdf")
      :snt5 (u5 / url-entity
            :value "https://arxiv.org/dot/abs/2022.html")
      :snt6 (u6 / url-entity
            :value "https://www.deepmind.com/scouts/62.06367 71.pdf"))

# ::snt ASSESS: Identify and measure AI risks 26  3.1 Benefiting people and the planet  26  3.2 Human -centred values and fairness  27  3.3 Transparency and explainability  32  3.4 Robustness, security, and safety  33  3.5 Interactions and trade -offs between the values -based Principles  34
# File 135

(a / assess-01
      :ARG2 (a2 / and
            :op1 (a3 / and
                  :op1 (ii / identify-01
                        :ARG1 (r / risk-01
                              :mod (ii2 / intelligent-01
                                    :mod (a4 / artificial))))
                  :op2 (m / measure-01
                        :ARG1 r)
                  :li 26)
            :op2 (b / benefit-01
                  :ARG1 (a5 / and
                        :op1 (p / person)
                        :op2 (p2 / planet))
                  :li 26)
            :op3 (a6 / and
                  :op1 (v / value
                        :ARG1-of (c / center-01
                              :ARG2 (h / human)))
                  :op2 (f / fairness)
                  :li 27)
            :op4 (a7 / and
                  :op1 (t / transparency)
                  :op2 (e / explain-01)
                  :li 32)
            :op5 (a8 / and
                  :op1 (s / strong-02)
                  :op2 (s2 / security)
                  :op3 (s3 / safe-01)
                  :li 33)
            :op6 (a9 / and
                  :op1 (ii3 / interact-01)
                  :op2 (t2 / trade-off-02
                        :ARG1 (p3 / principle
                              :ARG1-of (b2 / base-02
                                    :ARG2 (v2 / value))))
                  :li 34)))

# ::snt TREAT: Prevent, mitigate, or cease AI risks  36  4.1 Risks to people and the planet  36  4.2 Risks to human -centred values and fairness  37  4.3 Risks to transparency and explainability  40  4.4 Risks to robustness, security, and safety  42  4.5 Anticipating unknown risks and contingency plans  43  5.
# File 135

(m / multi-sentence
      :snt1 (o / or
            :op1 (p / prevent-01
                  :ARG1 (r / risk-01
                        :ARG2 (ii / intelligent-01
                              :mod (a / artificial))))
            :op2 (m2 / mitigate-01
                  :ARG1 r)
            :op3 (c / cease-01
                  :ARG1 r)
            :ARG1-of (t / treat-03))
      :snt2 (r2 / risk-01
            :ARG2 (a2 / and
                  :op1 (p2 / person)
                  :op2 (p3 / planet))
            :li 36)
      :snt3 (r3 / risk-01
            :ARG2 (a3 / and
                  :op1 (v / value
                        :ARG1-of (c2 / center-01
                              :ARG2 (h / human)))
                  :op2 (f / fairness))
            :li 37)
      :snt4 (r4 / risk-01
            :ARG2 (a4 / and
                  :op1 (t2 / transparency)
                  :op2 (e / explain-01))
            :li 40)
      :snt5 (a5 / anticipate-01
            :ARG1 (a6 / and
                  :op1 (r5 / risk-01
                        :ARG2 (p4 / plan-01
                              :ARG1-of (k / know-01
                                    :polarity -)))
                  :op2 p4
                  :mod (c3 / contingency)))
      :li 43
      :snt6 (r6 / risk-01
            :ARG2 (a7 / and
                  :op1 (r7 / robustness)
                  :op2 (s / security)
                  :op3 (s2 / safe-01))
            :li 42)
      :snt7 (r8 / rate-entity-91
            :ARG1 4.2
            :ARG2 4.3))

# ::snt that they benefit people; respect human rights and fairness; are  transpare nt and explainable; and are robust, secure and safe .
# File 135

(a / and
      :op1 (b / benefit-01
            :ARG0 (t / they)
            :ARG1 (p / person))
      :op2 (r / respect-01
            :ARG0 t
            :ARG1 (a2 / and
                  :op1 (r2 / right-05
                        :ARG1 (h / human))
                  :op2 (f / fairness)))
      :op3 (p2 / possible-01
            :ARG1 (e / explain-01
                  :ARG1 t))
      :op4 (a3 / and
            :op1 (r3 / robust
                  :domain t)
            :op2 (s / secure-02
                  :ARG1 t)
            :op3 (s2 / safe-01
                  :ARG1 t)))

# ::snt Dies  bedeutet, dass die KI -Akteure Maßnahmen ergreifen müssen, um sich erzustellen, dass ihre KI -Systeme  vertrauenswürdig sind, sprich  dass sie de m Mensc h zugutekommen, Menschenrechte und Fairness  achten, sowie transparent , erklärbar , robust, sicher und geschützt sind.
# File 135

(b / bedeutet-00
      :ARG0 (t / this)
      :ARG1 (o / obligate-01
            :ARG2 (e / ergreif-00
                  :ARG0 (o2 / organization
                        :name (n / name
                              :op1 "KI")
                        :ARG0-of (a / administrate-01))
                  :ARG1 (d / demonstrate-01
                        :ARG0 o2
                        :ARG1 (a2 / and
                              :op1 (z / zugutekommen
                                    :domain o2)
                              :op2 (d2 / deserve-01
                                    :ARG0 o2)
                              :op3 (f / fairness)
                              :op4 (t2 / transparent
                                    :domain o2
                                    :op5-of a2)
                              :domain o2)
                        :op6 (r / robust
                              :domain o2)
                        :op7 (s / secure-02
                              :ARG1 o2)
                        :op8 (g / geschützt
                              :domain o2))))
      :purpose (e2 / erzustellen-00
            :ARG0 o2
            :ARG1 (s2 / situation
                  :mod (v / vertrauenswürdig
                        :domain (s3 / system
                              :poss o2)))))

# ::snt • Human -centred values and fairness: the values of human rights, human agency, democracy,  and the rule of law should be incorporated throughout an AI system’s lifecycle, while allowing  human inter vention through safeguard mechanisms.
# File 135

(r / recommend-01
      :ARG1 (ii / incorporate-02
            :ARG1 (a / and
                  :op1 (v / value
                        :ARG1-of (c / center-01
                              :ARG2 (h / human)))
                  :op2 (f / fair-01)
                  :ARG1-of (m / mean-01
                        :ARG2 (a2 / and
                              :op1 (v2 / value
                                    :poss h)
                              :op2 (a3 / agency
                                    :mod h)
                              :op3 (d / democracy)
                              :op4 (r2 / rule-01
                                    :ARG1 (l / law)))))
            :time (t / throughout
                  :op1 (l2 / lifecycle
                        :poss (s / system
                              :ARG1-of (ii2 / intelligent-01
                                    :mod (a4 / artificial)))))
            :concession (a5 / allow-01
                  :ARG1 (e / enter-01
                        :ARG0 h)
                  :manner (m2 / mechanism
                        :mod (s2 / safeguard)))))

# ::snt The OECD AI Principles recognise the potential risks2 AI systems pose to human rights, privacy, fairness,  and equality; robustness and safety; and the need to address these, such as by building transparen cy,  accountability, and security into AI systems and enabling continuous monitoring and improvement.
# File 135

(r / recognize-02
      :ARG0 (p / principle
            :topic (ii / intelligent-01
                  :mod (a / artificial))
            :mod (o / organization
                  :name (n / name
                        :op1 "OECD")))
      :ARG1 (a2 / and
            :op1 (r2 / risk-01
                  :ARG0 (s / system
                        :quant 2
                        :mod (ii2 / intelligent-01))
                  :ARG2 (a3 / and
                        :op1 (r3 / right-05
                              :ARG1 (h / human))
                        :op2 (p2 / privacy)
                        :op3 (f / fairness)
                        :op4 (e / equal-01)
                        :op5 (r4 / robustness)
                        :op6 (s2 / safe-01))
                  :mod (p3 / potential))
            :op2 (n2 / need-01
                  :ARG1 (a4 / address-02
                        :ARG1 r2
                        :example (a5 / and
                              :op1 (b / build-02
                                    :ARG1 (a6 / and
                                          :op1 (t / transparency
                                                :mod (c / circuit
                                                      :ARG1-of (c2 / close-01)))
                                          :op2 (a7 / accountable-02)
                                          :op3 (s3 / security))
                                    :ARG2 s)
                              :op2 (e2 / enable-01
                                    :ARG1 (a8 / and
                                          :op1 (m / monitor-01
                                                :ARG1-of (c3 / continue-01))
                                          :op2 (ii3 / improve-01
                                                :ARG1-of (c4 / continue-01)))))))))

# ::snt For example, treating risks to  human rights, values, and fairness (e.g .
# File 135

(e / exemplify-01
      :ARG0 (t / treat-01
            :ARG1 (r / risk-01
                  :ARG2 (a / and
                        :op1 (r2 / right-05
                              :ARG1 (h / human))
                        :op2 (v / value
                              :poss h)
                        :op3 (f / fairness
                              :poss h)))
            :example (a2 / amr-unknown)))

# ::snt Sample uses of the high -level AI risk management interoperability framework   a) Treating risks to human  rights  and fairness during  deployment  b) Monitoring risks to robustness, security, and  safety in data collection and processing        The following sections illustrate the use of the  high-level AI risk management interoperability framework  to  define (Section 2), assess (Section 3), treat (Section 4), and govern (Section 5) AI risks.
# File 135

(ii / illustrate-01
      :ARG0 (s / section
            :ARG1-of (f / follow-04))
      :ARG1 (u / use-01
            :ARG1 (f2 / framework
                  :name (n / name
                        :op1 "Interoperability"
                        :op2 "Framework")
                  :purpose (m / manage-01
                        :ARG1 (r / risk-01
                              :mod (ii2 / intelligent-01
                                    :mod (a / artificial))))
                  :mod (l / level
                        :ARG1-of (h / high-02)))
            :ARG2 (a2 / and
                  :op1 (t / treat-03
                        :li "a"
                        :ARG1 (r2 / risk-01
                              :ARG2 (a3 / and
                                    :op1 (r3 / right-05
                                          :ARG1 (h2 / human))
                                    :op2 (f3 / fairness)))
                        :time (d / deploy-01))
                  :op2 (m2 / monitor-01
                        :li "b"
                        :ARG1 (r4 / risk-01
                              :ARG2 (a4 / and
                                    :op1 (r5 / robustness)
                                    :op2 (s2 / security)
                                    :op3 (s3 / safe-01)
                                    :location (a5 / and
                                          :op1 (c / collect-01
                                                :ARG1 (d2 / data))
                                          :op2 (p / process-01
                                                :ARG1 d2))))))
            :ARG2 (a6 / and
                  :op1 (d3 / define-01
                        :li 2
                        :ARG1 f2)
                  :op2 (a7 / assess-01
                        :li 3
                        :ARG1 f2)
                  :op3 (t2 / treat-03
                        :li 4
                        :ARG1 f2)
                  :op4 (g / govern-01
                        :li 5
                        :ARG1 f2))))

# ::snt Characterist ics of the team that builds, tests, and assesses performance across various  dimensions and considerations of an AI system – such as gender, country, and cultural background – have  been shown to impact the fairness of the system’s outputs, as developers can  incorporate unconscious  biases (Freire, 2021).
# File 135

(s / show-01
      :ARG1 (ii / impact-01
            :ARG0 (a / and
                  :op1 (p / personality
                        :ARG0-of (c / characterize-01
                              :ARG1 (t / team
                                    :ARG0-of (b / build-01)
                                    :ARG0-of (t2 / test-01
                                          :ARG1 (p2 / perform-02))
                                    :ARG0-of (a2 / assess-01
                                          :ARG1 p2))))
                  :op2 (c2 / consider-02
                        :ARG1 (a3 / and
                              :op1 (d / dimension
                                    :mod (v / various))
                              :op2 (b2 / background
                                    :mod (c3 / culture))
                              :example (a4 / and
                                    :op1 (g / gender)
                                    :op2 (c4 / country)
                                    :op3 b2))
                        :poss (s2 / system
                              :mod (ii2 / intelligent-01
                                    :mod (a5 / artificial)))))
            :ARG1 (f / fair-01
                  :ARG1 (o / output
                        :poss s2)))
      :ARG1-of (c5 / cause-01
            :ARG0 (p3 / possible-01
                  :ARG1 (ii3 / incorporate-02
                        :ARG0 (p4 / person
                              :ARG0-of (d2 / develop-02))
                        :ARG1 (b3 / bias
                              :mod (u / unconscious)))))
      :ARG1-of (d3 / describe-01
            :ARG0 (p5 / publication-91
                  :ARG0 (p6 / person
                        :name (n / name
                              :op1 "Freire"))
                  :time (d4 / date-entity
                        :year 2021))))

# ::snt Sample processes and technical attributes per OECD AI Principle   Principle  Sample processes and technical attributes   Benefiting people and the planet  Performance , energy consumption , environmental impact   Human -centred values and fairness  Bias and discrimination , privacy and data governance   Transparency and explainability  Interpretability, documentation, traceability, disclosure, redress mechanisms  (including the  ability to opt out , when appropriate)   Robustness, security, and safety  Reliabili ty, reproducibility, safety, and vulnerability to tampering   Accountability   Roles and responsibilities , risk management, ongoing processes for continuous  improvement   The next section describes some of these  process es and  technical  attributes  in detail and explores  illustrative tools to assess risks in AI systems.
# File 135

(a / and
      :op1 (a2 / and
            :op1 (s / sample-01
                  :ARG1 (a3 / and
                        :op1 (p / process-02)
                        :op2 (a4 / attribute-01
                              :mod (t / technical)))
                  :ARG1-of (s2 / say-01
                        :ARG0 (p2 / principle
                              :mod (o / organization
                                    :name (n / name
                                          :op1 "OECD")))))
            :op2 s
            :ARG1 (p3 / process-02)
            :mod (t2 / technical))
      :op3 (b / benefit-01
            :ARG1 (a5 / and
                  :op1 (p4 / person)
                  :op2 (p5 / planet)))
      :op4 (p6 / perform-02)
      :op5 (c / consume-01
            :ARG1 (e / energy))
      :op6 (ii / impact-01
            :ARG1 (e2 / environment))
      :op7 (a6 / and
            :op1 (v / value
                  :ARG1-of (c2 / center-01
                        :ARG2 (h / human)))
            :op2 (f / fairness))
      :op8 (a7 / and
            :op1 (b2 / bias-01)
            :op2 (d / discriminate-02)
            :op3 (p7 / privacy)
            :op4 (g / govern-01
                  :ARG1 (d2 / data)))
      :op9 (a8 / and
            :op1 (t3 / transparency)
            :op2 (e3 / explain-01)
            :op10 (d3 / documentation)
            :op11 (t4 / trace-02)
            :op12 (d4 / disclose-01)
            :op13 (m / mechanism
                  :ARG0-of (r / redress-01))
            :ARG2-of (ii2 / include-01
                  :ARG1 (c3 / capable-01
                        :ARG2 (o2 / opt-01
                              :ARG1 (o3 / out-06)
                              :condition (a9 / appropriate-02)))))
      :op10 (a10 / and
            :op1 (r2 / robustness)
            :op2 (s3 / security)
            :op3 (s4 / safe-01)
            :op4 (p8 / possible-01
                  :ARG1 (r3 / reproduce-01))
            :op5 (s5 / safe-01)
            :op6 (v2 / vulnerable-01
                  :ARG2 (t5 / tamper-01)))
      :op7 (a11 / accountable-02)
      :op8 (m2 / manage-01
            :ARG1 (r4 / risk-01))
      :op9 (p9 / process-02
            :ARG1 (ii3 / improve-01
                  :ARG1-of (c4 / continue-01)))
      :mod (t6 / this)
      :op2 (a12 / attribute-01
            :mod (t7 / technical))
      :op2 (d5 / describe-01
            :ARG0 (s6 / section
                  :mod (n2 / next))
            :ARG1 (t8 / tool
                  :ARG0-of (ii4 / illustrate-01)
                  :purpose (a13 / assess-01
                        :ARG1 (r5 / risk-01
                              :ARG1 (s7 / system
                                    :mod (ii5 / intelligent-01
                                          :mod (a14 / artificial))))))))

# ::snt 3.2 Human -centred values and fairness   AI should be developed based on  human -centred values, including human rights, fundamental freedoms,  equality, fairness, the rule of law, social justice, data protection and privacy, and consum er rights and  commercial fairness (OECD, 2022 [20]).
# File 135

(r / recommend-01
      :li 3
      :ARG1 (d / develop-02
            :ARG1 (ii / intelligent-01
                  :mod (a / artificial))
            :ARG1-of (b / base-02
                  :ARG2 (v / value
                        :ARG1-of (c / center-01
                              :ARG2 (h / human))
                        :ARG2-of (ii2 / include-01
                              :ARG1 (a2 / and
                                    :op1 (r2 / right-05
                                          :ARG1 h)
                                    :op2 (f / free-04
                                          :mod (f2 / fundamental))
                                    :op3 (e / equal-01)
                                    :op4 (f3 / fair-01)
                                    :op5 (r3 / rule-03
                                          :ARG1 (l / law))
                                    :op6 (j / justice
                                          :mod (s / social))
                                    :op7 (p / protect-01
                                          :ARG1 (a3 / and
                                                :op1 (d2 / data)
                                                :op2 (p2 / privacy)))
                                    :op8 (f4 / fair-01
                                          :mod (c2 / commerce)))))))
      :ARG1-of (d3 / describe-01
            :ARG0 (p3 / publication-91
                  :ARG0 (o / organization
                        :name (n / name
                              :op1 "OECD"))
                  :time (d4 / date-entity
                        :year 2022))))

# ::snt “human -in-the-loop” approaches), codes of  ethical conduct, and quality labels and certifications play a role in promoting human -centred values and  fairness (OECD, 2022 [20]).
# File 135

(p / play-02
      :ARG0 (a / and
            :op1 (a2 / approach-02
                  :mod (h / human
                        :location (l / loop)))
            :op2 (c / code-01
                  :ARG1 (c2 / conduct-02
                        :ARG1 (e / ethics)))
            :op3 (a3 / and
                  :op1 (l2 / label-01
                        :mod (q / quality))
                  :op2 (c3 / certify-01
                        :mod q)))
      :ARG1 (p2 / promote-02
            :ARG0 a
            :ARG1 (a4 / and
                  :op1 (v / value
                        :ARG1-of (c4 / center-01
                              :ARG2 (h2 / human)))
                  :op2 (f / fairness)))
      :ARG1-of (d / describe-01
            :ARG0 (p3 / publication-91
                  :ARG0 (o / organization
                        :name (n / name
                              :op1 "OECD"))
                  :time (d2 / date-entity
                        :year 2022)
                  :ARG1-of (c5 / cite-01
                        :ARG2 20))))

# ::snt Fairness implies that AI can and should empower all members of society and help reduce  biases  and exclusion .
# File 135

(ii / imply-01
      :ARG0 (f / fairness)
      :ARG1 (a / and
            :op1 (p / possible-01
                  :ARG1 (e / empower-01
                        :ARG0 (ii2 / intelligent-01
                              :mod (a2 / artificial))
                        :ARG1 (m / member
                              :mod (s / society)
                              :mod (a3 / all))))
            :op2 (r / recommend-01
                  :ARG1 e
                  :ARG2 ii2)
            :op3 (h / help-01
                  :ARG0 ii2
                  :ARG1 (r2 / reduce-01
                        :ARG1 (a4 / and
                              :op1 (b / bias-01)
                              :op2 (e2 / exclude-01))))))

# ::snt Different stakeholders have different perspectives on fairness and equity, and, as socio -technical systems,  AI applications require expertise beyond that of technologists.
# File 135

(a / and
      :op1 (h / have-03
            :ARG0 (s / stake
                  :ARG1-of (d / differ-02))
            :ARG1 (p / perspective
                  :ARG1-of (d2 / differ-02)
                  :topic (a2 / and
                        :op1 (f / fairness)
                        :op2 (e / equity))))
      :op2 (r / require-01
            :ARG0 (a3 / apply-02
                  :ARG1 (ii / intelligent-01
                        :mod (a4 / artificial)))
            :ARG1 (e2 / expertise
                  :mod (b / beyond
                        :op1 (e3 / expertise
                              :poss (t / technologist))))
            :prep-as (s2 / system
                  :mod (t2 / technical
                        :mod (s3 / society)))))

# ::snt To diagnose and mitigate biases in AI, it is  important to differentiate between indi vidual and group -level fairness (OECD, 2022 [20]).
# File 135

(ii / important-01
      :ARG1 (d / differentiate-01
            :ARG1 (f / fairness
                  :mod (s / subjective)
                  :mod (ii2 / independent))
            :ARG2 (f2 / fairness
                  :mod (l / level
                        :mod (g / group))))
      :purpose (a / and
            :op1 (d2 / diagnose-01
                  :ARG1 (b / bias-01
                        :ARG0 (a2 / artificial)))
            :op2 (m / mitigate-01
                  :ARG1 b))
      :ARG1-of (d3 / describe-01
            :ARG0 (p / publication-91
                  :ARG0 (o / organization
                        :name (n / name
                              :op1 "OECD"))
                  :time (d4 / date-entity
                        :year 2022)
                  :ARG1-of (c / cite-01
                        :ARG2 20))))

# ::snt Individual fairness   means that similar individuals should be treated similarly; and group fairness  means that the outcomes of  an AI system should not vary if the population is sp lit into groups (e.g .
# File 135

(a / and
      :op1 (m / mean-01
            :ARG1 (f / fairness
                  :mod (ii / individual))
            :ARG2 (r / recommend-01
                  :ARG1 (t / treat-01
                        :ARG1 ii
                        :ARG1-of (r2 / resemble-01))))
      :op2 (m2 / mean-01
            :ARG1 (f2 / fairness
                  :mod (g / group))
            :ARG2 (r3 / recommend-01
                  :ARG1 (v / vary-01
                        :polarity -
                        :ARG1 (o / outcome
                              :poss (s / system
                                    :mod (ii2 / intelligent-01
                                          :mod (a2 / artificial))))
                        :condition (s2 / split-01
                              :ARG1 (p / population)
                              :ARG2 (g2 / group
                                    :example (a3 / amr-unknown)))))))

# ::snt An important strand of literature seeks to implement mathematical fairness metrics to assess a model’s  impartiality towards subgroups (IDB-OECD, 2021 [21]; Chouldechova, 2017 [23]; Kleinberg, Mullainathan and  Raghavan, 2016 [24]; Corbett -Davies et  al., 2017 [25]; Koshiyama et  al., 2021 [26]).
# File 135

(s / seek-01
      :ARG0 (s2 / strand
            :consist-of (l / literature)
            :ARG1-of (ii / important-01))
      :ARG1 (ii2 / implement-01
            :ARG0 s2
            :ARG1 (m / metric
                  :mod (f / fairness
                        :mod (m2 / mathematics)))
            :purpose (a / assess-01
                  :ARG0 s2
                  :ARG1 (ii3 / impartial
                        :domain (m3 / model-01)
                        :beneficiary (s3 / subgroup))))
      :ARG1-of (d / describe-01
            :ARG0 (p / publication-91
                  :ARG0 (o / organization
                        :name (n / name
                              :op1 "IDB-OECD"))
                  :time (d2 / date-entity
                        :year 2021)
                  :ARG1-of (c / cite-01
                        :ARG2 (a2 / and
                              :op1 (p2 / publication
                                    :name (n2 / name
                                          :op1 "Chouldechova")
                                    :time (d3 / date-entity
                                          :year 2017))
                              :op2 (p3 / publication
                                    :name (n3 / name
                                          :op1 "Kleinberg"
                                          :op2 "Mullainathan"
                                          :op3 "and"
                                          :op4 "Raghavan")
                                    :time (d4 / date-entity
                                          :year 2016)
                                    :ARG1-of (c2 / cite-01
                                          :ARG2 23))
                              :op3 (p4 / publication
                                    :name (n4 / name
                                          :op1 "Corbett-Davies"
                                          :op2 "and"
                                          :op3 "Al."
                                          :op4 "2017")
                                    :ARG1-of (c3 / cite-01
                                          :ARG2 25))
                              :op4 (p5 / publication
                                    :name (n5 / name
                                          :op1 "Koshiyama"
                                          :op2 "and"
                                          :op3 "Al."
                                          :op4 "2021")))))))

# ::snt Different fairness  metrics   lead to varying ways to assess bias in a system.
# File 135

(l / lead-03
      :ARG0 (m / metric
            :topic (f / fair-01)
            :ARG1-of (d / differ-02))
      :ARG2 (w / way
            :ARG1-of (v / vary-01)
            :manner-of (a / assess-01
                  :ARG1 (b / bias-01)
                  :location (s / system))))

# ::snt The decision about which AI fairness metric to use shoul d consider the context, and its rationale should be  documented (IDB-OECD, 2021 [21]).
# File 135

(r / recommend-01
      :ARG1 (d / document-01
            :ARG1 (a / and
                  :op1 (c / consider-02
                        :ARG0 (d2 / decide-01
                              :ARG3 (m / metric
                                    :mod (f / fairness
                                          :mod (a2 / artificial))
                                    :ARG1-of (u / use-01)))
                        :ARG1 (c2 / context))
                  :op2 (r2 / rationale
                        :poss d2)))
      :ARG1-of (d3 / describe-01
            :ARG0 (p / publication-91
                  :ARG0 (o / organization
                        :name (n / name
                              :op1 "IDB-OECD"))
                  :ARG1-of (c3 / cite-01
                        :ARG2 21)
                  :time (d4 / date-entity
                        :year 2021))))

# ::snt In practice, no single AI fairness measure works for all problems and  complying with one definition usually means not fully complying with the o thers (Chouldechova, 2017 [23]).
# File 135

(a / and
      :op1 (w / work-09
            :polarity -
            :ARG1 (m / measure-02
                  :ARG1 (f / fair-01
                        :mod (a2 / artificial))
                  :ARG1-of (s / single-02))
            :ARG2 (p / problem
                  :mod (a3 / all))
            :ARG1-of (p2 / practice-01))
      :op2 (m2 / mean-01
            :ARG1 (c / comply-01
                  :ARG1 (t / thing
                        :ARG2-of (d / define-01)
                        :quant 1))
            :ARG2 (c2 / comply-01
                  :polarity -
                  :ARG1 (t2 / thing
                        :ARG0-of (w2 / wrong-04))
                  :degree (f2 / full))
            :mod (u / usual))
      :ARG1-of (d2 / describe-01
            :ARG0 (p3 / publication-91
                  :ARG0 (p4 / person
                        :name (n / name
                              :op1 "Chouldechova"))
                  :time (d3 / date-entity
                        :year 2017)
                  :ARG1-of (c3 / cite-01
                        :ARG2 23))))

# ::snt Therefore, complying with a given definition of fairness might not guarantee that the outcomes of an AI  system are fair.
# File 135

(c / cause-01
      :ARG1 (p / possible-01
            :ARG1 (g / guarantee-01
                  :polarity -
                  :ARG0 (c2 / comply-01
                        :ARG1 (t / thing
                              :ARG2-of (d / define-01
                                    :ARG1 (f / fair-01))
                              :ARG1-of (g2 / give-01)))
                  :ARG1 (f2 / fair-01
                        :ARG1 (o / outcome
                              :poss (s / system
                                    :mod (ii / intelligent-01
                                          :mod (a / artificial))))))))

# ::snt  Fairness vs. p erformance : The trade -off between fairness/bias and performance is the subject  of significant debate (Feldman et  al., 2015 [66]; Kleinberg, Mullainathan and Raghavan, 2016 [24];  Zafar et  al., 2019 [67]).
# File 135

(s / subject
      :topic-of (d / debate-01
            :ARG1 (t / trade-off-02
                  :ARG1 (f / fairness)
                  :ARG2 (b / bias-01)
                  :ARG3 (p / perform-02))
            :ARG1-of (s2 / significant-02))
      :topic (p2 / perform-02)
      :ARG1-of (d2 / describe-01
            :ARG0 (a / and
                  :op1 (p3 / publication-91
                        :ARG0 (a2 / and
                              :op1 (p4 / person
                                    :name (n / name
                                          :op1 "Feldman"))
                              :op2 (p5 / person
                                    :mod (o / other)))
                        :time (d3 / date-entity
                              :year 2015)
                        :ARG1-of (c / cite-01
                              :ARG2 66))
                  :op2 (p6 / publication-91
                        :ARG0 (a3 / and
                              :op1 (p7 / person
                                    :name (n2 / name
                                          :op1 "Kleinberg"))
                              :op2 (p8 / person
                                    :name (n3 / name
                                          :op1 "Mullainathan"))
                              :op3 (p9 / person
                                    :name (n4 / name
                                          :op1 "Raghavan")))
                        :time (d4 / date-entity
                              :year 2016)
                        :ARG1-of (d5 / describe-01
                              :ARG2 24))
                  :op3 (p10 / publication-91
                        :ARG0 (a4 / and
                              :op1 (p11 / person
                                    :name (n5 / name
                                          :op1 "Zafar"))
                              :op2 (p12 / person
                                    :mod (o2 / other)))
                        :time (d6 / date-entity
                              :year 2019)
                        :ARG1-of (d7 / describe-01
                              :ARG2 67)))))

# ::snt  Fairness vs. p erformance : The trade -off between fairness/bias and performance is the subject  of significant debate (Feldman et  al., 2015 [66]; Kleinberg, Mullainathan and Raghavan, 2016 [24];  Zafar et  al., 2019 [67]).
# File 135

(s / subject
      :topic-of (d / debate-01
            :ARG1 (t / trade-off-02
                  :ARG1 (f / fairness)
                  :ARG2 (b / bias-01)
                  :ARG3 (p / perform-02))
            :ARG1-of (s2 / significant-02))
      :topic (p2 / perform-02)
      :ARG1-of (d2 / describe-01
            :ARG0 (a / and
                  :op1 (p3 / publication-91
                        :ARG0 (a2 / and
                              :op1 (p4 / person
                                    :name (n / name
                                          :op1 "Feldman"))
                              :op2 (p5 / person
                                    :mod (o / other)))
                        :time (d3 / date-entity
                              :year 2015)
                        :ARG1-of (c / cite-01
                              :ARG2 66))
                  :op2 (p6 / publication-91
                        :ARG0 (a3 / and
                              :op1 (p7 / person
                                    :name (n2 / name
                                          :op1 "Kleinberg"))
                              :op2 (p8 / person
                                    :name (n3 / name
                                          :op1 "Mullainathan"))
                              :op3 (p9 / person
                                    :name (n4 / name
                                          :op1 "Raghavan")))
                        :time (d4 / date-entity
                              :year 2016)
                        :ARG1-of (d5 / describe-01
                              :ARG2 24))
                  :op3 (p10 / publication-91
                        :ARG0 (a4 / and
                              :op1 (p11 / person
                                    :name (n5 / name
                                          :op1 "Zafar"))
                              :op2 (p12 / person
                                    :mod (o2 / other)))
                        :time (d6 / date-entity
                              :year 2019)
                        :ARG1-of (d7 / describe-01
                              :ARG2 67)))))

# ::snt  Privacy vs. fairness: A related concern is the trad e-off between privacy and fairness.
# File 135

(c / concern-01
      :ARG0 (o / off
            :mod (t / tradition)
            :mod (b / between
                  :op1 (p / privacy)
                  :op2 (f / fairness)))
      :ARG1-of (r / relate-01)
      :topic (v / versus
            :op1 p
            :op2 f))

# ::snt The  opposite is also true: the greater the level of privacy, the more difficult it can be to scrutinise an AI  system and ensure its fairness.
# File 135

(t / true-01
      :ARG1 (c / correlate-91
            :ARG1 (m / more
                  :ARG3-of (h / have-degree-91
                        :ARG1 (l / level
                              :mod (p / privacy))
                        :ARG2 (g / great)))
            :ARG2 (m2 / more
                  :ARG3-of (h2 / have-degree-91
                        :ARG1 (a / and
                              :op1 (s / scrutinize-01
                                    :ARG1 (s2 / system
                                          :mod (ii / intelligent-01
                                                :mod (a2 / artificial))))
                              :op2 (e / ensure-01
                                    :ARG1 (f / fair-01
                                          :ARG1 s2)))
                        :ARG2 (d / difficult)
                        :ARG1-of (p2 / possible-01))))
      :mod (a3 / also)
      :ARG1-of (o / opposite-01))

# ::snt Kibana, Grafana and Zeppelin (Nurgaliev,  Karavakis and Aimar, 2016 [83])  Understand the expected generalisation  performance of the model on future data,  considering the economic and social context  (Arlot and Celisse, 2010 [17])  4.2 Risks to human -centred values and fairness   Bias and discrimination   Bias should be addressed early in the AI system design and development process , by implementing review  points at each lifecycle phase.
# File 135

(m / multi-sentence
      :snt1 (a / and
            :op1 (b / byline-91
                  :ARG1 (a2 / and
                        :op1 (p / person
                              :name (n / name
                                    :op1 "Kibana"))
                        :op2 (p2 / person
                              :name (n2 / name
                                    :op1 "Grafana"))
                        :op3 (p3 / person
                              :name (n3 / name
                                    :op1 "Zeppelin")))
                  :ARG1-of (d / describe-01
                        :ARG0 (p4 / publication-91
                              :ARG0 (a3 / and
                                    :op1 (p5 / person
                                          :name (n4 / name
                                                :op1 "Nurgaliev"))
                                    :op2 (p6 / person
                                          :name (n5 / name
                                                :op1 "Karavakis"))
                                    :op3 (p7 / person
                                          :name (n6 / name
                                                :op1 "Aimar")))
                              :time (d2 / date-entity
                                    :year 2016)))
                  :ARG1-of (d3 / describe-01
                        :ARG0 (p8 / publication-91
                              :ARG0 (a4 / and
                                    :op1 (p9 / person
                                          :name (n7 / name
                                                :op1 "Arlot"))
                                    :op2 (p10 / person
                                          :name (n8 / name
                                                :op1 "Celisse")))
                              :ARG1-of (c / cite-01
                                    :ARG2 17))))
            :op2 (r / recommend-01
                  :ARG1 (a5 / address-02
                        :ARG1 (r2 / risk-01
                              :ARG2 (a6 / and
                                    :op1 (v / value
                                          :ARG1-of (c2 / center-01
                                                :ARG2 (h / human)))
                                    :op2 (f / fairness)
                                    :op3 (d4 / discriminate-02)))
                        :time (e / early
                              :op1 (p11 / process-02
                                    :ARG1 (a7 / and
                                          :op1 (d5 / design-01
                                                :ARG1 (s / system
                                                      :mod (a8 / artificial)))
                                          :op2 (d6 / develop-02
                                                :ARG1 s))))
                        :manner (ii / implement-01
                              :ARG1 (p12 / point
                                    :mod (r3 / review-01))
                              :time (p13 / phase
                                    :mod (l / lifecycle)
                                    :mod (e2 / each)))))))

# ::snt includ e a variable for the  subject  of interest and simultaneously learn a predictor  and an adversary (Zhang, Lemoine and Mitchell,  2018 [90])   Fairness constraint: e.g .
# File 135

(a / and
      :op1 (ii / include-01
            :ARG1 (v / variable
                  :beneficiary (s / subject
                        :ARG2-of (ii2 / interest-01))
                  :example (l / learn-01
                        :ARG1 (a2 / and
                              :op1 (t / thing
                                    :ARG0-of (p / predict-01))
                              :op2 (t2 / thing
                                    :ARG0-of (o / oppose-01)))
                        :mod (s2 / simultaneous))
                  :ARG1-of (d / describe-01
                        :ARG0 (p2 / publication-91
                              :ARG0 (a3 / and
                                    :op1 (p3 / person
                                          :name (n / name
                                                :op1 "Zhang"))
                                    :op2 (p4 / person
                                          :name (n2 / name
                                                :op1 "Lemoine"))
                                    :op3 (p5 / person
                                          :name (n3 / name
                                                :op1 "Mitchell")))
                              :ARG1-of (c / cite-01
                                    :ARG2 90)
                              :time (d2 / date-entity
                                    :year 2018)))))
      :op2 (c2 / constraint
            :topic (f / fairness)
            :example (t3 / thing
                  :name (n4 / name
                        :op1 "Keynes"))))

# ::snt creat e a measure of decision boundary unfairness as a proxy for bias (Zafar et  al.,  2019 [67]; Donini et  al., 2018 [91])   Counter factual fairness: e.g .
# File 135

(c / create-01
      :ARG1 (m / measure-01
            :ARG1 (f / fairness
                  :polarity -
                  :mod (b / boundary
                        :mod (d / decide-01)))
            :ARG3 (p / proxy
                  :mod (b2 / bias-01))
            :example (a / and
                  :op1 (p2 / publication-91
                        :ARG0 (a2 / and
                              :op1 (p3 / person
                                    :name (n / name
                                          :op1 "Zafar"))
                              :op2 (p4 / person
                                    :mod (o / other)))
                        :time (d2 / date-entity
                              :year 2019)
                        :ARG1-of (c2 / cite-01
                              :ARG2 67))
                  :op2 (p5 / publication-91
                        :ARG0 (a3 / and
                              :op1 (p6 / person
                                    :name (n2 / name
                                          :op1 "Donini"))
                              :op2 (p7 / person
                                    :mod (o2 / other)))
                        :time (d3 / date-entity
                              :year 2018)
                        :ARG1-of (c3 / cite-01
                              :ARG2 91))))
      :ARG0-of (c4 / counter-01
            :ARG1 (f2 / fairness
                  :mod (f3 / fact))
            :example (t / thing
                  :name (n3 / name
                        :op1 "Globe"
                        :op2 "Globe"))))

# ::snt defin e that a decision is  fair towards an individual if it is the same both in the  actual world and in a counterfactual world where the  individual belonged to a different demographic group  (Kusner et  al., 2017 [92])   Remov e of disparate impact when a selection process  has widely different outcomes for different groups,  even as it appears to be neutral (Feldman et  al.,  2015 [66])  Prioritise context over optimisation:   selecting models b ased solely on  accuracy is not the best approach for bias  reduction as context should be considered  (Schwartz et  al., 2021 [54])  Verify and validate   Calibrate equality of odds: minimis e error disparity  across different population groups while maintaining  calibrated probability estimates (Pleiss et  al., 2017 [93])   Classify r eject -option s: instances belonging to deprived  and favored groups are labeled with desirab le and  undesirable labels, respectively (Kamiran and Calders,  2012 [85])  Prevalence at threshold: disentangle  normative questions of product and policy  design from empirical questions of system  implementation (Bakalar, Barreto and  Bergman, 2021 [94])   Create a reference dataset serving as  “ground truth” to AI developers  for testing   (Schwartz et  al., 2021 [54])  Deploy   Process fairness: reduc e the dependency of models on  sensitive features, e.g .
# File 135

(m / multi-sentence
      :snt1 (d / define-01
            :ARG1 (f / fair-01
                  :ARG1 (t / thing
                        :ARG1-of (d2 / decide-01))
                  :ARG2 (ii / individual)
                  :condition (s / same-01
                        :ARG1 t
                        :location (a / and
                              :op1 (w / world
                                    :ARG1-of (a2 / actual-02))
                              :op2 (w2 / world
                                    :mod (c / counterfactual)
                                    :location-of (b / belong-01
                                          :ARG0 (ii2 / individual)
                                          :ARG1 (g / group
                                                :mod (d3 / demography)
                                                :ARG1-of (d4 / differ-02))))))))
      :snt2 (d5 / deploy-01
            :ARG1 (d6 / dataset
                  :ARG0-of (r / reference-04)
                  :ARG0-of (s2 / serve-01
                        :ARG1 (t2 / truth
                              :mod (g2 / ground))
                        :ARG2 (p / person
                              :ARG0-of (d7 / develop-02
                                    :ARG1 (t3 / thing
                                          :ARG1-of (ii3 / intelligent-01)
                                          :mod (a3 / artificial))))
                        :purpose (t4 / test-01
                              :ARG0 p
                              :ARG1 t))))
      :snt3 (h / have-degree-91
            :polarity -
            :ARG1 (a4 / approach-02
                  :ARG1 (r2 / reduce-01
                        :ARG1 (b2 / bias-01))
                  :ARG2 (c2 / context))
            :ARG2 (g3 / good-02)
            :ARG3 (m2 / most))
      :snt4 (r3 / remove-01
            :ARG1 (ii4 / impact-01
                  :mod (d8 / disparate))
            :time (h2 / have-03
                  :ARG0 (p2 / process-02
                        :ARG1 (s3 / select-01))
                  :ARG1 (o / outcome
                        :ARG1-of (d9 / differ-02
                              :degree (w3 / wide))
                        :beneficiary (g4 / group
                              :ARG1-of (d10 / differ-02))))
            :ARG1-of (d11 / describe-01
                  :ARG0 (p3 / publication-91
                        :ARG0 (a5 / and
                              :op1 (p4 / person
                                    :name (n / name
                                          :op1 "Bakalar"))
                              :op2 (p5 / person
                                    :name (n2 / name
                                          :op1 "Barreto"))
                              :op3 (p6 / person
                                    :name (n3 / name
                                          :op1 "Bergman")))
                        :time (d12 / date-entity
                              :year 2021))
                  :ARG1-of (d13 / describe-01
                        :ARG0 (p7 / publication-91
                              :ARG0 (p8 / publication-91
                                    :ARG1 (p9 / publication-91
                                          :ARG0 (p10 / person
                                                :name (n4 / name
                                                      :op1 "Kusner"))
                                          :ARG1-of (d14 / describe-01
                                                :ARG1-of (d15 / describe-01
                                                      :ARG0 (p11 / publication-91
                                                            :ARG1 (d16 / date-entity
                                                                  :year 2021))))
                                          :ARG1-of (c3 / cite-01
                                                :ARG2 (d17 / date-entity
                                                      :ARG2 2012)))
                                    :ARG1-of (c4 / cite-01
                                          :ARG2 (d18 / date-entity
                                                :year 2021)))
                              :ARG1-of (c5 / cite-01
                                    :ARG2 (p12 / publication-91
                                          :ARG1-of (c6 / cite-01
                                                :ARG2 (d19 / date-entity
                                                      :year 2021))))
                              :ARG1-of d14
                              :ARG2 p8
                              :ARG1-of (c7 / cite-01
                                    :ARG2 (d20 / date-entity
                                          :ARG2 2015))
                              :ARG1-of (h3 / have-concession-91
                                    :ARG3 (d21 / date-entity
                                          :ARG2 2017))
                              :ARG1-of (h4 / have-degree-91
                                    :ARG2 g3
                                    :ARG1 a4)
                              :ARG3 (m3 / more)))))
      :snt4 (a6 / and
            :op1 (c8 / calculate-01
                  :ARG1 (e / equal-01
                        :ARG1 (o2 / odds)
                        :ARG2 (r4 / ratio-of
                              :op1 r4
                              :op2 (e2 / error)))
                  :ARG1-of (h5 / have-quant-91
                        :ARG3 (l / less))))
      :op2 (m4 / maintain-01
            :ARG1 e)
      :op2 (c9 / classify-01
            :ARG1 (o3 / opt-01
                  :ARG1 (t5 / thing))))

# ::snt ADVANCING  ACCOUNTABILITY IN A I  39                © OECD 2023     trade -offs exist and privacy -preserving approaches might come at the expense of explainability,  transp arency, and fairness.
# File 135

(a / and
      :op1 (a2 / accelerate-01
            :ARG1 (a3 / accountable-02)
            :ARG1-of (d / describe-01
                  :ARG0 (p / publication
                        :name (n / name
                              :op1 "A"
                              :op2 "I")
                        :ARG1-of (c / cite-01
                              :ARG2 39)
                        :ARG2-of (c2 / copyright-01
                              :ARG0 (o / organization
                                    :name (n2 / name
                                          :op1 "OECD"))
                              :time (d2 / date-entity
                                    :year 2023)))))
      :op2 (e / exist-01
            :ARG1 (t / trade-off-02))
      :op3 (p2 / possible-01
            :ARG1 (c3 / come-04
                  :ARG1 (a4 / approach-02
                        :ARG1 (p3 / preserve-01
                              :ARG1 (p4 / privacy)))
                  :ARG2 (c4 / compromise-02
                        :ARG0 a4
                        :ARG1 (a5 / and
                              :op1 (e2 / explain-01
                                    :ARG1-of p2))
                        :op2 (t2 / transpire-01)
                        :op3 (f / fairness)))))

# ::snt Data drift might decrease the  quality (accuracy, fairness, etc.)
# File 135

(p / possible-01
      :ARG1 (d / decrease-01
            :ARG0 (d2 / drift-01
                  :ARG1 (d3 / data))
            :ARG1 (q / quality
                  :ARG1-of (m / mean-01
                        :ARG2 (a / and
                              :op1 (a2 / accuracy)
                              :op2 (f / fairness)
                              :op3 (e / et-cetera))))))

# ::snt  Fairness,  transparency, explainability , and privacy metrics:  measures of bias according to a  given fairness paradigm (e.g .
# File 135

(a / and
      :op1 (f / fairness)
      :op2 (t / transparency)
      :op3 (e / explain-01
            :ARG1-of (p / possible-01))
      :op4 (m / metric
            :mod (p2 / privacy))
      :ARG1-of (m2 / mean-01
            :ARG2 (m3 / measure-01
                  :ARG1 (b / bias-01)
                  :ARG1-of (c / conform-01
                        :ARG2 (p3 / paradigm
                              :mod (f2 / fairness)
                              :ARG1-of (g / give-14)
                              :example (a2 / amr-unknown))))))

# ::snt  Fairness,  transparency, explainability , and privacy metrics:  measures of bias according to a  given fairness paradigm (e.g .
# File 135

(a / and
      :op1 (f / fairness)
      :op2 (t / transparency)
      :op3 (e / explain-01
            :ARG1-of (p / possible-01))
      :op4 (m / metric
            :mod (p2 / privacy))
      :ARG1-of (m2 / mean-01
            :ARG2 (m3 / measure-01
                  :ARG1 (b / bias-01)
                  :ARG1-of (c / conform-01
                        :ARG2 (p3 / paradigm
                              :mod (f2 / fairness)
                              :ARG1-of (g / give-14)
                              :example (a2 / amr-unknown))))))

# ::snt Ways to present metrics from an AI system’s monitoring and review process include:   ▪ Logs:  basic logging of metrics helps creat e conditional workflows, for example , by setting  thresholds for accuracy or fairness outside of which alerts are triggered and automated or manual  actions taken, such as retraining a model.
# File 135

(ii / include-01
      :ARG1 (a / and
            :op1 (l / log-01)
            :op2 (l2 / log-01
                  :mod (b / basic)
                  :ARG0-of (h / help-01
                        :ARG1 (c / creat-01
                              :ARG1 (f / flow-01
                                    :ARG1-of (c2 / condition-01))
                              :example (a2 / and
                                    :op1 (s / set-02
                                          :ARG1 (t / threshold
                                                :topic (o / or
                                                      :op1 (a3 / accuracy)
                                                      :op2 (f2 / fairness)))
                                          :ARG2 (o2 / outside
                                                :op1 (a4 / and
                                                      :op1 (t2 / trigger-01
                                                            :ARG1 (a5 / alert-01))
                                                      :op2 (o3 / or
                                                            :op1 (a6 / automate-01
                                                                  :ARG1 (a7 / act-02))
                                                            :op2 (a8 / act-02
                                                                  :manner (m / manual))
                                                            :example (r / retrain-01
                                                                  :ARG1 (m2 / model)))))))))))
      :ARG2 (w / way
            :manner-of (p / present-01
                  :ARG1 (m3 / metric
                        :source (a9 / and
                              :op1 (m4 / monitor-01
                                    :ARG0 (s2 / system
                                          :mod (ii2 / intelligent-01
                                                :mod (a10 / artificial))))
                              :op2 (r2 / review-01
                                    :ARG1 s2))))))

# ::snt set by organisations or government agencies with  remits not sector -specific , and encompassing broad areas like privacy, explainability , fairness,  robustness, safety , and security) or  sector -specific  (e.g.
# File 135

(s / set-02
      :ARG0 (o / or
            :op1 (o2 / organization)
            :op2 (a / agency
                  :mod (g / government-organization
                        :ARG0-of (g2 / govern-01)))
            :ARG0-of (h / have-03
                  :ARG1 (r / remit-01
                        :ARG1-of (s2 / specific-02
                              :polarity -
                              :ARG2 (s3 / sector))
                        :ARG0-of (e / encompass-01
                              :ARG1 (a2 / area
                                    :ARG1-of (b / broad-02)
                                    :example (a3 / and
                                          :op1 (p / privacy)
                                          :op2 (e2 / explain-01
                                                :ARG1-of (p2 / possible-01))
                                          :op3 (f / fairness)
                                          :op4 (r2 / robustness)
                                          :op5 (s4 / safe-01)
                                          :op6 (s5 / security)))))))
      :op2 (s6 / sector
            :ARG1-of (s7 / specific-02
                  :example a3)))

# ::snt [64]  Bakalar,  C., R.  Barreto and S.  Bergman (2021), Fairness on the ground: Applying algorithmic  fairness approaches to productio n systems.
# File 135

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Bakalar"))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "C."
                        :op2 "Bakalar"))
            :op3 (p4 / person
                  :name (n3 / name
                        :op1 "R."
                        :op2 "Barreto"))
            :op4 (p5 / person
                  :name (n4 / name
                        :op1 "S."
                        :op2 "Bergman")))
      :ARG1 (p6 / publication
            :name (n5 / name
                  :op1 "Fairness"
                  :op2 "on"
                  :op3 "the"
                  :op4 "ground")
            :ARG1-of (m / mean-01
                  :ARG2 (a2 / apply-02
                        :ARG1 (a3 / approach-02
                              :ARG1 (f / fairness)
                              :mod (a4 / algorithm))
                        :ARG2 (s / system
                              :mod (p7 / productio
                                    :mod (n6 / nation))))))
      :time (d / date-entity
            :year 2021)
      :ARG1-of (c / cite-01
            :ARG2 64))

# ::snt [64]  Bakalar,  C., R.  Barreto and S.  Bergman (2021), Fairness on the ground: Applying algorithmic  fairness approaches to productio n systems.
# File 135

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Bakalar"))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "C."
                        :op2 "Bakalar"))
            :op3 (p4 / person
                  :name (n3 / name
                        :op1 "R."
                        :op2 "Barreto"))
            :op4 (p5 / person
                  :name (n4 / name
                        :op1 "S."
                        :op2 "Bergman")))
      :ARG1 (p6 / publication
            :name (n5 / name
                  :op1 "Fairness"
                  :op2 "on"
                  :op3 "the"
                  :op4 "ground")
            :ARG1-of (m / mean-01
                  :ARG2 (a2 / apply-02
                        :ARG1 (a3 / approach-02
                              :ARG1 (f / fairness)
                              :mod (a4 / algorithm))
                        :ARG2 (s / system
                              :mod (p7 / productio
                                    :mod (n6 / nation))))))
      :time (d / date-entity
            :year 2021)
      :ARG1-of (c / cite-01
            :ARG2 64))

# ::snt (2018), AI Fairness 360: An extensible toolkit for detecting, understanding,  and mitigating unwanted algorithmic bias .
# File 135

(t / toolkit
      :domain (p / product
            :name (n / name
                  :op1 "AI"
                  :op2 "Fairness"
                  :op3 360)
            :time (d / date-entity
                  :year 2018))
      :ARG1-of (e / extend-01
            :ARG1-of (p2 / possible-01))
      :purpose (a / and
            :op1 (d2 / detect-01
                  :ARG1 (b / bias-01
                        :mod (a2 / algorithm)
                        :ARG1-of (w / want-01
                              :polarity -)))
            :op2 (u / understand-01
                  :ARG1 b)
            :op3 (m / mitigate-01
                  :ARG1 b)))

# ::snt [140]  Butterworth,  M. (2018), “The ICO and artificial intelligence: The role of fairness in the GDPR  framework”, Computer Law & Security Review , Vol.
# File 135

(p / publication-91
      :li 140
      :ARG0 (p2 / person
            :name (n / name
                  :op1 "M."
                  :op2 "Butterworth"))
      :ARG1 (p3 / publication
            :name (n2 / name
                  :op1 "The"
                  :op2 "Role"
                  :op3 "of"
                  :op4 "Fairfair"
                  :op5 "in"
                  :op6 "the"
                  :op7 "GDPR"
                  :op8 "Framework"))
      :ARG4 (j / journal
            :name (n3 / name
                  :op1 "Computer"
                  :op2 "Law"
                  :op3 "&"
                  :op4 "Security"
                  :op5 "Review"))
      :time (d / date-entity
            :year 2018))

# ::snt (2017), Algorithmic decision making and the cost of fairness .
# File 135

(a / and
      :op1 (m / make-01
            :ARG1 (d / decide-01
                  :manner (a2 / algorithm)))
      :op2 (c / cost-01
            :ARG1 (f / fair-01))
      :time (d2 / date-entity
            :year 2017))

# ::snt (2018), “Empirical Risk Minimization Under Fairness Constraints”, Advances  in Neural Information Processing Systems , pp.
# File 135

(p / publication-91
      :ARG1 (p2 / publication
            :name (n / name
                  :op1 "Empirical"
                  :op2 "Risk"
                  :op3 "Minimization"
                  :op4 "Under"
                  :op5 "Constraints"))
      :ARG4 p2
      :name n
      :op1 "Advances"
      :op2 "in"
      :op3 "Neural"
      :op4 "Information"
      :op5 "Processing"
      :op6 "Systems"
      :time (d / date-entity
            :year 2018)
      :ARG7 (v / value-interval
            :op1 1
            :op2 2))

# ::snt [4]  Kaminski,  M. and G.  Malgieri (2020), Multi -layered explanations from algorithmic impact  assessments in the GDPR In Proceedings of the 2020 Conference on Fairness,  Accountability, and Transparency .
# File 135

(e / explain-01
      :ARG0 (a / and
            :op1 (p / person
                  :name (n / name
                        :op1 "Kaminski"))
            :op2 (p2 / person
                  :name (n2 / name
                        :op1 "M."
                        :op2 "M."))
            :op3 (p3 / person
                  :name (n3 / name
                        :op1 "G."
                        :op2 "Malgieri")))
      :ARG3 (a2 / assess-01
            :ARG1 (ii / impact-01
                  :ARG0 (a3 / algorithm)))
      :ARG1-of (l / layer-01
            :quant (m / multiple))
      :subevent-of (l2 / law
            :name (n4 / name
                  :op1 "GDPR"))
      :subevent-of (c / conference
            :name (n5 / name
                  :op1 "2018"
                  :op2 "Conference"
                  :op3 "on"
                  :op4 "Fairness,"
                  :op5 "Accountability"
                  :op6 "and"
                  :op7 "Transparency"))
      :ARG1-of (d / describe-01
            :ARG0 (p4 / publication
                  :ARG0-of (c2 / cite-01
                        :ARG1 4)))
      :time (d2 / date-entity
            :year 2020))

# ::snt [72]  Koshiyama,  A. and Z.  Engin (2019), Algorithmic Impact Assessment: Fairness, Robustness  and Explainability in Automated Decision -Making .
# File 135

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Koshiyama"))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "A."
                        :op2 "Z."))
            :op3 (p4 / person
                  :name (n3 / name
                        :op1 "Engin")))
      :ARG1 (p5 / publication
            :name (n4 / name
                  :op1 "Algorithmic"
                  :op2 "Impact"
                  :op3 "Assessment"
                  :op4 ":"
                  :op5 ":"
                  :op6 ":"
                  :op7 "Fairness"
                  :op8 "Robustness"
                  :op9 "and"
                  :op10 "Explainable"
                  :op11 "in"
                  :op12 "Automated"
                  :op13 "Decision-Making"))
      :time (d / date-entity
            :year 2019)
      :ARG1-of (c / cite-01
            :ARG2 72))

# ::snt (2017), “Counterfactual fairness”, Advances in Neural Information Processing  Systems , pp.
# File 135

(p / publication-91
      :ARG1 (p2 / publication
            :name (n / name
                  :op1 "Counterfactual"
                  :op2 "Fairfair"))
      :ARG4 p2
      :name n
      :op1 "Advances"
      :op2 "in"
      :op3 "Neural"
      :op4 "Information"
      :op5 "Processing"
      :op6 "Systems"
      :time (d / date-entity
            :year 2017)
      :ARG7 (v / value-interval
            :op1 7
            :op2 9))

# ::snt [164]  OECD (2022), Rationale for the OECD AI Principle on “Human -centred values and fairness“ ,  https://oecd.ai/en/dashboards/ai -principles/P6  (accessed on 9  April 2022).
# File 135

(p / publication-91
      :ARG0 (o / organization
            :name (n / name
                  :op1 "OECD"))
      :ARG1 (p2 / publication
            :name (n2 / name
                  :op1 "Rationale"
                  :op2 "for"
                  :op3 "the"
                  :op4 "OECD"
                  :op5 "AI"
                  :op6 "Principles")
            :topic (a / and
                  :op1 (v / value
                        :ARG1-of (c / center-01
                              :ARG2 (h / human)))
                  :op2 (f / fairness)))
      :ARG4 (u / url-entity
            :value "https://oecd.ai/en/dashboards/ai-principles/P6")
      :ARG1-of (a2 / access-01
            :time (d / date-entity
                  :year 2022
                  :month 4
                  :day 9))
      :ARG1-of (c2 / cite-01
            :ARG2 164))

# ::snt (2017), “On fairness and calibration”, Advances in Neural Information  Processing Systems , pp.
# File 135

(p / publication-91
      :ARG4 (p2 / publication
            :name (n / name
                  :op1 "Advances"
                  :op2 "in"
                  :op3 "Neural"
                  :op4 "Information"
                  :op5 "Processing"
                  :op6 "Systems"))
      :ARG7 (v / value-interval
            :op1 1
            :op2 2)
      :time (d / date-entity
            :year 2017)
      :ARG1-of (t / title-01
            :ARG2 (a / and
                  :op1 (f / fairness)
                  :op2 (c / calibrate-01))))

# ::snt (2019), “Fairness Constraints: A Flexible Approach for Fair Classification”,  Journal of Machine Learning Research , Vol.
# File 135

(p / publication-91
      :ARG1 (p2 / publication
            :name (n / name
                  :op1 "Fairness"
                  :op2 "Constraints"
                  :op3 "A"
                  :op4 "Flexible"
                  :op5 " Approach"
                  :op6 "for"
                  :op7 "Fair"
                  :op8 "Classification"))
      :ARG4 (j / journal
            :name n
            :op1 "Journal"
            :op2 "of"
            :op3 "Machine"
            :op4 "Learning"
            :op5 "Research")
      :time (d / date-entity
            :year 2019))

# ::snt 7 Accuracy could also relate to other Principles, such as robustness and fairness.
# File 135

(p / possible-01
      :li 7
      :ARG1 (r / relate-01
            :ARG1 (a / accurate)
            :ARG2 (p2 / principle
                  :mod (o / other)
                  :example (a2 / and
                        :op1 (r2 / robustness)
                        :op2 (f / fair-01)))
            :mod (a3 / also)))

# ::snt New York has put in place an  automated decisions task force, to review key systems used by government agencies for accountability and  fairness  [2].
# File 18

(p / put-03
      :ARG0 (s / state
            :name (n / name
                  :op1 "New"
                  :op2 "York"))
      :ARG1 (ii / in-place
            :domain (t / task-01
                  :ARG2 (d / decide-01)
                  :ARG1-of (a / automate-01)))
      :purpose (r / review-01
            :ARG0 t
            :ARG1 (s2 / system
                  :ARG1-of (k / key-02)
                  :ARG1-of (u / use-01
                        :ARG0 (a2 / agency
                              :mod (g / government-organization
                                    :ARG0-of (g2 / govern-01)))
                        :ARG2 (a3 / and
                              :op1 (a4 / accountable-02)
                              :op2 (f / fair-01)))))
      :ARG1-of (d2 / describe-01
            :ARG0 (p2 / publication
                  :ARG1-of (c / cite-01
                        :ARG2 2))))

# ::snt Privacy protection   Fairness   Automated  decisions  Houston teachers fired by automated system   An AI was used by the Houston school district to assess teacher performance  and  in some cases fire them.
# File 18

(a / and
      :op1 (p / protect-01
            :ARG1 (p2 / privacy))
      :op2 (f / fairness)
      :op3 (d / decide-01
            :ARG1-of (a2 / automate-01))
      :op4 (f2 / fire-02
            :ARG1 (p3 / person
                  :ARG0-of (t / teach-01)
                  :location (c / city
                        :name (n / name
                              :op1 "Houston")))
            :ARG1-of (c2 / cause-01
                  :ARG0 (s / system
                        :ARG1-of (a3 / automate-01))))
      :op5 (u / use-01
            :ARG0 (d2 / district
                  :mod (s2 / school)
                  :location c)
            :ARG1 (ii / intelligent-01
                  :mod (a4 / artificial))
            :ARG2 (a5 / and
                  :op1 (a6 / assess-01
                        :ARG0 d2
                        :ARG1 (p4 / perform-02
                              :ARG0 (p5 / person
                                    :ARG0-of (t2 / teach-01))))
                  :op2 (f3 / fire-02
                        :ARG0 d2
                        :ARG1 p5
                        :time (c3 / case-04
                              :mod (s3 / some))))))

# ::snt Fairness    Transparency  and  explainability   Contestability   Accountability   Predicting  human  behaviour  The COMPAS sentencing tool   COMPAS is a tool used in the US to give recommendations to judges about  whether prospective parolee will re -offend.
# File 18

(m / multi-sentence
      :snt1 (a / and
            :op1 (f / fairness)
            :op2 (t / transparency)
            :op3 (e / explain-01)
            :op4 (c / contest-02)
            :op5 (a2 / accountable-02)
            :op6 (p / predict-01
                  :ARG1 (b / behave-01
                        :ARG0 (h / human))))
      :snt2 (t2 / tool
            :instrument-of (s / sentence-01)
            :domain (t3 / thing
                  :name (n / name
                        :op1 "Compass")))
      :snt3 (t4 / tool
            :ARG1-of (u / use-01
                  :ARG2 (r / recommend-01
                        :ARG0 (p2 / person
                              :ARG0-of (j / judge-01))
                        :ARG1 (t5 / truth-value
                              :polarity-of (o / offend-03
                                    :ARG0 (p3 / person
                                          :ARG1-of (p4 / parole-01)
                                          :mod (p5 / prospective))
                                    :mod (a3 / again)))
                        :ARG2 p2)
                  :location (c2 / country
                        :name (n2 / name
                              :op1 "US")))))

# ::snt Do no harm   Regulatory and legal  compliance   Privacy protection    Fairness   Transparency  and  explainability   Figure 2.
# File 18

(a / and
      :op1 (d / do-02
            :polarity -
            :mode imperative
            :ARG0 (y / you)
            :ARG1 (h / harm-01))
      :op2 (a2 / and
            :op1 (c / comply-01
                  :ARG1 (r / regulate-01))
            :op2 (c2 / comply-01
                  :ARG1 r
                  :ARG1-of (l / legal-02)))
      :op3 (p / protect-01
            :ARG1 (p2 / privacy))
      :op4 (f / fair-01)
      :op5 (t / transparency)
      :op6 (a3 / and
            :op1 (p3 / possible-01
                  :ARG1 (e / explain-01))
            :op2 (p4 / possible-01
                  :ARG1 e))
      :ARG1-of (d2 / describe-01
            :ARG0 (f2 / figure
                  :mod 2)))

# ::snt Fairness.
# File 18

(f / fairness)

# ::snt Ensuring fairness across the many  different groups in A ustralian society will be challenging, but this cuts right to the heart of ethical AI.
# File 18

(c / contrast-01
      :ARG1 (c2 / challenge-01
            :ARG2 (e / ensure-01
                  :ARG1 (f / fairness
                        :location (a / across
                              :op1 (g / group
                                    :ARG1-of (d / differ-02)
                                    :quant (m / many)
                                    :part-of (s / society
                                          :mod (c3 / continent
                                                :name (n / name
                                                      :op1 "Australia"))))))))
      :ARG2 (c4 / cut-01
            :ARG0 e
            :ARG4 (h / heart
                  :part-of (ii / intelligent-01
                        :mod (a2 / artificial)
                        :mod (e2 / ethics)))
            :mod (r / right)))

# ::snt When developers  need to codify  fairness  into AI algorithms , the re are various  challenge s in managing  often inevitable  trade offs and s ometimes there’s no “right” choice  because what is considered optimal may be disputed .
# File 18

(a / and
      :op1 (c / challenge-01
            :ARG2 (m / manage-01
                  :ARG1 (t / trade-off-02
                        :ARG1-of (a2 / avoid-01
                              :ARG1-of (p / possible-01
                                    :polarity -)
                              :frequency (o / often))))
            :mod (v / various))
      :op2 (c2 / choose-01
            :polarity -
            :ARG1-of (r / right-02)
            :ARG1-of (c3 / cause-01
                  :ARG0 (p2 / possible-01
                        :ARG1 (d / dispute-01
                              :ARG2 (o2 / optimal
                                    :ARG1-of (c4 / consider-01)))))
            :time o)
      :condition (n / need-01
            :ARG0 (p3 / person
                  :ARG0-of (d2 / develop-02))
            :ARG1 (c5 / codify-01
                  :ARG0 p3
                  :ARG1 (f / fairness)
                  :location (a3 / algorithm
                        :mod (ii / intelligent-01
                              :mod (a4 / artificial))))))

# ::snt Pathways forward involve a variety  of measures for different situations, ranging from explainable AI technologies  [27], testing, regulation that  requires transparency in the key priorities and fairness measures used in an AI system, through to  measures enabling external review and monitoring  [26].
# File 18

(ii / involve-01
      :ARG1 (v / variety
            :domain (m / measure-02
                  :ARG2 (s / situation
                        :ARG1-of (d / differ-02)))
            :ARG1-of (r / range-01
                  :ARG3 (a / and
                        :op1 (t / technology
                              :mod (a2 / artificial)
                              :ARG1-of (e / explain-01
                                    :ARG1-of (p / possible-01))
                              :ARG1-of (d2 / describe-01
                                    :ARG0 (p2 / publication
                                          :ARG1-of (c / cite-01
                                                :ARG2 27))))
                        :op2 (t2 / test-01)
                        :op3 (r2 / regulate-01
                              :ARG0-of (r3 / require-01
                                    :ARG1 (t3 / transparency
                                          :topic (a3 / and
                                                :op1 (p3 / priority
                                                      :ARG1-of (k / key-02))
                                                :op2 (m2 / measure-02
                                                      :ARG1 (f / fair-01)
                                                      :ARG1-of (u / use-01
                                                            :ARG2 (s2 / system
                                                                  :mod a2))))))))
                  :ARG4 (m3 / measure-02
                        :ARG0-of (e2 / enable-01
                              :ARG1 (a4 / and
                                    :op1 (r4 / review-01
                                          :mod (e3 / external))
                                    :op2 (m4 / monitor-01
                                          :mod e3)))
                        :ARG1-of (d3 / describe-01
                              :ARG0 (p4 / publication
                                    :ARG1-of (c2 / cite-01
                                          :ARG2 26))))))
      :ARG2 (p5 / path
            :direction (f2 / forward)))

# ::snt Mechanisms for monitoring  and improvement: Regular  monitoring of AI for accuracy,  fairness and suitability for the task  at hand.
# File 18

(m / mechanism
      :purpose (a / and
            :op1 (m2 / monitor-01)
            :op2 (ii / improve-01))
      :domain (m3 / monitor-01
            :ARG1 (ii2 / intelligent-01
                  :mod (a2 / artificial))
            :ARG2 (a3 / and
                  :op1 (a4 / accuracy)
                  :op2 (f / fairness)
                  :op3 (s / suitable-04
                        :ARG1 ii2
                        :ARG2 (t / task
                              :ARG1-of (a5 / at-hand-14))))
            :ARG1-of (r / regular-02)))

# ::snt Even when the  information is not flawed, if the priorities of the system are not aligned with expectations of fairness, then  the system can deliver negative outcomes.
# File 18

(h / have-condition-91
      :ARG1 (p / possible-01
            :ARG1 (d / deliver-01
                  :ARG0 (s / system)
                  :ARG1 (o / outcome
                        :ARG0-of (n / negative-02))))
      :ARG2 (a / align-01
            :polarity -
            :ARG1 (p2 / priority
                  :poss s)
            :ARG2 (e / expect-01
                  :ARG1 (f / fairness)))
      :concession (e2 / even-when
            :op1 (f2 / flaw-01
                  :polarity -
                  :ARG1 (ii / information))))

# ::snt ................................ ....................  36  5 Predicting human behaviour  ................................ ................................ ............................  38  5.2 Bias, predictions and discrimination  ................................ ................................ ... 39  5.3 Fairness and predictions  ................................ ................................ ......................  41  5.4 Transparency, policing and predictions ................................ ...............................  42  5.5 Medical predictions  ................................ ................................ .............................  44  5.6 Predictions and consumer behaviour ................................ ................................ .. 45  6 Current examples of AI in practice  ................................ ................................ ...................  48  6.1 Autonomous vehicles  ................................ ................................ ..........................  48  6.2 Personal identification and surveillance  ................................ .............................  52  6.3 Artificial Intelligence and Employment  ................................ ...............................  54  6.4 Gender Diversity in AI workforces  ................................ ................................ .......  55  6.5 Artificial Intelligence and Indigenous Communities  ................................ ............  55  7 A Proposed Ethics Framework  ................................ ................................ ..........................  57  7.1 Putting principles into practice  ................................ ................................ ...........  58
# File 18

(m / multi-sentence
      :snt1 (a / and
            :op1 (b / be-temporally-at-91
                  :ARG2 36)
            :op2 (b2 / be-temporally-at-91
                  :ARG2 5)
            :op3 (p / predict-01
                  :ARG1 (b3 / behave-01
                        :ARG0 (h / human)))
            :op4 (p2 / predict-01
                  :ARG1 (b4 / behave-01
                        :ARG0 (p3 / person
                              :ARG0-of (c / consume-01))))
            :op5 (e / example
                  :mod (ii / intelligent-01
                        :mod (a2 / artificial))
                  :ARG1-of (p4 / practice-01)
                  :mod (c2 / current))
            :op6 (a3 / and
                  :op1 (b5 / bias-01)
                  :op2 (p5 / predict-01)
                  :op3 (d / discriminate-02))
            :op7 (v / vehicle
                  :mod (a4 / autonomous))
            :op8 (n / number
                  :value 39)
            :op9 (n2 / number
                  :value 48)
            :op10 (n3 / number
                  :value 6.1)
            :op11 (n4 / number
                  :value 52)
            :op12 (n5 / number
                  :value 6.4)
            :op13 (n6 / number
                  :value 54)
            :op14 (n7 / number
                  :value 6.5)
            :op15 (n8 / number
                  :value 55)
            :op16 (n9 / number
                  :value 7)
            :op17 (n10 / number
                  :value 58)
            :snt2 (a5 / and
                  :op1 (f / fairness)
                  :op2 (s / surveil-01
                        :ARG1-of (p6 / personal-02))
                  :op3 (p7 / predict-01))))

# ::snt The Automated Decisions Task Force  will examine automated systems through the lens of equity, fairness and accountability, and is set to  release a report in December 2019 that will recommen d procedures for reviewing and assessing  algorithmic tools used by the city  [2].
# File 18

(a / and
      :op1 (e / examine-01
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "Automated"
                        :op2 "Decisions"
                        :op3 "Task"
                        :op4 "Force"))
            :ARG1 (s / system
                  :ARG1-of (a2 / automate-01))
            :manner (l / lens
                  :op1 (a3 / and
                        :op1 (e2 / equity)
                        :op2 (f / fairness)
                        :op3 (a4 / accountable-02))))
      :op2 (s2 / set-08
            :ARG1 o
            :ARG2 (r / release-01
                  :ARG0 o
                  :ARG1 (r2 / report
                        :ARG0-of (r3 / recommen-01
                              :ARG1 (p / procedure
                                    :purpose (a5 / and
                                          :op1 (r4 / review-01
                                                :ARG1 (t / tool
                                                      :mod (a6 / algorithm)
                                                      :ARG1-of (u / use-01
                                                            :ARG0 (c / city))))
                                          :op2 (a7 / assess-01
                                                :ARG1 t)))))
                  :time (d / date-entity
                        :month 12
                        :year 2019)))
      :ARG1-of (d2 / describe-01
            :ARG0 (p2 / publication
                  :ARG1-of (c2 / cite-01
                        :ARG2 2))))

# ::snt Artificial intelligence should operate on principles of intelligibility and fairness.
# File 18

(r / recommend-01
      :ARG1 (o / operate-01
            :ARG0 (ii / intelligent-01
                  :mod (a / artificial))
            :ARG1 (p / principle
                  :domain (a2 / and
                        :op1 (ii2 / intelligible)
                        :op2 (f / fair-01)))))

# ::snt Other elements of the report cover social licence, inclusion, privacy and data bias in AI, as well  as the differing concepts of fairness in algorithms.
# File 18

(c / cover-01
      :ARG0 (e / element
            :part-of (r / report)
            :mod (o / other))
      :ARG1 (a / and
            :op1 (l / license-01
                  :mod (s / society))
            :op2 (ii / include-01)
            :op3 (p / private-02)
            :op4 (b / bias-01
                  :ARG2 (d / data))
            :topic (a2 / artificial-intelligence))
      :op5 (c2 / concept
            :ARG1-of (d2 / differ-02)
            :topic (f / fair-01
                  :ARG1 (a3 / algorithm))))

# ::snt It also makes the key point that a  number of values are often in conflict with each other and there will inevitably be tradeoffs —for example,  quality of services can often  be in conflict with privacy; convenience can be in conflict with dignity and  accuracy can b e in conflict with fairness  [70].
# File 18

(p / point-04
      :ARG0 (ii / it)
      :ARG1 (a / and
            :op1 (c / conflict-01
                  :ARG0 (n / number
                        :quant-of (v / value)
                        :ARG1-of c)
                  :frequency (o / often))
            :op2 (a2 / avoid-01
                  :polarity -
                  :ARG1 (t / tradeoff-01
                        :example (a3 / and
                              :op1 (p2 / possible-01
                                    :ARG1 (c2 / conflict-01
                                          :ARG0 (q / quality
                                                :poss (s / serve-01))
                                          :ARG1 (p3 / privacy)
                                          :frequency (o2 / often)))
                              :op2 (p4 / possible-01
                                    :ARG1 (c3 / conflict-01
                                          :ARG0 (c4 / convenience)
                                          :ARG1 (d / dignity)))
                              :op3 (p5 / possible-01
                                    :ARG1 (c5 / conflict-01
                                          :ARG0 (a4 / accurate)
                                          :ARG1 (f / fairness)))))))
      :ARG1-of (k / key-02)
      :mod (a5 / also)
      :ARG1-of (d2 / describe-01
            :ARG0 (p6 / publication
                  :ARG1-of (c6 / cite-01
                        :ARG2 70))))

# ::snt It also  highlighted key developments in ethical AI rese arch and emerging strategies to combat bias, such as  recognising allocative and representational harms, new observational fairness strategies, anti -classification  strategies (which focus on appropriate input data and measuring results), classification pari ty (equal  performance across groups, even at a cost to accuracy among certain groups in some cases) and calibration  strategies.
# File 18

(h / highlight-01
      :ARG0 (ii / it)
      :ARG1 (d / develop-01
            :ARG1 (a / and
                  :op1 (s / strategy
                        :mod (ii2 / intelligent-01
                              :mod (a2 / artificial))
                        :mod (r / remote))
                  :op2 (s2 / strategy
                        :ARG0-of (e / emerge-02)))
            :ARG1-of (k / key-02)
            :purpose (c / combat-01
                  :ARG0 a
                  :ARG1 (b / bias-01))
            :example (a3 / and
                  :op1 (r2 / recognize-02
                        :ARG1 (h2 / harm-01
                              :ARG0 (a4 / and
                                    :op1 (a5 / allocate-01)
                                    :op2 (r3 / represent-01))))
                  :op2 (s3 / strategy
                        :mod (f / fairness)
                        :ARG1-of (n / new-01)
                        :mod (o / observe-01))
                  :op3 (s4 / strategy
                        :ARG0-of (o2 / oppose-01
                              :ARG1 (c2 / classify-01))
                        :ARG0-of (f2 / focus-01
                              :ARG1 (a6 / and
                                    :op1 (d2 / data
                                          :mod (ii3 / input)
                                          :ARG1-of (a7 / appropriate-02))
                                    :op2 (m / measure-01
                                          :ARG1 (r4 / result)))))
                  :op4 (c3 / classify-01
                        :mod (p / proportional)
                        :ARG1-of (m2 / mean-01
                              :ARG2 (p2 / perform-02
                                    :ARG1-of (e2 / equal-01
                                          :ARG3 (g / group))
                                    :concession (c4 / cost-01
                                          :ARG2 (a8 / accurate)
                                          :ARG3 (g2 / group
                                                :mod (c5 / certain))
                                          :time (c6 / case-04
                                                :mod (s5 / some))))))
                  :op5 (s6 / strategy
                        :mod (c7 / calibrate-01))))
      :mod (a9 / also))

# ::snt 4) Fairness Obligation.
# File 18

(o / obligate-01
      :li 4
      :ARG2 (f / fairness))

# ::snt Its site includes six key prin ciples: Fairness, inclusiveness, reliability and  safety, transparency, privacy and security, and accountability.
# File 18

(ii / include-01
      :ARG1 (p / principle
            :quant 6
            :ARG1-of (k / key-02)
            :domain (a / and
                  :op1 (f / fairness)
                  :op2 (ii2 / inclusiveness)
                  :op3 (r / rely-01
                        :ARG1-of (p2 / possible-01))
                  :op4 (s / safe-01)
                  :op5 (t / transparency)
                  :op6 (a2 / and
                        :op1 (p3 / privacy)
                        :op2 (s2 / security))
                  :op7 (a3 / accountable-02)))
      :ARG2 (s3 / site
            :poss (ii3 / it)))

# ::snt The guide focuses on five  key areas for developers: Accountability, Value Alignment, Explainability, Fairness and User Data Rights   [87].
# File 18

(f / focus-01
      :ARG0 (g / guide)
      :ARG2 (a / area
            :quant 5
            :ARG1-of (k / key-02)
            :beneficiary (p / person
                  :ARG0-of (d / develop-02))
            :ARG1-of (m / mean-01
                  :ARG2 (a2 / and
                        :op1 (a3 / accountable-02)
                        :op2 (a4 / align-01
                              :ARG2 (v / value))
                        :op3 (e / explain-01
                              :ARG1-of (p2 / possible-01))
                        :op4 (f2 / fairness)
                        :op5 (r / right-05
                              :ARG1 (p3 / person
                                    :ARG0-of (u / use-01
                                          :ARG1 (d2 / data)))))))
      :ARG1-of (d3 / describe-01
            :ARG0 (p4 / publication
                  :ARG1-of (c / cite-01
                        :ARG2 87))))

# ::snt Sometimes that will mean putting fairness ahead of profit.”   Weapons of Math Destruction, Cathy O’Neil     Humans are faced with tens of thousands of decisions each day.
# File 18

(m / multi-sentence
      :snt1 (m2 / mean-01
            :ARG1 (t / that)
            :ARG2 (p / put-01
                  :ARG1 (f / fairness)
                  :ARG2 (a / ahead
                        :op1 (p2 / profit-01)))
            :frequency (s / sometimes))
      :snt2 (s2 / say-01
            :ARG0 (p3 / person
                  :name (n / name
                        :op1 "Cathy"
                        :op2 "O’Neil"))
            :ARG1 (f2 / face-01
                  :ARG0 (h / human)
                  :ARG1 (d / decide-01
                        :quant (m3 / multiple
                              :op1 10000)
                        :frequency (t2 / temporal-quantity
                              :quant 1
                              :unit (d2 / day)))))
      :snt3 (w / weapon
            :ARG2-of (d3 / destroy-01
                  :ARG3 (m4 / mathematics))))

# ::snt Although the  previously discussed concepts of HITL, transparency and black  box issues and accountability apply, the capability to predict future potential actions poses additional  specific ethical concerns related to bias and fairness that require consideration.
# File 18

(p / pose-02
      :ARG0 (c / capable-01
            :ARG2 (p2 / predict-01
                  :ARG1 (a / act-02
                        :time (f / future)
                        :mod (p3 / potential))))
      :ARG1 (c2 / concern-01
            :mod (e / ethics)
            :ARG1-of (s / specific-02)
            :ARG1-of (r / relate-01
                  :ARG2 (a2 / and
                        :op1 (b / bias-01)
                        :op2 (f2 / fair-01)))
            :ARG0-of (r2 / require-01
                  :ARG1 (c3 / consider-02
                        :ARG1 c2))
            :mod (a3 / additional))
      :concession (a4 / apply-02
            :ARG1 (c4 / concept
                  :ARG1-of (d / discuss-01
                        :time (p4 / previous))
                  :topic (a5 / and
                        :op1 (l / law
                              :name (n / name
                                    :op1 " HITL"))
                        :op2 (t / transparency)
                        :op3 (ii / issue-02
                              :ARG0 (b2 / box
                                    :ARG1-of (b3 / black-04)))
                        :op4 (a6 / accountable-02)))))

# ::snt The discrepancy between the two analyses essentially  came down to the way each group assessed and measured fairness and balanced  it with accuracy of the  system.
# File 18

(c / come-down-23
      :ARG1 (d / discrepancy
            :mod (a / analyze-01
                  :quant 2))
      :ARG2 (a2 / and
            :op1 (w / way
                  :manner-of (a3 / assess-01
                        :ARG0 (g / group
                              :mod (e / each))
                        :ARG1 (f / fair-01)))
            :op2 (w2 / way
                  :manner-of (m / measure-01
                        :ARG0 g
                        :ARG1 f))
            :op3 (w3 / way
                  :manner-of (b / balance-01
                        :ARG0 g
                        :ARG1 f
                        :ARG2 (a4 / accurate
                              :domain (s / system)))))
      :mod (e2 / essential))

# ::snt It also suggests that internal reviews may miss key problems if they base their analysis on the same  assumptions of fairness as the original design.
# File 18

(s / suggest-01
      :ARG0 (ii / it)
      :ARG1 (p / possible-01
            :ARG1 (m / miss-02
                  :ARG0 (r / review-01
                        :ARG1-of (ii2 / internal-02))
                  :ARG1 (p2 / problem
                        :ARG1-of (k / key-02)))
            :condition (b / base-02
                  :ARG0 r
                  :ARG1 (a / analyze-01
                        :ARG0 r)
                  :ARG2 (a2 / assume-02
                        :ARG1 (f / fairness)
                        :ARG1-of (s2 / same-01
                              :ARG2 (d / design-01
                                    :mod (o / original))))))
      :mod (a3 / also))

# ::snt The ability to assess bias in predictive systems is intrinsically linked w ith how fairness is measured along  with the level of transparency involved.
# File 18

(l / link-01
      :ARG1 (c / capable-01
            :ARG2 (a / assess-01
                  :ARG1 (b / bias-01
                        :ARG0 (s / system
                              :ARG0-of (p / predict-01)))))
      :ARG2 (a2 / and
            :op1 (t / thing
                  :manner-of (m / measure-01
                        :ARG1 (f / fair-01)))
            :op2 (l2 / level
                  :degree-of (t2 / transparency
                        :ARG1-of (ii / involve-01))))
      :manner (ii2 / intrinsic))

# ::snt The complex interactions between bias, fairness and transparency in AI enabled predictive systems are  exemplified in the COMPAS case study.
# File 18

(e / exemplify-01
      :ARG0 (s / study
            :name (n / name
                  :op1 "CompAS")
            :mod (c / case))
      :ARG1 (ii / interact-01
            :ARG0 (b / bias-01)
            :ARG1 (f / fairness)
            :ARG2 (t / transparency)
            :mod (c2 / complex)
            :location (s2 / system
                  :ARG0-of (e2 / enable-01
                        :ARG1 (ii2 / intelligent-01
                              :mod (a / artificial)))
                  :ARG0-of (p / predict-01))))

# ::snt Although the use of AI enabled predictive systems to help support  decision making processes poses great potential benefits in boosting replicability and reducing human error  and bias, there are inherent ethical issues that must be addressed , particular ly the effects of indirect  discrimination  and fairness .
# File 18

(h / have-concession-91
      :ARG1 (p / pose-02
            :ARG0 (u / use-01
                  :ARG1 (ii / intelligent-01
                        :mod (a / artificial))
                  :ARG2 (h2 / help-01
                        :ARG0 (s / system
                              :ARG0-of (p2 / predict-01))
                        :ARG1 (s2 / support-01
                              :ARG0 s
                              :ARG1 (p3 / process-02
                                    :ARG1 (d / decide-01)))))
            :ARG1 (b / benefit-01
                  :ARG0 u
                  :ARG1 (a2 / and
                        :op1 (b2 / boost-01
                              :ARG0 u
                              :ARG1 (r / replicate-01))
                        :op2 (r2 / reduce-01
                              :ARG0 u
                              :ARG1 (a3 / and
                                    :op1 (e / err-01
                                          :ARG0 (h3 / human))
                                    :op2 (b3 / bias-01
                                          :ARG0 h3))))
                  :mod (p4 / potential)
                  :mod (g / great)))
      :ARG2 (o / obligate-01
            :ARG2 (a4 / address-02
                  :ARG1 (ii2 / issue-02
                        :ARG0 (a5 / and
                              :op1 (a6 / affect-01
                                    :ARG0 (d2 / discriminate-02
                                          :ARG1-of (d3 / direct-02
                                                :polarity -)))
                              :op2 (a7 / affect-01
                                    :ARG0 (f / fair-01))
                              :mod (p5 / particular))
                        :mod (e2 / ethics)
                        :mod (ii3 / inherent)))))

# ::snt The designers of algorithms need to pay  careful attention to how their systems come to a prediction and  there may be a role for government bodies in determining general boundaries and review and monitoring  processes —based on existing laws regarding discrimination —for how issues relating to  the separate but  related issues of  bias and fairness  can best be addressed and mitigated.
# File 18

(a / and
      :op1 (n / need-01
            :ARG0 (p / person
                  :ARG0-of (d / design-01
                        :ARG1 (a2 / algorithm)))
            :ARG1 (a3 / attend-02
                  :ARG0 p
                  :ARG1 (t / thing
                        :manner-of (c / come-01
                              :ARG1 (s / system
                                    :poss p)
                              :ARG4 (p2 / predict-01
                                    :ARG0 p)))
                  :ARG1-of (c2 / care-04)))
      :op2 (p3 / possible-01
            :ARG1 (r / role
                  :mod (b / body
                        :mod (g / government-organization
                              :ARG0-of (g2 / govern-01)))
                  :purpose (a4 / and
                        :op1 (d2 / determine-01
                              :ARG0 b
                              :ARG1 (b2 / boundary
                                    :ARG1-of (g3 / general-02)))
                        :op2 (a5 / and
                              :op1 (r2 / review-01
                                    :ARG0 b
                                    :ARG1 (p4 / process-02))
                              :op2 (m / monitor-01
                                    :ARG0 b
                                    :ARG1 p4)
                              :ARG1-of (b3 / base-02
                                    :ARG2 (l / law
                                          :ARG1-of (e / exist-01)
                                          :topic (d3 / discriminate-02))))
                        :purpose (t2 / thing
                              :manner-of p3
                              :ARG1 (a6 / and
                                    :op1 (a7 / address-02
                                          :ARG1 (ii / issue-02
                                                :ARG1-of (r3 / relate-01
                                                      :ARG2 (ii2 / issue-02
                                                            :ARG1 (a8 / and
                                                                  :op1 (b4 / bias-01)
                                                                  :op2 (f / fair-01))
                                                            :ARG1-of (s2 / separate-01
                                                                  :ARG1-of (c3 / contrast-01
                                                                        :ARG2 (r4 / relate-01
                                                                              :ARG1 ii2)))))))
                                    :op2 (m2 / mitigate-01
                                          :ARG1 ii)
                                    :ARG1-of (h / have-degree-91
                                          :ARG2 (g4 / good-02
                                                :ARG1 a6)
                                          :ARG3 (m3 / most))))))))

# ::snt 5.3 Fairness and predictions   The challenge of ensuring fairness in algorithms is not limited to biased datasets.
# File 18

(c / challenge-01
      :li 5.3
      :ARG2 (e / ensure-01
            :ARG1 (f / fair-01
                  :ARG1 (a / algorithm)))
      :ARG1-of (l / limit-01
            :polarity -
            :ARG2 (d / dataset
                  :ARG1-of (b / bias-01)))
      :topic (a2 / and
            :op1 (f2 / fairness)
            :op2 (p / predict-01)))

# ::snt 5.3 Fairness and predictions   The challenge of ensuring fairness in algorithms is not limited to biased datasets.
# File 18

(c / challenge-01
      :li 5.3
      :ARG2 (e / ensure-01
            :ARG1 (f / fair-01
                  :ARG1 (a / algorithm)))
      :ARG1-of (l / limit-01
            :polarity -
            :ARG2 (d / dataset
                  :ARG1-of (b / bias-01)))
      :topic (a2 / and
            :op1 (f2 / fairness)
            :op2 (p / predict-01)))

# ::snt So what is “fairness?” It really depends who you ask.
# File 18

(m / multi-sentence
      :snt1 (ii / infer-01
            :ARG1 (f / fairness
                  :domain (a / amr-unknown)))
      :snt2 (d / depend-01
            :ARG0 (ii2 / it)
            :ARG1 (p / person
                  :ARG1-of (a2 / ask-01
                        :ARG0 (y / you)))
            :ARG1-of (r / real-04)))

# ::snt “Fairness” is a difficult concept to pin down and AI designers essentially have to reduce it to statistics.
# File 18

(a / and
      :op1 (d / difficult
            :domain (p / pin-down-02
                  :ARG1 (c / concept
                        :domain (f / fairness))))
      :op2 (o / obligate-01
            :ARG1 (p2 / person
                  :ARG0-of (d2 / design-01
                        :ARG1 (a2 / artificial)))
            :ARG2 (r / reduce-01
                  :ARG0 p2
                  :ARG1 (f2 / fair-01
                        :ARG4 (s / statistics))
                  :mod (e / essential))))

# ::snt Researchers have come up with many dozens  of mathematical definitions to define what fairness means in  an algorithm and many of them perform extremely well when measured from one angle, but from a  different angle can produce very different results.
# File 18

(a / and
      :op1 (c / come-up-11
            :ARG0 (p / person
                  :ARG0-of (r / research-01))
            :ARG1 (t / thing
                  :ARG2-of (d / define-01
                        :ARG0 p
                        :ARG1 (t2 / thing
                              :ARG2-of (m / mean-01
                                    :ARG1 (f / fairness)
                                    :location (a2 / algorithm))))
                  :quant (m2 / multiple
                        :op1 12)
                  :mod (m3 / mathematics))
            :purpose (d2 / define-01
                  :ARG0 p
                  :ARG1 t2))
      :op2 (p2 / perform-02
            :ARG0 (t3 / thing
                  :quant (m4 / many)
                  :ARG2-of (d3 / define-01
                        :ARG0 p)
                  :ARG1-of (ii / include-91
                        :ARG2 t))
            :ARG1 (w / well-09
                  :degree (e / extreme))
            :time (m5 / measure-01
                  :ARG2 (a3 / angle
                        :quant 1))
            :concession-of (p3 / possible-01
                  :ARG1 (p4 / produce-01
                        :ARG0 (a4 / angle
                              :ARG1-of (d4 / differ-02
                                    :degree (v / very)))
                        :ARG1 (t4 / thing
                              :ARG2-of (r2 / result-01)
                              :ARG1-of (d5 / differ-02
                                    :degree v))))))

# ::snt This concept of differing perspectives of fairness is  exemplified in the COMPAS case study.
# File 18

(e / exemplify-01
      :ARG0 (s / study-01
            :ARG1 (c / case-04
                  :ARG1 (c2 / company
                        :name (n / name
                              :op1 "Compass"))))
      :ARG1 (c3 / concept
            :mod (t / this)
            :topic (p / perspective
                  :ARG1-of (d / differ-02)
                  :topic (f / fairness))))

# ::snt Put simply: it will sometimes be mathematically impossible to meet every single fairness measure because  some of them contradict each other and multiple datasets will be used in systems, and these datasets will  almost never be exactly equal in acc uracy or representativeness.
# File 18

(p / put-02
      :ARG1 (p2 / possible-01
            :polarity -
            :ARG1 (m / meet-01
                  :ARG1 (m2 / measure-01
                        :ARG1 (f / fair-01)
                        :ARG1-of (s / single-02)
                        :mod (e / every)))
            :mod (m3 / mathematics)
            :frequency (s2 / sometimes)
            :ARG1-of (c / cause-01
                  :ARG0 (a / and
                        :op1 (c2 / contradict-01
                              :ARG0 (s3 / some
                                    :ARG1-of (ii / include-91
                                          :ARG2 m2))
                              :ARG1 s3)
                        :op2 (u / use-01
                              :ARG1 (d / dataset
                                    :quant (m4 / multiple))
                              :location (s4 / system))
                        :op3 (e2 / equal-01
                              :polarity -
                              :ARG1 (d2 / dataset
                                    :mod (t / this))
                              :ARG3 (o / or
                                    :op1 (a2 / accurate)
                                    :op2 (r / represent-01))
                              :mod (e3 / exact)
                              :time (e4 / ever
                                    :mod (a3 / almost))))))
      :ARG1-of (s5 / simple-02))

# ::snt It is important for government and society to give consideration to the degree of flexibility that designers of  AI systems should have when it comes to making trade -offs between fairness m easures and other priorities  like profit .
# File 18

(ii / important-01
      :ARG1 (c / consider-02
            :ARG0 (a / and
                  :op1 (g / government-organization
                        :ARG0-of (g2 / govern-01))
                  :op2 (s / society))
            :ARG1 (d / degree
                  :degree-of (f / flexibility
                        :ARG1-of (h / have-03
                              :ARG0 (p / person
                                    :ARG0-of (d2 / design-01
                                          :ARG1 (s2 / system
                                                :mod (a2 / artificial))))
                              :ARG1-of (r / recommend-01)
                              :time (c2 / come-12
                                    :ARG1 (t / trade-off-02
                                          :ARG0 p
                                          :ARG1 (f2 / fairness)
                                          :ARG2 (p2 / priority
                                                :mod (o / other)
                                                :example (p3 / profit-01)))))))))

# ::snt If a company prioritises profit ahead of various forms of fairness, can they justify it?
# File 18

(p / possible-01
      :ARG1 (j / justify-01
            :ARG0 (c / company)
            :ARG1 (p2 / prioritize-01
                  :ARG0 c
                  :ARG1 (p3 / profit-01
                        :ARG0 c)
                  :ARG1-of (ii / instead-of-91
                        :ARG2 (f / fairness
                              :mod (f2 / form
                                    :mod (v / various))))))
      :polarity (a / amr-unknown))

# ::snt E ven when the  information is not flawed, if the priorities of the system are not aligned with expectations of fairness, then  the system can deliver negative outcomes.
# File 18

(p / possible-01
      :ARG1 (d / deliver-01
            :ARG0 (s / system)
            :ARG1 (o / outcome
                  :ARG0-of (n / negative-02)))
      :condition (f / flaw-01
            :polarity -
            :ARG1 (ii / information))
      :condition (a / align-01
            :polarity -
            :ARG1 (p2 / priority
                  :poss s)
            :ARG2 (e / expect-01
                  :ARG1 (f2 / fairness))))

# ::snt Fairness.
# File 18

(f / fairness)

# ::snt In addition, it can assess the algorithm’s accuracy, fairness and  performance.
# File 18

(a / and
      :op2 (p / possible-01
            :ARG1 (a2 / assess-01
                  :ARG0 (ii / it)
                  :ARG1 (a3 / and
                        :op1 (a4 / accurate
                              :domain (a5 / algorithm))
                        :op2 (f / fair-01
                              :ARG1 a5)
                        :op3 (p2 / perform-02
                              :ARG0 a5)))))

# ::snt 7.1.7 Monitoring AI   This consists of regular monitoring of AI or automated decision systems for accuracy, fairness and suitability  for the task at hand.
# File 18

(m / multi-sentence
      :snt1 (m2 / monitor-01
            :li "7.1.7"
            :ARG1 (ii / intelligent-01
                  :mod (a / artificial)))
      :snt2 (c / consist-01
            :ARG1 (t / this)
            :ARG2 (m3 / monitor-01
                  :ARG1 (o / or
                        :op1 (ii2 / intelligent-01
                              :mod a))
                  :op2 (s / system
                        :ARG0-of (d / decide-01)
                        :ARG1-of (a2 / automate-01)))
            :ARG2 (a3 / and
                  :op1 (a4 / accuracy)
                  :op2 (f / fairness)
                  :op3 (s2 / suitable-04
                        :ARG1 o
                        :ARG2 (t2 / task
                              :ARG1-of (a5 / at-hand-14))))
            :ARG1-of (r / regular-02)))

# ::snt Artificial Intelligence: Australia’s Ethics Framework (A Discussion Paper)   Page 64    Privacy Protection   /Consequence  Fairness   /Consequence  Physical harm   /Consequence  Contestability   /Consequence  Accountability   /Consequence  Regulatory and legal  Compliance   /Likelihood  Transparency and  explainability   /Likelihood  Number of  people affected   Insignificant  – no  private or sensitive  data is used by the AI  Insignificant  – has  no effect on a  person’s human  rights  Insignificant  –  application cannot  control or influence  other systems  Insignificant – the  application operates on  an opt -in basis and no  intervention is required  to reverse outcome in  the event someone  decides to opt out  Insignificant –  clear   accountability of  outcomes  Insignificant  – consent  gained for use of data.
# File 18

(m / multi-sentence
      :snt1 (p / publication
            :name (n / name
                  :op1 "Artificial"
                  :op2 "Intelligence"
                  :op3 "Framework")
            :medium p
            :name (n2 / name
                  :op1 "Australia's"
                  :op2 "Ethics"
                  :op3 "Framework")
            :ARG1-of (d / describe-01
                  :ARG0 (p2 / paper
                        :mod 64
                        :ARG1-of (d2 / discuss-01))))
      :snt2 (a / and
            :op1 (p3 / page
                  :mod 64)
            :op2 (p4 / protect-01
                  :ARG1 (p5 / privacy))
            :op3 (c / consequence-03)
            :op4 (f / fair-01)
            :op5 (c2 / consequence-03)
            :op6 (h / harm-01
                  :mod (p6 / physical))
            :op7 (c3 / contest-02)
            :op8 (c4 / consequence-03)
            :op9 (a2 / accountable-02)
            :op10 (a3 / and
                  :op1 (r / regulate-01)
                  :op2 (c5 / comply-01
                        :ARG1-of (l / legal-02)))
            :op11 (a4 / and
                  :op1 (t / transparency)
                  :op2 (e / explain-01))
            :op12 (l2 / likelihood)
            :op13 (n3 / number
                  :quant-of (p7 / person
                        :ARG1-of (a5 / affect-01)))
            :ARG1-of (s / significant-02
                  :polarity -))
      :op14 (u / use-01
            :polarity -
            :ARG0 (ii / intelligent-01
                  :mod (a6 / artificial))
            :ARG1 (d3 / data
                  :ARG1-of (p8 / private-02)
                  :ARG1-of (s2 / sensitive-03))
            :ARG1-of (s3 / significant-02))
      :op15 (s4 / significant-02
            :polarity -
            :ARG1 (c6 / consent-01
                  :ARG1 u
                  :ARG1 d3))
      :op16 (a7 / and
            :op1 (p9 / possible-01
                  :polarity -
                  :ARG1 (o / or
                        :op1 (c7 / control-01
                              :ARG0 ii
                              :ARG1 (s5 / system
                                    :mod (o2 / other)))
                        :op2 (ii2 / influence-01
                              :ARG0 ii
                              :ARG1 s5)))
            :op2 (r2 / require-01
                  :polarity -
                  :ARG1 (ii3 / intervene-01)
                  :purpose (r3 / reverse-01
                        :ARG1 (o3 / outcome))
                  :condition (d4 / decide-01
                        :ARG0 (s6 / someone)
                        :ARG1 (o4 / opt-01
                              :ARG0 s6
                              :ARG1 (o5 / out-06
                                    :ARG1 o3))))))

# ::snt Introducing AI Fairness 360.
# File 18

(ii / introduce-01
      :ARG1 (t / thing
            :name (n / name
                  :op1 "AI"
                  :op2 "Fairness"
                  :op3 360)))

# ::snt 206 Fairness Accountability and Transparency in Machine Learning.
# File 18

(a / and
      :li 206
      :op1 (a2 / accountable-02
            :ARG1 (f / fairness))
      :op2 (t / transparent
            :topic (l / learn-01
                  :mod (m / machine))))

# ::snt These included ensuring that AI adhered to ethical principles such as fairness and  transparency.
# File 18

(ii / include-01
      :ARG1 (e / ensure-01
            :ARG1 (a / adhere-02
                  :ARG0 (ii2 / intelligent-01
                        :mod (a2 / artificial))
                  :ARG1 (p / principle
                        :mod (e2 / ethics)
                        :example (a3 / and
                              :op1 (f / fairness)
                              :op2 (t / transparency)))))
      :ARG2 (t2 / this))

# ::snt Encourages a public debate on how to explore the  enormous potential of AI based on  fundamental European values, the principles of transparency, explainability, fairness,  accountability, responsibility and trustworthiness, as well as the principle that AI and  robotics should be human -centred and develope d to complement humans; stresses that  in a significant number of areas of human life, from sustainability to healthcare, AI can  provide benefits as an auxiliary tool for users and professionals, augmenting the  capabilities of humans without impeding their ability to freely act and decide; stresses  that the agreed AI ethical principles and requirements should be operationalised in all  domains of AI application, building in the necessary safeguards, which will increase  citizens’ trust, thereby making them emb race the benefits of AI;   19.
# File 85

(m / multi-sentence
      :snt1 (e / encourage-01
            :ARG1 (d / debate-01
                  :ARG1 (t / thing
                        :manner-of (e2 / explore-01
                              :ARG1 (p / potential
                                    :mod (e3 / enormous)
                                    :poss (ii / intelligent-01
                                          :mod (a / artificial)))))
                  :ARG1-of (p2 / public-02)
                  :ARG1-of (b / base-02
                        :ARG2 (a2 / and
                              :op1 (v / value
                                    :mod (c / continent
                                          :name (n / name
                                                :op1 "Europe"))
                                    :mod (f / fundamental))
                              :op2 (p3 / principle
                                    :topic (a3 / and
                                          :op1 (t2 / transparency)
                                          :op2 (e4 / explain-01)
                                          :op3 (f2 / fairness)
                                          :op4 (a4 / accountable-02)
                                          :op5 (r / responsible-02)
                                          :op6 (d2 / deserve-01
                                                :ARG1 (t3 / trust-01))))
                              :op3 (p4 / principle
                                    :topic (a5 / and
                                          :op1 (c2 / center-01
                                                :ARG1 (a6 / and
                                                      :op1 ii
                                                      :op2 (r2 / robot))
                                                :ARG2 (h / human))
                                          :op2 (d3 / develop-02
                                                :ARG1 a6
                                                :ARG4 (c3 / complement-01
                                                      :ARG0 a6
                                                      :ARG1 h)))
                                    :ARG1-of (a7 / agree-01))))))
      :snt2 (s / stress-01
            :ARG1 (p5 / possible-01
                  :ARG1 (p6 / provide-01
                        :ARG0 (ii2 / intelligent-01
                              :mod (a8 / artificial))
                        :ARG1 (b2 / benefit-01)
                        :ARG2 (a9 / and
                              :op1 (p7 / person
                                    :ARG0-of (u / use-01))
                              :op2 (p8 / professional))
                        :manner (t4 / tool
                              :mod (a10 / auxiliary))
                        :location (a11 / area
                              :ARG1-of (s2 / significant-02)
                              :poss (l / live-01
                                    :ARG0 h))
                        :example (a12 / and
                              :op1 (s3 / sustain-01
                                    :ARG1 h)
                              :op2 (h2 / healthcare)))
                  :ARG0-of (a13 / augment-01
                        :ARG1 (c4 / capable-01
                              :ARG1 h)
                        :manner (ii3 / impede-01
                              :polarity -
                              :ARG0 ii2
                              :ARG1 (c5 / capable-01
                                    :ARG1 h
                                    :ARG2 (a14 / and
                                          :op1 (a15 / act-02
                                                :ARG0 h)
                                          :op2 (d4 / decide-01
                                                :ARG0 h)))))))
      :snt3 (r3 / recommend-01
            :ARG1 (o / operate-01
                  :ARG1 (a16 / and
                        :op1 (p9 / principle
                              :mod (e5 / ethics)
                              :mod (ii4 / intelligent-01
                                    :mod (a17 / artificial)))
                        :op2 (r4 / require-01
                              :ARG1 ii4)))
            :location (d5 / domain
                  :mod (a18 / all)
                  :topic (a19 / apply-02
                        :ARG1 ii4))
            :ARG0-of (b3 / build-02
                  :ARG1 (s4 / safeguard
                        :ARG1-of (n2 / need-01))
                  :ARG0-of (c6 / cause-01
                        :ARG1 (ii5 / increase-01
                              :ARG1 (t5 / trust-01
                                    :ARG0 (c7 / citizen)))))))

# ::snt 19 The overarching  principles of GDPR, including those of  fairness, transparency, purpose limitation  and accountability, offer overall direction.
# File 110

(o / offer-01
      :li 19
      :ARG0 (p / principle
            :ARG0-of (o2 / overreach-01)
            :poss (l / law
                  :name (n / name
                        :op1 "GDPR"))
            :ARG2-of (ii / include-01
                  :ARG1 (a / and
                        :op1 (f / fairness)
                        :op2 (t / transparency)
                        :op3 (l2 / limit-01
                              :ARG1 (p2 / purpose))
                        :op4 (a2 / accountable-02))))
      :ARG1 (d / direct-01
            :mod (o3 / overall)))

# ::snt 23 The  limitations of DPIAs have been noted in terms of  promoting accountability and ensuring fairness  in the work context.
# File 110

(n / note-01
      :li 23
      :ARG1 (l / limit-01
            :ARG1 (t / thing
                  :name (n2 / name
                        :op1 "DPI"))
            :topic (a / and
                  :op1 (p / promote-02
                        :ARG0 t
                        :ARG1 (a2 / accountable-02))
                  :op2 (e / ensure-01
                        :ARG0 t
                        :ARG1 (f / fair-01))
                  :location (c / context
                        :mod (w / work-01)))))

# ::snt 71 Some variables, and  interpretations of fairness, are better suited to  quantification but methodological variables  cannot and should not delimit the scope of  impact assessment.
# File 110

(c / contrast-01
      :li 71
      :ARG1 (s / suit-01
            :ARG1 (a / and
                  :op1 (v / variable
                        :quant (s2 / some))
                  :op2 (ii / interpret-01
                        :ARG1 (f / fairness)))
            :ARG2 (q / quantify-01)
            :ARG1-of (h / have-degree-91
                  :ARG2 (g / good-02
                        :ARG1 s)
                  :ARG3 (m / more)))
      :ARG2 (a2 / and
            :op1 (p / possible-01
                  :polarity -
                  :ARG1 (l / limit-01
                        :ARG0 (v2 / variable
                              :mod (m2 / methodology))
                        :ARG1 (s3 / scope
                              :poss (a3 / assess-01
                                    :ARG1 (ii2 / impact-01)))))
            :op2 (r / recommend-01
                  :ARG1 l)))

# ::snt 73  IFOW’s AI and Hiring paper and the CDEI  Bias Review identify the limitations and  inconsistencies of technical auditing in isolation,  as well as the need for consistent, open  and shared approaches to addressing bias,  fairness and inequality.
# File 110

(ii / identify-01
      :li 73
      :ARG0 (a / and
            :op1 (p / paper
                  :name (n / name
                        :op1 "AI"
                        :op2 "and"
                        :op3 "Hiring"
                        :op4 "Paper")
                  :poss (o / organization
                        :name (n2 / name
                              :op1 "IFOW")))
            :op2 (c / conference
                  :name (n3 / name
                        :op1 "CDEI"
                        :op2 "Bias"
                        :op3 "Review")))
      :ARG1 (a2 / and
            :op1 (l / limit-01
                  :ARG0 (a3 / audit-01
                        :mod (t / technical)
                        :manner (ii2 / isolate-01)))
            :op2 (c2 / consistent-02
                  :polarity -
                  :ARG1 a3)
            :op3 (a4 / approach-02
                  :ARG1 (a5 / address-02
                        :ARG1 (a6 / and
                              :op1 (b / bias-01)
                              :op2 (f / fair-01)
                              :op3 (e / equal-01
                                    :polarity -)))
                  :ARG1-of (o2 / open-04)
                  :ARG1-of (s / share-01))
            :op4 (n4 / need-01
                  :ARG1 a4)))

# ::snt 77 Disclosures should therefore  include explanations of decision rationale;  responsibility and chains of development,  management and implementation; data and  how it has been used for decision-making;  fairness, including procedures to mitigate  bias and assessment of whether individuals  have received equal treatment; safety and  performance, primarily in reference to technical  indices such as accuracy and robustness; and  impact, including monitoring procedures and  impacts on individuals or society.
# File 110

(r / recommend-01
      :li 77
      :ARG1 (ii / include-01
            :ARG1 (a / and
                  :op1 (e / explain-01
                        :ARG1 (r2 / rationale
                              :mod (d / decide-01)))
                  :op2 (a2 / and
                        :op1 (r3 / responsible-03)
                        :op2 (c / chain-01
                              :ARG1 (a3 / and
                                    :op1 (d2 / develop-02)
                                    :op2 (m / manage-01)
                                    :op3 (ii2 / implement-01))))
                  :op3 (d3 / data)
                  :op4 (t / thing
                        :manner-of (u / use-01
                              :ARG1 d3
                              :ARG2 (d4 / decide-01)))
                  :op5 (f / fairness
                        :ARG2-of (ii3 / include-01
                              :ARG1 (p / procedure
                                    :ARG0-of (m2 / mitigate-01
                                          :ARG1 (b / bias-01))
                                    :ARG0-of (a4 / assess-01
                                          :ARG1 (t2 / truth-value
                                                :polarity-of (r4 / receive-01
                                                      :ARG0 (ii4 / individual)
                                                      :ARG1 (t3 / treat-01
                                                            :ARG1 ii4
                                                            :ARG1-of (e2 / equal-01))))))))
                  :op6 (a5 / and
                        :op1 (s / safe-01)
                        :op2 (p2 / perform-02)
                        :ARG1-of (r5 / reference-04
                              :ARG2 (ii5 / index
                                    :mod (t4 / technical)
                                    :example (a6 / and
                                          :op1 (a7 / accuracy)
                                          :op2 (r6 / robustness)))
                              :mod (p3 / primary)))
                  :op7 (ii6 / impact-01
                        :ARG2-of (ii7 / include-01
                              :ARG1 (a8 / and
                                    :op1 (p4 / procedure
                                          :ARG0-of (m3 / monitor-01))
                                    :op2 (ii8 / impact-01
                                          :ARG1 (o / or
                                                :op1 ii4
                                                :op2 (s2 / society)))))))
            :ARG2 (d5 / disclose-01)))

# ::snt 78 There is a lack of a universal  definition of fairness, for example, and there  are trade-offs and conflicts between differing  statistical interpretations of fairness, as well as  between desirable outcomes such as fairness  and accuracy.
# File 110

(a / and
      :li 78
      :op1 (l / lack-01
            :ARG1 (d / define-01
                  :ARG1 (f / fairness)
                  :mod (u / universal))
            :ARG0-of (e / exemplify-01))
      :op2 (a2 / and
            :op1 (t / trade-off-02
                  :ARG0 (ii / interpret-01
                        :ARG1 (f2 / fairness)
                        :mod (s / statistical)
                        :ARG1-of (d2 / differ-02)))
            :op2 (c / conflict-01
                  :ARG0 ii
                  :ARG1 (o / outcome
                        :ARG1-of (d3 / desirable-02)
                        :example (a3 / and
                              :op1 f2
                              :op2 (a4 / accurate))))))

# ::snt 79 This suggests normative  uncertainty around ‘fairness’ , pointing to  the need for both qualitative auditing and  participatory mechanisms to enable normative  evaluation and analysis of risk and impact.
# File 110

(s / suggest-01
      :li 79
      :ARG0 (t / this)
      :ARG1 (c / certain
            :polarity -
            :ARG1-of (n / norm-02)
            :topic (f / fairness))
      :ARG0-of (p / point-01
            :ARG1 (n2 / need-01
                  :ARG1 (e / enable-01
                        :ARG0 (a / and
                              :op1 (a2 / audit-01
                                    :mod (q / qualitative))
                              :op2 (m / mechanism
                                    :mod (p2 / participate-01))
                              :mod (b / both))
                        :ARG1 (a3 / and
                              :op1 (e2 / evaluate-01
                                    :ARG1 (a4 / and
                                          :op1 (r / risk-01)
                                          :op2 (ii / impact-01))
                                    :ARG1-of (n3 / norm-02))
                              :op2 (a5 / analyze-01
                                    :ARG1 a4))))))

# ::snt In Proceedings of the   2021 ACM Conference on Fairness, Accountability, and Transparency, 598–609.
# File 110

(b / be-located-at-91
      :ARG2 (c / conference
            :name (n / name
                  :op1 "ACM"
                  :op2 "Conference"
                  :op3 "on"
                  :op4 "Fairness"
                  :op5 "Accountability"
                  :op6 "and"
                  :op7 "Transparency")
            :time (d / date-entity
                  :year 2021)
            :ARG2-of (p / proceed-01)
            :ARG1-of (d2 / describe-01
                  :ARG0 (p2 / publication
                        :ARG1-of (c2 / cite-01
                              :ARG2 (b2 / between
                                    :op1 598))))))

# ::snt ” In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency , pp.
# File 110

(p / publication-91
      :ARG4 (c / conference
            :name (n / name
                  :op1 "ACM"
                  :op2 "Conference"
                  :op3 "on"
                  :op4 "Fairness"
                  :op5 "Accountability"
                  :op6 "and"
                  :op7 "Transparency")
            :time (d / date-entity
                  :year 2021))
      :ARG7 (v / value-interval
            :op1 1
            :op2 2))

# ::snt “Automation and Fairness: Assessing the Automation of Fairness in   Cases of Reasonable Pluralism and Considering the Blackbox of Human Judgment.
# File 110

(a / and
      :op1 (a2 / and
            :op1 (a3 / automate-01)
            :op2 (a4 / automate-01
                  :ARG1 (f / fairness)))
      :op2 (a5 / assess-01
            :ARG1 (a6 / automate-01
                  :ARG1 f
                  :subevent-of (c / case-04
                        :ARG1 (p / pluralism
                              :ARG1-of (r / reasonable-02)))))
      :op3 (c2 / consider-02
            :ARG1 (b / blackbox
                  :mod (j / judge-01
                        :ARG0 (h / human)))))

# ::snt NIST AI 100-1 AI RMF 1.0 about fairness and other values in certain domains.
# File 127

(m / multi-sentence
      :snt1 (e / equal-01
            :ARG1 (t / theoretical-condition
                  :name (n / name
                        :op1 "AI"))
            :ARG2 (r / ratio-of
                  :op1 100
                  :op2 1))
      :snt2 (c / concern-02
            :ARG0 (r2 / research-institute
                  :name (n2 / name
                        :op1 "NIST"))
            :ARG1 (a / and
                  :op1 (f / fairness)
                  :op2 (v / value
                        :mod (o / other))
                  :location (d / domain
                        :mod (c2 / certain)))
            :ARG1-of (r3 / rate-entity-91
                  :ARG2 1.0)))

# ::snt Under certain conditions such as data sparsity, privacyenhancing techniques can result in a loss in accuracy, affecting decisions about fairness and other values in certain domains.
# File 127

(p / possible-01
      :ARG1 (r / result-01
            :ARG1 (t / technique
                  :ARG0-of (e / enhance-01
                        :ARG1 (p2 / privacy)))
            :ARG2 (l / lose-02
                  :ARG1 (a / accurate))
            :ARG0-of (a2 / affect-01
                  :ARG1 (d / decide-01
                        :ARG3 (a3 / and
                              :op1 (f / fairness)
                              :op2 (v / value
                                    :mod (o / other))
                              :location (d2 / domain
                                    :mod (c / certain))))))
      :condition (c2 / condition
            :mod (c3 / certain)
            :example (s / sparsity
                  :mod (d3 / data))))

# ::snt 3.7 Fair – with Harmful Bias Managed Fairness in AI includes concerns for equality and equity by addressing issues such as harmful bias and discrimination.
# File 127

(ii / include-01
      :li 3.7
      :ARG1 (c / concern-01
            :ARG0 (a / and
                  :op1 (e / equal-01)
                  :op2 (e2 / equity))
            :manner (a2 / address-02
                  :ARG1 (ii2 / issue-02
                        :example (a3 / and
                              :op1 (b / bias-01
                                    :ARG0-of (h / harmful-02))
                              :op2 (d / discriminate-02)))))
      :ARG2 (m / manage-01
            :ARG1 (f / fairness
                  :mod (a4 / artificial))
            :manner (b2 / bias-01
                  :ARG0-of (h2 / harmful-02))))

# ::snt Standards of fairness can be complex and difficult to define because perceptions of fairness differ among cultures and may shift depending on application.
# File 127

(c / cause-01
      :ARG0 (a / and
            :op1 (d / differ-02
                  :ARG1 (p / perceive-01
                        :ARG1 (f / fairness))
                  :ARG3 (c2 / culture))
            :op2 (p2 / possible-01
                  :ARG1 (s / shift-01
                        :ARG1 p
                        :ARG0-of (d2 / depend-01
                              :ARG1 (a2 / apply-02
                                    :ARG1 (f2 / fairness))))))
      :ARG1 p2
      :ARG1 a
      :op1 (c3 / complex
            :domain (d3 / define-01
                  :ARG1 (s2 / standard
                        :mod (f3 / fairness))))
      :op2 (d4 / difficult
            :domain d3))

# ::snt Bias is tightly associated with the concepts of transparency as well as fairness in society.
# File 127

(a / associate-01
      :ARG1 (b / bias-01)
      :ARG2 (c / concept
            :topic (a2 / and
                  :op1 (t / transparency)
                  :op2 (f / fairness)
                  :location (s / society)))
      :ARG1-of (t2 / tight-05))

# ::snt MEASURE 2.11: Fairness and bias – as identified in the MAP function – are evaluated and results are documented.
# File 127

(m / measure-01
      :ARG2 11
      :ARG3 (a / and
            :op1 (e / evaluate-01
                  :ARG1 (a2 / and
                        :op1 (f / fairness)
                        :op2 (b / bias-01)
                        :ARG1-of (ii / identify-01
                              :location (f2 / function-01
                                    :ARG1 (t / thing
                                          :name (n / name
                                                :op1 "MAP"))))))
            :op2 (d / document-01
                  :ARG1 t
                  :ARG2-of (r / result-01))))

# ::snt FAccT ‘21: Proceedings of the  2021 ACM Conference on Fairness, Accountability, and Transparency, March 2021, pp.
# File 33

(p / publication-91
      :ARG4 21
      :ARG1 (c / conference
            :name (n / name
                  :op1 "ACM"
                  :op2 "Conference"
                  :op3 "on"
                  :op4 "Fairness"
                  :op5 "Accountability"
                  :op6 "and"
                  :op7 "Transparency")
            :time (d / date-entity
                  :year 2021))
      :ARG7 (v / value-interval
            :op1 1
            :op2 2)
      :ARG8 (p2 / publication
            :name (n2 / name
                  :op1 "FACCT"))
      :time (d2 / date-entity
            :month 3
            :year 2021))

# ::snt This is particularly important  for general-purpose AI systems where we have seen that bias and  unfairness may be embedded ‘upstream’ before deployment in  particular contexts and so such alerting is particularly crucial.
# File 33

(ii / important-01
      :ARG1 (t / this)
      :ARG2 (s / system
            :mod (ii2 / intelligent-01
                  :mod (a / artificial))
            :mod (g / general-purpose)
            :location-of (s2 / see-01
                  :ARG0 (w / we)
                  :ARG1 (p / possible-01
                        :ARG1 (e / embed-01
                              :ARG1 (a2 / and
                                    :op1 (b / bias-01)
                                    :op2 (f / fairness
                                          :polarity -))
                              :location (u / upstream)
                              :time (b2 / before
                                    :op1 (d / deploy-01
                                          :ARG1 s
                                          :ARG2 (c / context
                                                :mod (p2 / particular))))))))
      :ARG0-of (c2 / cause-01
            :ARG1 (c3 / crucial
                  :mod (p3 / particular)
                  :domain (a3 / alert-01
                        :mod (s3 / such)))))

# ::snt 1740-9713.2016.00960.x; Solon Barocas and Andrew D. Selbst, “Big Data’s Disparate Impact,” California Law Review  104, 671  (September 2016), https:/ /papers.ssrn.com/sol3/papers.cfm?abstract_id=2477899##; Arvind  Narayanan, “Translation Tutorial: 21 Definitions of Fairness and Their Politics,” presented at the  Conference on Fairness, Accountability, and Transparency, New Y ork, April 18, 2018, https:/ /www.
# File 66

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Solon"
                        :op2 "Barocas"))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "Andrew"
                        :op2 "D."
                        :op3 "Selbst")))
      :ARG1 (p4 / publication
            :name (n3 / name
                  :op1 "Translation"
                  :op2 "Tutorial"
                  :op3 "21"
                  :op4 "Definitions"
                  :op5 "of"
                  :op6 "Fairness"
                  :op7 "and"
                  :op8 "Their"
                  :op9 "Politics"))
      :ARG4 (j / journal
            :name (n4 / name
                  :op1 "California"
                  :op2 "Law"
                  :op3 "Review")
            :ARG1-of (c / cite-01
                  :ARG2 (a2 / and
                        :op1 104
                        :op2 671)))
      :time (d / date-entity
            :month 9
            :year 2016)
      :medium (u / url-entity
            :value "https:/ /www.ssrn.com/sol3/papers.cfm?abstract_id=2477899")
      :time (d2 / date-entity
            :day 18
            :month 4
            :year 2018)
      :location (c2 / city
            :name (n5 / name
                  :op1 "New"
                  :op2 "York")))

# ::snt 13  A vibrant community of academic researchers and practitioners are focused on fairness, accountability, and transparency.
# File 66

(f / focus-01
      :li 13
      :ARG1 (c / community
            :consist-of (a / and
                  :op1 (p / person
                        :ARG0-of (r / research-01)
                        :mod (a2 / academia))
                  :op2 (p2 / person
                        :ARG0-of (p3 / practice-01)
                        :mod a2))
            :mod (v / vibrant))
      :ARG2 (a3 / and
            :op1 (f2 / fairness)
            :op2 (a4 / accountable-02)
            :op3 (t / transparency)))

# ::snt 17  See, e.g., Joy Buolamwini and Timnit Gebru “Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification.” Proceedings of Machine Learning Research 81:1– 15, 2018  Conference on Fairness, Accountability, and Transparency; by developing a new face dataset that is  “more phenotypically balanced on the basis of skin type than existing benchmarks,” the researchers
# File 66

(s / see-01
      :li 17
      :ARG0 (y / you)
      :ARG1 (p / publication-91
            :ARG0 (a / and
                  :op1 (p2 / person
                        :name (n / name
                              :op1 "Joy"
                              :op2 "Bolamwini"))
                  :op2 (p3 / person
                        :name (n2 / name
                              :op1 "Timnit"
                              :op2 "Gebru")))
            :ARG1 (p4 / publication
                  :name (n3 / name
                        :op1 "Gender"
                        :op2 "Shadows"
                        :op3 "Intersectional"
                        :op4 "Accident"
                        :op5 "Disparities"
                        :op6 "in"
                        :op7 "Commercial"
                        :op8 "Gender"
                        :op9 "Classification"))
            :ARG4 (c / conference
                  :name (n4 / name
                        :op1 "Conference"
                        :op2 "on"
                        :op3 "Fairness"
                        :op4 "Accountability"
                        :op5 "and"
                        :op6 "Transparency")
                  :time (d / date-entity
                        :year 2018))
            :ARG7 (j / journal
                  :name (n5 / name
                        :op1 "Proceedings"
                        :op2 "of"
                        :op3 "Machine"
                        :op4 "Learning"
                        :op5 "Research"))
            :ARG8 (b / between
                  :op1 "1/1"
                  :op2 "15"))
      :manner (d2 / develop-02
            :ARG0 (p5 / person
                  :ARG0-of (r / research-01))
            :ARG1 (d3 / dataset
                  :topic (f / face
                        :ARG1-of (n6 / new-01))
                  :ARG1-of (b2 / balance-01
                        :ARG1-of (b3 / base-02
                              :ARG2 (t / type
                                    :mod (s2 / skin)))
                        :ARG2-of (h / have-degree-91
                              :ARG1 d3
                              :ARG3 (m / more)
                              :ARG4 (b4 / benchmark
                                    :ARG1-of (e / exist-01)))))))

# ::snt Calls on the Commission to consider reversing the rules governing the burden of proof  for harm caused by emerging digital technologies in clearly defined cases and after a  proper assessment, in order to empower consumers who have suffered harm or whose  property has been damaged to defend their rights while preventing abuse and providing  legal certainty for businesses, as well as to ensure fairness and to mitigate the  informational asymmetries impairing the situation of injured parties; 16.
# File 88

(c / call-03
      :li 16
      :ARG1 (c2 / consider-02
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "Commission"))
            :ARG1 (r / reverse-01
                  :ARG0 o
                  :ARG1 (r2 / rule-01
                        :ARG0-of (g / govern-01
                              :ARG1 (b / burden-01
                                    :ARG2 (p / prove-01
                                          :ARG1 (h / harm-01
                                                :ARG0 (t / technology
                                                      :ARG0-of (e / emerge-02)
                                                      :mod (d / digital))
                                                :ARG1-of (c3 / cause-01
                                                      :ARG0 (a / and
                                                            :op1 (c4 / case-03
                                                                  :ARG1-of (d2 / define-01
                                                                        :ARG1-of (c5 / clear-06)))
                                                            :op2 (a2 / assess-01
                                                                  :mod (p2 / proper))))))))))
            :purpose (a3 / and
                  :op1 (e2 / empower-01
                        :ARG0 o
                        :ARG1 (p3 / person
                              :ARG0-of (c6 / consume-01)
                              :ARG0-of (s / suffer-01
                                    :ARG1 (h2 / harm-01
                                          :ARG1 p3))
                              :ARG0-of (d3 / damage-01
                                    :ARG1 (p4 / property
                                          :poss p3)))
                        :ARG2 (d4 / defend-01
                              :ARG0 p3
                              :ARG1 (r3 / right-05
                                    :ARG1 p3))
                        :time (a4 / and
                              :op1 (p5 / prevent-01
                                    :ARG0 o
                                    :ARG1 (a5 / abuse-01))
                              :op2 (p6 / provide-01
                                    :ARG0 o
                                    :ARG1 (c7 / certainty
                                          :ARG1-of (l / legal-02))
                                    :ARG2 (b2 / business))
                              :op3 (e3 / ensure-01
                                    :ARG0 o
                                    :ARG1 (f / fairness))
                              :op4 (m / mitigate-01
                                    :ARG0 o
                                    :ARG1 (a6 / asymmetry
                                          :mod (ii / information)
                                          :ARG0-of (ii2 / impair-01
                                                :ARG1 (s2 / situation
                                                      :poss (p7 / party
                                                            :ARG1-of (ii3 / injure-01))))))))))
      :ARG2 o)

# ::snt Everyday Ethics  for AI is meant to guide team  discussions and daily practices.“You can use an eraser on the drafting table or a sledgehammer on the construction site.” Frank Lloyd Wright–  IBM embraces five foundational  pillars of trustworthy AI:  Explainability, Fairness,  Robustness, Transparency,  and Privacy.1 These pillars  underpin the development,  deployment and use of AI  systems.
# File 9

(m / multi-sentence
      :snt1 (m2 / mean-02
            :ARG1 (e / ethics
                  :mod (e2 / everyday)
                  :beneficiary (ii / intelligent-01
                        :mod (a / artificial)))
            :ARG2 (g / guide-01
                  :ARG0 e
                  :ARG1 (a2 / and
                        :op1 (d / discuss-01
                              :ARG0 (t / team))
                        :op2 (p / practice-01
                              :ARG0 t
                              :frequency (r / rate-entity-91
                                    :ARG3 (t2 / temporal-quantity
                                          :quant 1
                                          :unit (d2 / day)))))))
      :snt2 (p2 / possible-01
            :ARG1 (u / use-01
                  :ARG0 (y / you)
                  :ARG1 (o / or
                        :op1 (e3 / eraser)
                        :op2 (s / sledgehammer))
                  :location (t3 / table
                        :purpose (d3 / draft-01))
                  :location (s2 / site
                        :mod (c / construct-01)))
            :ARG1-of (q / quote-01
                  :ARG2 (p3 / person
                        :name (n / name
                              :op1 "Frank"
                              :op2 "Lloyd"
                              :op3 "Wright"))))
      :snt3 (e4 / embrace-01
            :ARG0 (c2 / company
                  :name (n2 / name
                        :op1 "IBM"))
            :ARG1 (p4 / pillar
                  :quant 5
                  :ARG2-of (f / found-01
                        :ARG1 (ii2 / intelligent-01
                              :mod (t4 / trustworthy)))
                  :domain (a3 / and
                        :op1 (e5 / explain-01
                              :ARG1-of (p5 / possible-01))
                        :op2 (f2 / fairness)
                        :op3 (r2 / robustness)
                        :op4 (t5 / transparency)
                        :op5 (p6 / privacy))
                  :mod (t6 / this)))
      :ARG0-of (u2 / underpin-01
            :ARG1 (a4 / and
                  :op1 (d4 / develop-02
                        :ARG1 ii2)
                  :op2 (d5 / deploy-01
                        :ARG1 ii2)
                  :op3 (u3 / use-01
                        :ARG1 ii2))))

# ::snt 02 AI Fairness 360:  This is an open source software  toolkit that enables developers to  use state-of-the-art algorithms to  regularly check for unwanted biases  from entering their machine learning  pipeline and to mitigate any biases  that are discovered.03 AI FactSheets 360:  Similar to nutrition labels for food or  information sheets for appliances,  this project increases transparency  so that AI consumers better  understand how the AI model or  service was created.
# File 9

(m / multi-sentence
      :snt1 (t / toolkit
            :domain (t2 / this)
            :mod (s / software
                  :ARG1-of (o / open-04))
            :ARG0-of (e / enable-01
                  :ARG1 (u / use-01
                        :ARG0 (p / person
                              :ARG0-of (d / develop-02))
                        :ARG1 (a / algorithm
                              :mod (s2 / state-of-the-art))
                        :ARG2 (a2 / and
                              :op1 (c / check-01
                                    :ARG0 p
                                    :ARG2 (b / bias-01
                                          :ARG1-of (w / want-01
                                                :polarity -))
                                    :ARG3 (e2 / enter-01
                                          :ARG0 b
                                          :ARG1 (p2 / pipeline
                                                :mod (l / learn-01
                                                      :manner (m2 / machine))
                                                :poss p))
                                    :ARG1-of (r / regular-02))
                              :op2 (m3 / mitigate-01
                                    :ARG0 p
                                    :ARG1 (b2 / bias-01
                                          :mod (a3 / any)
                                          :ARG1-of (d2 / discover-01)))))
                  :ARG2 p))
      :snt2 (ii / increase-01
            :li 2
            :ARG0 (p3 / project
                  :mod (t3 / this))
            :ARG1 (t4 / transparency)
            :purpose (u2 / understand-01
                  :ARG0 (p4 / person
                        :ARG0-of (c2 / consume-01
                              :ARG1 (o2 / or
                                    :op1 (m4 / model
                                          :mod (a4 / artificial))
                                    :op2 (s3 / service
                                          :mod a4))))
                  :ARG1 (t5 / thing
                        :manner-of (c3 / create-01
                              :ARG1 o2))
                  :ARG1-of (h / have-degree-91
                        :ARG2 (g / good-02
                              :ARG1 u2)
                        :ARG3 (m5 / more))))
      :snt3 (p5 / publication
            :name (n / name
                  :op1 "AI"
                  :op2 "FactSheets"
                  :op3 360)))

# ::snt While AI performs well with classification tasks, it is a machine, not a human, and does not  calculate fairness or equal ity12.
# File 40

(h / have-concession-91
      :ARG1 (a / and
            :op1 (m / machine
                  :domain (ii / intelligent-01
                        :mod (a2 / artificial))
                  :ARG1-of (ii2 / instead-of-91
                        :ARG2 (h2 / human
                              :domain ii)))
            :op2 (c / calculate-01
                  :polarity -
                  :ARG0 ii
                  :ARG1 (o / or
                        :op1 (f / fair-01)
                        :op2 (e / equal-01
                              :ARG1 (ii3 / ity12)))))
      :ARG2 (p / perform-02
            :ARG0 ii
            :ARG1 (t / task
                  :topic (c2 / classify-01))
            :ARG2 (w / well-09)))

# ::snt When selecting trained models, radiologists  should consider possible unintended consequences, and evaluate the fairness of the model’s  performance across the real -world data of multiple patient groups.
# File 40

(r / recommend-01
      :ARG1 (a / and
            :op1 (c / consider-02
                  :ARG0 (p / person
                        :ARG0-of (h / have-org-role-91
                              :ARG2 (r2 / radiologist)))
                  :ARG1 (p2 / possible-01
                        :ARG1 (c2 / consequence-03
                              :ARG1-of (ii / intend-01
                                    :polarity -))))
            :op2 (e / evaluate-01
                  :ARG0 p
                  :ARG1 (f / fair-01
                        :ARG1 (p3 / perform-02
                              :ARG0 (m / model-01
                                    :ARG1-of (t / train-01))))
                  :location (d / data
                        :mod (w / world
                              :ARG1-of (r3 / real-04))
                        :poss (g / group
                              :quant (m2 / multiple)
                              :consist-of (p4 / person
                                    :ARG0-of (h2 / have-rel-role-91
                                          :ARG2 (p5 / patient)))))))
      :time (s / select-01
            :ARG0 p
            :ARG1 m))

# ::snt Although there is no universally -agreed upon definition of “fairness ,” it seems a  reasonable position to suggest that health  care AI tools should make every effort to offer a  sufficient degree of equal opportunity and access for all served by the health  care system  within which it will be deplo yed, including minor ity groups69.
# File 40

(h / have-concession-91
      :li 69
      :ARG1 (s / seem-01
            :ARG1 (p / position-02
                  :ARG1 (s2 / suggest-01
                        :ARG1 (r / recommend-01
                              :ARG1 (e / effort-01
                                    :ARG0 (t / tool
                                          :purpose (ii / intelligent-01
                                                :mod (a / artificial))
                                          :mod (c / care-03
                                                :ARG1 (h2 / health)))
                                    :ARG1 (o / offer-01
                                          :ARG0 t
                                          :ARG1 (d / degree
                                                :ARG0-of (s3 / suffice-01)
                                                :quant-of (a2 / and
                                                      :op1 (o2 / opportunity)
                                                      :op2 (a3 / access-01)
                                                      :ARG1-of (e2 / equal-01)))
                                          :ARG3 (p2 / person
                                                :mod (a4 / all)
                                                :ARG1-of (s4 / serve-01
                                                      :ARG0 (s5 / system
                                                            :mod c))
                                                :ARG2-of (d2 / deplo-00)
                                                :ARG2-of (ii2 / include-91
                                                      :ARG1 (g / group
                                                            :ARG1-of (m / minor-01)))))
                                    :mod (e3 / every))))
                  :ARG1-of (r2 / reasonable-02)))
      :ARG2 (d3 / define-01
            :polarity -
            :ARG1 (f / fairness)
            :ARG1-of (a5 / agree-01
                  :manner (u / universal))))

# ::snt https://developers.google.com/machine -learning/crash -course/fairness/video -lecture.
# File 40

(h / hyperlink-91
      :ARG3 (u / url-entity
            :value "https://developers.google.com/machine-learning/crash-course/fairness/video -lecture"))

# ::snt Verma S, Rubin J (2018) Fairness definitions explained.
# File 40

(e / explain-01
      :ARG1 (d / define-01
            :ARG1 (f / fairness))
      :ARG1-of (p / publication-91
            :ARG0 (a / and
                  :op1 (p2 / person
                        :name (n / name
                              :op1 "Verma"))
                  :op2 (p3 / person
                        :name (n2 / name
                              :op1 "Rubin")))
            :time (d2 / date-entity
                  :year 2018)))

# ::snt Speciﬁcally it covers the crucial issues of Fairness, Accountability, Transparency and Explainability of the algorithms at the heart of AI systems.
# File 154

(c / cover-01
      :ARG0 (ii / it)
      :ARG1 (ii2 / issue-02
            :ARG0 (a / and
                  :op1 (f / fairness)
                  :op2 (a2 / accountable-02)
                  :op3 (t / transparency)
                  :op4 (p / possible-01
                        :ARG1 (e / explain-01))
                  :poss (a3 / algorithm
                        :location (h / heart
                              :part-of (s / system
                                    :mod (ii3 / intelligent-01
                                          :mod (a4 / artificial))))))
            :mod (c2 / crucial))
      :mod (p2 / precise))

# ::snt Speciﬁcally it covers the crucial issues of Fairness, Accountability, Transparency and Explainability of the algorithms at the heart of AI systems.
# File 154

(c / cover-01
      :ARG0 (ii / it)
      :ARG1 (ii2 / issue-02
            :ARG0 (a / and
                  :op1 (f / fairness)
                  :op2 (a2 / accountable-02)
                  :op3 (t / transparency)
                  :op4 (p / possible-01
                        :ARG1 (e / explain-01))
                  :poss (a3 / algorithm
                        :location (h / heart
                              :part-of (s / system
                                    :mod (ii3 / intelligent-01
                                          :mod (a4 / artificial))))))
            :mod (c2 / crucial))
      :mod (p2 / precise))

# ::snt ETHICS (as applied to AI)  The concepts of fairness, accountability, transparency and explainability.Note 1 to entry: for the purposes of this document, ethics does not include privacy  concerns, model accuracy (except insofar as fairness and redress are concerned, for example), employment, or any other AI-related issues besides those listed in the deﬁnition.
# File 154

(m / multi-sentence
      :snt1 (e / ethics
            :ARG1-of (a / apply-02
                  :ARG2 (ii / intelligent-01
                        :mod (a2 / artificial))))
      :snt2 (c / concept
            :domain (a3 / and
                  :op1 (f / fairness)
                  :op2 (a4 / accountable-02)
                  :op3 (t / transparency)
                  :op4 (e2 / explain-01)))
      :snt3 (ii2 / include-01
            :polarity -
            :ARG1 (o / or
                  :op1 (c2 / concern-01
                        :ARG0 (p / privacy))
                  :op2 (a5 / accurate
                        :mod (m2 / model))
                  :op3 (e3 / employ-01)
                  :op4 (ii3 / issue-02
                        :ARG1-of (r / relate-01
                              :ARG2 ii)
                        :mod (o2 / other)
                        :ARG2-of (e4 / except-01
                              :ARG1 (c3 / concern-02
                                    :ARG0 (a6 / and
                                          :op1 (f2 / fairness)
                                          :op2 (r2 / redress-01))
                                    :ARG1-of (e5 / exemplify-01)))))
            :ARG2 (e6 / ethics)
            :purpose (d / document
                  :mod (t2 / this)))
      :snt4 (n / note
            :mod 1
            :prep-to (e7 / enter-01)))

# ::snt ETHICS (as applied to AI)  The concepts of fairness, accountability, transparency and explainability.Note 1 to entry: for the purposes of this document, ethics does not include privacy  concerns, model accuracy (except insofar as fairness and redress are concerned, for example), employment, or any other AI-related issues besides those listed in the deﬁnition.
# File 154

(m / multi-sentence
      :snt1 (e / ethics
            :ARG1-of (a / apply-02
                  :ARG2 (ii / intelligent-01
                        :mod (a2 / artificial))))
      :snt2 (c / concept
            :domain (a3 / and
                  :op1 (f / fairness)
                  :op2 (a4 / accountable-02)
                  :op3 (t / transparency)
                  :op4 (e2 / explain-01)))
      :snt3 (ii2 / include-01
            :polarity -
            :ARG1 (o / or
                  :op1 (c2 / concern-01
                        :ARG0 (p / privacy))
                  :op2 (a5 / accurate
                        :mod (m2 / model))
                  :op3 (e3 / employ-01)
                  :op4 (ii3 / issue-02
                        :ARG1-of (r / relate-01
                              :ARG2 ii)
                        :mod (o2 / other)
                        :ARG2-of (e4 / except-01
                              :ARG1 (c3 / concern-02
                                    :ARG0 (a6 / and
                                          :op1 (f2 / fairness)
                                          :op2 (r2 / redress-01))
                                    :ARG1-of (e5 / exemplify-01)))))
            :ARG2 (e6 / ethics)
            :purpose (d / document
                  :mod (t2 / this)))
      :snt4 (n / note
            :mod 1
            :prep-to (e7 / enter-01)))

# ::snt ETHICS (as applied to AI)  The concepts of fairness, accountability, transparency and explainability.Note 1 to entry: for the purposes of this document, ethics does not include privacy  concerns, model accuracy (except insofar as fairness and redress are concerned, for example), employment, or any other AI-related issues besides those listed in the deﬁnition.
# File 154

(m / multi-sentence
      :snt1 (e / ethics
            :ARG1-of (a / apply-02
                  :ARG2 (ii / intelligent-01
                        :mod (a2 / artificial))))
      :snt2 (c / concept
            :domain (a3 / and
                  :op1 (f / fairness)
                  :op2 (a4 / accountable-02)
                  :op3 (t / transparency)
                  :op4 (e2 / explain-01)))
      :snt3 (ii2 / include-01
            :polarity -
            :ARG1 (o / or
                  :op1 (c2 / concern-01
                        :ARG0 (p / privacy))
                  :op2 (a5 / accurate
                        :mod (m2 / model))
                  :op3 (e3 / employ-01)
                  :op4 (ii3 / issue-02
                        :ARG1-of (r / relate-01
                              :ARG2 ii)
                        :mod (o2 / other)
                        :ARG2-of (e4 / except-01
                              :ARG1 (c3 / concern-02
                                    :ARG0 (a6 / and
                                          :op1 (f2 / fairness)
                                          :op2 (r2 / redress-01))
                                    :ARG1-of (e5 / exemplify-01)))))
            :ARG2 (e6 / ethics)
            :purpose (d / document
                  :mod (t2 / this)))
      :snt4 (n / note
            :mod 1
            :prep-to (e7 / enter-01)))

# ::snt When evaluating the fairness of an AI system, AI developer organisations  and AI operator organisations should consider whether AI subjects in the same circumstances receive equal treatment EXAMPLE: An organisation uses an AI tool to automate the pre-screening of candidates for a job opening.
# File 154

(m / multi-sentence
      :snt1 (r / recommend-01
            :ARG1 (c / consider-02
                  :ARG0 (a / and
                        :op1 (o / organization
                              :ARG0-of (d / develop-02
                                    :ARG1 (ii / intelligent-01
                                          :mod (a2 / artificial))))
                        :op2 (o2 / organization
                              :ARG0-of (o3 / operate-01
                                    :ARG1 (ii2 / intelligent-01
                                          :mod (a3 / artificial)))))
                  :ARG1 (t / truth-value
                        :polarity-of (t2 / treat-01
                              :ARG1 (s / subject
                                    :mod (ii3 / intelligent-01))
                              :ARG1-of (e / equal-01)
                              :time (c2 / circumstance
                                    :ARG1-of (s2 / same-01))))
                  :time (e2 / evaluate-01
                        :ARG1 (f / fair-01
                              :ARG1 (s3 / system
                                    :mod (ii4 / intelligent-01))))))
      :snt2 (e3 / exemplify-01
            :ARG0 (u / use-01
                  :ARG0 (o4 / organization)
                  :ARG1 (t3 / tool
                        :mod (a4 / artificial))
                  :ARG2 (a5 / automate-01
                        :ARG0 o4
                        :ARG1 (s4 / screen-01
                              :ARG1 (c3 / candidate)
                              :time (b / before
                                    :op1 (o5 / open-02
                                          :ARG1 (j / job))))))))

# ::snt AI developer organisations and AI operator organisations could consider formal procedures such as Discrimination Impact Assessments as a means of ensuring fairness       1.1.4.
# File 154

(p / possible-01
      :ARG1 (c / consider-02
            :ARG0 (a / and
                  :op1 (o / organization
                        :ARG0-of (d / develop-02
                              :ARG1 (a2 / artificial-intelligence)))
                  :op2 (o2 / organization
                        :ARG0-of (o3 / operate-01
                              :ARG1 (a3 / artificial-intelligence))))
            :ARG1 (p2 / procedure
                  :mod (f / formal)
                  :example (a4 / assess-01
                        :ARG1 (ii / impact-01
                              :ARG0 (d2 / discriminate-02))))
            :ARG2 (e / ensure-01
                  :ARG0 p2
                  :ARG1 (f2 / fair-01))))

# ::snt AI operator organisations could consider “crowd challenge” mechanisms  whereby a critical number of complaints triggers an investigation into the fairness and/or accuracy of a decision-making process as a whole 7 Adapted from EU Commission, Can I be subject to automated individual decision-making, including proﬁling?
# File 154

(m / multi-sentence
      :snt1 (p / possible-01
            :ARG1 (c / consider-02
                  :ARG0 (o / organization
                        :ARG0-of (o2 / operate-01
                              :ARG1 (a / artificial-physical)))
                  :ARG1 (m2 / mechanism
                        :ARG0-of (c2 / challenge-01
                              :ARG1 (c3 / crowd))
                        :ARG1-of (m3 / mean-01
                              :ARG2 (t / trigger-01
                                    :ARG0 (c4 / complain-01
                                          :quant (n / number
                                                :ARG1-of (c5 / critical-02)))
                                    :ARG1 (ii / investigate-01
                                          :ARG1 (a2 / and-or
                                                :op1 (f / fairness)
                                                :op2 (a3 / accuracy)
                                                :poss (p2 / process-02
                                                      :ARG1 (d / decide-01)
                                                      :extent (w / whole)))))))))
      :snt2 (p3 / possible-01
            :ARG1 (s / subject-01
                  :ARG1 (ii2 / i)
                  :ARG2 (a4 / automate-01
                        :ARG1 (d2 / decide-01
                              :mod (ii3 / individual)
                              :ARG2-of (ii4 / include-01
                                    :ARG1 (p4 / propaganda)))))
            :ARG1-of (a5 / adapt-01
                  :ARG3 (o3 / organization
                        :name (n2 / name
                              :op1 "EU"
                              :op2 "Commission")))
            :polarity (a6 / amr-unknown)))

# ::snt © Tieto Corporation1Tieto’s AI ethics guidelinesHuman rightsEnsuringthe freedomand libertyor peopleto serve the social good.Safety & securityAI systemsarebuiltto preventmisuseand reducetheriskof beingcompromised.Responsibility CommittedtoharnessAI forgood,fortheplanet andhumankind.Fairness & equalityUnbiased, fairandinclusiveAI fosteringdiversityandequalityamongpeople.TransparencyStrivingtowardsAI thatcanbeexplainedandexplainitself.
# File 15

(m / multi-sentence
      :snt1 (c / copyright-01
            :ARG0 (c2 / company
                  :name (n / name
                        :op1 "Tieto"
                        :op2 "Corporation1Tieto's"
                        :op3 "Ethics"
                        :op4 "Guidelines"))
            :ARG1 (g / guideline
                  :topic (ii / intelligent-01
                        :mod (a / artificial))))
      :snt2 (e / ensure-01
            :ARG0 (r / right-05
                  :ARG1 (h / human))
            :ARG1 (s / serve-01
                  :ARG0 (o / or
                        :op1 (f / free-04)
                        :op2 (l / liberty)
                        :op3 (p / person))
                  :ARG1 (g2 / good-04
                        :ARG1 (s2 / society))))
      :snt3 (p2 / prove-01
            :ARG0 (s3 / system
                  :mod (ii2 / intelligent-01
                        :mod a)))
      :ARG1 (a2 / and
            :op1 (s4 / safe-01)
            :op2 (s5 / security))
      :purpose (p3 / prevent-01
            :ARG0 s3
            :ARG1 (a3 / and
                  :op1 (m2 / misuse-01)
                  :op2 (r2 / reduce-01
                        :ARG1 (c3 / compromise-02))))
      :snt4 (r3 / responsible-03
            :ARG0 r3)
      :ARG1 (f2 / forgive-01
            :ARG0 ii2
            :ARG1 (a4 / and
                  :op1 (p4 / planet)
                  :op2 h)
            :op3 (h2 / humankind))
      :snt5 (a5 / and
            :op1 (b / bias-01
                  :polarity -
                  :ARG1 ii2)
            :op2 (f3 / fair-01
                  :polarity -
                  :ARG1 ii2)
            :op3 (ii3 / inclusive
                  :domain ii2)
            :ARG0-of (f4 / foster-01
                  :ARG1 (a6 / and
                        :op1 (d / diversity)
                        :op2 (e2 / equal-01))))
      :snt6 (t / transparency))

# ::snt Artificial intelligence and machine learning technologies  should  be designed, developed and used in  respect of fundamental human rights  and in accordance with the fairness principle , in particular by:   a.
# File 22

(r / recommend-01
      :li "a"
      :ARG1 (a / and
            :op1 (d / design-01
                  :ARG1 (a2 / and
                        :op1 (t / technology
                              :mod (a3 / artificial))
                        :op2 (t2 / technology
                              :mod (m / machine)
                              :instrument-of (l / learn-01))))
            :op2 (d2 / develop-02
                  :ARG1 a2)
            :op3 (u / use-01
                  :ARG1 a2)
            :purpose (r2 / respect-01
                  :ARG1 (r3 / right-05
                        :ARG1 (h / human)
                        :mod (f / fundamental)))
            :ARG1-of (a4 / accord-02
                  :ARG2 (p / principle
                        :topic (f2 / fairness))
                  :mod (p2 / particular))))

# ::snt 2  HARNESSING THE POWER  OF AI AND EMERGING TECHNOLOGIES   OECD DIGITAL ECONOMY PAPE RS    Foreword   This paper explores the opportunities and risks posed by AI and emerging technologies , including risks to  human rights, fairness and human agency.
# File 136

(m / multi-sentence
      :snt1 (p / publication
            :li 2
            :name (n / name
                  :op1 "Harnessing"
                  :op2 "the"
                  :op3 "Power"
                  :op4 "of"
                  :op5 "AI"
                  :op6 "and"
                  :op7 "Emerging"
                  :op8 "Technologies"))
      :snt2 (p2 / publication
            :name (n2 / name
                  :op1 "OECD"
                  :op2 "DIGITAL"
                  :op3 "ECONOMY"
                  :op4 "PAPE"
                  :op5 "RS"))
      :snt3 (p3 / publication
            :name (n3 / name
                  :op1 "Foreword"))
      :snt4 (e / explore-01
            :ARG0 (p4 / paper
                  :mod (t / this))
            :ARG1 (a / and
                  :op1 (o / opportunity)
                  :op2 (r / risk-01)
                  :ARG1-of (p5 / pose-02
                        :ARG0 (a2 / and
                              :op1 (ii / intelligent-01
                                    :mod (a3 / artificial))
                              :op2 (t2 / technology
                                    :ARG0-of (e2 / emerge-01))))
                  :ARG2-of (ii2 / include-01
                        :ARG1 (r2 / risk-01
                              :ARG2 (a4 / and
                                    :op1 (r3 / right-05
                                          :ARG1 (h / human))
                                    :op2 (f / fairness)
                                    :op3 (a5 / agency
                                          :mod h)))))))

# ::snt However, they also pose risks to human rights, fairness and human  agency, among others.
# File 136

(c / contrast-01
      :ARG2 (p / pose-02
            :ARG0 (t / they)
            :ARG1 (r / risk-01
                  :ARG2 (a / and
                        :op1 (r2 / right-05
                              :ARG1 (h / human))
                        :op2 (f / fairness)
                        :op3 (a2 / agency
                              :mod h)
                        :op4 (o / other)))
            :mod (a3 / also)))

# ::snt By adopting the OECD AI Principles , countries  agree d to a common set of priorities to promote and harness  the power of trustworthy AI, namely that AI systems: (1)  benefit people and the planet ; (2) respect  democratic values and human rights, includin g privacy and fairness; (3) be transparent and explainable;  (4) be robust, secure  and safe; and (5) hold AI actors accountable for their proper functioning .
# File 136

(a / agree-01
      :ARG0 (c / country)
      :ARG1 (s / set
            :consist-of (p / priority
                  :ARG1-of (s2 / share-01)
                  :purpose (a2 / and
                        :op1 (p2 / promote-02
                              :ARG1 (p3 / power-01
                                    :ARG0 (ii / intelligent-01
                                          :mod (a3 / artificial))
                                    :mod (t / trustworthy)))
                        :op2 (h / harness-01
                              :ARG1 p3))
                  :ARG1-of (m / mean-01
                        :ARG2 (a4 / and
                              :op1 (b / benefit-01
                                    :li 1
                                    :ARG0 (s3 / system
                                          :mod ii)
                                    :ARG1 (a5 / and
                                          :op1 (p4 / person)
                                          :op2 (p5 / planet)))
                              :op2 (r / respect-01
                                    :li 2
                                    :ARG0 s3
                                    :ARG1 (a6 / and
                                          :op1 (v / value
                                                :mod (d / democracy))
                                          :op2 (r2 / right-05
                                                :ARG1 (h2 / human))
                                          :ARG2-of (ii2 / include-01
                                                :ARG1 (a7 / and
                                                      :op1 (p6 / private-02)
                                                      :op2 (f / fairness)))))
                              :op3 (a8 / and
                                    :li 3
                                    :op1 (t2 / transparent)
                                    :op2 (p7 / possible-01
                                          :ARG1 (e / explain-01)))
                              :op4 (a9 / and
                                    :li 4
                                    :op1 (r3 / robust)
                                    :op2 (s4 / secure)
                                    :op3 (s5 / safe-01))
                              :op5 (h3 / hold-02
                                    :li 5
                                    :ARG0 s3
                                    :ARG1 (a10 / accountable-02
                                          :ARG0 p4
                                          :ARG0-of (a11 / act-01
                                                :mod ii))
                                    :ARG1 (f2 / function-01
                                          :ARG0 p4
                                          :mod (p8 / proper)))))))
      :manner (a12 / adopt-01
            :ARG0 c
            :ARG1 (p9 / principle
                  :mod ii
                  :mod (o / organization
                        :name (n / name
                              :op1 "OECD")))))

# ::snt [47]  Buolamwini,  J. and T.  Gebru (2018), “Gender shades: Intersectional accuracy disparities in  commercial gender classification”, Proceedings of Machine Learning Research: Conference  on fairness, accountability  and transparency , Vol.
# File 136

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Buolamwini"))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "J."
                        :op2 "T."
                        :op3 "Gebru")))
      :ARG1 (p4 / publication
            :name (n3 / name
                  :op1 "Gender"
                  :op2 "Shadows"
                  :op3 ":"
                  :op4 "Intersectional"
                  :op5 "Disparity"
                  :op6 "in"
                  :op7 "Commercial"
                  :op8 "Gender"
                  :op9 "Classification"))
      :ARG4 (j / journal
            :name (n4 / name
                  :op1 "Proceedings"
                  :op2 "of"
                  :op3 "Machine"
                  :op4 "Learning"
                  :op5 "Research:"
                  :op6 "Conference")
            :topic (a2 / and
                  :op1 (f / fairness)
                  :op2 (a3 / accountable-02)
                  :op3 (t / transparency)))
      :ARG7 (v / volume
            :mod 47)
      :time (d / date-entity
            :year 2018))

# ::snt For example, how do we, as a society, think about fairness?
# File 101

(e / exemplify-01
      :ARG0 (t / think-01
            :ARG0 (w / we
                  :mod (s / society))
            :ARG1 (f / fair-01)
            :ARG2 (a / amr-unknown)))

# ::snt For example: • Our open-source RAPPOR technology:  deployed worldwide as the first large-scale  data-collection mechanism with strong  protection guarantees of local differential  privacy8 • Secure aggregation protocol for federated  learning model updates: provides strong  cryptographic privacy for individual user’s  updates, averaging only updates from large  groups of participants9 Fairness AI systems are shaped by what their training data leaves out and what it over-represents.
# File 101

(e / exemplify-01
      :li 8
      :ARG0 (a / and
            :op1 (t / technology
                  :name (n / name
                        :op1 "RAPPOR")
                  :mod (s / source
                        :ARG1-of (o / open-04))
                  :poss (w / we)
                  :ARG1-of (d / deploy-01
                        :ARG2 (w2 / worldwide)
                        :manner (m / mechanism
                              :mod (c / collect-01
                                    :ARG1 (d2 / data))
                              :mod (l / large-scale)
                              :ARG0-of (p / protect-01
                                    :ARG1 (p2 / privacy
                                          :ARG1-of (l2 / local-02)
                                          :mod (d3 / differential))
                                    :ARG1-of (s2 / strong-02))
                              :ord (o2 / ordinal-entity
                                    :value 1))))
            :op2 (p3 / protocol
                  :ARG0-of (s3 / secure-02)
                  :instrument-of (a2 / aggregate-01
                        :ARG1 (u / update-01
                              :ARG1 (m2 / model
                                    :mod (l3 / learn-01)
                                    :ARG1-of (f / federate-01))))
                  :ARG0-of (p4 / provide-01
                        :ARG1 (p5 / privacy
                              :mod (c2 / cryptography)
                              :ARG1-of (s4 / strong-02))
                        :ARG2 (u2 / update-01
                              :ARG0 (p6 / person
                                    :ARG0-of (u3 / use-01)
                                    :mod (ii / individual))
                              :ARG1-of (a3 / average-01
                                    :ARG2 (u4 / update-01
                                          :ARG0 (g / group
                                                :mod (l4 / large)
                                                :consist-of (p7 / person
                                                      :ARG0-of (p8 / participate-01)))
                                          :mod (o3 / only))))))
            :op3 (s5 / shape-01
                  :ARG0 (a4 / and
                        :op1 (t2 / thing
                              :ARG1-of (l5 / leave-out-03
                                    :ARG0 (d4 / data
                                          :ARG2-of (t3 / train-01
                                                :ARG0 (s6 / system))))
                              :op2 (t4 / thing
                                    :ARG1-of (r / represent-01
                                          :ARG0 d4
                                          :ARG2-of (o4 / over-03))))
                        :ARG1 s6
                        :mod (a5 / artificial)
                        :mod (f2 / fairness)))))

# ::snt Addressing these disparate outcomes is a primary goal in the emerging research area of fairness in machine learning.
# File 101

(g / goal
      :mod (p / primary)
      :topic (a / area
            :ARG0-of (r / research-01)
            :ARG0-of (e / emerge-02)
            :mod (f / fairness
                  :topic (l / learn-01
                        :manner (m / machine))))
      :domain (a2 / address-02
            :ARG1 (o / outcome
                  :mod (d / disparate)
                  :mod (t / this))))

# ::snt • Our Privacy Working Group and ML Fairness teams will assess relevant issues in   the context of new tools that incorporate AI.
# File 101

(a / assess-01
      :ARG0 (a2 / and
            :op1 (g / group
                  :name (n / name
                        :op1 "Privacy"
                        :op2 "Working"
                        :op3 "Group")
                  :poss (w / we))
            :op2 (t / team
                  :name (n2 / name
                        :op1 "ML"
                        :op2 "Fairness")
                  :poss w))
      :ARG1 (ii / issue-02
            :ARG1-of (r / relevant-01))
      :topic (t2 / tool
            :ARG1-of (n3 / new-01)
            :ARG0-of (ii2 / incorporate-02
                  :ARG1 (ii3 / intelligent-01
                        :mod (a3 / artificial)))))

# ::snt The conceptual complexities surrounding what “values” are (e.g., Hitlin and Piliavin, 2004;  Malle and Dickert, 2007; Rohan, 2000; Sommer, 2016) make it currently difficult to envision  A/IS that have computational structures directly corresponding to social or cultural values  (such as “security,” “autonomy,” or “fairness”).
# File 1

(m / make-02
      :ARG0 (c / complexity
            :mod (c2 / conceptual)
            :ARG0-of (s / surround-01
                  :ARG1 (v / value))
            :example (a / and
                  :op1 (a2 / and
                        :op1 (p / person
                              :name (n / name
                                    :op1 "Hitlin"))
                        :op2 (p2 / person
                              :name (n2 / name
                                    :op1 "Pilus"))
                        :time (d / date-entity
                              :year 2004))
                  :op2 (a3 / and
                        :op1 (p3 / person
                              :name (n3 / name
                                    :op1 "Malle"))
                        :op2 (p4 / person
                              :name (n4 / name
                                    :op1 "Dickert"))
                        :time (d2 / date-entity
                              :year 2007))
                  :op3 (p5 / person
                        :name (n5 / name
                              :op1 "Rohan")
                        :time (d3 / date-entity
                              :year 2000))
                  :op4 (p6 / person
                        :name (n6 / name
                              :op1 "Sommer")
                        :time (d4 / date-entity
                              :year 2016))))
      :ARG1 (d5 / difficult
            :domain (e / envision-01
                  :ARG1 (s2 / slash
                        :op1 (a4 / analyze-01)
                        :op2 (s3 / science
                              :mod (ii / information))
                        :ARG0-of (h / have-03
                              :ARG1 (s4 / structure
                                    :mod (c3 / computational)
                                    :ARG1-of (c4 / correspond-02
                                          :ARG2 (o / or
                                                :op1 (v2 / value
                                                      :mod (s5 / society))
                                                :op2 (v3 / value
                                                      :mod (c5 / culture))
                                                :example o
                                                :op1 (s6 / security)
                                                :op2 (a5 / autonomy)
                                                :op3 (f / fairness)))
                                    :ARG1-of (d6 / direct-02))))))
      :time (c6 / current))

# ::snt For instance, an organization can refer to the “trade-offs” (or “value trade-offs”) involved in the examination of the fairness of an algorithm to a specific end user population.
# File 1

(e / exemplify-01
      :ARG0 (p / possible-01
            :ARG1 (r / refer-01
                  :ARG0 (o / organization)
                  :ARG1 (t / trade-off-02
                        :ARG1-of (ii / involve-01
                              :ARG2 (e2 / examine-01
                                    :ARG1 (f / fair-01
                                          :ARG1 f
                                          :ARG1 (a / algorithm)
                                          :ARG2 (p2 / population
                                                :ARG2-of (ii2 / include-91
                                                      :ARG1 (p3 / person
                                                            :ARG0-of (u / use-01
                                                                  :mod (e3 / end)))
                                                      :ARG1-of (s / specific-02)))))))
                  :ARG1-of (m / mean-01
                        :ARG2 (t2 / trade-off-02
                              :ARG1 (v / value))))))

# ::snt Organizational members must ensure that the technologies they create enhance meaningful human control over increasingly sophisticated systems and do not undermine or eliminate the values of respect, humanity, fairness, and dignity.
# File 1

(o / obligate-01
      :ARG2 (e / ensure-01
            :ARG0 (p / person
                  :ARG0-of (h / have-org-role-91
                        :ARG1 (o2 / organization)
                        :ARG2 (m / member)))
            :ARG1 (a / and
                  :op1 (e2 / enhance-01
                        :ARG0 (t / technology
                              :ARG1-of (c / create-01
                                    :ARG0 p))
                        :ARG1 (c2 / control-01
                              :ARG0 (h2 / human)
                              :ARG1 (s / system
                                    :mod (s2 / sophisticated
                                          :ARG1-of (ii / increase-01)))
                              :ARG0-of (m2 / meaningful-05)))
                  :op2 (o3 / or
                        :op1 (u / undermine-01
                              :polarity -
                              :ARG0 t
                              :ARG1 (v / value
                                    :example (a2 / and
                                          :op1 (r / respect-01)
                                          :op2 (h3 / humanity)
                                          :op3 (f / fairness)
                                          :op4 (d / dignity))))
                        :op2 (e3 / eliminate-01
                              :polarity -
                              :ARG0 t
                              :ARG1 v)))))

# ::snt • Zarsky, T. “ The Trouble with Algorithmic  Decisions: an Analytic Roadmap to Examine Efficiency and Fairness in Automated and Opaque Decision Making .” Science,  Technology & Human Values  41, no.
# File 1

(p / publication-91
      :ARG0 (p2 / person
            :name (n / name
                  :op1 "Zarsky"))
      :ARG1 (p3 / publication
            :name (n2 / name
                  :op1 "The"
                  :op2 "Trouble"
                  :op3 "with"
                  :op4 "Algorithmic"
                  :op5 "Decisions:"
                  :op6 "An"
                  :op7 "Analysis"
                  :op8 "Roadmap"
                  :op9 "to"
                  :op10 "Examine"
                  :op11 "and"
                  :op12 "Efficiency"
                  :op13 "and"
                  :op14 "Fairness"
                  :op15 "in"
                  :op16 "Automated"
                  :op17 "and"
                  :op18 "Op19 "
                  :op22 "Decision"))
      :ARG4 (j / journal
            :name (n3 / name
                  :op1 "Science,"
                  :op2 "Technology"
                  :op3 "and"
                  :op4 "Human"
                  :op5 "Values")
            :ord (o / ordinal-entity
                  :value 41)
            :ARG6 "No."))

# ::snt We recommend the following: • Enable a cross-disciplinary research  environment that encourages research on the fairness, security, transparency, understandability, privacy, and societal impacts of A/IS and that incorporates   independent means to properly vet, audit, and assign accountability to the A/IS applications.
# File 1

(r / recommend-01
      :ARG0 (w / we)
      :ARG1 (a / and
            :op1 (e / enable-01
                  :ARG1 (e2 / environment
                        :mod (r2 / research-01)
                        :mod (c / cross-disciplinary)
                        :ARG0-of (e3 / encourage-01
                              :ARG2 (r3 / research-01
                                    :ARG1 (a2 / and
                                          :op1 (f / fairness)
                                          :op2 (s / security)
                                          :op3 (t / transparency)
                                          :op4 (p / possible-01
                                                :ARG1 (u / understand-01))
                                          :op5 (p2 / privacy)
                                          :op6 (ii / impact-01
                                                :ARG0 (p3 / product
                                                      :name (n / name
                                                            :op1 "A/IS"))
                                                :ARG1 (s2 / society)))))
                        :ARG0-of (ii2 / incorporate-01
                              :ARG1 (m / means
                                    :ARG0-of (d / depend-01
                                          :polarity -)
                                    :instrument-of (a3 / and
                                          :op1 (v / vet-01
                                                :ARG1 (a4 / application
                                                      :mod p3)
                                                :manner (p4 / proper))
                                          :op2 (a5 / audit-01
                                                :ARG1 a4)
                                          :op3 (a6 / assign-01
                                                :ARG1 (a7 / accountable-02)
                                                :ARG2 a4))))))
            :ARG1-of (f2 / follow-04)))

# ::snt To better understand the societal implications of A/IS, we recommend that funding be increased for interdisciplinary research on topics ranging from basic research into intelligence to principles on ethics, safety, privacy, fairness, liability, and trustworthiness of A/IS technology.
# File 1

(r / recommend-01
      :ARG0 (w / we)
      :ARG1 (ii / increase-01
            :ARG1 (f / fund-01
                  :ARG1 (r2 / research-01
                        :ARG1 (t / topic
                              :ARG1-of (r3 / range-01
                                    :ARG3 (r4 / research-01
                                          :ARG1 (ii2 / intelligence)
                                          :mod (b / basic))
                                    :ARG4 (p / principle
                                          :topic (a / and
                                                :op1 (e / ethics)
                                                :op2 (s / safe-01)
                                                :op3 (p2 / privacy)
                                                :op4 (f2 / fairness)
                                                :op5 (l / liable-01)
                                                :op6 (d / deserve-01
                                                      :ARG0 (t2 / technology
                                                            :mod (s2 / slash
                                                                  :op1 (a2 / accident)
                                                                  :op2 (s3 / security)))
                                                      :ARG1 (t3 / trust-01))))))
                        :mod (ii3 / interdisciplinary))))
      :purpose (u / understand-01
            :ARG1 (ii4 / implicate-01
                  :ARG0 t2
                  :ARG1 (s4 / society))
            :ARG1-of (h / have-degree-91
                  :ARG2 (g / good-02
                        :ARG1 u)
                  :ARG3 (m / more))))

# ::snt 3Welcome 4 Foreword 5 Preliminary remarks 6  1 Introduction 7 2 Technological, philosophical, and legal perspectives 10 2.1 Initial situation and questions from IT 10  2.2 Initial situation and questions from philosophy 11 2.3 Initial situation and questions from law 12 2.4 Interdisciplinary observations 13 3	 Audit	areas	for	a	certification	system		 15 3.1 Autonomy and control 15 3.2 Fairness 16 3.3 Transparency 17 3.4 Reliability 18 3.5 Security 18 3.6 Data protection 18 4 Outlook 20 5 Imprint 21CONTENTS
# File 94

(m / multi-sentence
      :snt1 (w / welcome-01
            :ARG0 (ii / i)
            :ARG1 (y / you)
            :ARG2 (a / and
                  :op1 (f / foreword
                        :quant 4)
                  :op2 (r / remark-01
                        :quant 1)
                  :op3 (r2 / remark-01
                        :quant 7)
                  :op4 (r3 / remark-01
                        :quant 2)
                  :op5 (a2 / and
                        :op1 (p / perspective
                              :mod (t / technology))
                        :op2 (p2 / perspective
                              :mod (p3 / philosophy))
                        :op3 (p4 / perspective
                              :ARG1-of (l / legal-02)))
                  :snt2 (a3 / and
                        :op1 (s / situation
                              :mod (ii2 / initial))
                        :op2 (q / question-01
                              :ARG1 t))
                  :op3 (s2 / situation
                        :mod ii2)
                  :op4 (q2 / question-01
                        :ARG1 t))
            :snt3 (a4 / and
                  :op1 (s3 / situation
                        :mod ii2)
                  :op2 (q3 / question-01
                        :ARG1 p3))
            :snt4 (a5 / and
                  :op1 (s4 / situation
                        :mod ii2)
                  :op2 (l2 / law))
            :snt5 (a6 / and
                  :op1 (o / observe-01
                        :quant 13)
                  :op2 (o2 / observe-01
                        :quant 3)
                  :snt6 (a7 / and
                        :op1 (a8 / audit-01)
                        :op2 (c / control-01)
                        :snt7 (a9 / and
                              :op1 (a10 / autonomy)
                              :op2 (c2 / certify-01))
                        :snt8 (a11 / and
                              :op1 a10
                              :quant 15)
                        :op2 c)
                  :snt9 (a12 / and
                        :op1 (a13 / assert-02
                              :quant 3.2)
                        :op2 (a14 / assert-02
                              :quant 3.2))
                  :snt10 (a15 / and
                        :op1 (a16 / assert-02
                              :quant 17)
                        :op2 (r4 / rely-01
                              :quant 3.4))
                  :snt11 (a17 / and
                        :op1 (a18 / assert-02
                              :quant 18)
                        :op2 (s5 / security
                              :quant 3.5))
                  :snt12 (a19 / and
                        :op1 (a20 / assert-02
                              :quant 18)
                        :op2 (p5 / protect-01
                              :quant 20))
                  :snt13 (p6 / print-01
                        :quant 21))
            :snt14 (a21 / and
                  :op1 (a22 / assert-02
                        :quant 2)
                  :op2 (e / et-cetera))
            :snt15 e))

# ::snt As a result of this interdisciplinary  exchange,­it­also­defines­six­AI-specific­audit­areas­for­trustworthy­use­of­artificial­intelligence.­They­comprise­fairness, ­ transparency, autonomy and control, data protection as well  as security and reliability while addressing ethical and legal  requirements.
# File 94

(d / define-01
      :ARG0 (e / exchange-01
            :mod (ii / interdisciplinary)
            :mod (t / this))
      :ARG1 (a / audit-01
            :ARG1-of (s / specific-02
                  :ARG2 (ii2 / intelligent-01
                        :mod (a2 / artificial))))
      :ARG2 (a3 / and
            :op1 (f / fairness)
            :op2 (t2 / transparency)
            :op3 (a4 / autonomy)
            :op4 (c / control-01)
            :op5 (p / protect-01
                  :ARG1 (d2 / data))
            :op6 (a5 / and
                  :op1 (s2 / security)
                  :op2 (r / reliability)))
      :ARG2-of (r2 / result-01
            :ARG1 e)
      :time (a6 / address-02
            :ARG1 (t3 / thing
                  :ARG1-of (r3 / require-01)
                  :mod (e2 / ethics)
                  :ARG1-of (l / legal-02)))
      :ARG0-of a6
      :mod (a7 / also))

# ::snt Section 2.4 presents the effects of the different  interdisciplinary perspectives, in particular with regard to the  design­of­specific­AI­applications.­In­chapter­3,­the­specific ­ fundamental­audit­areas­are­then­justified­and­explained­in ­ separate sections from autonomy and control in section 3.1,  through fairness, transparency, reliability, and security, to data  protection in section 3.6.
# File 94

(a / and
      :op1 (p / present-01
            :ARG0 (s / section
                  :mod 2.4)
            :ARG1 (a2 / affect-01
                  :ARG0 (p2 / perspective
                        :ARG1-of (d / differ-02)
                        :mod (ii / interdisciplinary)
                        :topic (a3 / apply-02
                              :ARG1 (t / thing
                                    :ARG1-of (d2 / design-01)
                                    :ARG1-of (s2 / specific-02))))))
      :op2 (a4 / and
            :op1 (f / fairness)
            :op2 (t2 / transparency)
            :op3 (r / reliability)
            :op4 (s3 / security)
            :location (s4 / section
                  :mod 3.6))
      :op3 (p3 / protect-01
            :ARG1 (d3 / data)
            :location s4)
      :op4 (e / explain-01
            :ARG0 (c / chapter
                  :mod 3)
            :ARG1 (s5 / section
                  :ARG1-of (s6 / separate-01
                        :ARG2 (a5 / and
                              :op1 (a6 / autonomy)
                              :op2 (c2 / control-01)
                              :location s4))
                  :ARG1-of (s7 / specific-02))))

# ::snt They cover the areas of fairness, transparency, autonomy  and control, data protection as well as security and reliability.
# File 94

(c / cover-01
      :ARG0 (t / they)
      :ARG1 (a / and
            :op1 (a2 / and
                  :op1 (f / fairness)
                  :op2 (t2 / transparency)
                  :op3 (a3 / autonomy)
                  :op4 (c2 / control-01))
            :op2 (p / protect-01
                  :ARG1 (d / data))
            :op3 (s / security)
            :op4 (r / reliability)))

# ::snt They set out the framework within which AI applications  should move in their application context so that they do not  contradict ethical basic principles like fairness or transparency.
# File 94

(s / set-out-06
      :ARG0 (t / they)
      :ARG1 (f / framework
            :ARG2-of (m / move-01
                  :ARG0 (a / application
                        :mod (a2 / artificial))
                  :location (c / context
                        :mod (a3 / application))
                  :ARG1-of (r / recommend-01)
                  :purpose (c2 / contradict-01
                        :polarity -
                        :ARG0 a
                        :ARG1 (p / principle
                              :mod (b / basic)
                              :mod (e / ethics)
                              :example (o / or
                                    :op1 (f2 / fairness)
                                    :op2 (t2 / transparency)))))))

# ::snt Basic terms from philosophical ethics like justness, equality,  autonomy, fairness, and transparency etc.
# File 94

(t / term
      :mod (b / basic)
      :source (e / ethics
            :mod (p / philosophy))
      :example (a / and
            :op1 (j / just-02)
            :op2 (e2 / equal-01)
            :op3 (a2 / autonomy)
            :op4 (f / fair-01)
            :op5 (t2 / transparency)
            :op6 (e3 / et-cetera)))

# ::snt Many  other subsequent questions that result from  this – for  example, what fairness means in the context of the   application or what effects on the user, such as emotional  ties to the AI, are acceptable – cannot be answered from a  technological perspective alone, but instead require a holistic  approach again.If the general permissibility of the AI application has been  ensured, interdisciplinary questions also result for the  further development up to release, e.g.
# File 94

(p / possible-01
      :polarity -
      :ARG1 (a / answer-01
            :ARG1 (q / question-01
                  :ARG1 (o / or
                        :op1 (t / thing
                              :ARG2-of (m / mean-01
                                    :ARG1 (f / fairness)
                                    :location (c / context
                                          :mod (a2 / apply-02
                                                :ARG1 (ii / intelligent-01
                                                      :mod (a3 / artificial))))))
                        :op2 (t2 / thing
                              :ARG2-of (a4 / affect-01
                                    :ARG1 (p2 / person
                                          :ARG0-of (u / use-01)))
                              :ARG1-of (a5 / accept-01
                                    :ARG1-of (p3 / possible-01))
                              :example (t3 / tie-01
                                    :ARG1 (e / emotion)
                                    :ARG2 a2)))
                  :mod (o2 / other)
                  :quant (m2 / many)
                  :time (s / subsequent)
                  :ARG2-of (r / result-01
                        :ARG1 (t4 / this)))
            :ARG1-of (c2 / contrast-01
                  :ARG2 (r2 / require-01
                        :ARG1 (a6 / approach-02
                              :mod (h / holistic))
                        :mod (a7 / again))))
      :condition (e2 / ensure-01
            :ARG1 (p4 / permit-01
                  :ARG1 (a8 / apply-02
                        :ARG1 ii)
                  :ARG1-of (g / general-02)))
      :purpose (d / develop-02
            :mod (f2 / further)
            :time (u2 / up-to
                  :op1 (r3 / release-01)))
      :mod (ii2 / interdisciplinary))

# ::snt FAIRNESSDoes the AI application respect social values and laws?
# File 94

(r / respect-01
      :polarity (a / amr-unknown)
      :ARG0 (a2 / apply-02
            :ARG1 (ii / intelligent-01
                  :mod (a3 / artificial)))
      :ARG1 (a4 / and
            :op1 (v / value
                  :mod (s / society))
            :op2 (l / law
                  :mod s))
      :ARG1-of (f / fair-01))

# ::snt 3.2 Fairness Emanating from the general principle of equal treatment,  safeguarding the principle of fairness is to be required  from an AI application both in an ethical and in a legal  respect.
# File 94

(r / require-01
      :li 3
      :ARG1 (s / safeguard-01
            :ARG1 (p / principle
                  :topic (f / fairness)))
      :ARG2 (a / apply-02
            :ARG1 (ii / intelligent-01
                  :mod (a2 / artificial)))
      :manner (a3 / and
            :op1 (e / ethics)
            :op2 (r2 / respect-01
                  :ARG1 (f2 / fairness)
                  :ARG1-of (l / legal-02)))
      :ARG1-of (c / cause-01
            :ARG0 (e2 / establish-01
                  :ARG1 (p2 / principle
                        :ARG1-of (g / general-02)
                        :topic (t / treat-01
                              :ARG1-of (e3 / equal-01))))))

# ::snt 3.2 Fairness Emanating from the general principle of equal treatment,  safeguarding the principle of fairness is to be required  from an AI application both in an ethical and in a legal  respect.
# File 94

(r / require-01
      :li 3
      :ARG1 (s / safeguard-01
            :ARG1 (p / principle
                  :topic (f / fairness)))
      :ARG2 (a / apply-02
            :ARG1 (ii / intelligent-01
                  :mod (a2 / artificial)))
      :manner (a3 / and
            :op1 (e / ethics)
            :op2 (r2 / respect-01
                  :ARG1 (f2 / fairness)
                  :ARG1-of (l / legal-02)))
      :ARG1-of (c / cause-01
            :ARG0 (e2 / establish-01
                  :ARG1 (p2 / principle
                        :ARG1-of (g / general-02)
                        :topic (t / treat-01
                              :ARG1-of (e3 / equal-01))))))

# ::snt To­operationalize­fairness,­a­quantifiable­fairness­term­needs ­ to be respectively developed from a technical viewpoint.
# File 94

(n / need-01
      :ARG1 (d / develop-02
            :ARG1 (a / and
                  :op1 (f / fairness
                        :ARG1-of (o / operate-01))
                  :op2 (f2 / fairness
                        :ARG1-of (q / quantify-01
                              :ARG1-of (p / possible-01))))
            :manner (v / viewpoint
                  :mod (t / technical))))

# ::snt The  groups that should not be discriminated against therefore  need­to­be­identified­in­a­first­step.­These­groups­can­be ­ social minorities, but also companies or general legal persons  as is the case, for example, with pricing on digital marketplaces.­In­a­second­step,­the­chosen­fairness­definition­needs ­ to­be­quantified.­The­differentiation­of­group­fairness­and ­ individual fairness should be highlighted in particular in this  process.
# File 94

(m / multi-sentence
      :snt1 (n / need-01
            :ARG0 (g / group
                  :ARG1-of (d / discriminate-02
                        :polarity -
                        :ARG1-of (r / recommend-01)))
            :ARG1 (ii / identify-01
                  :ARG1 g
                  :ARG2 (s / step
                        :ord (o / ordinal-entity
                              :value 1)))
            :ARG1-of (c / cause-01
                  :ARG0 (p / possible-01
                        :ARG1 (c2 / contrast-01
                              :ARG1 (m2 / minority
                                    :mod (s2 / social)
                                    :domain (g2 / group
                                          :mod (t / this)))
                              :ARG2 (o2 / or
                                    :op1 (c3 / company)
                                    :op2 (p2 / person
                                          :ARG1-of (l / legal-02)
                                          :ARG1-of (g3 / general-02))
                                    :example (p3 / price-01
                                          :location (m3 / marketplace
                                                :mod (d2 / digital))))))))
      :snt2 (r2 / recommend-01
            :ARG1 (h / highlight-01
                  :ARG0 (p4 / process-02
                        :mod (t2 / this))
                  :ARG1 (f / fairness
                        :ARG3-of (d3 / differ-02
                              :ARG1 (g4 / group))
                        :ARG3 (f2 / fairness
                              :mod (ii2 / individual)))
                  :mod (p5 / particular)))
      :snt3 (n2 / need-01
            :ARG1 (q / quantify-01
                  :ARG1 (d4 / define-01
                        :ARG1 (f3 / fairness
                              :ARG1-of (c4 / choose-01))))))

# ::snt Regarding group fairness, it should be required  that the results for all existing groups are comparable, for  example, in the sense of “hit probability” in all groups.
# File 94

(r / recommend-01
      :ARG1 (r2 / require-01
            :ARG1 (c / compare-01
                  :ARG1 (r3 / result-01
                        :ARG1 (g / group
                              :ARG1-of (e / exist-01)
                              :mod (a / all)))
                  :ARG0-of (e2 / exemplify-01
                        :ARG1 (p / probability
                              :mod (h / hit-01)
                              :mod (g2 / group
                                    :mod (a2 / all))))))
      :topic (f / fair-01
            :ARG1 g2))

# ::snt 17AUDIT AREAS FOR A CERTIFICATION SYSTEM   case of individual fairness, the same treatment of the same  individuals is set   as a standard.
# File 94

(m / multi-sentence
      :snt1 (a / area
            :quant 17
            :purpose (a2 / audit-01)
            :part-of (s / system
                  :mod (c / certify-01)))
      :snt2 (s2 / set-02
            :ARG1 (t / treat-01
                  :ARG1 (ii / individual
                        :ARG1-of (s3 / same-01))
                  :ARG1-of (s4 / same-01))
            :ARG2 (s5 / standard)
            :condition (f / fairness
                  :mod (ii2 / individual))))

# ::snt This includes  understanding what purpose the application has, what it  does, what the potential risks are (also in terms of other  audit areas, for example, reliability, security, and fairness),  and who the target group of the application is.
# File 94

(ii / include-01
      :ARG1 (a / and
            :op1 (u / understand-01
                  :ARG1 (a2 / and
                        :op1 (h / have-purpose-91
                              :ARG1 (a3 / application))
                        :op2 (t / thing
                              :ARG1-of (d / do-02
                                    :ARG0 a3))
                        :op3 (t2 / thing
                              :ARG1-of (r / risk-01
                                    :mod (p / potential))
                              :topic (a4 / area
                                    :ARG2-of (a5 / audit-01)
                                    :mod (o / other)
                                    :example (a6 / and
                                          :op1 (r2 / rely-01
                                                :ARG1-of (p2 / possible-01))
                                          :op2 (s / security)
                                          :op3 (f / fairness))))))
            :op2 (g / group
                  :ARG1-of (t3 / target-01)
                  :domain a3))
      :ARG2 (t4 / this))

# ::snt Ethical principles of respect for  human autonomy, prevention of harm, fairness, explicability, and privacy were charted.
# File 180

(c / chart-01
      :ARG1 (p / principle
            :mod (e / ethics)
            :domain (a / and
                  :op1 (r / respect-01
                        :ARG1 (a2 / autonomy
                              :mod (h / human)))
                  :op2 (p2 / prevent-01
                        :ARG1 (h2 / harm-01))
                  :op3 (f / fair-01)
                  :op4 (p3 / possible-01
                        :ARG1 (e2 / explain-01))
                  :op5 (p4 / private-02))))

# ::snt In the few instances where ethical principles were  considered, fairness, preservation of human autonomy, explicability and privacy were equally discussed.
# File 180

(d / discuss-01
      :ARG1 (a / and
            :op1 (f / fairness)
            :op2 (p / preserve-01
                  :ARG1 (a2 / autonomy
                        :mod (h / human)))
            :op3 (p2 / possible-01
                  :ARG1 (e / explain-01))
            :op4 (p3 / private-02))
      :ARG3-of (e2 / equal-01)
      :location (ii / instance
            :quant (f2 / few)
            :time-of (c / consider-02
                  :ARG1 (p4 / principle
                        :mod (e3 / ethics)))))

# ::snt It is important to build information systems that are capable  of detecting unfairness and dealing with it in an adequate  manner.
# File 180

(ii / important-01
      :ARG1 (b / build-01
            :ARG1 (s / system
                  :mod (ii2 / information)
                  :ARG1-of (c / capable-01
                        :ARG2 (a / and
                              :op1 (d / detect-01
                                    :ARG0 s
                                    :ARG1 (f / fairness
                                          :polarity -))
                              :op2 (d2 / deal-01
                                    :ARG0 s
                                    :ARG2 f
                                    :manner (a2 / adequate)))))))

# ::snt Provisions regarding information systems ought to also respect the regional  and national legal framework related to the Personal Data  Protection (lawfulness, fairness, and transparency, purpose  limitation, data minimization, accuracy, storage limitation, integrity and confidentiality, accountability).
# File 180

(r / recommend-01
      :ARG1 (r2 / respect-01
            :ARG0 (p / provide-01
                  :ARG2 (s / system
                        :mod (ii / information)))
            :ARG1 (a / and
                  :op1 (f / framework
                        :mod (r3 / region)
                        :ARG1-of (l / legal-02))
                  :op2 (f2 / framework
                        :mod (n / nation)
                        :ARG1-of (l2 / legal-02))
                  :ARG1-of (r4 / relate-01
                        :ARG2 (l3 / law
                              :name (n2 / name
                                    :op1 "Personal"
                                    :op2 "Data"
                                    :op3 "Protection")))
                  :ARG1-of (m / mean-01
                        :ARG2 (a2 / and
                              :op1 (l4 / law)
                              :op2 (f3 / fairness)
                              :op3 (t / transparency)
                              :op4 (l5 / limit-01
                                    :ARG1 (p2 / purpose))
                              :op5 (m2 / minimize-01
                                    :ARG1 (d / data))
                              :op6 (a3 / accurate)
                              :op7 (l6 / limit-01
                                    :ARG1 (s2 / store-01))
                              :op8 (a4 / and
                                    :op1 (ii2 / integrity)
                                    :op2 (c / confidentiality))
                              :op9 (a5 / accountable-02))))
            :mod (a6 / also)))

# ::snt These ethical principles are respect for human autonomy,  prevention of harm, fairness, and explicability.
# File 180

(p / principle
      :mod (e / ethics)
      :domain (a / and
            :op1 (r / respect-01
                  :ARG1 (a2 / autonomy
                        :mod (h / human)))
            :op2 (p2 / prevent-01
                  :ARG1 (h2 / harm-01))
            :op3 (f / fair-01)
            :op4 (p3 / possible-01
                  :ARG1 (e2 / explain-01)))
      :mod (t / this))

# ::snt In this scoping review, study finding regarding the ethical principles of respect for human autonomy, prevention  of harm, fairness, explicability and patient privacy were  extracted.
# File 180

(e / extract-01
      :ARG1 (t / thing
            :ARG1-of (f / find-01
                  :ARG0 (s / study-01))
            :topic (p / principle
                  :mod (e2 / ethics)
                  :domain (a / and
                        :op1 (r / respect-01
                              :ARG1 (a2 / autonomy
                                    :mod (h / human)))
                        :op2 (p2 / prevent-01
                              :ARG1 (h2 / harm-01))
                        :op3 (f2 / fair-01)
                        :op4 (p3 / possible-01
                              :ARG1 (e3 / explain-01))
                        :op5 (p4 / private-02
                              :ARG1 (p5 / patient)))))
      :location (r2 / review-01
            :ARG1-of (s2 / scope-01)
            :mod (t2 / this)))

# ::snt Responsible data science centers around four challenging  topics: fairness, i.e., data science without prejudice; accuracy, i.e., data science without guesswork; confidentiality,  i.e., data science that ensures confidentiality and transpar ency, i.e., data science that provides transparency [28].
# File 180

(c / center-01
      :ARG1 (s / science
            :mod (d / data)
            :ARG1-of (r / responsible-02))
      :ARG2 (t / topic
            :quant 4
            :ARG0-of (c2 / challenge-01)
            :ARG1-of (m / mean-01
                  :ARG2 (a / and
                        :op1 (f / fairness
                              :ARG1-of (m2 / mean-01
                                    :ARG2 (s2 / science
                                          :mod (d2 / data)
                                          :ARG0-of (p / prejudice-01
                                                :polarity -))))
                        :op2 (a2 / accuracy
                              :ARG1-of (m3 / mean-01
                                    :ARG2 (s3 / science
                                          :mod (d3 / data)
                                          :ARG0-of (e / ensure-01
                                                :ARG1 (a3 / and
                                                      :op1 (c3 / confidentiality)
                                                      :op2 (ii / integrity
                                                            :mod (t2 / transpar))
                                                      :ARG1-of (m4 / mean-01
                                                            :ARG2 (s4 / science
                                                                  :mod (d4 / data)
                                                                  :ARG0-of (p2 / provide-01
                                                                        :ARG1 (t3 / transparency))))))))))))
      :ARG1-of (d5 / describe-01
            :ARG0 (p3 / publication
                  :ARG1-of (c4 / cite-01
                        :ARG2 28))))

# ::snt Unintended discrimination and  profiling also represent important challenges, and technical and regulatory aspects ought to be carefully considered to  safeguard fairness in decision-making [29].
# File 180

(a / and
      :op1 (r / represent-01
            :ARG0 (a2 / and
                  :op1 (d / discriminate-02
                        :ARG1-of (ii / intend-01
                              :polarity -))
                  :op2 (p / profile-01))
            :ARG1 (c / challenge-01
                  :ARG1-of (ii2 / important-01))
            :mod (a3 / also))
      :op2 (r2 / recommend-01
            :ARG1 (c2 / consider-02
                  :ARG1 (s / safeguard-01
                        :ARG0 (a4 / aspect
                              :mod (t / technical)
                              :mod (r3 / regulate-01))
                        :ARG1 (f / fair-01
                              :ARG1 (m / make-01
                                    :ARG1 (d2 / decide-01))))
                  :manner (c3 / careful))
            :ARG1-of (d3 / describe-01
                  :ARG0 (p2 / publication
                        :ARG1-of (c4 / cite-01
                              :ARG2 29)))))

# ::snt Using mathematical notions of fairness can offer a step  in this direction.
# File 180

(p / possible-01
      :ARG1 (o / offer-01
            :ARG0 (u / use-01
                  :ARG1 (n / notion
                        :mod (m / mathematics)
                        :topic (f / fairness)))
            :ARG1 (s / step-01
                  :ARG2 (d / direction
                        :mod (t / this)))))

# ::snt To assess whether algorithms are resulting in fair  outcomes, as well as to mitigate such potential effects, various efforts have been deployed focusing on mathematical  definitions of fairness.
# File 180

(d / deploy-01
      :ARG1 (e / effort-01
            :mod (v / various)
            :ARG0-of (f / focus-01
                  :ARG1 (d2 / define-01
                        :ARG0 (m / mathematics)
                        :ARG1 (f2 / fair-01))))
      :purpose (a / and
            :op1 (a2 / assess-01
                  :ARG1 (t / truth-value
                        :polarity-of (r / result-01
                              :ARG1 (a3 / algorithm)
                              :ARG2 (o / outcome
                                    :ARG1-of (f3 / fair-01)))))
            :op2 (m2 / mitigate-01
                  :ARG1 (a4 / affect-01
                        :mod (p / potential)
                        :mod (s / such)))))

# ::snt These, however, are starkly different  to real-life determination of fairness, grounded in shared  ethical beliefs and values.
# File 180

(c / contrast-01
      :ARG2 (d / differ-02
            :ARG1 (t / this)
            :ARG2 (d2 / determine-01
                  :ARG1 (f / fair-01)
                  :ARG1-of (r / real-04)
                  :ARG1-of (g / ground-02
                        :ARG2 (a / and
                              :op1 (b / believe-01)
                              :op2 (v / value)
                              :ARG1-of (s / share-01)
                              :mod (e / ethics))))
            :ARG1-of (s2 / stark-02)))

# ::snt Different definitions have been put forward that formalize  fairness in AI mathematically.
# File 180

(p / put-01
      :ARG1 (t / thing
            :ARG2-of (d / define-01)
            :ARG1-of (d2 / differ-02)
            :ARG0-of (f / formalize-01
                  :ARG1 (f2 / fairness
                        :mod (a / artificial))
                  :manner (m / mathematics)))
      :ARG2 (f3 / forward))

# ::snt These can be grouped into  concepts of fairness across groups or individuals [31– 33].
# File 180

(p / possible-01
      :ARG1 (g / group-01
            :ARG1 (t / this)
            :ARG2 (c / concept
                  :topic (f / fair-01)
                  :location (a / across
                        :op1 (o / or
                              :op1 (g2 / group)
                              :op2 (ii / individual)))))
      :ARG1-of (d / describe-01
            :ARG0 (p2 / publication
                  :ARG1-of (c2 / cite-01
                        :ARG2 (a2 / and
                              :op1 31
                              :op2 33)))))

# ::snt Fairness in AI is violated by so-called biases.
# File 180

(v / violate-01
      :ARG0 (b / bias-01
            :mod (s / so-called))
      :ARG1 (f / fair-01
            :mod (a / artificial)))

# ::snt To prevent harm and to  respect the principle of fairness, it is important to validate  AI algorithms correctly and to ensure that the outcomes are  sufficiently reliable and generalizable to be applicable in  clinical practice.
# File 180

(ii / important-01
      :ARG1 (a / and
            :op1 (v / validate-01
                  :ARG1 (a2 / algorithm
                        :mod (ii2 / intelligent-01
                              :mod (a3 / artificial)))
                  :ARG1-of (c / correct-02))
            :op2 (e / ensure-01
                  :ARG1 (a4 / and
                        :op1 (r / rely-01
                              :ARG1 (o / outcome)
                              :ARG1-of (s / suffice-01
                                    :ARG0 (p / possible-01
                                          :ARG1 (g / generalize-01
                                                :ARG1 o))))
                        :op2 p)))
      :purpose (a5 / and
            :op1 (p2 / prevent-01
                  :ARG1 (h / harm-01))
            :op2 (r2 / respect-01
                  :ARG1 (p3 / principle
                        :topic (f / fairness)))))

# ::snt Data were extracted from the Table 1  Data charting listStudy-specific characteristics Authors Year of publication Journal Type of research Methodological design Study setting Participant characteristics Type of AI-based technology Ethical principles  Respect for human autonomy  Prevention of harm  Fairness  Explicability  Patient privacyTable 2  Search queries employed in database searches Date Query (2010–2020) Database # Hits 21.07.20 (“Artificial intelligence” or  “machine learning” or “deep  learning”) and (“ethic*” OR  “bioethic*”)PubMed/Medline 1268 21.07.20 [(Artificial intelligence or  machine learning or deep  learning) and (ethic* or  bioethic*)].afOVID/Embase 898
# File 180

(m / multi-sentence
      :snt1 (e / extract-01
            :ARG1 (d / data)
            :ARG2 (t / table
                  :mod 1
                  :ARG2-of (l / list-01
                        :ARG1 (t2 / thing
                              :ARG2-of (c / characteristic-02)
                              :ARG1-of (s / specific-02
                                    :ARG2 (s2 / study-01))))))
      :snt2 (t3 / type-03
            :ARG1 (r / research-01)
            :ARG2 (t4 / thing
                  :ARG1-of (d2 / design-01)
                  :mod (m2 / methodology)))
      :snt3 (t5 / type-03
            :ARG1 (p / person
                  :ARG0-of (p2 / participate-01
                        :ARG1 (s3 / study-01)))
            :ARG2 (t6 / technology
                  :ARG1-of (b / base-02
                        :ARG2 (ii / intelligent-01
                              :mod (a / artificial)))))
      :snt4 (p3 / principle
            :mod (e2 / ethics))
      :snt5 (r2 / respect-01
            :ARG1 (a2 / autonomy
                  :poss (h / human)))
      :snt6 (p4 / prevent-01
            :ARG1 (h2 / harm-01))
      :snt7 (p5 / possible-01
            :ARG1 (e3 / explain-01))
      :snt8 (p6 / privacy
            :poss (p7 / patient))
      :snt9 (h3 / hit-02
            :ARG0 (q / query-01
                  :ARG1 (s4 / search-01
                        :ARG1 (d3 / database))
                  :time (d4 / date-interval
                        :op1 (d5 / date-entity
                              :year 2010)
                        :op2 (d6 / date-entity
                              :year 2020)))
            :ARG1 (d7 / date-entity
                  :day 20
                  :month "21.07.20"
                  :ARG1-of (m3 / mean-01
                        :ARG2 (a3 / and
                              :op1 (ii2 / intelligence
                                    :mod a)
                              :op2 (m4 / machine
                                    :ARG1-of (l2 / learn-01
                                          :ARG1-of (d8 / deep-02)))
                              :op3 e2)
                        :op4 (b2 / bioethic)))))

# ::snt 545 AI and Ethics (2022) 2:539–551  1 3 issues of using AI in healthcare research, some thought that  loss of privacy was an acceptable sacrifice for the greater  good.Different studies discussed the principle of fairness [25,  41, 42, 45–48, 51].
# File 180

(m / multi-sentence
      :snt1 (p / publication-91
            :ARG5 "2:539"
            :ARG1 (e / ethics)
            :ARG4 (p2 / publication
                  :name (n / name
                        :op1 "AI"
                        :op2 "and"
                        :op3 "Ethics"))
            :time (d / date-entity
                  :year 2022))
      :snt2 (t / think-01
            :ARG0 (s / some)
            :ARG1 (s2 / sacrifice-01
                  :ARG1 (l / lose-02
                        :ARG1 (p3 / privacy))
                  :ARG2 (g / good-04
                        :ARG1-of (h / have-degree-91
                              :ARG2 (g2 / great)
                              :ARG3 (m2 / more)))
                  :ARG1-of (a / accept-01
                        :ARG1-of (p4 / possible-01))))
      :snt3 (d2 / discuss-01
            :ARG0 (s3 / study-01
                  :ARG1-of (d3 / differ-02))
            :ARG1 (p5 / principle
                  :topic (f / fairness))
            :ARG1-of (d4 / describe-01
                  :ARG0 (a2 / and
                        :op1 (p6 / publication
                              :ARG1-of (c / cite-01
                                    :ARG2 25))
                        :op2 (p7 / publication
                              :ARG1-of (c2 / cite-01
                                    :ARG2 41))
                        :op3 (p8 / publication
                              :ARG1-of (c3 / cite-01
                                    :ARG2 42))
                        :op4 (p9 / publication
                              :ARG1-of (c4 / cite-01
                                    :ARG2 45))
                        :op5 (p10 / publication
                              :ARG1-of (c5 / cite-01
                                    :ARG2 48))
                        :op6 (p11 / publication
                              :ARG1-of (c6 / cite-01
                                    :ARG2 51))))))

# ::snt Looking at the  application of AI in healthcare, the principles of fairness,  preservation of human autonomy, explicability and patient  privacy were equally the most frequent ethical aspects that  were studied in the literature as is shown in the map Study  participants were healthcare professionals, care providers,  some groups of patients.
# File 180

(a / aspect
      :mod (e / ethics)
      :domain (a2 / and
            :op1 (p / principle
                  :topic (f / fairness))
            :op2 (p2 / preserve-01
                  :ARG1 (a3 / autonomy
                        :mod (h / human)))
            :op3 (p3 / possible-01
                  :ARG1 (e2 / explain-01))
            :op4 (p4 / private-02
                  :ARG1 (p5 / patient)))
      :ARG1-of (s / study-01
            :medium (l / literature)
            :ARG1-of (r / resemble-01
                  :ARG2 (s2 / show-01
                        :ARG0 (s3 / study-01
                              :ARG1 (m / map)))))
      :ARG1-of (h2 / have-degree-91
            :ARG2 (f2 / frequent-02
                  :ARG1 a)
            :ARG3 (m2 / most))
      :ARG1-of (e3 / equal-01)
      :condition (l2 / look-01
            :ARG1 (a4 / apply-02
                  :ARG1 (ii / intelligent-01
                        :mod (a5 / artificial))
                  :ARG2 (h3 / healthcare)))
      :example (a6 / and
            :op1 (p6 / professional
                  :mod h3)
            :op2 (p7 / person
                  :ARG0-of (p8 / provide-01
                        :ARG1 (c / care-03)))
            :op3 (g / group
                  :mod (p9 / patient)
                  :quant (s4 / some))
            :domain (p10 / person
                  :ARG0-of (p11 / participate-01))))

# ::snt 2  Map of outcomes (i.e.,  ethical principles) measured  by the number of studies in the  scoping review Explicabilit y 9 articles  (50%) Patient privacy  9 article s (50%)Human  autonomy   9 articles  (50%) Fairness 8 articles  (44%) Prevention of  harm   6 articles  (33%)
# File 180

(m / measure-01
      :li 2
      :ARG1 (m2 / map-01
            :ARG1 (o / outcome
                  :ARG1-of (m3 / mean-01
                        :ARG2 (p / principle
                              :mod (e / ethics)))))
      :ARG2 (n / number
            :quant-of (s / study-01
                  :subevent-of (r / review-01
                        :ARG1-of (s2 / scope-01))))
      :example (a / and
            :op1 (e2 / exemplify-01
                  :ARG0 (a2 / article
                        :quant 9)
                  :ARG1 (p2 / privacy
                        :mod (p3 / patient)))
            :op2 (e3 / exemplify-01
                  :ARG0 (a3 / article
                        :quant 9)
                  :ARG1 (a4 / autonomy
                        :mod (h / human))
                  :mod (p4 / percentage-entity
                        :value 50))
            :op3 (e4 / exemplify-01
                  :ARG0 (a5 / article
                        :quant 9)
                  :ARG1 (f / fairness
                        :mod (p5 / percentage-entity
                              :value 50)))
            :op4 (e5 / exemplify-01
                  :ARG0 (a6 / article
                        :quant 8)
                  :ARG1 (p6 / prevent-01
                        :ARG1 (h2 / harm-01))
                  :mod (p7 / percentage-entity
                        :value 44))
            :op5 (e6 / exemplify-01
                  :ARG0 (a7 / article
                        :quant 6)
                  :ARG1 (p8 / percentage-entity
                        :value 33))))

# ::snt 547 AI and Ethics (2022) 2:539–551  1 3Table 4  Extracted data regarding ethical principles Study-specific extracted data regarding ethical principles Authors Year AI-based technology Human autonomy Prevention of harm Fairness Explicability Patient privacy Anderson and Anderson 2019 Predictive algorithms  DNN– − – Black-box issue – Blease et al.
# File 180

(m / multi-sentence
      :snt1 (p / publication-91
            :ARG5 47
            :ARG1 (a / and
                  :op1 (ii / intelligent-01
                        :mod (a2 / artificial))
                  :op2 (e / ethics))
            :ARG4 (v / value-interval
                  :op1 539
                  :op2 5551)
            :time (d / date-entity
                  :year 2022))
      :snt2 (t / table
            :mod 4
            :ARG1-of (d2 / describe-01
                  :ARG0 (a3 / and
                        :op1 (e2 / extract-01
                              :ARG1 (d3 / data
                                    :ARG0-of (r / regard-01
                                          :ARG1 (p2 / principle
                                                :mod (e3 / ethics))))
                              :ARG1-of (s / specific-02
                                    :ARG2 (s2 / study-01)))
                        :op2 (e4 / extract-01
                              :ARG1 (d4 / data
                                    :ARG0-of (r2 / regard-01
                                          :ARG1 p2))))))
      :snt3 (a4 / and
            :op1 (t2 / technology
                  :ARG1-of (b / base-02
                        :ARG2 (ii2 / intelligent-01
                              :mod a2)))
            :mod (h / human))
      :op2 (p3 / prevent-01
            :ARG1 (h2 / harm-01))
      :op3 (p4 / possible-01
            :ARG1 (e5 / explain-01))
      :op4 (p5 / privacy
            :mod (p6 / patient))
      :time (y / year
            :mod 2019)
      :snt4 (a5 / algorithm
            :ARG1-of (p7 / predict-01)
            :mod (d5 / deep-learning)
            :ARG1-of (m2 / mean-01
                  :ARG2 (ii3 / issue-02
                        :ARG0 (b2 / box
                              :ARG1-of (b3 / black-04))
                        :ARG1-of d2
                        :ARG0 (a6 / and
                              :op1 (p8 / person
                                    :name (n / name
                                          :op1 "Blease"))
                              :op2 (p9 / person
                                    :mod (o / other)))))))

# ::snt 2020 AI decision support  systemInformed consent – Bias could lead to discriminationExplicability GDPR, Patients as co-managers  of data Buruk 2020 AI-based technology Autonomy based on  personal dataPrevention of harm Equity, diversity inclusion, fairnessExplicability Privacy and data governance Chen 2020 AI prediction model for  readmission AI prediction model for  mortality– – Bias based on insurance  type Significant difference for  race, gender and insur ance type– – Fiske et al.
# File 180

(m / multi-sentence
      :snt1 (a / and
            :op1 (s / support-01
                  :ARG0 (s2 / system
                        :mod (ii / intelligent-01
                              :mod (a2 / artificial)))
                  :ARG1 (d / decide-01
                        :time (d2 / date-entity
                              :year 2020)))
            :op2 (c / consent-01
                  :ARG1-of (ii2 / inform-01))
            :snt2 (p / possible-01
                  :ARG1 (l / lead-03
                        :ARG0 (b / bias-01)
                        :ARG2 (d3 / discriminate-02)))
            :snt3 (a3 / and
                  :op1 (l2 / law
                        :name (n / name
                              :op1 "GDPR"))
                  :op2 (p2 / patient
                        :ARG0-of (m2 / manage-01
                              :ARG1 (d4 / data)
                              :mod (t / together)))
                  :op3 (t2 / technology
                        :ARG1-of (b2 / base-02
                              :ARG2 ii))
                  :op4 (a4 / autonomy
                        :ARG1-of (b3 / base-02
                              :ARG2 (d5 / data
                                    :ARG1-of (p3 / personal-02))))
                  :snt4 (a5 / and
                        :op1 (p4 / prevent-01
                              :ARG1 (h / harm-01))
                        :op2 (ii3 / include-01
                              :ARG2 (d6 / diversity))
                        :op3 (f / fairness)
                        :op4 (p5 / privacy)
                        :op5 (g / govern-01
                              :ARG1 (d7 / data))
                        :ARG1-of (p6 / possible-01))
                  :snt5 (a6 / and
                        :op1 (m3 / model-01
                              :ARG0 (p7 / person
                                    :name (n2 / name
                                          :op1 "Chen"))
                              :ARG1 (ii4 / intelligent-01
                                    :mod a2))
                        :time (d8 / date-entity
                              :year 2020)
                        :topic (r / readmission))
                  :op2 (m4 / model-01
                        :ARG0 p7
                        :ARG1 (d9 / die-01)
                        :mod ii4))
            :snt6 (b4 / bias-01
                  :ARG1-of (b5 / base-02
                        :ARG2 (t3 / type
                              :mod (ii5 / insure-02)))
                  :ARG1-of (s3 / significant-02))
            :snt7 (a7 / and
                  :op1 (p8 / person
                        :name (n3 / name
                              :op1 "Fiske"))
                  :op2 (e / et-cetera))))

# ::snt 2020 AI for social good Receiver-contextualized  intervention with  respect to autonomyNon-maleficence Justice & situational  fairnessReceiver-contextualized  explanation and transparent purposesPrivacy protection and  data subject consent Grote et al.
# File 180

(m / multi-sentence
      :snt1 (ii / intelligent-01
            :mod (a / artificial)
            :purpose (g / good-04
                  :ARG2 (s / society))
            :time (d / date-entity
                  :year 2020))
      :snt2 (ii2 / intervene-01
            :ARG0 (p / person
                  :ARG0-of (r / receive-01)
                  :ARG1-of (c / contextualize-01))
            :topic (a2 / autonomy)
            :mod (v / violence
                  :polarity -)
            :mod (j / justice)
            :mod (f / fairness
                  :mod (s2 / situational)))
      :snt3 (a3 / and
            :op1 (e / explain-01
                  :ARG0 (p2 / person
                        :ARG0-of (r2 / receive-01))
                  :ARG1-of (c2 / contextualize-01))
            :op2 (p3 / purpose
                  :mod (t / transparency)))
      :snt4 (a4 / and
            :op1 (p4 / protect-01
                  :ARG1 (p5 / privacy))
            :op2 (c3 / consent-01
                  :ARG1 (d2 / data)
                  :ARG2-of (s3 / subject-01
                        :ARG1 p5))
            :poss (a5 / and
                  :op1 (p6 / person
                        :name (n / name
                              :op1 "Grote"))
                  :op2 (e2 / et-al))))

# ::snt The current published literature about the ethical issues  in applying AI-based technology in healthcare showed the  principles of fairness, preservation of human autonomy,  explicability and patient privacy were equally the most frequent ethical aspects that were discussed.
# File 180

(s / show-01
      :ARG0 (l / literature
            :time (c / current)
            :ARG1-of (p / publish-01)
            :topic (ii / issue-02
                  :ARG0 (a / apply-02
                        :ARG1 (t / technology
                              :ARG1-of (b / base-02
                                    :ARG2 (ii2 / intelligent-01
                                          :mod (a2 / artificial))))
                        :ARG2 (h / healthcare))
                  :mod (e / ethics)))
      :ARG1 (a3 / aspect
            :mod (e2 / ethics)
            :ARG1-of (d / discuss-01)
            :domain (a4 / and
                  :op1 (p2 / principle
                        :topic (f / fairness))
                  :op2 (p3 / preserve-01
                        :ARG1 (a5 / autonomy
                              :mod (h2 / human)))
                  :op3 (p4 / possible-01
                        :ARG1 (e3 / explain-01))
                  :op4 (p5 / private-02
                        :ARG1 (p6 / patient)))
            :ARG1-of (h3 / have-degree-91
                  :ARG2 (f2 / frequent-02
                        :ARG1 a3)
                  :ARG3 (m / most))
            :ARG3 (e4 / equal)))

# ::snt Another scoping review published in the beginning of  2021, indeed, highlights the critical need for exploring the  ethical implications of AI within LMICs [7 ].Table 4  (continued) Study-specific extracted data regarding ethical principles Authors Year AI-based technology Human autonomy Prevention of harm Fairness Explicability Patient privacy Petkus 2020 AI and clinical decision support system  (CDSS)CDSS can ignore patient  preferences– CDSS with embedded  unconscious bias may  lead to unfair care– – Stanfill 2019 AI in healthcare data and  information management– – – – HIPAA1 (USA), CAG  2 (UK) Yoon 2020 Conditional generative  adversarial networks  (GAN) framework– – – – Synthetic data sets to  protect patient privacy 1.
# File 180

(m / multi-sentence
      :snt1 (h / highlight-01
            :ARG0 (r / review-01
                  :mod (s / scoping)
                  :ARG1-of (p / publish-01
                        :time (b / begin-01
                              :ARG1 (d / date-entity
                                    :year 2021)))
                  :mod (a / another))
            :ARG1 (n / need-01
                  :ARG1 (e / explore-01
                        :ARG1 (ii / implicate-01
                              :ARG0 (ii2 / intelligent-01
                                    :mod (a2 / artificial))
                              :ARG1 (e2 / ethics))
                        :location (p2 / product
                              :name (n2 / name
                                    :op1 "LMIC")))
                  :ARG1-of (c / critical-02)))
      :snt2 (a3 / and
            :op1 (p3 / possible-01
                  :ARG1 (ii3 / ignore-01
                        :ARG0 (p4 / product
                              :name (n3 / name
                                    :op1 "CDSS")
                              :ARG0-of (s2 / support-01
                                    :ARG1 (p5 / patient)))
                        :ARG1 (p6 / prefer-01
                              :ARG0 (p7 / patient))))
            :op2 (p8 / possible-01
                  :ARG1 (l / lead-03
                        :ARG0 (p9 / product
                              :name (n4 / name
                                    :op1 "CDSS")
                              :ARG0-of (b2 / bias-01
                                    :mod (u / unconscious)))
                        :ARG2 (c2 / care-03
                              :ARG1-of (f / fair-01
                                    :polarity -))))
            :op3 (ii4 / intelligent-01
                  :mod (a4 / artificial)
                  :time (d2 / date-entity
                        :year 2019)
                  :location (a5 / and
                        :op1 (d3 / data
                              :mod (h2 / healthcare))
                        :op2 (m2 / manage-01
                              :ARG1 (ii5 / information))))
            :op4 (p10 / product
                  :name (n5 / name
                        :op1 "CAG"
                        :op2 2)
                  :location (c3 / country
                        :name (n6 / name
                              :op1 "UK")))
            :op5 (f2 / framework
                  :name (n7 / name
                        :op1 "GAN")
                  :mod (g / generative)
                  :mod (c4 / contingency))
            :op6 (s3 / set
                  :consist-of (d4 / data
                        :mod (s4 / synthetic))
                  :purpose (p11 / protect-01
                        :ARG1 (p12 / privacy
                              :poss (p13 / patient)))))
      :ARG1-of (d5 / describe-01
            :ARG0 (p14 / publication
                  :ARG1-of (c5 / cite-01
                        :ARG2 7)))
      :ARG1-of (c6 / continue-01))

# ::snt Ethics Guidelines for trustworthy AI  suggests a checklist with seven key requirements for trustworthy AI including (1) human agency and oversight, (2)  technical robustness and safety, (3) privacy and data gov ernance, (4) transparency, (5) diversity, non-discrimination,  and fairness, (6) environmental and societal well-being and  (7) accountability.
# File 180

(s / suggest-01
      :ARG0 (g / guideline
            :mod (e / ethics)
            :topic (ii / intelligent-01
                  :mod (a / artificial)))
      :ARG1 (c / checklist
            :consist-of (r / require-01
                  :ARG0 ii
                  :ARG1 (t / thing
                        :quant 7
                        :ARG1-of (k / key-02)
                        :ARG2-of (ii2 / include-01
                              :ARG1 (a2 / and
                                    :op1 (a3 / and
                                          :li 1
                                          :op1 (a4 / agency
                                                :mod (h / human))
                                          :op2 (o / oversee-01
                                                :ARG0 h))
                                    :op2 (a5 / and
                                          :li 2
                                          :op1 (r2 / robustness
                                                :mod (t2 / technical))
                                          :op2 (s2 / safe-01))
                                    :op3 (a6 / and
                                          :li 3
                                          :op1 (p / privacy)
                                          :op2 (g2 / government-organization
                                                :ARG0-of (g3 / govern-01)
                                                :mod (d / data)))
                                    :op4 (t3 / transparency)
                                    :op5 (a7 / and
                                          :li 5
                                          :op1 (d2 / diversity)
                                          :op2 (d3 / discriminate-02
                                                :polarity -)
                                          :op3 (f / fair-01))
                                    :op6 (a8 / and
                                          :li 6
                                          :op1 (w / well-09
                                                :ARG1 (a9 / and
                                                      :op1 (e2 / environment)
                                                      :op2 (s3 / society)))
                                          :op2 (a10 / accountable-02
                                                :li 7))))))))

# ::snt There were no practical tools or frameworks for testing  whether an AI technique upholds the principle of fairness,  prevention of harm, human autonomy or explicability.
# File 180

(o / or
      :op1 (t / tool
            :polarity -
            :ARG1-of (p / practical-03))
      :op2 (f / framework
            :polarity -)
      :purpose (t2 / test-01
            :ARG1 (t3 / truth-value
                  :polarity-of (u / uphold-01
                        :ARG0 (t4 / technique
                              :mod (a / artificial))
                        :ARG1 (o2 / or
                              :op1 (p2 / principle
                                    :topic (f2 / fairness))
                              :op2 (p3 / prevent-01
                                    :ARG1 (h / harm-01))
                              :op3 (a2 / autonomy
                                    :poss (h2 / human))
                              :op4 (p4 / possible-01
                                    :ARG1 (e / explain-01)))))))

# ::snt Lee, M.S.A., Floridi, L., Singh, J.: Formalising trade-offs beyond  algorithmic fairness: lessons from ethical philosophy and welfare  economics.
# File 180

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Lee")
                  :ARG0-of (h / have-org-role-91
                        :ARG2 (d / doctor
                              :mod (m / medicine))))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "Floridi")
                  :ARG0-of h)
            :op3 (p4 / person
                  :name (n3 / name
                        :op1 "Singh")
                  :ARG0-of h
                  :ARG2 d))
      :op4 (p5 / person
            :name (n4 / name
                  :op1 "J.")
            :ARG0-of h
            :ARG2 d)
      :ARG1 (f / form-01
            :ARG1 (t / trade-off-02
                  :mod (b / beyond
                        :op1 (f2 / fairness
                              :mod (a2 / algorithm))))
            :ARG1-of (m2 / mean-01
                  :ARG2 (l / lesson
                        :source (a3 / and
                              :op1 (p6 / philosophy
                                    :mod (e / ethics))
                              :op2 (w / welfare
                                    :mod (e2 / economics)))))))

# ::snt : Fairness and machine learning.
# File 180

(a / and
      :op1 (f / fairness)
      :op2 (l / learn-01
            :instrument (m / machine)))

# ::snt Performance and security  Bias and fairness  Is your AI fair?
# File 148

(m / multi-sentence
      :snt1 (a / and
            :op1 (p / perform-02)
            :op2 (s / security))
      :snt2 (a2 / and
            :op1 (b / bias-01)
            :op2 (f / fair-01))
      :snt3 (f2 / fair-01
            :ARG1 (a3 / artificial-intelligence
                  :poss (y / you))
            :polarity (a4 / amr-unknown)))

# ::snt How are you  defining that fairness?
# File 148

(d / define-01
      :ARG0 (y / you)
      :ARG1 (f / fair-01
            :mod (t / that))
      :ARG2 (a / amr-unknown))

# ::snt Fairness  The development of AI should  result in individuals within  similar groups being treated in  a fair manner, without  favoritism or discrimination,  and without causing or  resulting in harm.
# File 148

(m / multi-sentence
      :snt1 (f / fairness)
      :snt2 (r / recommend-01
            :ARG1 (r2 / result-01
                  :ARG1 (d / develop-02
                        :ARG1 (ii / intelligent-01
                              :mod (a / artificial)))
                  :ARG2 (t / treat-01
                        :ARG1 (ii2 / individual
                              :ARG1-of (ii3 / include-91
                                    :ARG2 (g / group
                                          :ARG1-of (r3 / resemble-01))))
                        :ARG2 (m2 / manner
                              :ARG1-of (f2 / fair-01))
                        :manner (o / or
                              :polarity -
                              :op1 (f3 / favoritism)
                              :op2 (d2 / discriminate-02))
                        :manner (o2 / or
                              :op1 (c / cause-01
                                    :polarity -
                                    :ARG1 (h / harm-01))
                              :op2 r2
                              :polarity -
                              :ARG2 h)))))

# ::snt Periodic  assessments Periodic audits are necessary to assess the performance of AI in terms of fairness, safety  and reliability, and where relevant areas comply with internal and external standards.
# File 148

(m / multi-sentence
      :snt1 (a / assess-01
            :frequency (p / period))
      :snt2 (n / need-01
            :ARG1 (a2 / audit-01
                  :frequency (p2 / period))
            :purpose (a3 / assess-01
                  :ARG1 (p3 / perform-02
                        :ARG0 (a4 / artificial-intelligence)
                        :topic (a5 / and
                              :op1 (f / fairness)
                              :op2 (s / safe-01)
                              :op3 (r / rely-01
                                    :ARG1 a4
                                    :ARG1-of (p4 / possible-01)))
                        :location (c / comply-01
                              :ARG0 (a6 / area
                                    :ARG1-of (r2 / relevant-01))
                              :ARG1 (a7 / and
                                    :op1 (s2 / standard
                                          :ARG1-of (ii / internal-02))
                                    :op2 (s3 / standard
                                          :mod (e / external))))))))

# ::snt Mature  organizations also place a higher importance on the Fairness principle (5th place versus  8th place for less mature firms).
# File 148

(p / place-01
      :ARG0 (o / organization
            :ARG1-of (m / mature-02))
      :ARG1 (ii / important-01
            :ARG1 (p2 / principle
                  :topic (f / fairness))
            :ARG1-of (h / have-degree-91
                  :ARG2 (h2 / high-02
                        :ARG1 ii)
                  :ARG3 (m2 / more)))
      :ARG1-of (m3 / mean-01
            :ARG2 (v / versus
                  :op1 (p3 / place
                        :ord (o2 / ordinal-entity
                              :value 5)
                        :domain o)
                  :op2 (p4 / place
                        :ord (o3 / ordinal-entity
                              :value 8)
                        :domain o)
                  :condition (f2 / firm
                        :ARG1-of (h3 / have-degree-91
                              :ARG2 (m4 / mature-02
                                    :ARG1 f2)
                              :ARG3 (l / less)))))
      :mod (a / also))

# ::snt For example, different teams using different bias  assessment tools with different definitions of fairness may develop tools and systems that  these teams believe are meeting the objective of fairness, but they may actually be in  conflict with one another.
# File 148

(e / exemplify-01
      :ARG0 (c / contrast-01
            :ARG1 (p / possible-01
                  :ARG1 (d / develop-02
                        :ARG0 (t / team
                              :ARG0-of (u / use-01
                                    :ARG1 (t2 / tool
                                          :ARG1-of (b / bias-01
                                                :ARG1-of (d2 / differ-02))
                                          :instrument-of (a / assess-01))
                                    :ARG0-of (h / have-03
                                          :ARG1 (t3 / thing
                                                :ARG2-of (d3 / define-01
                                                      :ARG1 (f / fair-01))
                                                :ARG1-of (d4 / differ-02)))))
                        :ARG1 (a2 / and
                              :op1 (t4 / tool)
                              :op2 (s / system)
                              :ARG0-of (m / meet-01
                                    :ARG1 (o / objective
                                          :mod (f2 / fair-01))
                                    :ARG1-of (b2 / believe-01
                                          :ARG0 t)))))
            :ARG2 (p2 / possible-01
                  :ARG1 (c2 / conflict-01
                        :ARG0 t
                        :ARG1 t
                        :ARG1-of (a3 / actual-02)))))

# ::snt First of all, how can existing regulations or new ones facilitate algorithmic accountability  or fairness?
# File 166

(p / possible-01
      :ARG1 (f / facilitate-01
            :ARG0 (o / or
                  :op1 (r / regulate-01
                        :ARG1-of (e / exist-01))
                  :op2 (r2 / regulate-01
                        :ARG1-of (n / new-01)))
            :ARG1 (o2 / or
                  :op1 (a / accountable-02
                        :mod (a2 / algorithm))
                  :op2 (f2 / fair-01))
            :manner (a3 / amr-unknown))
      :mod (f3 / first-of-all))

# ::snt The prohibition of discrimination (see subsection 3.7)   The Council of Europe could shed light on how algorithmic accountability or fairness can be  facilitated and how the developers of algorithms can be enabled to devise automated decisions that  respect human rights and will not (unintentionally) discriminate  against individuals .
# File 166

(p / possible-01
      :ARG1 (s / shed-light-10
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "Council"
                        :op2 "of"
                        :op3 "Europe"))
            :ARG1 (a / and
                  :op1 (p2 / possible-01
                        :ARG1 (f / facilitate-01
                              :ARG1 (o2 / or
                                    :op1 (a2 / accountable-02
                                          :ARG1 (a3 / algorithm))
                                    :op2 (f2 / fairness
                                          :mod (a4 / algorithm)))))
                  :op2 (e / enable-01
                        :ARG1 (d / devise-01
                              :ARG0 (p3 / person
                                    :ARG0-of (d2 / develop-02
                                          :ARG1 (a5 / algorithm)))
                              :ARG1 (d3 / decide-01
                                    :ARG1-of (a6 / automate-01)
                                    :ARG0-of (r / respect-01
                                          :ARG1 (r2 / right-05
                                                :ARG1 (h / human)))
                                    :ARG0-of (d4 / discriminate-02
                                          :polarity -
                                          :ARG1 (ii / individual)
                                          :ARG1-of (ii2 / intend-01
                                                :polarity -))))
                        :ARG2 p3)))
      :ARG1-of (c / cause-01
            :ARG0 (p4 / prohibit-01
                  :ARG1 (d5 / discriminate-02)
                  :ARG1-of (d6 / describe-01
                        :ARG0 (s2 / section
                              :mod 3.7)))))

# ::snt Universal access to education must be achieved through principles of solidarity and fairness.
# File 151

(o / obligate-01
      :ARG2 (a / achieve-01
            :ARG1 (a2 / access-01
                  :ARG1 (e / educate-01)
                  :mod (u / universal))
            :manner (p / principle
                  :mod (s / solidarity)
                  :mod (f / fairness))))

# ::snt For this reason, the sponsors of the call express their desire to work together, in this context and at a national and international level, to promote “algor-ethics”, namely the ethical use of AI as defined by the following principles: •  T ransparency:  in principle, AI systems must be explainable; •  I nclusion:  the needs of all human beings must be  taken into consideration so that everyone can benefit  and all individuals can be offered the best possible conditions to express themselves and develop; •  Re sponsibility:  those who design and deploy the  use of AI must proceed with responsibility and transparency; •  I mpartiality:  do not create or act according to bias,  thus safeguarding fairness and human dignity; •  Re liability:  AI systems must be able to work reliably; •  S ecurity and privacy:  AI systems must work securely  and respect the privacy of users.
# File 151

(e / express-01
      :ARG0 (p / person
            :ARG0-of (s / sponsor-01
                  :ARG1 (c / call-03)))
      :ARG1 (d / desire-01
            :ARG0 p
            :ARG1 (w / work-01
                  :ARG0 p
                  :ARG1 (p2 / promote-02
                        :ARG0 p
                        :ARG1 (e2 / ethics
                              :mod (a / algorithm)
                              :ARG1-of (d2 / define-01
                                    :ARG0 (p3 / principle
                                          :ARG1-of (m / mean-01
                                                :ARG2 (a2 / and
                                                      :op1 (p4 / possible-01
                                                            :ARG1 (e3 / explain-01
                                                                  :ARG1 (s2 / system
                                                                        :mod (ii / intelligent-01
                                                                              :mod (a3 / artificial))))))
                                                :op2 (o / obligate-01
                                                      :ARG1 (p5 / proceed-01
                                                            :ARG0 (p6 / person
                                                                  :ARG0-of (d3 / design-01
                                                                        :ARG1 s2)
                                                                  :ARG0-of (d4 / deploy-01
                                                                        :ARG1 s2))
                                                            :manner (a4 / and
                                                                  :op1 (r / responsible-02
                                                                        :ARG0 p6)
                                                                  :op2 (t / transparency)))))))))
                  :ARG1-of (c2 / cause-01
                        :ARG0 (t2 / this))))
      :op2 (p7 / possible-01
            :ARG1 (c3 / consider-02
                  :ARG1 (t3 / thing
                        :ARG1-of (n / need-01
                              :ARG0 (b / being
                                    :mod (h / human)
                                    :mod (a5 / all)))))
            :purpose (a6 / and
                  :op1 (p8 / possible-01
                        :ARG1 (b2 / benefit-01
                              :ARG1 (e4 / everyone)))
                  :op2 (p9 / possible-01
                        :ARG1 (o2 / offer-01
                              :ARG1 (c4 / condition
                                    :ARG1-of (h2 / have-degree-91
                                          :ARG2 (g / good-02
                                                :ARG1 c4)
                                          :ARG3 (m2 / most)))
                              :ARG3 (ii2 / individual
                                    :mod a5)
                              :purpose (a7 / and
                                    :op1 (e5 / express-01
                                          :ARG0 ii2
                                          :ARG1 ii2)
                                    :op2 (d5 / develop-02
                                          :ARG0 ii2))))))
      :op3 (a8 / and
            :op1 (s3 / secure-02
                  :ARG1 s2)
            :op2 (r2 / respect-01
                  :ARG0 s2
                  :ARG1 (p10 / privacy
                        :poss (p11 / person
                              :ARG0-of (u / use-01
                                    :ARG1 s2))))))

# ::snt In sectors like finance, key  criteria such as fairness, discrimination, and transparency have long been  subject to extensive regulatory intervention, and sectoral regulation  must ensure continuity while accounting for the increasing use of AI.
# File 45

(a / and
      :op1 (s / subject-01
            :ARG1 (c / criteria
                  :ARG1-of (k / key-02)
                  :example (a2 / and
                        :op1 (f / fairness)
                        :op2 (d / discriminate-02)
                        :op3 (t / transparency)))
            :ARG2 (ii / intervene-01
                  :ARG0 (r / regulate-01)
                  :ARG1-of (e / extensive-03))
            :ARG1-of (l / long-03)
            :location (s2 / sector
                  :example (f2 / finance)))
      :op2 (o / obligate-01
            :ARG2 (e2 / ensure-01
                  :ARG0 (r2 / regulate-01
                        :mod (s3 / sector))
                  :ARG1 (c2 / continue-01)
                  :time (a3 / account-01
                        :ARG0 r2
                        :ARG1 (u / use-01
                              :ARG1 (ii2 / intelligent-01
                                    :mod (a4 / artificial))
                              :ARG1-of (ii3 / increase-01))))))

# ::snt STRENGTHENING INTERNATIONAL COOPERATION  ON AI21over a three-year period, also involving several thousand experts.29 AI Now  was an early civil society mover in propounding recommendations for  government policies.30 There is considerable overlap among these various sets of principles, including  on the importance of fairness, privacy preservation, and respect for human  rights and autonomy.
# File 45

(m / multi-sentence
      :snt1 (s / strengthen-01
            :li 29
            :ARG1 (c / cooperate-01
                  :mod (ii / international)
                  :topic (t / thing
                        :name (n / name
                              :op1 "AI21")))
            :duration (t2 / temporal-quantity
                  :quant 3
                  :unit (y / year))
            :ARG2-of (ii2 / involve-01
                  :ARG1 (p / person
                        :ARG1-of (e / expert-01)
                        :quant (s2 / several
                              :op1 1000))
                  :mod (a / also)))
      :snt2 (m2 / move-02
            :li 30
            :ARG0 (o / organization
                  :name (n2 / name
                        :op1 "AI"
                        :op2 "Now"))
            :ARG1 (p2 / propound-01
                  :ARG0 o
                  :ARG1 (r / recommend-01
                        :ARG3 (t3 / thing
                              :ARG1-of (p3 / policy-01
                                    :ARG0 (g / government-organization
                                          :ARG0-of (g2 / govern-01))))))
            :ARG2 (s3 / society
                  :mod (c2 / civil))
            :time (e2 / early))
      :snt3 (o2 / overlap-01
            :li 30
            :ARG0 (s4 / set
                  :consist-of (p4 / principle)
                  :mod (v / various)
                  :mod (t4 / this)
                  :ARG2-of (ii3 / include-01
                        :ARG1 (ii4 / important-01
                              :ARG1 (a2 / and
                                    :op1 (f / fairness)
                                    :op2 (p5 / preserve-01
                                          :ARG1 (p6 / privacy))
                                    :op3 (r2 / respect-01
                                          :op1 (r3 / right-05
                                                :ARG1 (h / human))
                                          :op2 (a3 / autonomy
                                                :poss h))
                                    :ARG1-of r2)))))
      :degree (c3 / considerable))

# ::snt An analysis of 22 AI ethics principles found that the  values of accountability, privacy, fairness, transparency, and cybersecurity  appeared in over 70 percent of the documents.
# File 45

(f / find-01
      :ARG0 (a / analyze-01
            :ARG1 (p / principle
                  :quant 22
                  :topic (e / ethics)
                  :mod (a2 / artificial)))
      :ARG1 (a3 / appear-01
            :ARG1 (v / value
                  :example (a4 / and
                        :op1 (a5 / accountable-02)
                        :op2 (p2 / privacy)
                        :op3 (f2 / fairness)
                        :op4 (t / transparency)
                        :op5 (c / cybersecurity)))
            :location (d / document
                  :ARG1-of (ii / include-91
                        :ARG2 (d2 / document)
                        :ARG3 (o / over
                              :op1 (p3 / percentage-entity
                                    :value 70))))))

# ::snt Other common principles  include human oversight, explainability or interpretability, legal status of  AI systems, and the equitable economic effect of AI.31 A separate analysis  of 84 AI ethics documents done in 2019 found that there has been a global  convergence around “transparency, justice and fairness, non-maleficence,  responsibility and privacy.”32 While much progress has been made aligning on responsible AI, there remain  differences—even among FCAI participants.
# File 45

(m / multi-sentence
      :snt1 (ii / include-01
            :li 31
            :ARG1 (a / and
                  :op1 (o / oversight
                        :mod (h / human))
                  :op2 (o2 / or
                        :op1 (p / possible-01
                              :ARG1 (e / explain-01))
                        :op2 (p2 / possible-01
                              :ARG1 (ii2 / interpret-01)))
                  :op3 (s / status
                        :ARG1-of (l / legal-02)
                        :poss (s2 / system
                              :mod (a2 / artificial)))
                  :op4 (a3 / affect-01
                        :ARG0 (ii3 / intelligent-01
                              :mod (a4 / artificial))
                        :ARG1 (e2 / economy)
                        :mod (e3 / equitable)))
            :ARG2 (p3 / principle
                  :ARG1-of (s3 / share-01)
                  :mod (o3 / other)))
      :snt2 (f / find-01
            :li 32
            :ARG0 (a5 / analyze-01
                  :ARG1 (d / document
                        :quant 84
                        :topic (e4 / ethics)
                        :mod (ii4 / intelligent-01
                              :mod (a6 / artificial)))
                  :ARG1-of (s4 / separate-02)
                  :time (d2 / date-entity
                        :year 2019))
            :ARG1 (c / converge-01
                  :ARG1 (a7 / and
                        :op1 (t / transparency)
                        :op2 (j / justice)
                        :op3 (f2 / fairness)
                        :op4 (m2 / malice
                              :polarity -)
                        :op5 (r / responsible-02)
                        :op6 (p4 / privacy))
                  :mod (g / globe)))
      :snt3 (c2 / contrast-01
            :ARG1 (p5 / progress-01
                  :ARG1 (a8 / align-01
                        :ARG2 ii4)
                  :quant (m3 / much))
            :ARG2 (r2 / remain-01
                  :ARG1 (d3 / differ-02
                        :ARG1 (p6 / person
                              :ARG0-of (p7 / participate-01
                                    :ARG1 (e5 / event
                                          :name (n / name
                                                :op1 "FCAI")))))
                  :mod (e6 / even))))

# ::snt In addition, Canada has issued regulations to address certain risks related to  artificial intelligence and the processing of personal information in the federal  government; the Directive on Automated Decision-Making came into effect  April 19, 2019, requiring federal government bodies to complete algorithmic  impact assessments prior to utilizing automated decisionmaking tools, notify  affected parties both before and after automated decisions, and analyze  all results for potential bias.57 In the private sector, the federal Personal  Information Protection and Electronic Documents Act (PIPEDA) regulates  how businesses handle personal information, setting out ten fair information  principles that include safeguards to maintain privacy, accuracy, and fairness  in data processing and minimize potential harms or discrimination to
# File 45

(m / multi-sentence
      :snt1 (a / and
            :op2 (ii / issue-01
                  :ARG0 (c / country
                        :name (n / name
                              :op1 "Canada"))
                  :ARG1 (r / regulate-01
                        :ARG0 c
                        :ARG0-of (a2 / address-02
                              :ARG1 (r2 / risk-01
                                    :ARG1-of (r3 / relate-01
                                          :ARG2 (a3 / and
                                                :op1 (ii2 / intelligent-01
                                                      :mod (a4 / artificial))
                                                :op2 (p / process-01
                                                      :ARG0 (g / government-organization
                                                            :ARG0-of (g2 / govern-01)
                                                            :mod (f / federal))
                                                      :ARG1 (ii3 / information
                                                            :ARG1-of (p2 / personal-02)))))
                                    :mod (c2 / certain))))))
      :snt2 (r4 / regulate-01
            :li 57
            :ARG0 (l / law
                  :name (n2 / name
                        :op1 "Directive"
                        :op2 "on"
                        :op3 "Automated"
                        :op4 "Decision-Making")
                  :ARG0-of (r5 / require-01
                        :ARG1 (a5 / and
                              :op1 (c3 / complete-01
                                    :ARG0 (b / body
                                          :mod (g3 / government-organization
                                                :ARG0-of (g4 / govern-01)
                                                :mod (f2 / federal)))
                                    :ARG1 (a6 / assess-01
                                          :ARG1 (ii4 / impact-01)
                                          :mod (a7 / algorithm))
                                    :time (p3 / prior
                                          :op1 (u / utilize-01
                                                :ARG0 b
                                                :ARG1 (t / tool
                                                      :instrument-of (m2 / make-01
                                                            :ARG1 (d / decide-01))
                                                      :ARG1-of (a8 / automate-01)))))
                              :op2 (n3 / notify-01
                                    :ARG0 b
                                    :ARG1 (p4 / party
                                          :ARG1-of (a9 / affect-01))
                                    :time (a10 / and
                                          :op1 (b2 / before
                                                :op1 d)
                                          :op2 (a11 / after
                                                :op1 d)))
                              :op3 (a12 / analyze-01
                                    :ARG0 b
                                    :ARG1 (t2 / thing
                                          :ARG2-of (r6 / result-01)
                                          :mod (a13 / all))
                                    :ARG2 (b3 / bias-01
                                          :mod (p5 / potential))))
                        :ARG2 b))
            :snt3 (s / set-out-06
                  :ARG0 (l2 / law
                        :name (n4 / name
                              :op1 "Personal"
                              :op2 "Information"
                              :op3 "Protection"
                              :op4 "and"
                              :op5 "Electronic"
                              :op6 "Documents"
                              :op7 "Act"))
                  :ARG1 (p6 / principle
                        :quant 10
                        :topic (ii5 / information
                              :ARG1-of (f3 / fair-01))
                        :ARG2-of (ii6 / include-01
                              :ARG1 (s2 / safeguard-01
                                    :ARG1 (a14 / and
                                          :op1 (m3 / maintain-01
                                                :ARG1 (a15 / and
                                                      :op1 (p7 / privacy)
                                                      :op2 (a16 / accurate)
                                                      :op3 (f4 / fairness))
                                                :topic (p8 / process-01
                                                      :ARG1 (d2 / data))))
                                    :op2 (m4 / minimize-01
                                          :ARG1 (o / or
                                                :op1 (h / harm-01
                                                      :ARG1-of (p9 / possible-01))
                                                :op2 (d3 / discriminate-02)))))))
            :location (s3 / sector
                  :ARG1-of (p10 / private-02))))

# ::snt An integral element of its AI governance is its Society  5.0, a conceptual vision document guiding actions in science, technology,  and innovation aimed at synergies for a prosperous future.79 The Society 5.0  framework frames Japan’s AI principles (human-centricity, education/literacy,  privacy, security, fair competition, fairness, accountability and transparency,  and innovation) mainly in relation to cultural and social aspects of its society.80  The Cabinet Office Council on Industrial Competitiveness81 has targeted selfdriving cars, drones, and production management, including smart factories,  all powered by AI, as key opportunities to increase Japan’s productivity.
# File 45

(m / multi-sentence
      :snt2 (t / target-01
            :li 80
            :ARG0 (g / government-organization
                  :name (n / name
                        :op1 "Cabinet"
                        :op2 "Office"
                        :op3 "Council"
                        :op4 "on"
                        :op5 "Industrial"
                        :op6 "Competitive"
                        :op7 "Compitiveness"))
            :ARG1 (o / opportunity
                  :ARG1-of (k / key-02)
                  :purpose (ii / increase-01
                        :ARG0 g
                        :ARG1 (p / productive-03
                              :ARG0 (c / country
                                    :name (n2 / name
                                          :op1 "Japan"))))
                  :domain (a / and
                        :op1 (c2 / car
                              :ARG0-of (d / drive-01
                                    :ARG1 (s / self)))
                        :op2 (d2 / drone)
                        :op3 (m2 / manage-01
                              :ARG1 (p2 / produce-01)
                              :ARG2-of (ii2 / include-01
                                    :ARG1 (f / factory
                                          :ARG1-of (s2 / smart-06)
                                          :ARG1-of (p3 / power-01
                                                :ARG0 (a2 / artificial-03)))))))
            :ARG2 (s3 / synergize-01
                  :ARG1-of (a3 / aim-02
                        :ARG2 (f2 / future
                              :ARG0-of (p4 / prosper-01)))))
      :snt1 (f3 / frame-06
            :ARG0 (e / element
                  :mod (ii3 / integral)
                  :part-of (g2 / govern-01
                        :ARG0 (ii4 / it)
                        :ARG1 (a4 / artificial-03))
                  :domain (d3 / document
                        :name (n3 / name
                              :op1 "Society")))))

# ::snt In addition, Singapore has released nonbinding guidance to help organizations  navigate data ethics and governance principles, such as transparency, fairness,  and explainability.
# File 45

(a / and
      :op2 (r / release-01
            :ARG0 (c / country
                  :name (n / name
                        :op1 "Singapore"))
            :ARG1 (g / guide-01
                  :ARG1-of (b / binding-07
                        :polarity -)
                  :ARG0-of (h / help-01
                        :ARG1 (n2 / navigate-01
                              :ARG0 (o / organization)
                              :ARG1 (a2 / and
                                    :op1 (e / ethics
                                          :mod (d / data))
                                    :op2 (p / principle
                                          :topic (g2 / govern-01)
                                          :example (a3 / and
                                                :op1 (t / transparency)
                                                :op2 (f / fairness)
                                                :op3 (e2 / explain-01
                                                      :ARG1-of (p2 / possible-01))))))
                        :ARG2 o))))

# ::snt It names the Alan Turing Institute as  the national AI research center to “remain a globally leading player in AI,”  “promote the U.K.’s interests through collaborations with international  partners,” and “attract world-leading talent to the U.K..”98Singapore has  released nonbinding  guidance to help  organizations  navigate data ethics  and governance  principles, such  as transparency,  fairness, and  explainability.
# File 45

(a / and
      :li 98
      :op1 (n / name-01
            :ARG0 (ii / it)
            :ARG1 (r / research-institute
                  :name (n2 / name
                        :op1 "Alan"
                        :op2 "Turing"
                        :op3 "Institute"))
            :ARG2 (c / center
                  :mod (n3 / nation)
                  :purpose (a2 / and
                        :op1 (r2 / remain-01
                              :ARG1 (c2 / country
                                    :name (n4 / name
                                          :op1 "U.K."))
                              :ARG3 (p / play-02
                                    :ARG0 c2
                                    :ARG1 (ii2 / intelligent-01
                                          :mod (a3 / artificial))
                                    :mod (g / globe)))
                        :op2 (p2 / promote-02
                              :ARG0 c2
                              :ARG1 (ii3 / interest-01
                                    :ARG1 c2)
                              :manner (c3 / collaborate-01
                                    :ARG0 c2
                                    :ARG1 (c4 / country
                                          :ARG0-of (p3 / partner-01
                                                :ARG1 c2)
                                          :mod (ii4 / international))))
                        :op3 (a4 / attract-01
                              :ARG0 c2
                              :ARG1 (t / talent
                                    :ARG0-of (l / lead-02
                                          :ARG1 (w / world)))
                              :ARG2 c2))))
      :op2 (r3 / release-01
            :ARG0 (c5 / country
                  :name (n5 / name
                        :op1 "Singapore"))
            :ARG1 (g2 / guide-01
                  :ARG1 c5
                  :ARG2 (h / help-01
                        :ARG0 c5
                        :ARG1 (n6 / navigate-01
                              :ARG0 (o / organization)
                              :ARG1 (p4 / principle
                                    :example (a5 / and
                                          :op1 (e / ethics
                                                :mod (d / data))
                                          :op2 (g3 / govern-01))))
                        :ARG2 o))
            :ARG1-of (b / bind-01
                  :polarity -)))

# ::snt In addition to identifying a  need for review of regulations, the report also recognized a need to address  the threat of unintended consequences by ensuring an ethical governance  approach that emphasizes fairness and safety.
# File 45

(a / and
      :op1 (r / recognize-01
            :ARG0 (r2 / report)
            :ARG1 (n / need-01
                  :ARG1 (a2 / address-02
                        :ARG1 (t / threaten-01
                              :ARG0 (c / consequence-03
                                    :ARG1-of (ii / intend-01
                                          :polarity -)))
                        :ARG2 (e / ensure-01
                              :ARG1 (a3 / approach-02
                                    :ARG1 (g / govern-01
                                          :mod (e2 / ethics))
                                    :ARG0-of (e3 / emphasize-01
                                          :ARG1 (a4 / and
                                                :op1 (f / fairness)
                                                :op2 (s / safe-01)))))))
            :mod (a5 / also))
      :op2 (ii2 / identify-01
            :ARG0 r2
            :ARG1 (n2 / need-01
                  :ARG1 (r3 / review-01
                        :ARG1 (r4 / regulate-01)))))

# ::snt AI activities in the 7 administrations participating in the FCAI  AI ethics Frameworks Existing AI  regulation AI standards Public  Investment Australia Australia’s AI Ethics Framework Review of existing  regulations per  the AI Action Plan Standards Australia focuses on  by-design and standards testing;  AI Standards Roadmap AUD 124.1 million  (USD 90.9 million)  2021-2022  Canada CIFAR Pan-Canadian AI  Strategy 2017; Digital  Charter 2017/2021; Montreal  Declaration for Responsible  Development of AI Directive on  Automated  Decision Making;  Algorithmic  Impact  Assessment CIO Strategy Council develops  AI Standards and is accredited  by Standards Council of Canada,  focusing on ethical design and  ADM audits; $8.6 million over  five years, starting in 2021–22,  to advance the development and  adoption of AI standards CAD 125 million  (USD 100 million)  2017-2022  EU Ethics Guidelines for  Trustworthy AI; White Paper on  AI; Proposal for a regulation on  AI; National ethics guidelines Coordinated Plan  on AI; Proposal  for a regulation on  AI; Digital Decade  package CEN-CENELC Joint Technical  Committee 21 ‘Artificial  Intelligence’; national standards  focus on EU interoperability,  ethics, fundamental rights, and  safety EUR 20 billion  (USD 23.3 billion)  per year until 2030,  national funding Japan R&D Guidelines 2018; Social  Principles of Human-Centric AI  2019; AI Utilization Guidelines  2019; Society 5.0 framework Draft AI Utilization  Principles  Guidelines 2019;  AI Technology  Strategy 2017 Ministry of Economy, Trade  and Industry (METI), Japanese  Industrial Standards Committee  and Information Technology  Standards Commission focus  on developing sector-specific  standards in transportation,  safety, and patents Yen 77 billion  (USD 70 billion)  2018  Singapore Model AI Governance  Framework, 2nd Edition,  2020; Implementation and  Self-Assessment Guide for  Organizations; Principles  to Promote Fairness,  Ethics, Accountability and  Transparency National AI  Strategy Voluntary Horizontal Model  Framework contributes to global  standards for AI-related policies  and guidelines Up to SG$150  million  (USD 110.8  million)  2017-2022   U.K.
# File 45

(m / multi-sentence
      :snt1 (a / and
            :op1 (f / focus-01
                  :ARG0 (g / government-organization
                        :quant 7
                        :ARG0-of (a2 / administrate-01)
                        :ARG0-of (p / participate-01
                              :ARG1 (c / conference
                                    :name (n / name
                                          :op1 "FCAI"))))
                  :ARG1 (a3 / and
                        :op1 (s / standard
                              :mod (e / ethics)
                              :mod (a4 / artificial))
                        :op2 (s2 / standard
                              :mod (e2 / ethics)
                              :ARG1-of (e3 / exist-01))))
            :op2 (p2 / publication
                  :name (n2 / name
                        :op1 "Public"
                        :op2 "Investment"
                        :op3 "Board")
                  :mod (c2 / country
                        :name (n3 / name
                              :op1 "Australia")))
            :op3 (r / review-01
                  :ARG0 (g2 / government-organization
                        :name (n4 / name
                              :op1 "Standards"
                              :op2 "Council"
                              :op3 "of"
                              :op4 "Canada"))
                  :ARG1 (r2 / regulate-01
                        :ARG1 (ii / intelligent-01
                              :mod (a5 / artificial)))
                  :time (d / date-entity
                        :year 2017))
            :op4 (p3 / publication
                  :name (n5 / name
                        :op1 "Model"
                        :op2 "AI"
                        :op3 "Governance"
                        :op4 "Framework")
                  :time (d2 / date-entity
                        :year 2020)
                  :mod (c3 / country
                        :name (n6 / name
                              :op1 "Singapore")))
            :op5 (p4 / publication
                  :name (n7 / name
                        :op1 "Social"
                        :op2 "Principles"
                        :op3 "of"
                        :op4 "Human-Centric"
                        :op5 "AI")
                  :time (d3 / date-entity
                        :year 2019))
            :op6 (p5 / publication
                  :name (n8 / name
                        :op1 "Draft"
                        :op2 "AI"
                        :op3 "Utilization"
                        :op4 "Principles")
                  :time (d4 / date-entity
                        :year 2019))
            :op7 (p6 / publication
                  :name (n9 / name
                        :op1 "CEN-CENELC"
                        :op2 "Joint"
                        :op3 "Technical"
                        :op4 "Committee")
                  :time (d5 / date-entity
                        :year 2017))
            :op8 (p7 / publication
                  :name (n10 / name
                        :op1 "Public"
                        :op2 "Accountability"
                        :op3 "and"
                        :op4 "Transparency"
                        :op5 "Guide"
                        :op6 "for"
                        :op7 "Organization"))
            :op9 (p8 / publication
                  :name (n11 / name
                        :op1 "Information"
                        :op2 "Technology"
                        :op3 "Standards"
                        :op4 "Commission")
                  :time (d6 / date-entity
                        :year 2017))
            :op10 (p9 / publication
                  :name (n12 / name
                        :op1 "Yuan"
                        :op2 "2000000000"
                        :op3 "Yuan")
                  :ARG1-of (r3 / rate-entity-91
                        :ARG2 (t / temporal-quantity
                              :quant 1
                              :unit (y / year))))
            :op11 (m2 / monetary-quantity
                  :quant 125000000
                  :unit (d7 / dollar)))
      :op12 (m3 / monetary-quantity
            :quant 100000000
            :unit (d8 / dollar))
      :time (d9 / date-entity
            :quant 1
            :unit (y2 / year))
      :purpose (a6 / advance-01
            :ARG1 (a7 / and
                  :op1 (d10 / develop-02
                        :ARG1 s)
                  :op2 (a8 / adopt-01
                        :ARG1 s)))
      :mod (g3 / globe)
      :snt2 (a9 / and
            :op1 (ii2 / intercede-01
                  :ARG0 (o / organization
                        :name (n13 / name
                              :op1 "EU"))
                  :ARG1 (o2 / organization
                        :name (n14 / name
                              :op1 "European"
                              :op2 "Civilization"
                              :op3 "Union")))
            :op2 (o3 / organization
                  :name (n15 / name
                        :op1 "European"
                        :op3 "Union")))
      :op3 (o4 / organization
            :name (n16 / name
                  :op1 "European"
                  :op4 "Union"
                  :op5 "Union"
                  :op6 "Union"
                  :op7 "of"
                  :op8 "Civilization"
                  :op9 "Union"))
      :op4 "Union"
      :snt3 p6)

# ::snt STRENGTHENING INTERNATIONAL COOPERATION  ON AI45Table 2. International frameworks for the development of responsible AI Values Definitions EU Australia Japan Singapore OECD Human  centeredAI systems should be designed to be  inclusive, accommodating the needs of the  individuals that interact with it, and used in  a manner that is aligned with the values of  the community in which it is deployed.✔ ✔ ✔ ✔ ✔ Mitigate risks  and promote  benefitsAI systems should be designed and  deployed for the benefit of end users and  avoid unintended negative impacts on third  parties.✔ ✔ ✔ ✔ ✔ Fairness Governance and technical safeguards are  important to identify and mitigate risks of  unfair biases, particularly in circumstances  where an AI system could have a  consequential impact on people.✔ ✔ ✔ ✔ ✔ Explainability AI systems should be understandable;  context will dictate the appropriate  mechanisms for providing transparency  about a particular system’s decisionmaking  processes.✔ ✔ ✔ ✔ ✔ Privacy and  securityAI systems should be secure and enable  users to make informed choices regarding  use of personal information.✔ ◑ ✔ ○ ✔ Safety and  reliabilityAI systems should be designed to mitigate  foreseeable safety risks and adequately  tested to ensure that they operate as  intended.✔ ✔ ◑ ✔ ✔ Accountability A lifecycle approach to AI accountability,  including appropriate governance  structures for the design phase and redress  mechanisms following deployment is  important.✔ ✔ ◑ ✔ ✔ Riskbased and  proportionateRisks are context-specific and encourage  stakeholders to deploy risk management  techniques that are tailored to specific use  cases.✔ ✔ ○ ✔ ✔ Multiple  stakeholdersMultiple stakeholders have important roles  to play in mitigating risks involved in the  development, deployment, and use of AI.◑ ◑ ✔ ✔ ✔ Promotes  innovationGovernment is a key enabler of AI  innovation, and promotes a policy  environment that is conducive to crossborder data flows, value-added data  services, access to non-sensitive  government data, R&D, and workforce  development initiatives.○ ◑ ✔ ○ ✔ ✔  Satisfactory       ◑ Partial       ○ Unaddressed Source: BSA/The Software Alliance153
# File 45

(m / multi-sentence
      :snt1 (a / and
            :op1 (s / strengthen-01
                  :ARG1 (c / cooperate-01
                        :mod (ii / international)
                        :topic (p / product
                              :name (n / name
                                    :op1 "AI45"))))
            :op2 (d / dictate-01
                  :ARG0 (c2 / context)
                  :ARG1 (a2 / and
                        :op1 (a3 / approach-02
                              :ARG1 (a4 / accountable-02
                                    :ARG1 p)
                              :mod (l / lifecycle)
                              :ARG2-of (ii2 / include-01
                                    :ARG1 (a5 / and
                                          :op1 (p2 / phase
                                                :mod (d2 / design-01))
                                          :op2 (m2 / mechanism
                                                :ARG0-of (r / redress-01
                                                      :ARG1 p2))))))))
      :snt2 (a6 / and
            :op1 (r2 / recommend-01
                  :ARG1 (a7 / and
                        :op1 (s2 / secure-02
                              :ARG1 (s3 / system
                                    :mod (ii3 / intelligent-01
                                          :mod (a8 / artificial))))
                        :op2 (e / enable-01
                              :ARG0 s3
                              :ARG1 (c3 / choose-01
                                    :ARG0 (p3 / person
                                          :ARG0-of (u / use-01))
                                    :ARG1 (u2 / use-01
                                          :ARG1 (ii4 / information
                                                :ARG1-of (p4 / personal-02)))))))
            :op2 (r3 / recommend-01
                  :ARG1 (d3 / design-01
                        :ARG1 s3
                        :ARG3 (a9 / and
                              :op1 (ii5 / inclusive)
                              :op2 (a10 / accommodate-01
                                    :ARG0 s3
                                    :ARG1 (n2 / need-01
                                          :ARG0 (p5 / person
                                                :ARG0-of (ii6 / interact-01
                                                      :ARG1 s3)))
                                    :manner (a11 / align-01
                                          :ARG1 s3
                                          :ARG2 (v / value
                                                :poss (c4 / community
                                                      :location-of (d4 / deploy-01
                                                            :ARG1 s3)))))
                              :op3 (a12 / avoid-01
                                    :ARG0 s3
                                    :ARG1 (ii7 / impact-01
                                          :ARG0 s3
                                          :ARG1 (p6 / party
                                                :ord (o / ordinal-entity
                                                      :value 3))
                                          :ARG1-of (ii8 / intend-01
                                                :polarity -)))))))
      :snt3 (a13 / and
            :op1 (d5 / depend-01
                  :ARG0 (r4 / risk-01))
            :op2 (d6 / depend-01
                  :ARG0 (r5 / risk-01)))
      :op3 (e2 / encourage-01
            :ARG0 (a14 / and
                  :op1 (g / government-organization
                        :ARG0-of (g2 / govern-01))
                  :op2 (o2 / organization
                        :name (n3 / name
                              :op1 "OECD")))
            :ARG2 (d7 / deploy-01
                  :ARG1 (t / technique
                        :ARG1-of (t2 / tailor-01
                              :ARG2 (c5 / case-04
                                    :ARG1 (a15 / and
                                          :op1 (d8 / data
                                                :ARG1-of (s4 / sensitive-03
                                                      :polarity -))
                                          :op2 (d9 / data
                                                :ARG1-of (a16 / add-02))))))))
      :ARG1-of (ii9 / important-01))

# ::snt It covers best practices for compliance with  data protection laws in development and deployment of AI systems  and focuses on accountability and governance; data protection impact  assessment; lawfulness, fairness, and transparency; security and data  minimization; and individual rights in AI systems.184 • The Partnership on AI hosted important discussions for the development  of an end-to-end approach to internal algorithmic auditing, including an  analysis of how to learn across industries.185
# File 45

(m / multi-sentence
      :li 185
      :snt1 (a / and
            :op1 (c / cover-01
                  :ARG0 (ii / it)
                  :ARG1 (p / practice-01
                        :ARG1 (c2 / comply-01
                              :ARG1 (l / law
                                    :topic (p2 / protect-01
                                          :ARG1 (d / data)))
                              :time (a2 / and
                                    :op1 (d2 / develop-02
                                          :ARG1 (s / system
                                                :mod (a3 / artificial)))
                                    :op2 (d3 / deploy-01
                                          :ARG1 s)))
                        :ARG1-of (h / have-degree-91
                              :ARG2 (g / good-02
                                    :ARG1 p)
                              :ARG3 (m2 / most))))
            :op2 (f / focus-01
                  :ARG0 ii
                  :ARG2 (a4 / and
                        :op1 (a5 / and
                              :op1 (a6 / accountable-02)
                              :op2 (g2 / govern-01))
                        :op2 (a7 / assess-01
                              :ARG1 (ii2 / impact-01
                                    :ARG0 (l2 / law
                                          :topic (p3 / protect-01
                                                :ARG1 (d4 / data)))))
                        :op3 (f2 / fairness)
                        :op4 (t / transparency)
                        :op5 (a8 / and
                              :op1 (s2 / secure-02)
                              :op2 (m3 / minimize-01
                                    :ARG1 (d5 / data)))
                        :op6 (r / right-05
                              :ARG1 (ii3 / individual)
                              :location (s3 / system
                                    :mod (a9 / artificial))))))
      :snt2 (h2 / host-01
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "The"
                        :op2 "Partnership"
                        :op3 "on"
                        :op4 "AI"))
            :ARG1 (d6 / discuss-01
                  :ARG1 (d7 / develop-02
                        :ARG1 (a10 / approach-02
                              :ARG1 (a11 / audit-01
                                    :mod (a12 / algorithm)
                                    :ARG1-of (ii4 / internal-02))
                              :mod (e / end-to-end)
                              :ARG2-of (ii5 / include-01
                                    :ARG1 (a13 / analyze-01
                                          :ARG1 (t2 / thing
                                                :manner-of (l3 / learn-01
                                                      :location (a14 / across
                                                            :op1 (ii6 / industry))))))))
                  :ARG1-of (ii7 / important-01))))

# ::snt Because of the importance to these governments  and others of fairness, due process, nondiscrimination, and humancentered AI, they face a heightened need to practice what they preach by  ensuring the AI that they deploy is ethical and trustworthy.
# File 45

(c / cause-01
      :ARG0 (ii / important-01
            :ARG1 (a / and
                  :op1 (f / fairness)
                  :op2 (d / due-process)
                  :op3 (d2 / discriminate-02
                        :polarity -)
                  :op4 (ii2 / intelligent-01
                        :mod (a2 / artificial)
                        :ARG1-of (c2 / center-01
                              :ARG2 (h / human))))
            :ARG2 (a3 / and
                  :op1 (g / government-organization
                        :ARG0-of (g2 / govern-01)
                        :mod (t / this))
                  :op2 (o / other)))
      :ARG1 (f2 / face-01
            :ARG0 (t2 / they)
            :ARG1 (n / need-01
                  :ARG1 (p / practice-01
                        :ARG0 t2
                        :ARG1 (t3 / thing
                              :ARG1-of (p2 / preach-01
                                    :ARG0 t2))
                        :manner (e / ensure-01
                              :ARG0 t2
                              :ARG1 (a4 / and
                                    :op1 (e2 / ethics
                                          :domain (ii3 / intelligent-01
                                                :mod a2))
                                    :op2 (t4 / trustworthy
                                          :domain ii3))))
                  :ARG1-of (h2 / heighten-01))))

# ::snt Some examples  are discussed below:196 • In sectors like finance, key criteria such as fairness, discrimination, and  transparency have been subject to extensive regulatory intervention  in the past, and sectoral regulation must ensure continuity while at  the same time accounting for the increasing use of AI.
# File 45

(d / discuss-01
      :li 196
      :ARG1 (e / example
            :quant (s / some))
      :location (b / below)
      :example-of (a / and
            :op1 (s2 / subject-01
                  :ARG1 (c / criteria
                        :ARG1-of (k / key-02)
                        :example (a2 / and
                              :op1 (f / fairness)
                              :op2 (d2 / discriminate-02)
                              :op3 (t / transparency)))
                  :ARG2 (ii / intervene-01
                        :ARG0 (r / regulate-01)
                        :ARG1-of (e2 / extensive-03))
                  :time (p / past)
                  :location (s3 / sector
                        :example (f2 / finance)))
            :op2 (o / obligate-01
                  :ARG1 (r2 / regulate-01
                        :mod (s4 / sector))
                  :ARG2 (e3 / ensure-01
                        :ARG0 r2
                        :ARG1 (c2 / continue-01)
                        :time (a3 / account-01
                              :ARG0 r2
                              :ARG1 (u / use-01
                                    :ARG1 (ii2 / intelligent-01
                                          :mod (a4 / artificial))
                                    :ARG1-of (ii3 / increase-01)))))))

# ::snt AI policies and investment by FCAI participants   | ⮌  contents AI ethical  framework307Existing AI  regulation308Data governance309 AI Standards310Computing power Privacy IP Cyber SI315Model AI Governance  Framework, 2nd Edition,  2020;  Implementation and SelfAssessment Guide for  Organisations (ISAGO);  Principles to Promote  Fairness, Ethics,  Accountability and  Transparency (FEAT) National AI Strategy Personal Data  Protection Act 2012  (PDPA) (amended in  2020);  Trusted Data  Sharing Framework  (voluntary)Patents Act;  Copyright Act;  AI2 Scheme  for fast-track  examinationCybersecurity  Act 2018;  Computer  Misuse ActSpring SG: Voluntary  Horizontal Model  Framework also  contributes to global  standards for AI-related  policies and guidelinesNSCC cooperates with  Japan’s RIKEN and RIST  to access Fugaku;  National Research  Foundation builds second  national supercomputer  system (SG$200 million) U.K.316Guidance on Ethics,  Transparency  Accountability for ADMNational AI Strategy Data Protection Act  2018 (U.K. GDPR);  U.K. eIDAS RegulationCopyright, Designs  and Patents Act  1988Cyber Security  Information  Sharing  Partnership, UK  GDPRBritish Standard Institute  focuses on international  cooperation and  healthcare standardsGBP 20 million funding  for DiRAC (academic);  High Performance  Computing facility US317Principles in Executive  Order 13859 and  Executive Order 13960;  Agency specific  frameworks, statespecific guidelines  Government  agencies assessing  where AI regulation  is needed, where  existing regulation  applies, and roles  for self assessment,  codes, etc.
# File 45

(m / multi-sentence
      :snt1 (a / and
            :op1 (a2 / and
                  :op1 (p / policy-01
                        :ARG0 (o / organization
                              :ARG0-of (p2 / participate-01
                                    :ARG1 (c / conference
                                          :name (n / name
                                                :op1 "FCAI")))))
                  :op2 (ii / invest-01
                        :ARG0 o))
            :op2 (f / focus-01
                  :ARG0 o
                  :ARG2 (a3 / and
                        :op1 (c2 / cooperate-01
                              :mod (ii2 / international))
                        :op2 (s / standard
                              :mod (h / healthcare)))))
      :snt2 (a4 / and
            :op1 (r / regulate-01
                  :ARG1 (ii3 / intelligent-01
                        :mod (a5 / artificial))
                  :ARG1-of (e / exist-01)
                  :ARG1-of (c3 / cite-01
                        :ARG2 308))
            :op2 (r2 / regulate-01
                  :ARG1 (p3 / power
                        :mod (c4 / computer))
                  :ARG1-of (m2 / mean-01
                        :ARG2 (l / law
                              :name (n2 / name
                                    :op1 "Cybersecurity"
                                    :op2 "Act")
                              :time (d / date-entity
                                    :year 2018))))
            :op3 (l2 / law
                  :name (n3 / name
                        :op1 "European"
                        :op2 "Digital"
                        :op3 "Security"
                        :op4 "Act")
                  :ARG1-of (m3 / mean-01
                        :ARG2 (a6 / and
                              :op1 (l3 / law
                                    :name (n4 / name
                                          :op1 "Cyber"
                                          :op2 "Security"
                                          :op3 "and"
                                          :op4 "Information"
                                          :op5 "Sharing"
                                          :op6 "Framework"))
                              :op2 (l4 / law
                                    :name (n5 / name
                                          :op1 "FEAT"))))
                  :op4 (l5 / law
                        :name (n6 / name
                              :op1 "National"
                              :op2 "Data"
                              :op3 "Protection"
                              :op4 "Act")
                        :time (d2 / date-entity
                              :year 2012))
                  :op5 (o2 / organization
                        :name (n7 / name
                              :op1 "National"
                              :op2 "Research"
                              :op3 "Foundation")
                        :ARG0-of (b / build-01
                              :ARG1 (s2 / system
                                    :mod (c5 / computer)
                                    :mod (n8 / nation)
                                    :ARG1-of (c6 / cost-01
                                          :ARG2 (m4 / monetary-quantity
                                                :quant 200000000
                                                :unit (p4 / pound)))))))
            :op6 (f2 / facility
                  :name (n9 / name
                        :op1 "US317"
                        :op2 "High"
                        :op3 "Performing"
                        :op4 "Technology"
                        :op5 "System"))
            :op7 (l6 / law
                  :name (n10 / name
                        :op1 "Executive"
                        :op2 "Order"
                        :op3 "13859"))
            :op8 (l7 / law
                  :name (n11 / name
                        :op1 "Executive"
                        :op2 "Orders"
                        :op3 "13960")))
      :op9 (f3 / framework
            :ARG1-of (s3 / specific-02
                  :ARG2 (a7 / agency)))
      :op10 (g / guideline
            :mod (s4 / state))
      :op11 a7
      :ARG0-of (a8 / assess-01
            :ARG1 (r3 / regulate-01
                  :ARG1 (ii4 / intelligent-01)))
      :op12 (a9 / and
            :op1 (a10 / assess-01
                  :ARG1 (s5 / self)))
      :op12 (c7 / code)
      :op13 (e2 / et-cetera))

# ::snt Inioluwa Debora Raji, et al., “Closing the AI accountability gap: Defining an end-to-end framework for internal algorithmic auditing,”  Conference on Fairness, Accountability, and Transparency (FAT* ’20), January 27-30, 2020, https://arxiv.org/pdf/2001.00973.pdf.
# File 45

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Inioluwa"
                        :op2 "Debora"
                        :op3 "Raji"))
            :op2 (p3 / person
                  :mod (o / other)))
      :ARG1 (p4 / publication
            :name (n2 / name
                  :op1 "Closing"
                  :op2 "the"
                  :op3 "Accountability"
                  :op4 "Gap")
            :ARG1-of (m / mean-01
                  :ARG2 (d / define-01
                        :ARG1 (f / framework
                              :mod (e / end-to-end)
                              :purpose (a2 / audit-01
                                    :mod (a3 / algorithm)
                                    :ARG1-of (ii / internal-02))))))
      :ARG4 (c / conference
            :name (n3 / name
                  :op1 "Conference"
                  :op2 "on"
                  :op3 "Fairness,"
                  :op4 "Accountability"
                  :op5 "and"
                  :op6 "Transparency")
            :time (d2 / date-interval
                  :op1 (d3 / date-entity
                        :month 1
                        :day 27
                        :year 2020)
                  :op2 (d4 / date-entity
                        :month 1
                        :day 30
                        :year 2020)))
      :ARG4 (u / url-entity
            :value "https://arxiv.org/pdf/2001.00973.pdf"))

# ::snt The key themes of the Guidance are accountability and governance; data protection; lawfulness, fairness, and transparency;  security and data minimisation; and ensuring that individuals can effectively exercise their rights relating to their data.
# File 45

(t / theme
      :ARG1-of (k / key-02)
      :poss (g / government-organization
            :name (n / name
                  :op1 "Guidance"))
      :domain (a / and
            :op1 (a2 / and
                  :op1 (a3 / accountable-02)
                  :op2 (g2 / govern-01))
            :op2 (p / protect-01
                  :ARG1 (d / data))
            :op3 (l / lawfulness)
            :op4 (f / fairness)
            :op5 (t2 / transparency)
            :op6 (a4 / and
                  :op1 (s / security)
                  :op2 (m / minimize-01
                        :ARG1 (d2 / data)))
            :op7 (e / ensure-01
                  :ARG1 (p2 / possible-01
                        :ARG1 (e2 / exercise-01
                              :ARG0 (ii / individual)
                              :ARG1 (r / right-05
                                    :ARG1 ii
                                    :ARG1-of (r2 / relate-01
                                          :ARG2 d2))
                              :ARG1-of (e3 / effective-04))))))

# ::snt “AI Fairness 360,” IBM Research Trusted AI, accessed August 27, 2021, https://aif360.mybluemix.net/; “AI Explainability 360,” IBM Research  Trusted AI, accessed August 27, 2021, https://aix360.mybluemix.net/.
# File 45

(a / and
      :op1 (p / publication
            :name (n / name
                  :op1 "AI"
                  :op2 "Fairness"
                  :op3 360)
            :medium (p2 / publication
                  :name (n2 / name
                        :op1 "IBM"
                        :op2 "Research"
                        :op3 "Trusted"
                        :op4 "AI"))
            :ARG1-of (a2 / access-01
                  :time (d / date-entity
                        :day 27
                        :month 8
                        :year 2021))
            :mod (u / url-entity
                  :value "https://aif360.mybluemix.net/"))
      :op2 (p3 / publication
            :name (n3 / name
                  :op1 "AI"
                  :op2 "Explainedability"
                  :op3 360)
            :medium p2
            :ARG1-of (a3 / access-01
                  :time d)))

# ::snt “Model artificial intelligence governance framework: second edition,” Personal Data Protection Commission Singapore, January 2020,  https://www.pdpc.gov.sg/help-and-resources/2020/01/second-edition-of-model-artificial-intelligence-governance-framework ; “Singapore’s  approach to AI governance,” Personal Data Protection Commissioner Singapore, accessed September 1, 2021, https://www.pdpc.gov.sg/ Help-and-Resources/2020/01/Model-AI-Governance-Framework; “Principles to promote fairness, ethics, accountability, and transparency  (FEAT) in the use of artificial intelligence and data analytics in Singapore’s financial sector,” Monetary Authority of Singapore, http://www.
# File 45

(a / and
      :op1 (p / publication
            :name (n / name
                  :op1 "Model"
                  :op2 "Artificial"
                  :op3 "Intelligence"
                  :op4 "Governance"
                  :op5 "Framework")
            :mod (e / edition
                  :ord (o / ordinal-entity
                        :value 2))
            :medium (p2 / publication
                  :name (n2 / name
                        :op1 "Personal"
                        :op2 "Data"
                        :op3 "Protection"
                        :op4 "Commission"
                        :op5 "Singapore"))
            :time (d / date-entity
                  :month 1
                  :year 2020))
      :op2 (p3 / publication
            :name (n3 / name
                  :op1 "Monetary"
                  :op2 "Authority"
                  :op3 "of"
                  :op4 "Singapore")
            :ARG1-of (a2 / access-01
                  :time (d2 / date-entity
                        :month 9
                        :day 1
                        :year 2021))
            :medium (u / url-entity
                  :value "https://www.pdpc.gov.sg/help-and-resources/2020/01/Model-AI-Governance-Framework"))
      :op3 (p4 / publication
            :name (n4 / name
                  :op1 "FEAT")
            :ARG0-of (p5 / promote-02
                  :ARG1 (a3 / and
                        :op1 (f / fairness)
                        :op2 (e2 / ethics)
                        :op3 (a4 / accountable-02)
                        :op4 (t / transparency))
                  :topic (u2 / use-01
                        :ARG1 (a5 / and
                              :op1 (ii / intelligent-01
                                    :mod (a6 / artificial))
                              :op2 (a7 / analyze-01
                                    :ARG1 (d3 / data)))
                        :ARG2 (s / sector
                              :mod (f2 / finance)
                              :location (c / country
                                    :name (n5 / name
                                          :op1 "Singapore")))))))

# ::snt pdf; “Launch of AI: Accelerated initiative for artificial intelligence—an accelerated application-to-grant service for patent applications in  artificial intelligence,” Intellectual Property Office of Singapore, April 26, 2019, https://www.ipos.gov.sg/docs/default-source/resourceslibrary/patents/circulars/(2019)-circular-no-2---ai2-initiative_final.pdf?sfvrsn=2; “Singapore’s approach to AI governance,” Personal Data  Protection Commissioner Singapore, accessed September 1, 2021, https://www.pdpc.gov.sg/Help-and-Resources/2020/01/Model-AIGovernance-Framework; “Principles to promote fairness, ethics, accountability, and transparency (FEAT) in the use of artificial intelligence  and data analytics in Singapore’s financial sector,” Monetary Authority of Singapore, http://www.mas.gov.sg/~/media/MAS/News%20 and%20Publications/Monographs%20and%20Information%20Papers/FEAT%20Principles%20Final.pdf; Singapore researchers plug in to  world’s fastest supercomputer,” HPC Wire, November 30, 2020, https://www.hpcwire.com/off-the-wire/singapore-researchers-plug-in-toworlds-fastest-supercomputer/;  316.
# File 45

(a / and
      :op1 (p / publication-91
            :ARG1 (p2 / publication
                  :name (n / name
                        :op1 "Launch"
                        :op2 "of"
                        :op3 "Accelerated"
                        :op4 "Initiative"
                        :op5 "for"
                        :op6 "Artificial"
                        :op7 "Intelligence")
                  :ARG1-of (m / mean-01
                        :ARG2 (p3 / publication
                              :name (n2 / name
                                    :op1 "Public"
                                    :op2 "Data"
                                    :op3 "Protection"
                                    :op4 "Commission")
                              :mod (c / country
                                    :name (n3 / name
                                          :op1 "Singapore"))
                              :ARG1-of (a2 / access-01
                                    :time (d / date-entity
                                          :month 9
                                          :day 1
                                          :year 2021)))))
            :ARG4 (u / url-entity
                  :value "https://www.hpcwire.gov.sg/off-the-wire/singapore-researchers-plug-in-toworlds-fastest-supercomputer/"))
      :op2 (p4 / publication
            :name (n4 / name
                  :op1 "Model-AIGovernance-Framework"))
      :op3 (p5 / publication
            :name (n5 / name
                  :op1 "Principles"
                  :op2 "to"
                  :op3 "Promoting"
                  :op4 "for"
                  :op5 "Artificial"
                  :op6 "Intelligence"
                  :op7 "and"
                  :op8 "Ethics"
                  :op9 "and"
                  :op10 "Data"
                  :op11 "Accountability"
                  :op12 "and"
                  :op13 "Transparency"))
      :time (d2 / date-entity
            :month 11
            :day 30
            :year 2020))

# ::snt The Com mission published a Communication31 welcom ing the seven key requirements  identified in  the Guidelines of the High -Level Expert Group :    Human agency and oversight ,    Technical robustness and safety ,    Privacy and data governance ,    Transparency ,    Diversity, non-discrimination and fairness ,    Societal and environmental wellbeing , and    Accountability .
# File 72

(p / publish-01
      :ARG0 (m / mission-01
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "Communication"
                        :op2 "31")))
      :ARG1 (t / thing
            :quant 7
            :ARG1-of (r / require-01)
            :ARG1-of (k / key-02)
            :ARG1-of (ii / identify-01
                  :ARG0 (g / guideline
                        :poss (o2 / organization
                              :name (n2 / name
                                    :op1 "High-Level"
                                    :op2 "Expert"
                                    :op3 "Group"))))
            :ARG2-of (ii2 / include-91
                  :ARG1 (a / and
                        :op1 (a2 / and
                              :op1 (a3 / agency
                                    :mod (h / human))
                              :op2 (o3 / oversee-01))
                        :op2 (a4 / and
                              :op1 (r2 / robustness
                                    :mod (t2 / technical))
                              :op2 (s / safe-01))
                        :op3 (a5 / and
                              :op1 (p2 / privacy)
                              :op2 (g2 / govern-01
                                    :ARG1 (d / data)))
                        :op4 (t3 / transparency)
                        :op5 (a6 / and
                              :op1 (d2 / diversity)
                              :op2 (d3 / discriminate-01
                                    :polarity -)
                              :op3 (f / fairness))
                        :op6 (a7 / and
                              :op1 (w / well-09
                                    :ARG1 (s2 / society))
                              :op2 (e / environment))
                        :op7 (a8 / accountable-02)))))

# ::snt Source: Tolan S., Miron M., Gomez E. and Castillo C. "Why Machine Learning May Lead to Unfairness:  Evidence from Risk Assessment for Juvenile Justice in Catalonia", Best Paper Award, International  Conference on AI and Law , 2019   Certain AI programmes for facial analysis display gender and racial bias, demonstrating low errors for  determining the gender of lighter -skinned men but high errors in determining gender for darker -skinned  women .
# File 72

(m / multi-sentence
      :snt1 (s / source-01
            :ARG2 (p / publication-91
                  :ARG0 (a / and
                        :op1 (p2 / person
                              :name (n / name
                                    :op1 "Tolan"))
                        :op2 (p3 / person
                              :name (n2 / name
                                    :op1 "Miron"))
                        :op3 (p4 / person
                              :name (n3 / name
                                    :op1 "Gomez"
                                    :op2 "E."))
                        :op4 (p5 / person
                              :name (n4 / name
                                    :op1 "Castillo"
                                    :op2 "C.")))
                  :ARG1 (p6 / publication
                        :name (n5 / name
                              :op1 "Why"
                              :op2 "Machine"
                              :op3 "Learning")
                        :ARG0-of (d / demonstrate-01
                              :ARG1 (c / contrast-01
                                    :ARG1 (e / err-01
                                          :ARG1 (d2 / determine-01
                                                :ARG1 (g / gender
                                                      :poss (m2 / man
                                                            :ARG1-of (h / have-degree-91
                                                                  :ARG2 (d3 / dark-02
                                                                        :ARG1 (s2 / skin)
                                                                        :ARG3 (m3 / more)))))
                                                :ARG1-of (l / low-04))
                                          :ARG2 (e2 / err-01
                                                :ARG1 (d4 / determine-01
                                                      :ARG1 (g2 / gender
                                                            :poss (w / woman
                                                                  :ARG1-of (h2 / have-degree-91
                                                                        :ARG2 (d5 / dark-02
                                                                              :ARG1 (s3 / skin)
                                                                              :ARG3 (m4 / more)))))
                                                      :ARG1-of (h3 / high-02)))))
                              :ARG4 (a2 / award
                                    :name (n6 / name
                                          :op1 "Best"
                                          :op2 "Paper"
                                          :op3 "Award")
                                    :mod (c2 / conference
                                          :name (n7 / name
                                                :op1 "International"
                                                :op2 "Conference"
                                                :op3 "on"
                                                :op4 "AI"
                                                :op5 "and"
                                                :op6 "Law"))
                                    :time (d6 / date-entity
                                          :year 2019)))
                        :snt2 (d7 / display-01
                              :ARG0 (p7 / program
                                    :mod (a3 / artificial)
                                    :mod (c3 / certain)
                                    :instrument-of (a4 / analyze-01
                                          :ARG1 (f / face))))
                        :ARG1 (a5 / and
                              :op1 (b / bias-01
                                    :ARG1 p7
                                    :ARG3 (g3 / gender))
                              :op2 (b2 / bias-01
                                    :ARG0 p7
                                    :ARG1 p7
                                    :ARG3 (r / race)))))))

# ::snt Source: Joy Buolamwini, Timnit Gebru ; Proceedings of the 1st Conference on Fairness,  Accountability and Transparency, PMLR 81:77 -91, 2018 .
# File 72

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Joy"
                        :op2 "Buolamwini"))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "Timnit"
                        :op2 "Gebru")))
      :ARG1 (p4 / Proceedings
            :part-of (c / conference
                  :ord (o / ordinal-entity
                        :value 1)
                  :topic a
                  :op1 (f / fairness)
                  :op2 (a2 / accountable-02)
                  :op3 (t / transparency)))
      :ARG4 (j / journal
            :name (n3 / name
                  :op1 "MPLR"))
      :ARG7 (v / value-interval
            :op1 81
            :op2 7791)
      :time (d / date-entity
            :year 2018))

# ::snt An End-To-End Machine Learning Pipeline That Ensures Fairness Policies  8.
# File 185

(p / pipeline
      :li 8
      :mod (m / machine
            :ARG0-of (l / learn-01))
      :mod (e / end-to-end)
      :ARG0-of (e2 / ensure-01
            :ARG1 (p2 / policy-01
                  :ARG2 (f / fairness))))

# ::snt The  EGD intends to promote fairness and prosperity and  an efficient, competitive,  and more sustainable  economy for Europ e. With respect to the environment, it targets no net greenhouse gas emissions by  2050, decoupling economic growth from resource use, preserving , and enhancing the EU ’s natural  capital and protecting people ’s health and well- being from environmental risks and impacts.
# File 91

(m / multi-sentence
      :snt1 (ii / intend-01
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "EGD"))
            :ARG1 (p / promote-02
                  :ARG0 o
                  :ARG1 (a / and
                        :op1 (f / fairness)
                        :op2 (p2 / prosper-01)
                        :op3 (e / economy
                              :ARG1-of (e2 / efficient-01)
                              :ARG0-of (c / compete-01)
                              :ARG1-of (h / have-degree-91
                                    :ARG2 (s / sustain-01
                                          :ARG1 e)
                                    :ARG3 (m2 / more)))
                        :beneficiary (o2 / organization
                              :name (n2 / name
                                    :op1 "European"
                                    :op2 "Union")))))
      :snt2 (t / target-01
            :ARG0 (ii2 / it)
            :ARG1 (a2 / and
                  :op1 (e3 / emit-01
                        :polarity -
                        :ARG1 (g / gas
                              :mod (g2 / greenhouse))
                        :mod (n3 / net)
                        :time (b / by
                              :op1 (d / date-entity
                                    :year 2050)))
                  :op2 (d2 / decouple-01
                        :ARG1 (g3 / grow-01
                              :ARG1 (e4 / economy))
                        :ARG2 (u / use-01
                              :ARG1 (r / resource)))
                  :op3 (p3 / preserve-01
                        :ARG1 (c2 / capital
                              :poss o2
                              :ARG1-of (n4 / natural-03)))
                  :op4 (e5 / enhance-01
                        :ARG1 c2)
                  :op5 (p4 / protect-01
                        :ARG1 (a3 / and
                              :op1 (h2 / healthy
                                    :domain (p5 / person))
                              :op2 (w / well-09
                                    :ARG1 p5))
                        :ARG2 (a4 / and
                              :op1 (r2 / risk-01
                                    :ARG2 (e6 / environment)
                                    :op2 (ii3 / impact-01
                                          :ARG1 e6))))
                  :topic e6)))

# ::snt The y focus on i)  orienting AI towards inclusive  growth, sustainable development and well- being , ii) basing AI on human- centr ed values and fairness,  iii) permitting transparency  and explainability, iv)  ensuring robustness, security and safety, and v)  calling for accountability.
# File 91

(f / focus-01
      :ARG1 (a / and
            :op1 (o / orient-01
                  :li "i"
                  :ARG1 (ii / intelligent-01
                        :mod (a2 / artificial))
                  :ARG2 (a3 / and
                        :op1 (g / grow-01
                              :mod (ii2 / inclusive))
                        :op2 (d / develop-02
                              :ARG1-of (s / sustain-01
                                    :ARG1-of (p / possible-01)))
                        :op3 (w / well-09)))
            :op2 (b / base-02
                  :li "ii"
                  :ARG1 ii
                  :ARG2 (a4 / and
                        :op1 (v / value
                              :mod (c / center
                                    :mod (h / human)))
                        :op2 (f2 / fairness)))
            :op3 (p2 / permit-01
                  :li "iii"
                  :ARG1 (a5 / and
                        :op1 (t / transparency)
                        :op2 (e / explain-01)))
            :op4 (e2 / ensure-01
                  :li "iv"
                  :ARG1 (a6 / and
                        :op1 (r / robustness)
                        :op2 (s2 / security)
                        :op3 (s3 / safe-01)))
            :op5 (c2 / call-03
                  :li "v"
                  :ARG1 (a7 / accountable-02)))
      :mod (y / y))

# ::snt Much of the regulatory and ethics discussion about AI in the EU has also centred the concept of fairness, which has been  demonstrated to be particularly contentious because it means different things to technical and nontechnical communities.
# File 80

(c / center-01
      :ARG0 (d / discuss-01
            :ARG1 (a / and
                  :op1 (r / regulate-01)
                  :op2 (e / ethics))
            :topic (ii / intelligent-01
                  :mod (a2 / artificial))
            :location (o / organization
                  :name (n / name
                        :op1 "EU"))
            :quant (m / much))
      :ARG1 (c2 / concept
            :topic (f / fair-01
                  :ARG1-of (d2 / demonstrate-01
                        :ARG3 (c3 / contentious
                              :mod (p / particular))
                        :ARG1-of (c4 / cause-01
                              :ARG0 (m2 / mean-01
                                    :ARG1 f
                                    :ARG2 (t / thing
                                          :ARG1-of (d3 / differ-02))
                                    :ARG3 (a3 / and
                                          :op1 (c5 / community
                                                :mod (t2 / technical))
                                          :op2 (c6 / community
                                                :mod (t3 / technical
                                                      :polarity -))))))))
      :mod (a4 / also))

# ::snt Fairness and  abstraction in sociotechnical systems.
# File 80

(a / and
      :op1 (f / fairness)
      :op2 (a2 / abstract-02)
      :location (s / system
            :mod (s2 / society)))

# ::snt In Proceedings of the conference on fairness, accountability, and transparency  (pp.
# File 80

(b / be-located-at-91
      :ARG1 (p / publication-91
            :ARG1 (c / conference
                  :topic (a / and
                        :op1 (f / fairness)
                        :op2 (a2 / accountable-02)
                        :op3 (t / transparency)))
            :ARG7 (v / value-interval
                  :op1 1
                  :op2 2))
      :ARG2 c)

# ::snt STOA  | Panel for the Future of Science and Technology      8 been developed to supplement the practice and enforcement of technical and organisational  measures required by GDPR.28  In the domain of AI, and largely in the absence of governing legislation, AI ethics committees are an  increasingly common feature of corporate data governance, which are proposed as a way to  institutionalise ethical decision making to help eradicate bias from — and to promote fairness in —  AI systems.29 New non -corporate initiatives, such as the Distributed Artificial Intelligence Research  (DAIR) Institute, which seeks to be a ' space for independent, community -rooted AI research free  from Big Tech 's pervasive influence' , are also developing industry -wide standards for bias mitigation  in AI datasets ' by making it common practice for researchers to write accompanying documentation  about how they gathered their data, what its limitations are  and how it should (or should not) be  used '.30 Inspired by innovations in cybersecurity governance, we have also seen the emergence of  so-called bug bounty programs to promote the discovery and mitigation of algorithmic harms.31  In the domain of content moderation, social media platforms have also created so -called 'oversight  boards ' — an attempt at strengthening ' independent judgement ' regarding decisions to remove  harmful or illegal content on platforms.
# File 80

(m / multi-sentence
      :snt1 (o / organization
            :name (n / name
                  :op1 "STOA"))
      :snt2 (d / develop-02
            :li 8
            :ARG1 (o2 / organization
                  :name (n2 / name
                        :op1 "Panel"
                        :op2 "for"
                        :op3 "the"
                        :op4 "Future"
                        :op5 "of"
                        :op6 "Science"
                        :op7 "and"
                        :op8 "Technology"))
            :ARG3 (a / and
                  :op1 (p / practice-01
                        :ARG1 (a2 / and
                              :op1 (m2 / measure-02
                                    :ARG1 (t / technology))
                              :op2 (m3 / measure-02
                                    :ARG1 (o3 / organize-01))
                              :ARG1-of (r / require-01
                                    :ARG0 (l / law
                                          :name (n3 / name
                                                :op1 "GDPR")))))
                  :op2 (e / enforce-01
                        :ARG1 a2))
            :mod (a3 / also))
      :snt3 (s / see-01
            :li 28
            :ARG0 (w / we)
            :ARG1 (e2 / emerge-01
                  :ARG0 (p2 / program
                        :name (n4 / name
                              :op1 "Bug"
                              :op2 "Bounty")
                        :mod (s2 / so-called)
                        :ARG0-of (s3 / seek-01
                              :ARG1 (s4 / space
                                    :domain (r2 / research-01
                                          :ARG1 (ii / intelligent-01
                                                :mod (a4 / artificial)))
                                    :ARG1-of (r3 / root-02
                                          :ARG2 (c / community))
                                    :ARG1-of (f / free-04
                                          :ARG2 (ii2 / influence-01
                                                :ARG0 (c2 / company
                                                      :name (n5 / name
                                                            :op1 "Big"
                                                            :op2 "Tech"))
                                                :ARG1 r2))))))
            :mod (a5 / also))
      :snt4 (p3 / propose-01
            :li 31
            :ARG1 (f2 / feature
                  :mod (c3 / common
                        :ARG1-of (ii3 / increase-01))
                  :poss (g / govern-01
                        :ARG0 (c4 / corporation)
                        :ARG1 (d2 / data))
                  :domain (c5 / committee
                        :mod (e3 / ethics)))
            :topic (a6 / and
                  :op1 (h / help-01
                        :ARG0 c5
                        :ARG1 (e4 / eradicate-01
                              :ARG0 c5
                              :ARG1 (b / bias-01
                                    :source (s5 / system
                                          :mod (ii4 / intelligent-01
                                                :mod a4))))))
            :op2 (p4 / promote-02
                  :ARG0 c5
                  :ARG1 (f3 / fair-01)))
      :snt5 (a7 / attempt-01
            :li 31
            :ARG0 (p5 / platform)
            :ARG1 (s6 / strengthen-01
                  :ARG0 p5
                  :ARG1 (j / judge-01
                        :ARG0-of (d3 / depend-01
                              :polarity -)
                        :topic (d4 / decide-01
                              :ARG3 (o4 / or
                                    :op1 (c6 / content
                                          :ARG1-of (h2 / harmful-02))
                                    :op2 (c7 / content
                                          :ARG1-of (l2 / legal-02
                                                :polarity -))))))))

# ::snt The first global standard -setting instrument on the ethics of AI, it advances a  number of principles including fairness and non- discrimination, sustainability, privacy, safety and  security, transparency and explainability, and awareness  and literacy.
# File 80

(a / advance-01
      :ARG0 (ii / instrument
            :domain (ii2 / it)
            :ord (o / ordinal-entity
                  :value 1)
            :ARG0-of (s / set-02
                  :ARG1 (s2 / standard
                        :mod (g / globe)))
            :topic (e / ethics
                  :mod (a2 / artificial)))
      :ARG1 (p / principle
            :quant (n / number)
            :ARG2-of (ii3 / include-01
                  :ARG1 (a3 / and
                        :op1 (a4 / and
                              :op1 (f / fairness)
                              :op2 (d / discriminate-02
                                    :polarity -))
                        :op2 (s3 / sustain-01
                              :ARG1-of (p2 / possible-01))
                        :op3 (p3 / privacy)
                        :op4 (a5 / and
                              :op1 (s4 / safe-01)
                              :op2 (s5 / security))
                        :op5 (a6 / and
                              :op1 (t / transparency)
                              :op2 (e2 / explain-01
                                    :ARG1-of p2)))
                  :op6 (a7 / and
                        :op1 (a8 / awareness)
                        :op2 (l / literacy)))))

# ::snt Whereas a thin description of the rule of law will take into  account how institutions can ensure fairness, due process and accountability for the governing of  data, a thick description will acknowledge the ways in which the governance of data takes pla ce in  practice.
# File 80

(c / contrast-01
      :ARG1 (t / take-into-account-04
            :ARG0 (d / describe-01
                  :ARG1 (r / rule-01
                        :ARG1 (l / law))
                  :ARG1-of (t2 / thin-03))
            :ARG1 (p / possible-01
                  :ARG1 (e / ensure-01
                        :ARG0 (ii / institution)
                        :ARG1 (a / and
                              :op1 (f / fairness)
                              :op2 (d2 / due-process)
                              :op3 (a2 / accountable-02
                                    :ARG0 ii
                                    :ARG1 (g / govern-01
                                          :ARG1 (d3 / data)))))))
      :ARG2 (a3 / acknowledge-01
            :ARG0 (d4 / describe-01
                  :ARG1-of (t3 / thick-03)
                  :ARG1 (w / way
                        :manner-of (t4 / take-10
                              :ARG0 g
                              :ARG1 (p2 / practice-01))))))

# ::snt Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency .
# File 80

(p / proceed-01
      :ARG1 (c / conference
            :name (n / name
                  :op1 "ACM"
                  :op2 "Conference"
                  :op3 "on"
                  :op4 "Fairness"
                  :op5 "Accountability"
                  :op6 "and"
                  :op7 "Transparency")
            :time (d / date-entity
                  :year 2021)))

# ::snt Draft AI Utilization Principles (1 /2) 1) Principle of proper utilization 2) Principle of data quality 3) Principle of collaboration  4) Principle of safety 5) Principle of security 6) Principle of privacy 7) Principles of human dignity  and individual autonomy 8) Principle of fairness 9) Principle of transparency 10) Principle of accountabilityThe Conference assessed use cases and ecosystem prospects of AI services and identified the benefits and the  risks of AI systems.
# File 109

(a / and
      :op1 (a2 / assess-01
            :ARG0 (c / conference)
            :ARG1 (a3 / and
                  :op1 (c2 / case-04
                        :ARG1 (u / use-01))
                  :op2 (p / prospect-02
                        :ARG1 (s / service
                              :mod (ii / intelligent-01
                                    :mod (a4 / artificial)))
                        :mod (e / ecosystem))))
      :op2 (ii2 / identify-01
            :ARG0 c
            :ARG1 (a5 / and
                  :op1 (b / benefit-01
                        :ARG0 (s2 / system
                              :mod ii))
                  :op2 (r / risk-01
                        :ARG0 s2)))
      :op3 (p2 / principle
            :li 1
            :topic (u2 / utilize-01
                  :mod (p3 / proper)))
      :op4 (p4 / principle
            :topic (c3 / collaborate-01)
            :li 3)
      :op5 (p5 / principle
            :topic (s3 / safe-01)
            :li 4)
      :op6 (p6 / principle
            :topic (s4 / security)
            :li 5)
      :op7 (p7 / principle
            :topic (p8 / privacy)
            :li 7)
      :op8 (p9 / principle
            :topic (d / dignity
                  :mod (h / human))
            :li 8)
      :op9 (p10 / principle
            :topic (f / fair-01)
            :li 9)
      :op10 (p11 / principle
            :topic (a6 / accountable-02)
            :li 10)
      :ARG1-of (d2 / draft-01))

# ::snt 8)Principle of fairness AI service providers, business users, and data providers should  take into consideration that individuals will not be discriminated  unfairly by the judgments of AI systems or AI services.
# File 109

(r / recommend-01
      :li 8
      :ARG1 (c / consider-02
            :ARG0 (a / and
                  :op1 (c2 / company
                        :ARG0-of (p / provide-01
                              :ARG1 (s / service
                                    :mod (ii / intelligent-01
                                          :mod (a2 / artificial)))))
                  :op2 (p2 / person
                        :ARG0-of (u / use-01
                              :ARG1 (b / business)))
                  :op3 (c3 / company
                        :ARG0-of (p3 / provide-01
                              :ARG1 (d / data))))
            :ARG1 (d2 / discriminate-02
                  :polarity -
                  :ARG0 (j / judge-01
                        :ARG0 (o / or
                              :op1 (s2 / system
                                    :mod (ii2 / intelligent-01
                                          :mod a2))
                              :op2 s))
                  :ARG1 (ii3 / individual)
                  :ARG1-of (f / fair-01
                        :polarity -)))
      :ARG2 (p4 / principle
            :topic (f2 / fairness)))

# ::snt Points of theContent of Each Principle (9/11) 198)Principle of fairness AI service providers, business users, and data providers should take into consideration that individuals will not be  discriminated unfairly by the judgment of AI systems or AI services.
# File 109

(m / multi-sentence
      :snt1 (p / point
            :mod (c / content
                  :part-of (p2 / principle
                        :mod (e / each)))
            :ARG1-of (d / describe-01
                  :ARG0 (p3 / publication
                        :name (n / name
                              :op1 "9/11"))
                  :ARG2 p3
                  :ARG1-of (c2 / cite-01
                        :ARG2 198)))
      :snt2 (r / recommend-01
            :ARG1 (c3 / consider-02
                  :ARG0 (a / and
                        :op1 (c4 / company
                              :ARG0-of (p4 / provide-01
                                    :ARG1 (s / service
                                          :mod (ii / intelligent-01
                                                :mod (a2 / artificial)))))
                        :op2 (p5 / person
                              :ARG0-of (u / use-01
                                    :ARG1 (b / business)))
                        :op3 (c5 / company
                              :ARG0-of (p6 / provide-01
                                    :ARG1 (d2 / data))))
                  :ARG1 (d3 / discriminate-02
                        :polarity -
                        :ARG0 (j / judge-01
                              :ARG0 (o / or
                                    :op1 (s2 / system
                                          :mod (ii2 / intelligent-01
                                                :mod a2)))
                              :op2 s))
                  :ARG1 (ii3 / individual)
                  :ARG1-of (f / fair-01
                        :polarity -))))

# ::snt The details of EU AI regulation could also influence how “trustworthy AI” is conceived  across the world, shaping research agendas  aimed at ensuring the safety and fairness of AI  systems.
# File 48

(p / possible-01
      :ARG1 (ii / influence-01
            :ARG0 (d / detail-01
                  :ARG1 (r / regulate-01
                        :ARG0 (o / organization
                              :name (n / name
                                    :op1 "EU"))
                        :ARG1 (ii2 / intelligent-01
                              :mod (a / artificial))))
            :ARG1 (t / thing
                  :manner-of (c / conceive-01
                        :ARG1 (ii3 / intelligent-01
                              :mod a
                              :ARG0-of (d2 / deserve-01
                                    :ARG1 (t2 / trust-01)))
                        :location (a2 / across
                              :op1 (w / world))))
            :ARG0-of (s / shape-01
                  :ARG1 (a3 / agenda
                        :mod (r2 / research-01)
                        :ARG1-of (a4 / aim-02
                              :ARG2 (e / ensure-01
                                    :ARG0 a3
                                    :ARG1 (a5 / and
                                          :op1 (s2 / safe-01
                                                :ARG1 (s3 / system
                                                      :mod ii2))
                                          :op2 (f / fairness
                                                :poss s3)))))))
      :mod (a6 / also))

# ::snt The globalAIfield should invest in certain research topics – including explainability, fairness, transparency, robustness, and human  oversight – to help guide the EU’s regulatory  efforts.
# File 48

(r / recommend-01
      :ARG1 (ii / invest-01
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "GlobalAIfield"))
            :ARG2 (t / topic
                  :mod (r2 / research-01)
                  :mod (c / certain)
                  :ARG2-of (ii2 / include-01
                        :ARG1 (a / and
                              :op1 (e / explain-01
                                    :ARG1-of (p / possible-01))
                              :op2 (f / fairness)
                              :op3 (t2 / transparency)
                              :op4 (r3 / robustness)
                              :op5 (o2 / oversee-01
                                    :ARG0 (h / human))))))
      :purpose (h2 / help-01
            :ARG0 o
            :ARG1 (g / guide-01
                  :ARG0 t
                  :ARG1 (e2 / effort-01
                        :ARG0 (o3 / organization
                              :name (n2 / name
                                    :op1 "EU"))
                        :ARG1 (r4 / regulate-01)))))

# ::snt This includes information fairness, i.e.
# File 48

(ii / include-01
      :ARG1 (f / fairness
            :mod (ii2 / information)
            :ARG1-of (m / mean-01
                  :ARG2 (t / thing)))
      :ARG2 (t2 / this))

# ::snt providing data subjects  with information on how their data is used,  and substantive fairness, which means that  the content of an automated inference or decision must be fair.356This requirement challenges the application of AI models that are  biased or trained on biased data.
# File 48

(c / challenge-01
      :li 356
      :ARG0 (t / thing
            :ARG1-of (r / require-01)
            :mod (t2 / this))
      :ARG1 (a / apply-02
            :ARG1 (m / model-01
                  :ARG1 (ii / intelligent-01
                        :mod (a2 / artificial))
                  :ARG1-of (b / bias-01)
                  :ARG2-of (t3 / train-01
                        :ARG2 (d / data
                              :ARG1-of (b2 / bias-01)))))
      :manner (p / provide-01
            :ARG1 (a3 / and
                  :op1 (ii2 / information
                        :topic (t4 / thing
                              :manner-of (u / use-01
                                    :ARG1 (d2 / data
                                          :poss (s / subject))))
                        :op2 (f / fairness
                              :mod (s2 / substantive)
                              :ARG1-of (m2 / mean-01
                                    :ARG2 (o / obligate-01
                                          :ARG2 (f2 / fair-01
                                                :ARG1 (t5 / thing
                                                      :ARG1-of (c2 / contain-01
                                                            :ARG0 (o2 / or
                                                                  :op1 (ii3 / infer-01
                                                                        :ARG1-of (a4 / automate-01))
                                                                  :op2 (d3 / decide-01)))))))))
                  :ARG2 s)))

# ::snt Many companies have begun to explore the ideas of fairness, inclusion, accountability, and  transparency in machine learning, including Microsoft, Google, and Deepmind (Alphabet).
# File 188

(b / begin-01
      :ARG0 (c / company
            :quant (m / many)
            :ARG2-of (ii / include-91
                  :ARG1 (a / and
                        :op1 (c2 / company
                              :name (n / name
                                    :op1 "Microsoft"))
                        :op2 (c3 / company
                              :name (n2 / name
                                    :op1 "Google"))
                        :op3 (c4 / company
                              :name (n3 / name
                                    :op1 "Deepmind")
                              :ARG1-of (m2 / mean-01
                                    :ARG2 (c5 / company
                                          :name (n4 / name
                                                :op1 "Alphabet")))))))
      :ARG1 (e / explore-01
            :ARG0 c
            :ARG1 (ii2 / idea
                  :topic (a2 / and
                        :op1 (f / fairness)
                        :op2 (ii3 / include-01)
                        :op3 (a3 / accountable-02)
                        :op4 (t / transparency))
                  :topic (l / learn-01
                        :mod (m3 / machine)))))

# ::snt 5 How to Prevent Discriminatory Outcomes in Machine LearningDrawing on existing work, we propose four central principles  to combat bias in machine learning and uphold human  rights and dignity: Active Inclusion Fairness Right to Understanding Access to Remedy – Active Inclusion: The development and design of  ML applications must actively seek a diversity of  input, especially of the norms and values of specific  populations affected by the output of AI systems.
# File 188

(p / propose-01
      :li 5
      :ARG0 (w / we)
      :ARG1 (p2 / principle
            :quant 4
            :mod (c / central)
            :purpose (a / and
                  :op1 (c2 / combat-01
                        :ARG0 p2
                        :ARG1 (b / bias-01
                              :ARG1 (l / learn-01
                                    :ARG1 (m / machine))))
                  :op2 (u / uphold-01
                        :ARG0 p2
                        :ARG1 (a2 / and
                              :op1 (r / right-05
                                    :ARG1 (h / human))
                              :op2 (d / dignity
                                    :poss h))))
            :ARG1-of (m2 / mean-01
                  :ARG2 (a3 / and
                        :op1 (r2 / right-05
                              :ARG2 (f / fairness)
                              :ARG1-of (a4 / activity-06))
                        :op2 (r3 / right-05
                              :ARG2 (u2 / understand-01
                                    :ARG1 (a5 / access-01
                                          :ARG1 (r4 / remedy-01)))
                              :ARG1-of (a6 / activity-06))))
            :ARG1-of (m3 / mean-01
                  :ARG2 (o / obligate-01
                        :ARG1 (a7 / and
                              :op1 (d2 / develop-02
                                    :ARG1 (a8 / application
                                          :mod (m4 / machine)))
                              :op2 (d3 / design-01
                                    :ARG1 a8))
                        :ARG2 (s / seek-01
                              :ARG0 a7
                              :ARG1 (d4 / diverse
                                    :domain (ii / input
                                          :mod (e / especially)
                                          :consist-of (a9 / and
                                                :op1 (n / norm)
                                                :op2 (v / value)
                                                :poss (p3 / population
                                                      :ARG1-of (s2 / specific-02)
                                                      :ARG1-of (a10 / affect-01
                                                            :ARG0 (o2 / output
                                                                  :poss (s3 / system
                                                                        :mod (ii2 / intelligent-01
                                                                              :mod (a11 / artificial)))))))))
                              :ARG1-of (a12 / activity-06)))))
      :ARG1-of (d5 / draw-02
            :ARG2 (w2 / work-01
                  :ARG1-of (e2 / exist-01))))

# ::snt – Fairness: People involved in conceptualizing,  developing, and implementing machine learning  systems should consider which definition of fairness  best applies to their context and application, and  prioritize it in the architecture of the machine learning  system and its evaluation metrics.
# File 188

(a / and
      :op1 (f / fairness)
      :op2 (r / recommend-01
            :ARG1 (a2 / and
                  :op1 (c / consider-02
                        :ARG0 (p / person
                              :ARG1-of (ii / involve-01
                                    :ARG2 (a3 / and
                                          :op1 (c2 / conceptualize-01
                                                :ARG0 p
                                                :ARG1 (s / system
                                                      :mod (l / learn-01
                                                            :ARG1 (m / machine))))
                                          :op2 (d / develop-02
                                                :ARG0 p
                                                :ARG1 s)
                                          :op3 (ii2 / implement-01
                                                :ARG0 p
                                                :ARG1 s))))
                        :ARG1 (t / thing
                              :ARG2-of (d2 / define-01
                                    :ARG1 (f2 / fairness))
                              :ARG1-of (a4 / apply-02
                                    :ARG2 (a5 / and
                                          :op1 (c3 / context
                                                :poss p)
                                          :op2 (a6 / application
                                                :poss p))
                                    :ARG1-of (h / have-degree-91
                                          :ARG2 (g / good-02
                                                :ARG1 a4)
                                          :ARG3 (m2 / most)))))
                  :op2 (p2 / prioritize-01
                        :ARG0 p
                        :ARG1 t
                        :location (a7 / and
                              :op1 (a8 / architecture
                                    :poss (s2 / system
                                          :mod l))
                              :op2 (m3 / metric
                                    :purpose (e / evaluate-01
                                          :ARG1 s2)))))))

# ::snt – Fairness: People involved in conceptualizing,  developing, and implementing machine learning  systems should consider which definition of fairness  best applies to their context and application, and  prioritize it in the architecture of the machine learning  system and its evaluation metrics.
# File 188

(a / and
      :op1 (f / fairness)
      :op2 (r / recommend-01
            :ARG1 (a2 / and
                  :op1 (c / consider-02
                        :ARG0 (p / person
                              :ARG1-of (ii / involve-01
                                    :ARG2 (a3 / and
                                          :op1 (c2 / conceptualize-01
                                                :ARG0 p
                                                :ARG1 (s / system
                                                      :mod (l / learn-01
                                                            :ARG1 (m / machine))))
                                          :op2 (d / develop-02
                                                :ARG0 p
                                                :ARG1 s)
                                          :op3 (ii2 / implement-01
                                                :ARG0 p
                                                :ARG1 s))))
                        :ARG1 (t / thing
                              :ARG2-of (d2 / define-01
                                    :ARG1 (f2 / fairness))
                              :ARG1-of (a4 / apply-02
                                    :ARG2 (a5 / and
                                          :op1 (c3 / context
                                                :poss p)
                                          :op2 (a6 / application
                                                :poss p))
                                    :ARG1-of (h / have-degree-91
                                          :ARG2 (g / good-02
                                                :ARG1 a4)
                                          :ARG3 (m2 / most)))))
                  :op2 (p2 / prioritize-01
                        :ARG0 p
                        :ARG1 t
                        :location (a7 / and
                              :op1 (a8 / architecture
                                    :poss (s2 / system
                                          :mod l))
                              :op2 (m3 / metric
                                    :purpose (e / evaluate-01
                                          :ARG1 s2)))))))

# ::snt Active Inclusion Fairness Right to Understanding Access to RemedyActive Inclusion Fairness Right to Understanding Access to RemedyActive Inclusion Fairness Right to Understanding Access to RemedyActive Inclusion Fairness Right to Understanding Access to Remedy
# File 188

(a / and
      :op1 (r / right-05
            :ARG1 (o / organization
                  :name (n / name
                        :op1 "Active"
                        :op2 "Inclusion"
                        :op3 "Fairness"))
            :ARG2 (u / understand-01
                  :ARG0 o
                  :ARG1 (a2 / access-01
                        :ARG1 (r2 / remedy-01))))
      :op2 (r3 / right-05
            :ARG1 o
            :ARG2 (u2 / understand-01
                  :ARG0 o
                  :ARG1 (a3 / access-01
                        :ARG1 r2)))
      :op3 (r4 / right-05
            :ARG1 o
            :ARG2 (u3 / understand-01
                  :ARG0 o
                  :ARG1 a3))
      :op4 (r5 / right-05
            :ARG1 o
            :ARG2 (u4 / understand-01
                  :ARG0 o
                  :ARG1 a3)))

# ::snt The nuances  of how it works may be difficult for non-experts to digest,  but its promise is plain: increased efficiency, accuracy, scale  and speed in making decisions and finding the best answers  to questions ranging from “What type of illness is this?” to  “What should you do next?” ML systems could potentially increase fairness in making  decisions about which humans can be biased.
# File 188

(m / multi-sentence
      :snt1 (c / contrast-01
            :ARG1 (p / possible-01
                  :ARG1 (d / difficult
                        :domain (d2 / digest-01
                              :ARG0 (p2 / person
                                    :ARG1-of (e / expert-01
                                          :polarity -))
                              :ARG1 (n / nuances
                                    :topic (t / thing
                                          :manner-of (w / work-09
                                                :ARG1 (ii / it)))))))
            :ARG2 (p3 / promise-01
                  :ARG0 ii
                  :ARG2 (a / and
                        :op1 (e2 / efficient-01)
                        :op2 (a2 / accurate)
                        :op3 (s / scale)
                        :op4 (s2 / speed)
                        :topic (a3 / and
                              :op1 (d3 / decide-01)
                              :op2 (f / find-01
                                    :ARG1 (t2 / thing
                                          :ARG2-of (a4 / answer-01
                                                :ARG1 (q / question-01
                                                      :ARG1 (a5 / and
                                                            :op1 (ii2 / ill-01
                                                                  :mod (t3 / type
                                                                        :mod (a6 / amr-unknown)))
                                                            :op2 (r / recommend-01
                                                                  :ARG1 (d4 / do-02
                                                                        :ARG0 (y / you)
                                                                        :ARG1 (t4 / thing)
                                                                        :time (n2 / next))))))
                                          :ARG1-of (r2 / range-01
                                                :ARG3 (p4 / possible-01
                                                      :ARG1 (b / bias-01
                                                            :ARG1 (h / human)))))))
                        :ARG1-of (ii3 / increase-01))
                  :mod (p5 / plain)))
      :snt2 (p6 / possible-01
            :ARG1 (ii4 / increase-01
                  :ARG0 (s3 / system
                        :mod (t5 / thing
                              :name (n3 / name
                                    :op1 "ML")))
                  :ARG1 (f2 / fair-01
                        :ARG1 (d5 / decide-01
                              :ARG1 (t6 / thing
                                    :ARG2-of b))))
            :mod (p7 / potential)))

# ::snt Concerns Around Algorithm Design Modeling for fairness   Where is the risk for discrimination in  algorithm design and deployment?
# File 188

(m / multi-sentence
      :snt1 (c / concern-01
            :ARG0 (m2 / model-01
                  :ARG1 (d / design-01
                        :ARG1 (a / algorithm))
                  :ARG3 (f / fairness)))
      :snt2 (r / risk-01
            :ARG2 (d2 / discriminate-02
                  :ARG1 (a2 / and
                        :op1 (d3 / design-01
                              :ARG1 (a3 / algorithm))
                        :op2 (d4 / deploy-01
                              :ARG1 a3)))
            :location (a4 / amr-unknown)))

# ::snt Building a model with inadvertently discriminatory  features Humans have to define for algorithms what “success”  looks like – and it usually means maximizing profits or  accuracy or efficiency, rather than maximizing fairness.17 For  example, one ML model tasked with predicting likelihood  to re-offend had a similar error rate for black and white  defendants, but was more likely to err by wrongly predicting  that black defendants would re-offend and that white  defendants would not.18 When humans specify what weight  ML algorithms should give to variables, this can create  bias: for example, an algorithm to assess loan applicants  may consider both income levels and reliability of past  repayments; a human decision to give more weight to the  former may unfairly discriminate against members of groups  which tend to be lower-income, such as women.
# File 188

(m / multi-sentence
      :li 17
      :snt1 (a / and
            :op1 (o / obligate-01
                  :ARG1 (h / human)
                  :ARG2 (d / define-01
                        :ARG0 h
                        :ARG1 (r / resemble-01
                              :ARG1 (s / success)
                              :ARG2 (t / thing
                                    :ARG1-of (l / look-02
                                          :ARG0 (a2 / algorithm))))))
            :op2 (m2 / mean-01
                  :ARG1 d
                  :ARG2 (m3 / maximize-01
                        :ARG1 (o2 / or
                              :op1 (t2 / thing
                                    :ARG2-of (p / profit-01))
                              :op2 (a3 / accuracy)
                              :op3 (e / efficient-01))
                        :ARG1-of (ii / instead-of-91
                              :ARG2 (m4 / maximize-01
                                    :ARG1 (f / fairness))))
                  :mod (u / usual)))
      :snt2 (p2 / possible-01
            :ARG1 (c / create-01
                  :ARG0 (s2 / specify-01
                        :ARG0 (h2 / human)
                        :ARG1 (r2 / recommend-01
                              :ARG1 (g / give-01
                                    :ARG0 (a4 / algorithm
                                          :mod (m5 / machine
                                                :ARG1-of (a5 / automate-01)))
                                    :ARG1 (w / weight)
                                    :ARG2 (v / variable))))
                  :ARG1 (b / bias-01
                        :example (a6 / and
                              :op1 (p3 / possible-01
                                    :ARG1 (c2 / consider-02
                                          :ARG0 (a7 / algorithm
                                                :ARG0-of (a8 / assess-01
                                                      :ARG1 (p4 / person
                                                            :ARG0-of (a9 / apply-01
                                                                  :ARG1 (l2 / loan-01)))))
                                          :ARG1 (a10 / and
                                                :op1 (l3 / level
                                                      :mod (ii2 / income))
                                                :op2 (r3 / rely-01
                                                      :ARG1 (r4 / repay-01
                                                            :time (p5 / past))))))
                              :op2 (p6 / possible-01
                                    :ARG1 (d2 / discriminate-02
                                          :ARG0 (d3 / decide-01
                                                :ARG0 h2
                                                :ARG1 (g2 / give-01
                                                      :ARG0 h2
                                                      :ARG1 (w2 / weight
                                                            :mod (m6 / more))
                                                      :ARG2 (p7 / person
                                                            :ARG1-of (b2 / black-05)
                                                            :ARG1-of (w3 / white-02))))
                                          :ARG1-of (f2 / fair-01
                                                :polarity -)))))))
      :snt3 (c3 / contrast-01
            :ARG1 (h3 / have-03
                  :ARG0 (m7 / model
                        :quant 1
                        :mod (t3 / thing
                              :name (n / name
                                    :op1 "ML"))
                        :ARG1-of (t4 / task-01
                              :ARG2 (p8 / predict-01
                                    :ARG0 m7
                                    :ARG1 (l4 / likelihood
                                          :mod (o3 / offend-03
                                                :mod (a11 / again))))))
                  :ARG1 (r5 / rate
                        :mod (e2 / error)
                        :ARG1-of (r6 / resemble-01)))
            :ARG2 (l5 / likely-01
                  :ARG1 (e3 / err-01
                        :ARG0 m7
                        :manner (p9 / predict-01
                              :ARG0 m7
                              :ARG1 (a12 / and
                                    :op1 (o4 / offend-03
                                          :ARG1 (p10 / person
                                                :ARG1-of b2)
                                          :ARG1-of (d4 / defend-01)))
                              :op2 (o5 / offend-03
                                    :polarity -
                                    :ARG1-of w3)))))
      :ARG2-of (h4 / have-degree-91
            :ARG1 m7
            :ARG3 m6))

# ::snt What-if scenario: China and social credit  scores   While few details are publicly available,  reports suggest that China is creating a  model to score its citizens by analyzing  a wide range of data from banking, tax,  professional, and performance records,  to smartphones, e-commerce, and social  media.22 The aim is speculated to be “to  use the data to enforce a moral authority as designed by  the Communist Party.”23 One open question is what it will  mean if governments act on scores computed using data  that is incomplete, historically biased, and using models not  built for “fairness”.
# File 188

(m / multi-sentence
      :snt1 (s / scenario
            :topic (a / and
                  :op1 (c / country
                        :name (n / name
                              :op1 "China"))
                  :op2 (s2 / score-01
                        :ARG1 c
                        :ARG3 (c2 / credit-02
                              :mod (s3 / social))))
            :snt2 (c3 / contrast-01
                  :ARG1 (s4 / suggest-01
                        :ARG0 (r / report-01)
                        :ARG1 (c4 / create-01
                              :ARG0 c
                              :name (n2 / name
                                    :op1 "China"))
                        :ARG1 (m2 / model)
                        :purpose (s5 / score-01
                              :ARG0 c
                              :ARG1 (c5 / citizen
                                    :poss c)
                              :manner (a2 / analyze-01
                                    :ARG0 c
                                    :ARG1 (r2 / range-01
                                          :ARG1 (d / data)
                                          :ARG3 (a3 / and
                                                :op1 (b / bank-01)
                                                :op2 (t / tax-01)
                                                :op3 (p / professional)
                                                :op4 (p2 / perform-02))
                                          :ARG4 (a4 / and
                                                :op1 (s6 / smartphone)
                                                :op2 (e / e-commerce)
                                                :op3 (m3 / media
                                                      :mod s3)))
                                    :ARG1-of (w / wide-02)))))
            :ARG2 (a5 / available-02
                  :ARG2 (d2 / detail
                        :quant (f / few))
                  :ARG1-of (p3 / public-02)))
      :snt3 (s7 / speculate-01
            :li 22
            :ARG1 (a6 / aim-01
                  :ARG1 (u / use-01
                        :ARG1 (d3 / data)
                        :ARG2 (e2 / enforce-01
                              :ARG1 (a7 / authority
                                    :ARG1-of (m4 / moral-02)
                                    :ARG1-of (d4 / design-01
                                          :ARG0 (p4 / political-party
                                                :name (n3 / name
                                                      :op1 "Communist"
                                                      :op2 "Party"))))))))
      :snt4 (q / question-01
            :li 23
            :ARG1 (t2 / thing
                  :ARG2-of (m5 / mean-01
                        :ARG1 (ii / it)
                        :condition (a8 / act-02
                              :ARG0 (g / government-organization
                                    :ARG0-of (g2 / govern-01))
                              :ARG1 t2
                              :ARG2-of (s8 / score-01
                                    :ARG1-of (c6 / compute-01
                                          :manner (u2 / use-01
                                                :ARG1 (d5 / data
                                                      :ARG1-of (b2 / bias-01
                                                            :mod (h / history)))
                                                :ARG1-of (b3 / build-01
                                                      :polarity -
                                                      :purpose (f2 / fairness)))))))))
      :ARG1-of (o / open-04))

# ::snt – The FATML (Fairness, Accountability and  Transparency in Machine Learning) Principles  (2016)  – on accountable algorithms; developed by a  large network of scientists, researchers, and industry  professionals.
# File 188

(a / and
      :op1 (p / publication
            :name (n / name
                  :op1 "FATML")
            :ARG1-of (m / mean-01
                  :ARG2 (a2 / and
                        :op1 (f / fairness)
                        :op2 (a3 / accountable-02)
                        :op3 (t / transparency
                              :mod (m2 / machine
                                    :ARG1-of (l / learn-01)))))
            :time (d / date-entity
                  :year 2016))
      :op2 (d2 / develop-02
            :ARG0 (n2 / network
                  :mod (l2 / large)
                  :consist-of (a4 / and
                        :op1 (s / scientist)
                        :op2 (p2 / person
                              :ARG0-of (r / research-01))
                        :op3 (p3 / professional
                              :mod (ii / industry))))
            :ARG1 (a5 / algorithm
                  :ARG0-of (a6 / accountable-02))))

# ::snt Fairness  There are many different ways of defining  fairness; people involved in conceptualizing,  developing, and implementing machine  learning systems should consider which  definition best applies to their context and application.
# File 188

(m / multi-sentence
      :snt1 (h / have-manner-91
            :ARG1 (d / define-01
                  :ARG1 (f / fairness))
            :ARG2 (w / way
                  :quant (m2 / many)
                  :ARG1-of (d2 / differ-02)))
      :snt2 (r / recommend-01
            :ARG1 (c / consider-02
                  :ARG0 (p / person
                        :ARG1-of (ii / involve-01
                              :ARG2 (a / and
                                    :op1 (c2 / conceptualize-01
                                          :ARG0 p
                                          :ARG1 (s / system
                                                :mod (l / learn-01
                                                      :mod (m3 / machine))))
                                    :op2 (d3 / develop-02
                                          :ARG0 p
                                          :ARG1 s)
                                    :op3 (ii2 / implement-01
                                          :ARG0 p
                                          :ARG1 s))))
                  :ARG1 (t / thing
                        :ARG2-of (d4 / define-01)
                        :ARG1-of (a2 / apply-02
                              :ARG2 (a3 / and
                                    :op1 (c3 / context
                                          :poss s)
                                    :op2 (a4 / apply-02
                                          :ARG2 s))
                              :ARG1-of (h2 / have-degree-91
                                    :ARG2 (g / good-02
                                          :ARG1 t)
                                    :ARG3 (m4 / most))))))
      :snt3 (f2 / fairness))

# ::snt Fairness  There are many different ways of defining  fairness; people involved in conceptualizing,  developing, and implementing machine  learning systems should consider which  definition best applies to their context and application.
# File 188

(m / multi-sentence
      :snt1 (h / have-manner-91
            :ARG1 (d / define-01
                  :ARG1 (f / fairness))
            :ARG2 (w / way
                  :quant (m2 / many)
                  :ARG1-of (d2 / differ-02)))
      :snt2 (r / recommend-01
            :ARG1 (c / consider-02
                  :ARG0 (p / person
                        :ARG1-of (ii / involve-01
                              :ARG2 (a / and
                                    :op1 (c2 / conceptualize-01
                                          :ARG0 p
                                          :ARG1 (s / system
                                                :mod (l / learn-01
                                                      :mod (m3 / machine))))
                                    :op2 (d3 / develop-02
                                          :ARG0 p
                                          :ARG1 s)
                                    :op3 (ii2 / implement-01
                                          :ARG0 p
                                          :ARG1 s))))
                  :ARG1 (t / thing
                        :ARG2-of (d4 / define-01)
                        :ARG1-of (a2 / apply-02
                              :ARG2 (a3 / and
                                    :op1 (c3 / context
                                          :poss s)
                                    :op2 (a4 / apply-02
                                          :ARG2 s))
                              :ARG1-of (h2 / have-degree-91
                                    :ARG2 (g / good-02
                                          :ARG1 t)
                                    :ARG3 (m4 / most))))))
      :snt3 (f2 / fairness))

# ::snt In every case, fairness and the dignity of affected people  should be prioritized in the architecture of the machine  learning system and its evaluation metrics, as issues  with  bias are long-term and structural.29  Guiding Questions: – Have we identified a definition of fairness that suits the  context and application for our product and aligns with  the International Declaration of Human Rights?
# File 188

(m / multi-sentence
      :snt1 (r / recommend-01
            :ARG1 (p / prioritize-01
                  :ARG1 (a / and
                        :op1 (f / fairness)
                        :op2 (d / dignity
                              :poss (p2 / person
                                    :ARG1-of (a2 / affect-01))))
                  :location (a3 / and
                        :op1 (a4 / architect-01
                              :ARG1 (s / system
                                    :instrument-of (l / learn-01
                                          :ARG1 (m2 / machine))))
                        :op2 (m3 / metric
                              :instrument-of (e / evaluate-01
                                    :ARG1 s))))
            :ARG1-of (c / cause-01
                  :ARG0 (a5 / and
                        :op1 (l2 / long-03)
                        :op2 (s2 / structure)
                        :domain (ii / issue-02
                              :ARG0 (b / bias-01)))))
      :snt2 (q / question-01
            :li 29
            :ARG1 (ii2 / identify-01
                  :ARG0 (w / we)
                  :ARG1 (d2 / define-01
                        :ARG1 (f2 / fairness)
                        :ARG1-of (s3 / suit-01
                              :ARG2 (a6 / and
                                    :op1 (c2 / context)
                                    :op2 (a7 / apply-02
                                          :ARG2 (p3 / product
                                                :poss w))))
                        :ARG1-of (a8 / align-01
                              :ARG2 (p4 / publication
                                    :name (n / name
                                          :op1 "International"
                                          :op2 "Declaration"
                                          :op3 "of"
                                          :op4 "Human"
                                          :op5 "Rights"))))
                  :polarity (a9 / amr-unknown))
            :ARG0-of (g / guide-01))
      :mod (c3 / case
            :mod (e2 / every)))

# ::snt – Have we included all the relevant domain experts whose  interdisciplinary insights allow us to understand potential  sources of bias or unfairness and design ways to  counteract them?
# File 188

(ii / include-01
      :polarity (a / amr-unknown)
      :ARG0 (w / we)
      :ARG1 (p / person
            :ARG1-of (e / expert-01
                  :ARG2 (d / domain))
            :ARG1-of (r / relevant-01)
            :mod (a2 / all)
            :ARG0-of (ii2 / insight-05
                  :mod (ii3 / interdisciplinary)
                  :ARG0-of (a3 / allow-01
                        :ARG1 (a4 / and
                              :op1 (u / understand-01
                                    :ARG0 w
                                    :ARG1 (s / source-02
                                          :ARG1 (o / or
                                                :op1 (b / bias-01)
                                                :op2 (f / fairness
                                                      :polarity -))
                                          :mod (p2 / potential)))
                              :op2 (d2 / design-01
                                    :ARG0 w
                                    :ARG1 (w2 / way
                                          :ARG0-of (c / counteract-01
                                                :ARG1 s))))))))

# ::snt – Have we applied “rigorous pre-release trials to ensure  that [the ML system] will not amplify biases and error  due to any issues with the training data, algorithms, or  other elements of system design?”30  – Have we outlined an ongoing system for evaluating  fairness throughout the life cycle of our product?
# File 188

(m / multi-sentence
      :snt2 (o / outline-01
            :li 30
            :ARG0 (w / we)
            :ARG1 (s / system
                  :ARG1-of (g / go-on-15)
                  :purpose (e / evaluate-01
                        :ARG1 (f / fairness)
                        :duration (t / throughout
                              :op1 (c / cycle-02
                                    :ARG1 (p / product
                                          :poss w)
                                    :ARG2 (l / live-01)))))
            :polarity (a / amr-unknown))
      :snt1 (a2 / apply-02
            :ARG0 w
            :ARG1 (t2 / try-01
                  :ARG1-of (r / rigorous-00)
                  :time (b / before
                        :op1 (r2 / release-01
                              :ARG1 p)))
            :purpose (e2 / ensure-01
                  :ARG0 w
                  :ARG1 (a3 / amplify-01
                        :polarity -
                        :ARG0 (s2 / system
                              :mod (m2 / machine
                                    :ARG1-of (a4 / automate-01)))
                        :ARG1 (a5 / and
                              :op1 (b2 / bias-01)
                              :op2 (e3 / err-01))
                        :ARG1-of (c2 / cause-01
                              :ARG0 (ii / issue-02
                                    :ARG0 (o2 / or
                                          :op1 (d / data
                                                :mod (t3 / train-01))
                                          :op2 (a6 / algorithm)
                                          :op3 (e4 / element
                                                :mod (o3 / other)
                                                :part-of (d2 / design-01
                                                      :ARG1 s2))
                                          :mod (a7 / any))))))))

# ::snt Do  we have an escalation/emergency procedure to correct  unforeseen cases of unfairness when we uncover  them?
# File 188

(h / have-03
      :polarity (a / amr-unknown)
      :ARG0 (w / we)
      :ARG1 (p / procedure
            :mod (s / slash
                  :op1 (e / escalate-01)
                  :op2 (e2 / emergency))
            :purpose (c / correct-01
                  :ARG0 w
                  :ARG1 (c2 / case-04
                        :ARG1 (f / fairness
                              :polarity -)
                        :ARG1-of (f2 / foresee-01
                              :polarity -))
                  :time (u / uncover-01
                        :ARG0 w
                        :ARG1 c2))))

# ::snt 29 In “Fairness in Criminal Justice Risk Assessments: The State of the  Art” Berk et al, 2017 provide a through review of the technical pathways  towards promoting fairness in machine learning.
# File 188

(p / provide-01
      :li 29
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Berk"))
            :op2 (p3 / person
                  :mod (o / other)))
      :ARG1 (r / review-01
            :ARG1 (p4 / pathway
                  :mod (t / technical)
                  :direction (p5 / promote-02
                        :ARG1 (f / fairness
                              :prep-in (l / learn-01
                                    :mod (m / machine))))))
      :medium (p6 / publication-91
            :ARG1 (a2 / assess-01
                  :ARG1 (f2 / fairness
                        :prep-in (j / justice
                              :mod (c / criminal)))
                  :ARG2 (r2 / risk-01))
            :ARG4 (s / state
                  :mod (a3 / art)))
      :time (d / date-entity
            :year 2017))

# ::snt 29 In “Fairness in Criminal Justice Risk Assessments: The State of the  Art” Berk et al, 2017 provide a through review of the technical pathways  towards promoting fairness in machine learning.
# File 188

(p / provide-01
      :li 29
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Berk"))
            :op2 (p3 / person
                  :mod (o / other)))
      :ARG1 (r / review-01
            :ARG1 (p4 / pathway
                  :mod (t / technical)
                  :direction (p5 / promote-02
                        :ARG1 (f / fairness
                              :prep-in (l / learn-01
                                    :mod (m / machine))))))
      :medium (p6 / publication-91
            :ARG1 (a2 / assess-01
                  :ARG1 (f2 / fairness
                        :prep-in (j / justice
                              :mod (c / criminal)))
                  :ARG2 (r2 / risk-01))
            :ARG4 (s / state
                  :mod (a3 / art)))
      :time (d / date-entity
            :year 2017))

# ::snt Berk et al, 2017, Fairness  in Criminal Justice Risk Assessments: The State of the Art https://arxiv.org/ abs/1703.0920730 Ai Now Institute 2017 Report
# File 188

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Berk"))
            :op2 (p3 / person
                  :mod (o / other)))
      :ARG1 (p4 / publication
            :name (n2 / name
                  :op1 "Fairness"
                  :op2 "in"
                  :op3 "Criminal"
                  :op4 "Justice"
                  :op5 "Risk"
                  :op6 "Assessments"
                  :op7 "The"
                  :op8 "State"
                  :op9 "of"
                  :op10 "the"
                  :op11 "Art"))
      :time (d / date-entity
            :year 2017)
      :ARG4 p4
      :name (n3 / name
            :op1 "Ai"
            :op2 "Now"
            :op3 "Institute")
      :time (d2 / date-entity
            :year 2017
            :month 2
            :day 30))

# ::snt to design a fair and  contextually appropriate ML model Train ML designers/developers and AI  leaders on human rights responsibilitiesHave leaders and data scientists who are able to translate ethics into code that runs the  ML systems; minimize risk of inadvertent or blatant discrimination  What can companies do to avoid building a model with discriminatory features?50 Action Impact Organize research Have an up-to-date understanding of how certain models have performed in similar  contexts to guide model and data selection Ensure diversity in ML development  teamsBring different perspectives together; afford insights into which model types and data  types may need to be considered in order to design an ML system that is both accurate  and non-discriminating  Keep models up to date and contextually  relevantReduce chances of bias and error that can result from static ML applications that no  longer reflect the real-time realities and needs of a given context Map out risks Have a sense of what could go wrong in order to identify what stages will require humanin-the-loop checks and how to leverage dynamic testing; determine what set of indicators  could be used to detect discrimination and might be helpful for dynamic testing Include dynamic testing Determine how algorithms are performing according to a chosen set of indicators that  reflect non-discrimination in order to course correct (either by changing the training data,  target variables, parameters, cost functions, or other elements of the ML application) if  necessary  Calibrate models to include fairness  criteria where appropriateBalance a model’s success according not only to accuracy but also to fairness and nondiscrimination Engage stakeholders and domain experts  in participatory mannerBest identify what types of considerations should be made for an ML model being  applied in a particular domain (industry, geography, population, etc.)
# File 188

(m / multi-sentence
      :snt1 (h / have-purpose-91
            :ARG2 (d / design-01
                  :ARG1 (m2 / model
                        :ARG1-of (ii / intelligent-01))
                  :ARG1-of (a / appropriate-02
                        :mod (c / context))))
      :snt2 (a2 / and
            :op1 (t / train-01
                  :ARG1 (a3 / and
                        :op1 (p / person
                              :ARG0-of (d2 / design-01
                                    :ARG1 (p2 / product
                                          :name (n / name
                                                :op1 "ML"))))
                        :op2 (p3 / person
                              :ARG0-of (d3 / develop-02
                                    :ARG1 p2)))
                  :ARG2 (a4 / and
                        :op1 (p4 / person
                              :ARG0-of (d4 / design-01
                                    :ARG1 p2))
                        :op2 (p5 / person
                              :ARG0-of (l / lead-02)
                              :mod (d5 / data)))
                  :topic (r / responsible-03
                        :ARG1 (r2 / right-05
                              :ARG1 (h2 / human)))))
      :op2 (e / ensure-01
            :ARG1 (d6 / diversity)
            :ARG2 (t2 / team
                  :ARG0-of (d7 / develop-02
                        :ARG1 p2)))
      :op3 (a5 / and
            :op1 (b / bring-01
                  :ARG1 (p6 / perspective
                        :ARG1-of (d8 / differ-02))
                  :ARG2 (t3 / together))
            :op2 (a6 / afford-02
                  :ARG1 (ii2 / insight
                        :topic (o / obligate-01
                              :ARG2 (c2 / consider-02
                                    :ARG1 (a7 / and
                                          :op1 (t4 / type
                                                :mod (m3 / model))
                                          :op2 (t5 / type
                                                :mod (d9 / data))))
                              :purpose (d10 / design-01
                                    :ARG1 (s / system
                                          :ARG3 (a8 / and
                                                :op1 (a9 / accurate)
                                                :op2 (d11 / discriminate-01
                                                      :polarity -)))))))
            :op4 (m4 / minimize-01
                  :ARG1 (r3 / risk-01
                        :ARG1 (d12 / discriminate-01
                              :mod (b2 / blatant))))
            :op5 (ii3 / identify-01
                  :ARG1 (p7 / possible-01
                        :ARG1 (a10 / avoid-01
                              :ARG0 (c3 / company)
                              :ARG1 (b3 / build-01
                                    :ARG0 c3
                                    :ARG1 (m5 / model
                                          :ARG0-of (h3 / have-03
                                                :ARG1 (f / feature
                                                      :ARG0-of d12
                                                      :polarity -))))))))
      :condition (n2 / need-01)
      :snt3 (ii4 / include-01
            :ARG1 (c4 / criteria
                  :mod (f2 / fairness))
            :ARG2 (t6 / test-01))
      :snt4 (a11 / and
            :op1 (t7 / test-01
                  :mod (d13 / dynamic))
            :op2 (d14 / determine-01
                  :ARG1 (s2 / set
                        :ARG1-of (c5 / choose-01)
                        :consist-of (ii5 / indicate-01)
                        :ARG0-of (p8 / possible-01
                              :ARG1 (c6 / correct-01
                                    :ARG1 (o2 / or
                                          :op1 (v / variable
                                                :ARG1-of (t8 / target-01))
                                          :op2 (p9 / parameter)
                                          :op3 (f3 / function
                                                :mod (c7 / cost))
                                          :op4 (e2 / element
                                                :mod (o3 / other)
                                                :part-of (a12 / apply-02
                                                      :ARG1 (a13 / and
                                                            :ARG1 (a14 / automate-01)))))))))))

# ::snt to design a fair and  contextually appropriate ML model Train ML designers/developers and AI  leaders on human rights responsibilitiesHave leaders and data scientists who are able to translate ethics into code that runs the  ML systems; minimize risk of inadvertent or blatant discrimination  What can companies do to avoid building a model with discriminatory features?50 Action Impact Organize research Have an up-to-date understanding of how certain models have performed in similar  contexts to guide model and data selection Ensure diversity in ML development  teamsBring different perspectives together; afford insights into which model types and data  types may need to be considered in order to design an ML system that is both accurate  and non-discriminating  Keep models up to date and contextually  relevantReduce chances of bias and error that can result from static ML applications that no  longer reflect the real-time realities and needs of a given context Map out risks Have a sense of what could go wrong in order to identify what stages will require humanin-the-loop checks and how to leverage dynamic testing; determine what set of indicators  could be used to detect discrimination and might be helpful for dynamic testing Include dynamic testing Determine how algorithms are performing according to a chosen set of indicators that  reflect non-discrimination in order to course correct (either by changing the training data,  target variables, parameters, cost functions, or other elements of the ML application) if  necessary  Calibrate models to include fairness  criteria where appropriateBalance a model’s success according not only to accuracy but also to fairness and nondiscrimination Engage stakeholders and domain experts  in participatory mannerBest identify what types of considerations should be made for an ML model being  applied in a particular domain (industry, geography, population, etc.)
# File 188

(m / multi-sentence
      :snt1 (h / have-purpose-91
            :ARG2 (d / design-01
                  :ARG1 (m2 / model
                        :ARG1-of (ii / intelligent-01))
                  :ARG1-of (a / appropriate-02
                        :mod (c / context))))
      :snt2 (a2 / and
            :op1 (t / train-01
                  :ARG1 (a3 / and
                        :op1 (p / person
                              :ARG0-of (d2 / design-01
                                    :ARG1 (p2 / product
                                          :name (n / name
                                                :op1 "ML"))))
                        :op2 (p3 / person
                              :ARG0-of (d3 / develop-02
                                    :ARG1 p2)))
                  :ARG2 (a4 / and
                        :op1 (p4 / person
                              :ARG0-of (d4 / design-01
                                    :ARG1 p2))
                        :op2 (p5 / person
                              :ARG0-of (l / lead-02)
                              :mod (d5 / data)))
                  :topic (r / responsible-03
                        :ARG1 (r2 / right-05
                              :ARG1 (h2 / human)))))
      :op2 (e / ensure-01
            :ARG1 (d6 / diversity)
            :ARG2 (t2 / team
                  :ARG0-of (d7 / develop-02
                        :ARG1 p2)))
      :op3 (a5 / and
            :op1 (b / bring-01
                  :ARG1 (p6 / perspective
                        :ARG1-of (d8 / differ-02))
                  :ARG2 (t3 / together))
            :op2 (a6 / afford-02
                  :ARG1 (ii2 / insight
                        :topic (o / obligate-01
                              :ARG2 (c2 / consider-02
                                    :ARG1 (a7 / and
                                          :op1 (t4 / type
                                                :mod (m3 / model))
                                          :op2 (t5 / type
                                                :mod (d9 / data))))
                              :purpose (d10 / design-01
                                    :ARG1 (s / system
                                          :ARG3 (a8 / and
                                                :op1 (a9 / accurate)
                                                :op2 (d11 / discriminate-01
                                                      :polarity -)))))))
            :op4 (m4 / minimize-01
                  :ARG1 (r3 / risk-01
                        :ARG1 (d12 / discriminate-01
                              :mod (b2 / blatant))))
            :op5 (ii3 / identify-01
                  :ARG1 (p7 / possible-01
                        :ARG1 (a10 / avoid-01
                              :ARG0 (c3 / company)
                              :ARG1 (b3 / build-01
                                    :ARG0 c3
                                    :ARG1 (m5 / model
                                          :ARG0-of (h3 / have-03
                                                :ARG1 (f / feature
                                                      :ARG0-of d12
                                                      :polarity -))))))))
      :condition (n2 / need-01)
      :snt3 (ii4 / include-01
            :ARG1 (c4 / criteria
                  :mod (f2 / fairness))
            :ARG2 (t6 / test-01))
      :snt4 (a11 / and
            :op1 (t7 / test-01
                  :mod (d13 / dynamic))
            :op2 (d14 / determine-01
                  :ARG1 (s2 / set
                        :ARG1-of (c5 / choose-01)
                        :consist-of (ii5 / indicate-01)
                        :ARG0-of (p8 / possible-01
                              :ARG1 (c6 / correct-01
                                    :ARG1 (o2 / or
                                          :op1 (v / variable
                                                :ARG1-of (t8 / target-01))
                                          :op2 (p9 / parameter)
                                          :op3 (f3 / function
                                                :mod (c7 / cost))
                                          :op4 (e2 / element
                                                :mod (o3 / other)
                                                :part-of (a12 / apply-02
                                                      :ARG1 (a13 / and
                                                            :ARG1 (a14 / automate-01)))))))))))

# ::snt Map out risks Have a sense of what could go wrong in order to identify what stages will require  human-in-the-loop checks and how to leverage dynamic testing; determine what set  of indicators could be used to detect discrimination and might be helpful for dynamic  testing Include dynamic testing Determine how algorithms are performing according to a chosen set of indicators that  reflect non-discrimination in order to course correct (either by changing the training data,  the target variables, parameters, cost functions, or other elements of the ML application)  if necessary  Calibrate models to include fairness crite ria where appropriateCreate automatic checks and balances in the ML system that might be able to prevent  discrimination even when it is intended; balance a model’s success according not only to  accuracy but also to fairness and non-discrimination Train ML designers/developers and AI  leaders on human rights responsibilitiesHave leaders and data scientists who are able to translate ethics into code that runs the  ML systems; minimize risk of inadvertent or blatant discrimination  Restrict ML deployment in cases where it  is judged incongruous with human rightsProtect people from discriminatory outcomes in the most sensitive application contexts;  limit human rights abuses
# File 188

(m / multi-sentence
      :snt1 (m2 / map-01
            :ARG1 (r / risk-01))
      :snt2 (h / have-03
            :ARG1 (s / sense-01
                  :ARG1 (p / possible-01
                        :ARG1 (g / go-08
                              :ARG1 (w / wrong-02)))
                  :purpose (ii / identify-01
                        :ARG1 (a / and
                              :op1 (s2 / stage
                                    :ARG0-of (r2 / require-01
                                          :ARG1 (c / check-01
                                                :ARG0 (h2 / human
                                                      :location (l / loop)))))
                              :op2 (t / thing
                                    :manner-of (l2 / leverage-01
                                          :ARG1 (t2 / test-01
                                                :mod (d / dynamic))))))))
      :snt3 (a2 / and
            :op1 (r3 / restrict-01
                  :ARG1 (d2 / deploy-01
                        :ARG1 (p2 / product
                              :name (n / name
                                    :op1 "ML")))
                  :condition (j / judge-01
                        :ARG1 p2
                        :ARG2 (a3 / appropriate-02)))
            :op2 (c2 / create-01
                  :ARG1 (a4 / and
                        :op1 (c3 / check-01)
                        :op2 (b / balance-01
                              :ARG1 (s3 / succeed-01
                                    :ARG0 (m3 / model))
                              :ARG1-of (c4 / conform-01
                                    :ARG2 (a5 / and
                                          :op1 (a6 / accuracy)
                                          :op2 (d3 / discriminate-02
                                                :polarity -))))
                        :mod (a7 / automatic)
                        :ARG0-of (p3 / prevent-01
                              :ARG1 (d4 / discriminate-02)
                              :ARG1-of (p4 / possible-01)
                              :concession (e / even-when
                                    :op1 (ii2 / intend-01
                                          :ARG1 d4))))))
      :op3 (l3 / limit-01
            :ARG1 (a8 / abuse-01
                  :ARG1 (r4 / right-05
                        :ARG1 (h3 / human))))
      :op4 (h4 / have-03
            :ARG1 (a9 / and
                  :op1 (p5 / person
                        :ARG0-of (d5 / design-01
                              :ARG1 p2))
                  :op2 (p6 / person
                        :ARG0-of (d6 / develop-02
                              :ARG1 p2))
                  :op3 (p7 / person
                        :ARG0-of (l4 / lead-02
                              :ARG1 p2)
                        :mod (a10 / artificial)))
            :ARG0-of (t3 / translate-01
                  :ARG1 (e2 / ethics)
                  :ARG2 (c5 / code
                        :ARG0-of (r5 / run-01
                              :ARG1 p2)))))

# ::snt 21 How to Prevent Discriminatory Outcomes in Machine LearningAppendix 3: Principles on the Ethical Design  and Use of AI and Autonomous Systems  Asilomar Principles (Ethics and  Values) on Safe, Ethical, and  Beneficial use of AI*FATML Principles for Accountable  AlgorithmsIEEE Principles on Ethically Aligned  Design* Safety/Security/ Accuracy (Verifiability)  Safety – AI systems should be  safe and secure throughout their  operational lifetime, and verifiably so  where applicable and feasible  Accuracy –  Identify, log, and  articulate sources of AI error  and uncertainty throughout the  algorithm and its data sources  so that expected and worst-case  implications can be understood and  inform mitigation proceduresHuman Benefit (Safety) – AI must be  verifiably safe and secure throughout  its operational lifetime Transparency/ Explainability/ AuditabilityFailure Transparency –  If systems  cause harm, it should be possible  to ascertain why Judicial Transparency –  If systems  are involved in key judicial decisionmaking, an explanation that is  auditable by a competent human  authority should be made availableExplainability –  Ensure that  algorithmic decisions, as well as any  data driving those decisions, can be  explained to end users and other  stakeholders in nontechnical terms Auditability –  Enable interested third  parties to probe, understand, and  review the behavior of the algorithm  through disclosure of information  that enables monitoring, checking,  or criticism, including through the  provision of detailed documentation,  technically suitable APIs, and  permissive use of termsTransparency/Traceability –  It must  be possible to discover how and why  a system made a particular decision  or acted in a certain way, and, if a  system causes harm, to discover the  root cause Responsibility Responsibility –  Designers  and builders of AI systems  are stakeholders in the moral  implications of their use, misuse,  and actions  Responsibility –  Make available  externally visible avenues of redress  for adverse individual or societal  effects, and designate an internal role  for the person who is responsible for  the timely remedy of such issues  Responsibility – Designers and  developers of systems should remain  aware of and take into account the  diversity of existing relevant cultural  norms; manufacturers must be  able to provide programmatic-level  accountability proving why a system  operates in certain ways Fairness and  Values AlignmentShared Benefit –  AI technologies  should benefit and empower as  many people as possible  Shared Prosperity –  The  economic prosperity created by AI  should be shared broadly, to the  benefit all of humanity Non-Subversion –  The power  conferred by control of highly  advanced AI systems should  respect and improve, rather than  subvert, social and civic processesFairness –  Ensure that algorithmic  decisions do not create  discriminatory or unjust impacts  when comparing across different  demographics  Embedding Values into AI –  Identify  the norms and elicit the values  of a specific community affected  by a particular AI, and ensure the  norms and values included in AI  are compatible with the relevant  community Human Benefit (Human Rights) –   Design and operate AI in a way that  respects human rights, freedoms,  human dignity, and cultural diversity   Privacy Personal Privacy –  People should  have the right to access, manage,  and control the data they generate,  given AI systems’ power to analyze  and utilize that data  Liberty and Privacy –  The use  of personal data by AI must not  unreasonably curtail people’s real or  perceived liberty Personal Data and Individual  Access Control –  People must be  able to define, access, and manage  their personal data as curators of their  unique identity       Notes: (*) Both the Asilomar and IEEE guidelines include additional principles that relate to human control, the avoidance of lethal autonomous weapons arms  race, and long-term capability questions regarding the beneficence of artificial general intelligence and superintelligence.
# File 188

(m / multi-sentence
      :snt1 (a / and
            :li 21
            :op1 (p / prevent-01
                  :ARG1 (e / event
                        :ARG0-of (d / discriminate-02))
                  :ARG2 (a2 / automate-01))
            :op2 (ii / include-01
                  :ARG1 (p2 / principle
                        :topic (a3 / and
                              :op1 (d2 / design-01
                                    :ARG1 (s / system
                                          :mod (a4 / artificial)))
                              :op2 (u / use-01
                                    :ARG1 s)))
                  :ARG2 (p3 / principle
                        :topic (a5 / and
                              :op1 (d3 / design-01
                                    :ARG1 s)
                              :op2 (u2 / use-01
                                    :ARG1 (s2 / system
                                          :mod (a6 / autonomy)))))))
      :snt2 (a7 / and
            :op1 (e2 / ensure-01
                  :ARG1 (p4 / possible-01
                        :ARG1 (e3 / explain-01
                              :ARG0 (a8 / and
                                    :op1 (p5 / person
                                          :ARG0-of (u3 / use-01)
                                          :ARG1-of (c / competent-01))
                                    :op2 (p6 / person
                                          :ARG0-of (b / build-01
                                                :ARG1 s2)))))))
      :op2 (p7 / possible-01
            :ARG1 (p8 / provide-01
                  :ARG0 p6
                  :ARG1 (a9 / accountable-02
                        :ARG0 p6
                        :mod (l / level
                              :mod (p9 / program))
                        :ARG0-of (p10 / prove-01
                              :ARG1 (c2 / cause-01
                                    :ARG1 (o / operate-01
                                          :ARG0 (s3 / system)
                                          :manner (c3 / certain)))))))
      :snt3 (a10 / and
            :op1 (a11 / and
                  :op1 (ii2 / identify-01
                        :ARG1 (s4 / source-02
                              :ARG1 (a12 / and
                                    :op1 (e4 / error
                                          :mod (a13 / artificial))
                                    :op2 (c4 / certainty
                                          :polarity -))))
                  :op2 (l2 / log-01
                        :ARG1 s4)
                  :op3 (a14 / articulate-01
                        :ARG1 s4)))
      :op2 (e5 / ensure-01
            :ARG1 (c5 / compatible-00
                  :ARG1 (a15 / and
                        :op1 (n / norm)
                        :op2 (v / value)
                        :ARG1-of (ii3 / include-91
                              :ARG2 (n2 / norm
                                    :ARG1-of (r / relevant-01)))))
            :ARG2 (a16 / and
                  :op1 (d4 / design-01
                        :ARG1 (s5 / system))
                  :op2 (o2 / operate-01
                        :ARG1 s5)))
      :snt4 (a17 / and
            :op1 (a18 / and_11
                  :op1 (s6 / safe-01)
                  :op2 (s7 / secure-02)
                  :ARG1-of (p11 / possible-01))
            :op2 (s8 / slash
                  :op1 (p12 / possible-01
                        :ARG1 (e6 / explain-01))
                  :op2 (p13 / possible-01
                        :ARG1 (a19 / audit-01))))
      :op3 (s9 / slash
            :op1 (p14 / possible-01
                  :ARG1 (e7 / explain-01))
            :op2 (a20 / audit-01))
      :op4 (p15 / possible-01
            :ARG1 (f / fail-01))
      :snt5 (a21 / and
            :op1 (p16 / privacy)
            :op2 (p17 / privacy))
      :snt6 (h / have-condition-91
            :ARG1 (r2 / recommend-01
                  :ARG1 (a22 / and
                        :ARG1 (a23 / and
                              :op1 (r3 / respect-01
                                    :ARG1 (a24 / and
                                          :ARG1 (a25 / and
                                                :ARG1 (a26 / and
                                                      :op1 (r4 / right-05
                                                            :ARG1 (h2 / human))
                                                      :op2 (f2 / free-04
                                                            :ARG1 (h3 / human)))))
                                    :op2 (e8 / et-cetera)))
                        :ARG2 (p18 / possible-01
                              :ARG1 a25
                              :ARG1 a26
                              :ARG1 (a27 / and
                                    :ARG1 a25
                                    :ARG1 a25)))))
      :ARG2 (c6 / cause-01
            :ARG0 (c7 / control-01
                  :ARG1 (b2 / behave-01
                        :ARG0 (a28 / algorithm
                              :ARG1-of (a29 / advanced-02))))))

# ::snt As this is a rapidly  changing field, the methods and assumptions by  which such testing is conducted, along with the  results, should be openly documented and publicly  available, with clear versioning to accommodate  updates and new findings.”54  Map human rights risks throughout the life cycle  of machine learning products, from development  to deployment and use; this mapping should take  into account risks inherent in machine learning,  including data bias and inadequate data, and must  include the intended uses and the potential for  human rights abuses in each case Update human rights risks for each new use case  of a ML applicationBusinesses involved in  developing or deploying  machine learning systems Public-sector entities  involved in deploying  machine learning systems,  such as has been done  by New York City where  an initial mapping of risks  led the  City Council to  consider a bill  to ensure  transparency and testing  of algorithmic decisionmaking systems  54 “The 10 Top Recommendations for the AI Field in 2017” AiNow Institute https://medium.com/@AINowInstitute/the-10-top-recommendations-for-the-ai-field-in2017-b3253624a7Fairness Active inclusion Right to Understanding Access to Redress
# File 188

(m / multi-sentence
      :snt1 (c / cause-01
            :ARG0 (f / field
                  :ARG1-of (c2 / change-01
                        :manner (r / rapid))
                  :domain (t / this))
            :ARG1 (r2 / recommend-01
                  :ARG1 (a / and
                        :op1 (d / document-01
                              :ARG1 (a2 / and
                                    :op1 (m2 / method)
                                    :op2 (t2 / thing
                                          :ARG1-of (a3 / assume-02))
                                    :instrument-of (c3 / conduct-01
                                          :ARG1 (t3 / test-01
                                                :mod (s / such))))
                              :ARG1-of (o / open-04))
                        :op2 (a4 / available-02
                              :ARG2 a2
                              :ARG1-of (p / public-02))
                        :manner (v / version-01
                              :ARG1-of (a5 / accommodate-01
                                    :ARG0 a2
                                    :ARG1 (a6 / and
                                          :op1 (u / update-01)
                                          :op2 (t4 / thing
                                                :ARG1-of (f2 / find-01)
                                                :ARG1-of (n / new-01))))))))
      :snt2 (r3 / recommend-01
            :ARG1 (m3 / map-01
                  :ARG1 (r4 / risk-01
                        :ARG2 (r5 / right-05
                              :ARG1 (h / human)))
                  :duration (c4 / cycle-02
                        :ARG1 (p2 / product
                              :ARG0-of (l / learn-01
                                    :ARG1 (m4 / machine)))
                        :ARG2 (a7 / and
                              :op1 (d2 / develop-02
                                    :ARG1 p2)
                              :op2 (d3 / deploy-01
                                    :ARG1 p2)))
                  :example (m5 / map-01
                        :ARG0 (c5 / city
                              :name (n2 / name
                                    :op1 "New"
                                    :op2 "York"))
                        :ARG1 (r6 / risk-01)
                        :ARG0-of (l2 / lead-03
                              :ARG1 c5
                              :ARG2 (c6 / consider-02
                                    :ARG0 c5
                                    :ARG1 (b / bill
                                          :ARG0-of (e / ensure-01
                                                :ARG1 (a8 / and
                                                      :op1 (t5 / transparency)
                                                      :op2 (t6 / test-01
                                                            :ARG1 (s2 / system
                                                                  :mod (d4 / decide-01
                                                                        :manner (a9 / algorithm))))))))))))
      :snt3 (p3 / publication
            :mod 54
            :name (n3 / name
                  :op1 "AiNow"
                  :op2 "Institute")
            :ARG1-of (c7 / cite-01
                  :ARG2 (u2 / url-entity
                        :value "https://medium.com/@AINowInstitute/the-10-top-recommendations-for-the-ai-field-in2017-b3253624a7Fairness"))))

# ::snt 23 How to Prevent Discriminatory Outcomes in Machine LearningDevelop  and/or  enhance  Industry  Stan dardsDevelop  or  augment standards  to evaluate fairness,  inclusion, and  accountability in  machine learningCompanies with the capacity to do so should  partake in industry-wide efforts to arrive at a  common understanding and set of standards  for fairness and non-discrimination and dignity  assurance in machine learning.Businesses involved in  developing or deploying  machine learning systems.
# File 188

(m / multi-sentence
      :snt1 (t / thing
            :li 23
            :manner-of (p / prevent-01
                  :ARG1 (o / outcome
                        :ARG1-of (d / discriminate-02
                              :polarity -))
                  :ARG2 (l / learn-01
                        :ARG1 (m2 / machine))))
      :snt2 (s / say-01
            :ARG0 (p2 / person
                  :name (n / name
                        :op1 "Stan"
                        :op2 "Dardard"))
            :ARG1 (r / recommend-01
                  :ARG1 (p3 / partake-01
                        :ARG0 (c / company
                              :ARG1-of (c2 / capable-01
                                    :ARG2 (d2 / do-02
                                          :ARG0 c
                                          :ARG1 (s2 / so))))
                        :ARG1 (e / effort-01
                              :ARG1 (a / arrive-01
                                    :ARG1 (a2 / and
                                          :op1 (u / understand-01
                                                :ARG1-of (s3 / share-01
                                                      :ARG0 (ii / industry)))
                                          :op2 (s4 / set
                                                :consist-of (s5 / standard-02
                                                      :ARG1 (e2 / evaluate-01
                                                            :ARG1 (a3 / and
                                                                  :op1 (f / fairness)
                                                                  :op2 (ii2 / include-01)
                                                                  :op3 (a4 / accountable-02)
                                                                  :topic (l2 / learn-01
                                                                        :ARG1 (m3 / machine))))))))))
                  :ARG2 (b / business
                        :ARG1-of (ii3 / involve-01
                              :ARG2 (o2 / or
                                    :op1 (d3 / develop-02
                                          :ARG1 (s6 / system
                                                :mod (l3 / learn-01
                                                      :ARG1 (m4 / machine))))
                                    :op2 (d4 / deploy-01
                                          :ARG1 s6)))))))

# ::snt This might look similar  to approaches taken to  develop standards for  fairness in trade in the Fair  Trade movement.
# File 188

(p / possible-01
      :ARG1 (r / resemble-01
            :ARG1 (t / this)
            :ARG2 (a / approach-02
                  :ARG1 (d / develop-02
                        :ARG1 (s / standard-02
                              :ARG2 (f / fair-01
                                    :ARG1 (t2 / trade-01))))
                  :subevent-of (m / movement-07
                        :ARG1 (f2 / fair-01
                              :ARG1 (t3 / trade-01))))))

# ::snt Public-sector entities  involved in deploying  machine learning systems Develop  or augment  standards to evaluate  fairness, inclusion, and  accountability in machine  learningCompanies with the capacity to do so should  partake in industry-wide efforts to arrive at a  common understanding and set of standards  for fairness and non-discrimination in machine  learning.
# File 188

(r / recommend-01
      :ARG1 (p / partake-01
            :ARG0 (c / company
                  :ARG1-of (c2 / capable-01
                        :ARG2 (d / do-02
                              :ARG0 c
                              :ARG1 (s / so))))
            :ARG1 (e / effort-01
                  :ARG1 (a / arrive-01
                        :ARG1 (a2 / and
                              :op1 (u / understand-01
                                    :mod (c3 / common))
                              :op2 (s2 / set
                                    :consist-of (s3 / standard
                                          :topic (a3 / and
                                                :op1 (f / fairness)
                                                :op2 (d2 / discriminate-01
                                                      :polarity -)
                                                :topic (l / learn-01
                                                      :mod (m / machine)))))))
                  :ARG1-of (w / wide-02
                        :ARG2 (ii / industry))))
      :ARG2 (o / or
            :op1 (d3 / develop-02
                  :ARG0 (e2 / entity
                        :mod (s4 / sector
                              :ARG1-of (p2 / public-02))
                        :ARG1-of (ii2 / involve-01
                              :ARG2 (d4 / deploy-01
                                    :ARG0 e2
                                    :ARG1 (s5 / system
                                          :mod l))))
                  :ARG1 s3)
            :op2 (a4 / augment-01
                  :ARG0 e2
                  :ARG1 s3)
            :purpose (e3 / evaluate-01
                  :ARG0 c
                  :ARG1 (a5 / and
                        :op1 f
                        :op2 (ii3 / include-01)
                        :op3 (a6 / accountable-02)
                        :topic l))))

# ::snt This might look  similar to approaches  taken to develop standards  for fairness in trade in the  Fair Trade movement.
# File 188

(p / possible-01
      :ARG1 (l / look-02
            :ARG0 (t / this)
            :ARG1 (a / approach-02
                  :ARG1 (d / develop-02
                        :ARG1 (s / standard-02
                              :ARG2 (f / fair-01
                                    :ARG1 (t2 / trade-01))))
                  :subevent-of (m / movement-07
                        :ARG1 (f2 / fair-01
                              :ARG1 (t3 / trade-01))))))

# ::snt 26 How to Prevent Discriminatory Outcomes in Machine LearningOptimize  ML mod els for  fairness,  account ability,  transpar ency, and  editabilityCalibrate models to  include fairness criteria In general, calibrating false positive and false  negative rates in each group or population  for which an algorithm is making decisions  can help to equalize impacts.
# File 188

(m / multi-sentence
      :snt1 (t / thing
            :li 26
            :manner-of (p / prevent-01
                  :ARG1 (o / outcome
                        :ARG1-of (d / discriminate-02))
                  :ARG2 (l / learn-01
                        :ARG1 (m2 / machine))))
      :snt2 (a / and
            :op1 (o2 / optimize-01
                  :ARG1 (m3 / mod-02
                        :ARG1 m2)
                  :ARG2 (t2 / thing
                        :name (n / name
                              :op1 "ML")))
            :purpose (a2 / and
                  :op1 (f / fairness)
                  :op2 (c / capable-01
                        :ARG2 (a3 / account-01))
                  :op3 (t3 / thing
                        :name n
                        :op1 "Transpar"
                        :op2 "Ency"))
            :op4 (e / edit-01
                  :ARG1-of (p2 / possible-01)))
      :op2 (c2 / calibrate-01
            :ARG1 (m4 / model)
            :purpose (ii / include-01
                  :ARG1 (c3 / criteria
                        :topic (f2 / fairness))
                  :ARG2 m4))
      :snt3 (p3 / possible-01
            :ARG1 (h / help-01
                  :ARG0 (c4 / calibrate-01
                        :ARG1 (a4 / and
                              :op1 (r / rate
                                    :mod (p4 / positive
                                          :mod (f3 / false)))
                              :op2 (r2 / rate
                                    :mod (n2 / negative
                                          :mod f3))
                              :location (o3 / or
                                    :op1 (g / group)
                                    :op2 (p5 / population)
                                    :ARG2-of (d2 / decide-01
                                          :ARG0 (a5 / algorithm)))))
                  :ARG1 (e2 / equalize-01
                        :ARG1 (ii2 / impact-01)))
            :ARG1-of (g2 / general-02)))

# ::snt In other words,  the individuals responsible for designing  algorithms and weighting variables should  ask the question, “When this system fails,  who will it fail for, and how can we prevent  that failure?”64  Johndrow and Lum’s article, “An algorithm  for removing sensitive information:  application to race-independent recidivism  prediction,” provides a thorough analysis  of how machine learning algorithms can be  employed to augment fairness in AI-backed  decision making.65Businesses developing  ML systems- starting  with company leadership  that makes the strategic  decisions for how AI  should be developed/  deploye Include dynamic testing Create and integrate quality assessment  indicators that include fairness and  accountability66   Where appropriate, integrate dynamic testing  procedures to provide accountability either  by67: – Employing cryptographic  commitments (equivalents of sealed  documents held by third party or in  a safe place) – Fair random choices (a technique  allowing software to make fully  reproducible random choices) – Zero knowledge proofs  (cryptographic tools that allow a  decision-maker to prove that the  decision policy that was actually  used has a certain property without  revealing either how the property is  known or what the decision policy  is) ML development teams Teams tasked with  monitoring and evaluating  ML applications once they  are implemented 64 Interviews with Cathy O’Neil and Joshua Cohen  65 Johndrow and Lum 2017, An algorithm for removing sensitive information: application to race-independent recidivism prediction, https://arxiv.org/abs/1703.04957 66 Datta, Sen, and Zick “Algorithmic Transparency via Quantitiative Input Influence: Theory and Experiments with Learning Systems” ( http://www.fatml.org/ schedule/2016/presentation/algorithmic-transparency-quantitative-input )  67 All pulled from “Algorithmic Accountability” citing Kroll et al.
# File 188

(m / multi-sentence
      :snt1 (r / recommend-01
            :ARG1 (a / ask-01
                  :ARG0 (ii / individual
                        :ARG0-of (r2 / responsible-01
                              :ARG1 (a2 / and
                                    :op1 (d / design-01
                                          :ARG0 ii
                                          :ARG1 (a3 / algorithm))
                                    :op2 (w / weight-01
                                          :ARG0 ii
                                          :ARG1 (v / variable)))))
                  :ARG1 (a4 / and
                        :op1 (f / fail-01
                              :ARG1 (a5 / amr-unknown)
                              :ARG2 (s / system
                                    :mod (t / this)))
                        :op2 (p / possible-01
                              :ARG1 (p2 / prevent-01
                                    :ARG0 (w2 / we)
                                    :ARG1 (f2 / fail-01
                                          :ARG1 s))))))
      :snt2 (a6 / and
            :li 65
            :op1 (ii2 / interview-01
                  :ARG0 (a7 / and
                        :op1 (p3 / person
                              :name (n / name
                                    :op1 "Cathy"
                                    :op2 "O'Neil"))
                        :op2 (p4 / person
                              :name (n2 / name
                                    :op1 "Joshua"
                                    :op2 "Cohen")))
                  :ARG1 (p5 / publication
                        :name (n3 / name
                              :op1 "Algorithmic"
                              :op2 "Accountability")))
            :op2 (p6 / publication
                  :name (n4 / name
                        :op1 "Algorithmic"
                        :op2 "Transparency"
                        :op3 "and"
                        :op4 "Experiments"
                        :op5 "with"
                        :op6 "Learning"
                        :op7 "Systems")
                  :ARG1-of (c / cite-01
                        :ARG0 (a8 / and
                              :op1 (p7 / person
                                    :name (n5 / name
                                          :op1 "Kroll"))
                              :op2 (p8 / person
                                    :name (n6 / name
                                          :op1 "Lum"))))
                  :ARG1-of c
                  :ARG2 (p9 / publication
                        :name (n7 / name
                              :op1 "http://www.fatml.org/abs/1703.04957"))))
      :snt3 (a9 / and
            :li 67
            :op1 (c2 / create-01
                  :ARG1 (t2 / thing
                        :ARG0-of (ii3 / indicate-01
                              :ARG1 (a10 / and
                                    :op1 (f3 / fair-01)
                                    :op2 (a11 / accountable-02))))
                  :ARG1-of (ii4 / include-91
                        :ARG2 a10)))
      :op2 (ii5 / integrate-01
            :ARG1 t2)
      :location (a12 / area
            :ARG1-of (a13 / appropriate-02))
      :op2 (e / employ-02
            :ARG1 (t3 / thing
                  :ARG1-of (m2 / mean-01
                        :ARG2 (t4 / thing
                              :ARG2-of (c3 / commit-01
                                    :ARG1 (t5 / thing
                                          :ARG1-of (d2 / document-01)
                                          :ARG1-of (s2 / seal-01)
                                          :ARG1-of (h / hold-01
                                                :ARG0 (o / or
                                                      :op1 (t6 / third-party)
                                                      :op2 (p10 / place
                                                            :ARG1-of (s3 / safe-01))))))))
                  :mod (t7 / technique
                        :ARG0-of (a14 / allow-01
                              :ARG1 (c4 / choose-01
                                    :ARG0 (s4 / software)
                                    :ARG1-of (r3 / reproduce-01
                                          :ARG1-of (p11 / possible-01)))
                              :mod (r4 / random))))))

# ::snt The social principles for AI are comprised of seven princi ples: (1) Human -centric, (2)  Education/Literacy, (3) Privacy Protection, (4) Ensuring Security, (5) Fair Competition, (6) Fairness,  Accountability, and Transparency, and (7) Innovation.
# File 122

(c / comprise-01
      :ARG1 (p / principle
            :mod (s / society)
            :purpose (ii / intelligent-01
                  :mod (a / artificial)))
      :ARG2 p
      :quant 7
      :consist-of (a2 / and
            :op1 (c2 / center-01
                  :li 1
                  :ARG1 (h / human))
            :op2 (s2 / slash
                  :op1 (e / educate-01)
                  :op2 (l / literacy))
            :op3 (p2 / protect-01
                  :li 3
                  :ARG1 (p3 / privacy))
            :op4 (e2 / ensure-01
                  :li 4
                  :ARG1 (s3 / secure-02))
            :op5 (c3 / compete-01
                  :li 5
                  :ARG1-of (f / fair-01))
            :op6 (a3 / and
                  :li 6
                  :op1 (f2 / fairness)
                  :op2 (a4 / accountable-02)
                  :op3 (t / transparency))
            :op7 (ii2 / innovate-01
                  :li 7)))

# ::snt    7 C. AI Governance Guidelines   While AI systems can have a positive impact on companies, for example, helping them overcome HR  shortages, improve productivity and develop  high-value -added businesses, because the development  and operation of AI systems is accompanied by risks unique to A I, such as unintentional impairment  of fairness or safety issues, companies that develop and operate AI systems should take  these issues  as your own matter．．．．．．．．．．．．．．．  in understanding the overall conditions associated with AI systems and value  provided by AI system.
# File 122

(m / multi-sentence
      :snt1 (g / guideline
            :topic (g2 / govern-01
                  :mod (a / artificial)))
      :snt2 (r / recommend-01
            :ARG1 (t / take-04
                  :ARG0 (c / company
                        :ARG0-of (d / develop-02
                              :ARG1 (s / system
                                    :mod (ii / intelligent-01
                                          :mod (a2 / artificial))))
                        :ARG0-of (o / operate-01
                              :ARG1 s))
                  :ARG1 (ii2 / issue-02
                        :mod (t2 / this))
                  :ARG2 (m2 / matter
                        :poss (y / you)))
            :concession (p / possible-01
                  :ARG1 (ii3 / impact-01
                        :ARG0 (s2 / system
                              :mod (ii4 / intelligent-01
                                    :mod (a3 / artificial)))
                        :ARG1 (c2 / company)
                        :mod (p2 / positive)
                        :example (h / help-01
                              :ARG0 s2
                              :ARG1 (a4 / and
                                    :op1 (o2 / overcome-01
                                          :ARG0 c2
                                          :ARG1 (s3 / short-06
                                                :ARG1 c2
                                                :ARG2 (a5 / and
                                                      :op1 (r2 / resource
                                                            :mod (h2 / human))
                                                      :op2 (p3 / productive-03
                                                            :ARG0 c2))))
                                    :op2 (d2 / develop-02
                                          :ARG0 c2
                                          :ARG1 (b / business
                                                :ARG1-of (a6 / add-02
                                                      :ARG2 (v / value
                                                            :ARG1-of (h3 / high-02))))))
                              :ARG2 c2))
                  :ARG1-of (c3 / cause-01
                        :ARG0 (a7 / accompany-01
                              :ARG0 (r3 / risk-01
                                    :ARG1-of (u / unique-01
                                          :ARG2 s2)
                                    :example (ii5 / impair-01
                                          :ARG1 (o3 / or
                                                :op1 (f / fairness)
                                                :op2 (s4 / safe-01))
                                          :ARG1-of (ii6 / intend-01
                                                :polarity -)))
                              :ARG1 (a8 / and
                                    :op1 d
                                    :op2 (o4 / operate-01))
                              :ARG1 (u2 / understand-01
                                    :ARG1 (a9 / and
                                          :op1 (c4 / condition
                                                :ARG1-of (a10 / associate-01
                                                      :ARG2 s2)
                                                :mod (o5 / overall))
                                          :op2 (v2 / value
                                                :ARG1-of (p4 / provide-01
                                                      :ARG0 s2)))))))))

# ::snt In our analysis, w e  see that many incidents relate to the management of personal information, fairness, and security.
# File 122

(s / see-01
      :ARG0 (w / we)
      :ARG1 (r / relate-01
            :ARG1 (ii / incident
                  :quant (m / many))
            :ARG2 (m2 / manage-01
                  :ARG1 (a / and
                        :op1 (ii2 / information
                              :ARG1-of (p / personal-02))
                        :op2 (f / fairness)
                        :op3 (s2 / security))))
      :location (a2 / analyze-01
            :ARG0 w))

# ::snt On the other  hand, haphazard provision of AI to businesses can entail risks peculiar to AI, such as unintentionally  impairing fairness and causing safety problems.
# File 122

(c / contrast-01
      :ARG2 (p / possible-01
            :ARG1 (e / entail-01
                  :ARG0 (p2 / provide-01
                        :ARG1 (ii / intelligent-01
                              :mod (a / artificial))
                        :ARG2 (b / business)
                        :manner (h / haphazard))
                  :ARG1 (r / risk-01
                        :ARG1-of (p3 / peculiar-01
                              :ARG2 ii)
                        :example (a2 / and
                              :op1 (ii2 / impair-01
                                    :ARG1 (f / fairness)
                                    :ARG1-of (ii3 / intend-01
                                          :polarity -))
                              :op2 (c2 / cause-01
                                    :ARG1 (p4 / problem
                                          :topic (s / safe-01))))))))

# ::snt Our chief technology officer  receives progress reports on all pr ojects, and these reports contain sections on fairness and other  matters associated with AI ethics.
# File 122

(a / and
      :op1 (r / receive-01
            :ARG0 (p / person
                  :ARG0-of (h / have-org-role-91
                        :ARG1 (w / we)
                        :ARG2 (o / officer
                              :mod (c / chief)
                              :topic (t / technology))))
            :ARG1 (r2 / report-01
                  :ARG1 (p2 / proceed-01
                        :ARG1 (p3 / project
                              :mod (a2 / all)
                              :mod (o2 / other)))))
      :op2 (c2 / contain-01
            :ARG0 r2
            :ARG1 (s / section
                  :topic (a3 / and
                        :op1 (f / fairness)
                        :op2 (m / matter
                              :mod (o3 / other)
                              :ARG1-of (a4 / associate-01
                                    :ARG2 (e / ethics
                                          :mod (ii / intelligent-01
                                                :mod (a5 / artificial)))))))))

# ::snt    26  Column: Initiatives for ensuring fairness     It is difficult to define standards of fairness and to practically apply fairness principles.
# File 122

(m / multi-sentence
      :snt1 (c / column
            :mod 26
            :topic (ii / initiative
                  :purpose (e / ensure-01
                        :ARG1 (f / fairness))))
      :snt2 (d / difficult
            :domain (a / and
                  :op1 (d2 / define-01
                        :ARG1 (s / standard
                              :topic (f2 / fairness)))
                  :op2 (a2 / apply-02
                        :ARG1 (p / principle
                              :topic f2)
                        :ARG1-of (p2 / practical-02)))))

# ::snt The OECD  Network of Experts Working Group on Implementing Trustworthy AI has put t ogether a  collection of initiatives for putting principles such as fairness into practice, and has classified  these into three categories: technical, procedural,  and educational.
# File 122

(a / and
      :op1 (p / put-03
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "OECD"
                        :op2 "Network"
                        :op3 "of"
                        :op4 "Experts"
                        :op5 "Working"
                        :op6 "Group"
                        :op7 "on"
                        :op8 "Implementing"
                        :op9 "Trustworthy"
                        :op10 "AI"))
            :ARG1 (c / collect-01
                  :ARG1 (ii / initiative
                        :purpose (p2 / put-03
                              :ARG1 (p3 / principle
                                    :example (f / fairness))
                              :ARG2 (p4 / practice-01
                                    :ARG1 p3))))
            :ARG2 (t / together))
      :op2 (c2 / classify-01
            :ARG0 o
            :ARG1 c
            :ARG2 (c3 / category
                  :quant 3
                  :domain (a2 / and
                        :op1 (t2 / technical)
                        :op2 (p5 / procedure)
                        :op3 (e / educate-01)))))

# ::snt As for technical tools for  ensuring fairness, the working group reports effor ts carried out at AT&T, Microsoft, LinkedIn,  Google, and IBM, but none at Japanese companies.
# File 122

(r / report-01
      :ARG0 (g / group
            :ARG0-of (w / work-01))
      :ARG1 (c / contrast-01
            :ARG1 (c2 / carry-out-03
                  :ARG1 (t / thing)
                  :location (a / and
                        :op1 (c3 / company
                              :name (n / name
                                    :op1 "AT&T"))
                        :op2 (c4 / company
                              :name (n2 / name
                                    :op1 "Microsoft"))
                        :op3 (c5 / company
                              :name (n3 / name
                                    :op1 "LinkedIn"))
                        :op4 (c6 / company
                              :name (n4 / name
                                    :op1 "Google"))
                        :op5 (c7 / company
                              :name (n5 / name
                                    :op1 "IBM"))))
            :ARG2 (c8 / carry-out-03
                  :polarity -
                  :ARG1 t
                  :location (c9 / company
                        :mod (c10 / country
                              :name (n6 / name
                                    :op1 "Japan")))))
      :topic (t2 / tool
            :mod (t3 / technology)
            :instrument-of (e / ensure-01
                  :ARG1 (f / fair-01))))

# ::snt The sample tool featured in the OECD  Framework of Tools for Trustworthy AI is LinkedIn's Fairness Toolkit (LiFT).
# File 122

(t / tool
      :ARG1-of (s / sample-01)
      :domain (t2 / tool
            :name (n / name
                  :op1 "Fairness"
                  :op2 "Toolkit")
            :poss (c / company
                  :name (n2 / name
                        :op1 "LinkedIn")))
      :ARG1-of (f / feature-01
            :ARG2 (t3 / treaty
                  :name (n3 / name
                        :op1 "Framework"
                        :op2 "of"
                        :op3 "Tools"
                        :op4 "for"
                        :op5 "Trustworthy"
                        :op6 "AI")
                  :mod (o / organization
                        :name (n4 / name
                              :op1 "OECD")))))

# ::snt Classification -of-tools chart, excerpted from AI Wonk at OECD.AI.14  Standards of fairness and common understanding on practice regarding fairness may be  defined de facto in international discussions like one at the OECD.
# File 122

(m / multi-sentence
      :snt1 (c / chart-01
            :ARG1 (c2 / classify-01
                  :ARG1 (t / tool))
            :ARG1-of (e / excerpt-01
                  :ARG2 (p / publication
                        :name (n / name
                              :op1 "AI"
                              :op2 "Wonk")
                        :location (o / organization
                              :name (n2 / name
                                    :op1 "OECD")))))
      :snt2 (p2 / possible-01
            :li 14
            :ARG1 (d / define-01
                  :ARG0 (d2 / discuss-01
                        :mod (ii / international)
                        :ARG1-of (r / resemble-01
                              :ARG2 (o2 / one
                                    :location (o3 / organization
                                          :name (n3 / name
                                                :op1 "OECD")))))
                  :ARG1 (a / and
                        :op1 (s / standard-02
                              :ARG1 (f / fairness))
                        :op2 (u / understand-01
                              :ARG1 (p3 / practice-01
                                    :ARG1 f)
                              :mod (c3 / common)))
                  :mod (d3 / de-facto))))

# ::snt Because standards of  fairness may d iffer due to cultural differences and differences in business customs, we will  need to disseminate efforts of Japanese companies to ensure that the diversities found in  Japan are also well recognized in the discussion.
# File 122

(n / need-01
      :ARG0 (w / we)
      :ARG1 (d / disseminate-01
            :ARG0 (c / company
                  :mod (c2 / country
                        :name (n2 / name
                              :op1 "Japan")))
            :ARG1 (e / effort-01
                  :ARG0 c
                  :ARG1 (e2 / ensure-01
                        :ARG0 c
                        :ARG1 (r / recognize-01
                              :ARG1 (d2 / diversity
                                    :ARG1-of (f / find-01
                                          :location c2))
                              :ARG1-of (w2 / well-09)
                              :location (d3 / discuss-01)
                              :mod (a / also)))))
      :ARG1-of (c3 / cause-01
            :ARG0 (p / possible-01
                  :ARG1 (f2 / fair-01
                        :ARG1-of (h / have-degree-91)
                        :ARG2-of h
                        :ARG3 (m / more)))
            :ARG1-of (c4 / cause-01
                  :ARG0 (a2 / and
                        :op1 (d4 / differ-02
                              :ARG1 (c5 / culture))
                        :op2 (d5 / differ-02
                              :ARG3 (c6 / custom
                                    :mod (b / business)))))))

# ::snt 15 Fujitsu, “Developing a ‘Fairness by Design’ AI development method that considers fairness － which differs  depen ding on culture and business customs － in the design phase” (March 31, 2021),  https://pr.fujitsu.com/jp/news/2021/ 03 / 31 -1.html .
# File 122

(p / publication-91
      :li 15
      :ARG0 (c / company
            :name (n / name
                  :op1 "Fujitsu"))
      :ARG1 (p2 / publication
            :name (n2 / name
                  :op1 "Developing"
                  :op2 "a"
                  :op3 "Fairness"
                  :op4 "by"
                  :op5 "Design")
            :mod (m / method
                  :mod (d / develop-02
                        :ARG1 (ii / intelligent-01
                              :mod (a / artificial)))
                  :ARG0-of (c2 / consider-02
                        :ARG1 (f / fairness))
                  :ARG1-of (d2 / differ-02
                        :ARG2 (a2 / and
                              :op1 (c3 / culture)
                              :op2 (c4 / custom
                                    :mod (b / business)))
                        :time (p3 / phase
                              :mod (d3 / design-01)))))
      :ARG4 (u / url-entity
            :value "https://pr.fujitsu.com/jp/news/2021/ 03 / 31 -1.html")
      :time (d4 / date-entity
            :year 2021
            :month 3
            :day 31))

# ::snt 15 Fujitsu, “Developing a ‘Fairness by Design’ AI development method that considers fairness － which differs  depen ding on culture and business customs － in the design phase” (March 31, 2021),  https://pr.fujitsu.com/jp/news/2021/ 03 / 31 -1.html .
# File 122

(p / publication-91
      :li 15
      :ARG0 (c / company
            :name (n / name
                  :op1 "Fujitsu"))
      :ARG1 (p2 / publication
            :name (n2 / name
                  :op1 "Developing"
                  :op2 "a"
                  :op3 "Fairness"
                  :op4 "by"
                  :op5 "Design")
            :mod (m / method
                  :mod (d / develop-02
                        :ARG1 (ii / intelligent-01
                              :mod (a / artificial)))
                  :ARG0-of (c2 / consider-02
                        :ARG1 (f / fairness))
                  :ARG1-of (d2 / differ-02
                        :ARG2 (a2 / and
                              :op1 (c3 / culture)
                              :op2 (c4 / custom
                                    :mod (b / business)))
                        :time (p3 / phase
                              :mod (d3 / design-01)))))
      :ARG4 (u / url-entity
            :value "https://pr.fujitsu.com/jp/news/2021/ 03 / 31 -1.html")
      :time (d4 / date-entity
            :year 2021
            :month 3
            :day 31))

# ::snt As a result, discussions proceeded smoothly, and we learned that  there were no significant differences in the understanding of AI ethics as engineers who had been of  the view  that we should focus on growth were by then familiar with papers dealing with matters such  as fairness.
# File 122

(r / result-01
      :ARG2 (a / and
            :op1 (p / proceed-01
                  :ARG1 (d / discuss-01)
                  :ARG1-of (s / smooth-04))
            :op2 (l / learn-01
                  :ARG0 (w / we)
                  :ARG1 (d2 / differ-02
                        :polarity -
                        :ARG1 (u / understand-01
                              :ARG1 (e / ethics
                                    :mod (a2 / artificial)))
                        :ARG1-of (s2 / significant-02))
                  :ARG1-of (c / cause-01
                        :ARG0 (f / familiarize-01
                              :ARG1 (p2 / person
                                    :ARG0-of (e2 / engineer-01)
                                    :ARG0-of (v / view-02
                                          :ARG1 (r2 / recommend-01
                                                :ARG1 (f2 / focus-01
                                                      :ARG0 w
                                                      :ARG2 (g / grow-01)))))
                              :ARG2 (p3 / paper
                                    :ARG0-of (d3 / deal-01
                                          :ARG1 (m / matter
                                                :example (f3 / fairness))))
                              :time (b / by
                                    :op1 (t / then)))))))

# ::snt We  outsourced our AI system development to an AI system developer and have receive d explanations  from development personnel in areas ranging from data set content to the verification of AI model  behavior to ensure that we are able to address not only the matter of accuracy but also fairness.
# File 122

(a / and
      :op1 (o / outsource-01
            :ARG0 (w / we)
            :ARG1 (d / develop-02
                  :ARG1 (s / system
                        :mod (ii / intelligent-01
                              :mod (a2 / artificial))))
            :ARG2 (p / person
                  :ARG0-of (d2 / develop-02
                        :ARG1 s)))
      :op2 (r / receive-01
            :ARG0 w
            :ARG1 (e / explain-01
                  :ARG0 (p2 / person
                        :ARG0-of (h / have-org-role-91
                              :ARG2 (p3 / personnel
                                    :ARG0-of (d3 / develop-02))))
                  :ARG1 (a3 / area
                        :ARG1-of (r2 / range-01
                              :ARG3 (c / content
                                    :mod (d4 / data
                                          :mod (s2 / set)))
                              :ARG4 (v / verify-01
                                    :ARG1 (b / behave-01
                                          :ARG0 (m / model
                                                :mod ii)))))
                  :purpose (e2 / ensure-01
                        :ARG0 p2
                        :ARG1 (p4 / possible-01
                              :ARG1 (a4 / address-02
                                    :ARG0 w
                                    :ARG1 (a5 / and
                                          :op1 (m2 / matter
                                                :topic (a6 / accurate))
                                          :op2 (m3 / matter
                                                :topic (f / fair-01)
                                                :mod (a7 / also)))))))))

# ::snt These development personnel have informed us t hat, in order to ensure accuracy and fairness,  the AI system will need to receive maintenance if differences begin to appear between the user  profile assumed at the time of development and the actual user profile .
# File 122

(ii / inform-01
      :ARG0 (p / person
            :ARG0-of (h / have-org-role-91
                  :ARG2 (p2 / personnel
                        :mod (d / develop-02)))
            :mod (t / this))
      :ARG1 (w / we)
      :ARG2 (n / need-01
            :ARG0 (s / system
                  :mod (ii2 / intelligent-01
                        :mod (a / artificial)))
            :ARG1 (r / receive-01
                  :ARG1 (m / maintain-01
                        :ARG1 s))
            :purpose (e / ensure-01
                  :ARG0 s
                  :ARG1 (a2 / and
                        :op1 (a3 / accurate)
                        :op2 (f / fair-01)))
            :condition (b / begin-01
                  :ARG1 (a4 / appear-01
                        :ARG1 (d2 / differ-02
                              :ARG1 (p3 / profile
                                    :mod (p4 / person
                                          :ARG0-of (u / use-01))
                                    :ARG1-of (a5 / assume-02
                                          :time (d3 / develop-02)))
                              :ARG2 (p5 / profile
                                    :ARG1-of (a6 / actual-02)
                                    :mod p4))))))

# ::snt E. Are the AI system developer and  opera tor aware of the fairness that is  required of the AI system?
# File 122

(r / realize-01
      :ARG0 (a / and
            :op1 (p / person
                  :ARG0-of (d / develop-02
                        :ARG1 (s / system
                              :mod (ii / intelligent-01
                                    :mod (a2 / artificial)))))
            :op2 (o / opera))
      :ARG1 (f / fairness
            :ARG1-of (r2 / require-01
                  :ARG0 s))
      :polarity (a3 / amr-unknown))

# ::snt Operation / Monitoring E  Example: Did the AI system developer and operator  investigate incidents related to fairness of the AI system they  are going to develop/opera te and/or other similar AI  systems?
# File 122

(m / multi-sentence
      :snt1 (s / slash
            :op1 (o / operate-01)
            :op2 (m2 / monitor-01))
      :snt2 (e / exemplify-01
            :ARG0 (ii / investigate-01
                  :ARG0 (a / and
                        :op1 (p / person
                              :ARG0-of (d / develop-02
                                    :ARG1 (s2 / system
                                          :mod (ii2 / intelligent-01
                                                :mod (a2 / artificial)))))
                        :op2 (p2 / person
                              :ARG0-of (o2 / operate-01)))
                  :ARG1 (ii3 / incident
                        :ARG1-of (r / relate-01
                              :ARG2 (f / fairness
                                    :poss (s3 / system
                                          :mod (ii4 / intelligent-01)
                                          :ARG1-of (d2 / develop-02
                                                :ARG0 a)
                                          :mod (o3 / operate-01
                                                :ARG0 a)
                                          :mod (o4 / or
                                                :op1 o3
                                                :op2 o3
                                                :op3 (s4 / system
                                                      :ARG1-of (r2 / resemble-01
                                                            :ARG2 s3)
                                                      :mod (o5 / other)))))))
                  :polarity (a3 / amr-unknown))))

# ::snt Example: Did the AI system developer, where possible,  select an appropriate index of fairness from those proposed,  and conduct an assessment on the rang e acceptable in the  society?
# File 122

(e / exemplify-01
      :ARG0 (a / and
            :op1 (s / select-01
                  :ARG0 (p / person
                        :ARG0-of (d / develop-02
                              :ARG1 (s2 / system
                                    :mod (ii / intelligent-01
                                          :mod (a2 / artificial)))))
                  :ARG1 (ii2 / index
                        :ARG1-of (a3 / appropriate-02
                              :ARG2 (f / fairness))
                        :ARG1-of (ii3 / include-91
                              :ARG2 (ii4 / index
                                    :ARG1-of (p2 / propose-01)))))
            :op2 (c / conduct-01
                  :ARG0 p
                  :ARG1 (a4 / assess-01
                        :ARG0 p
                        :ARG1 (r / ring
                              :ARG1-of (a5 / accept-01
                                    :ARG1-of (p3 / possible-01)
                                    :location (s3 / society)))))
            :location (p4 / possible-01)
            :polarity (a6 / amr-unknown)))

# ::snt E. Did the AI system developer address  the issues related to fairness of the AI  system?
# File 122

(a / address-02
      :ARG0 (p / person
            :ARG0-of (d / develop-02
                  :ARG1 (s / system
                        :mod (ii / intelligent-01
                              :mod (a2 / artificial)))))
      :ARG1 (ii2 / issue-02
            :ARG1-of (r / relate-01
                  :ARG2 (f / fairness
                        :poss s)))
      :polarity (a3 / amr-unknown))

# ::snt Example: If the AI system developer selected an appropriate  index of fairness from those proposed, did they take a  measure to warn against output data that is outside the  acceptable range?
# File 122

(e / exemplify-01
      :ARG0 (m / measure-02
            :ARG0 (p / person
                  :ARG0-of (d / develop-02
                        :ARG1 (s / system
                              :mod (ii / intelligent-01
                                    :mod (a / artificial)))))
            :ARG1 (w / warn-01
                  :ARG0 p
                  :ARG1 (d2 / data
                        :mod (o / output)
                        :location (o2 / outside
                              :op1 (t / thing
                                    :ARG5-of (r / range-01)
                                    :ARG1-of (a2 / accept-01
                                          :ARG1-of (p2 / possible-01))))))
            :polarity (a3 / amr-unknown)
            :condition (s2 / select-01
                  :ARG0 p
                  :ARG1 (ii2 / index
                        :ARG1-of (a4 / appropriate-02)
                        :topic (f / fair-01)
                        :ARG1-of (ii3 / include-91
                              :ARG2 (ii4 / index
                                    :ARG1-of (p3 / propose-01)))))))

# ::snt Example: If the AI s ystem developer selected an appropriate  index of fairness from those proposed, and there is a  possibility that data outside the acceptable range may be  output, did the AI system developer summarize such  possibility as a precaution for the AI system operato r and  users?
# File 122

(e / exemplify-01
      :ARG0 (s / summarize-01
            :ARG0 (p / person
                  :ARG0-of (d / develop-02
                        :ARG1 (s2 / system
                              :mod (a / artificial))))
            :ARG1 (p2 / possible-01
                  :ARG1 (o / output
                        :mod (d2 / data
                              :location (o2 / outside
                                    :op1 (t / thing
                                          :ARG5-of (r / range-01)
                                          :ARG1-of (a2 / accept-01
                                                :ARG1-of (p3 / possible-01)))))))
            :purpose (p4 / precaution-02
                  :ARG0 p
                  :ARG2 (a3 / and
                        :op1 (o3 / operate-01
                              :ARG1 s2)
                        :op2 (p5 / person
                              :ARG0-of (u / use-01))))
            :polarity (a4 / amr-unknown)
            :condition (a5 / and
                  :op1 (s3 / select-01
                        :ARG0 p
                        :ARG1 (ii / index
                              :ARG1-of (a6 / appropriate-02)
                              :topic (f / fair-01)
                              :ARG1-of (ii2 / include-91
                                    :ARG2 (ii3 / index
                                          :ARG1-of (p6 / propose-01)))))
                  :op2 (p7 / possible-01
                        :ARG1 o))))

# ::snt as well as  enhancing the fairness?
# File 122

(a / and
      :op2 (e / enhance-01
            :ARG1 (f / fairness))
      :polarity (a2 / amr-unknown))

# ::snt C. Did the AI system developer ensure  the fairness of the AI system which the  AI syste m developer is going to  develop?
# File 122

(e / ensure-01
      :li "C"
      :ARG0 (p / person
            :ARG0-of (d / develop-02
                  :ARG1 (s / system
                        :mod (ii / intelligent-01
                              :mod (a / artificial)))))
      :ARG1 (f / fair-01
            :ARG1 (s2 / system
                  :mod (ii2 / intelligent-01
                        :mod a))
            :ARG1-of (d2 / develop-02
                  :ARG0 p))
      :polarity (a2 / amr-unknown))

# ::snt Example: Did the AI system developer examine proposed  definition and index of fairness, establish definition and index  if appropriate, and objectively evaluate fairness ?
# File 122

(e / exemplify-01
      :ARG0 (a / and
            :op1 (e2 / examine-01
                  :ARG0 (p / person
                        :ARG0-of (d / develop-02
                              :ARG1 (s / system
                                    :mod (ii / intelligent-01
                                          :mod (a2 / artificial)))))
                  :ARG1 (a3 / and
                        :op1 (d2 / define-01
                              :ARG1 (f / fairness))
                        :op2 (ii2 / index
                              :topic f)
                        :ARG1-of (p2 / propose-01)))
            :op2 (e3 / establish-01
                  :ARG0 p
                  :ARG1 a3
                  :condition (a4 / appropriate-02
                        :ARG1 a3))
            :op3 (e4 / evaluate-01
                  :ARG0 p
                  :ARG1 f
                  :manner (o / objective))
            :polarity (a5 / amr-unknown)))

# ::snt E. Di d the AI system operator  understand the measures taken by the  AI system developer against the issue  of fairness?
# File 122

(u / understand-01
      :polarity (a / amr-unknown)
      :ARG0 (p / person
            :ARG0-of (o / operate-01
                  :ARG1 (s / system
                        :mod (ii / intelligent-01
                              :mod (a2 / artificial)))))
      :ARG1 (m / measure-02
            :ARG0 (p2 / person
                  :ARG0-of (d / develop-02
                        :ARG1 s))
            :ARG2 (ii2 / issue-02
                  :ARG0 (f / fairness))))

# ::snt Example: If the AI system developer selected an appropriate  index of fairness from those proposed, and took a measure  to warn against output da ta that is outside the acceptable  range, did the AI system operator understand the meaning of  such warning?
# File 122

(e / exemplify-01
      :ARG0 (u / understand-01
            :ARG0 (p / person
                  :ARG0-of (o / operate-01
                        :ARG1 (s / system
                              :mod (ii / intelligent-01))))
            :ARG1 (m / mean-01
                  :ARG1 (w / warn-01
                        :mod (s2 / such)))
            :polarity (a / amr-unknown)
            :condition (a2 / and
                  :op1 (s3 / select-01
                        :ARG0 p
                        :ARG1 (ii2 / index
                              :ARG1-of (a3 / appropriate-02)
                              :topic (f / fair-01)
                              :ARG1-of (ii3 / include-91
                                    :ARG2 (ii4 / index
                                          :ARG1-of (p2 / propose-01)))))
                  :op2 (m2 / measure-02
                        :ARG0 p
                        :ARG1 (w2 / warn-01
                              :ARG0 p
                              :ARG1 (o2 / output
                                    :ARG1-of (b / be-located-at-91
                                          :ARG2 (o3 / outside
                                                :op1 (t / thing
                                                      :ARG5-of (r / range-01)
                                                      :ARG1-of (a4 / accept-01
                                                            :ARG1-of (p3 / possible-01)))))))))))

# ::snt Example: Did the AI system operator understand the  precautions related to fairness that were summarized by the  AI system developer?
# File 122

(e / exemplify-01
      :ARG0 (u / understand-01
            :ARG0 (p / person
                  :ARG0-of (o / operate-01
                        :ARG1 (s / system
                              :mod (ii / intelligent-01
                                    :mod (a / artificial)))))
            :ARG1 (p2 / precaution-02
                  :ARG1-of (r / relate-01
                        :ARG2 (f / fairness))
                  :ARG1-of (s2 / summarize-01
                        :ARG0 (p3 / person
                              :ARG0-of (d / develop-02
                                    :ARG1 s))))
            :polarity (a2 / amr-unknown)))

# ::snt and from the perspective of  fairness?
# File 122

(a / and
      :op2 (h / have-manner-91
            :polarity (a2 / amr-unknown)
            :ARG2 (p / perspective
                  :topic (f / fair-01))))

# ::snt At the  same time, it can constitute a powerful instrument for a fruitful transformation of the national education  system to develop personalized learning plans while ensuring fairness and trustworthiness.
# File 115

(p / possible-01
      :ARG1 (c / constitute-01
            :ARG0 (ii / it)
            :ARG1 (ii2 / instrument
                  :ARG1-of (p2 / powerful-02)
                  :purpose (t / transform-01
                        :ARG1 (s / system
                              :mod (e / educate-01)
                              :mod (n / nation))
                        :ARG2 (d / develop-02
                              :ARG0 s
                              :ARG1 (p3 / plan-01
                                    :ARG1 (l / learn-01)
                                    :ARG1-of (p4 / personalize-01))
                              :time (e2 / ensure-01
                                    :ARG0 s
                                    :ARG1 (a / and
                                          :op1 (f / fairness)
                                          :op2 (d2 / deserve-01
                                                :ARG1 (t2 / trust-01)))))
                        :mod (f2 / fruitful))))
      :time (t3 / time
            :ARG1-of (s2 / same-01)))

# ::snt In case that  the scope of Art icle 22 GDPR is not applicable, the basic  principles of Art icle 5 GDPR still apply which protect individual rights in particular through  the principles of lawfulness , fairness and accountability.
# File 54

(a / apply-02
      :ARG1 (p / principle
            :mod (b / basic)
            :part-of (l / law
                  :name (n / name
                        :op1 "Art"
                        :op2 "_0 :op3 "))))

# ::snt They violate, among other things, certain requirements of the GDPR such as the principle  of fairness, the restriction of processing to legitimate purposes and the adequacy of the  processing .
# File 54

(v / violate-01
      :ARG0 (t / they)
      :ARG1 (t2 / thing
            :ARG1-of (r / require-01
                  :ARG0 (l / law
                        :name (n / name
                              :op1 "GDPR")))
            :mod (c / certain)
            :example (a / and
                  :op1 (p / principle
                        :topic (f / fairness))
                  :op2 (r2 / restrict-01
                        :ARG1 (p2 / process-01)
                        :ARG2 (p3 / purpose
                              :ARG1-of (l2 / legitimate-02)))
                  :op3 (a2 / adequacy
                        :poss (p4 / process-01)))
            :ARG2-of (ii / include-91
                  :ARG1 (t3 / thing
                        :mod (o / other)))))

# ::snt (Original paperby Jac ob Me tcalf, Emanuel Moss, Eliz abethAnne W atkins, Ranjit Singh, andMadeleine Clar e Elish) (Resear ch summar y by Dr. Iga Kozlowska) Overview:AlgorithmicImpactAssessmen ts(AIAs)areausefultooltohelpAIsystemdesigner s,developer sandprocur erstoanaly zethebene fitsandpotentialpitfallsofalgorithmicsystems.Tobeeffectiv einaddr essingissuesoftranspar ency ,fairness,andaccountability ,theauthor softhisarticlearguethattheimpactsiden tifiedinAIAsneedtoascloselyrepresen tharmsaspossible.Andsecondly ,thatthereareaccountabilityforumsthatcancompelalgorithmdeveloper s to mak e appr opria te chang es to AI s ystemsin acc ordance with AIA findings.
# File 125

(m / multi-sentence
      :snt1 (a / and
            :op1 (p / paper
                  :mod (o / original)
                  :ARG1-of (w / write-01
                        :ARG0 (a2 / and
                              :op1 (p2 / person
                                    :name (n / name
                                          :op1 "Jacob"
                                          :op2 "Ob"
                                          :op3 "Me"
                                          :op4 "Tutor"))
                              :op2 (p3 / person
                                    :name (n2 / name
                                          :op1 "Emanuel"
                                          :op2 "Moss"))
                              :op3 (p4 / person
                                    :name (n3 / name
                                          :op1 "Eliz"
                                          :op2 "AbethAnne"
                                          :op3 "W"
                                          :op4 "Atkins"))
                              :op4 (p5 / person
                                    :name (n4 / name
                                          :op1 "Ranjit"
                                          :op2 "Singh"))
                              :op5 (p6 / person
                                    :name (n5 / name
                                          :op1 "Madeleine"
                                          :op2 "Clar"
                                          :op3 "Elish")))))
            :op2 (c / change-01
                  :ARG0 (p7 / person
                        :ARG0-of (d / develop-02
                              :ARG1 (s / software
                                    :ARG1-of (ii / intelligent-01
                                          :mod (a3 / artificial)))))
                  :ARG1 s
                  :ARG1-of (a4 / associate-01
                        :ARG2 (t / thing
                              :ARG1-of (f / find-01
                                    :ARG0 (o2 / organization
                                          :name (n6 / name
                                                :op1 "AIA")))))))
      :snt2 (a5 / and
            :op2 (p8 / person
                  :ARG0-of w)
            :ARG0-of (a6 / author-01
                  :ARG1 (s2 / string-entity
                        :value "tifiedinAIAsneedtoascloselyrepresen tharmsaspossible.Tobeeffectiv einaddr essingissuesoftranspar-ency,"))))

# ::snt Forexample,inyourAIA,youmaymeasur ehowfaryourmodeldeviatesfromyourfairnessbenchmark,whichmaybebasedonacompan ypolicy(orjustgroupconsensus)thatmodeloutcomesshouldn’tdivergemorethan10%acrosssomedemogr aphicchar acteristics(let’ssayage,gender ,race)andtheirintersections.Thatmetricmeasur estheimpactofyour,sayfacerecognitionmodel,onyourcustomer ’sabilitytogetequalqualityofservice.Theimpactisthattherewillbenomorethana10%differenceinpredictiv equalitybetween,forexample,youngBlack w omen and older whit e men.
# File 125

(m / multi-sentence
      :snt1 (e / exemplify-01
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "inyourAIA")))
      :snt2 (p / possible-01
            :ARG1 (d / distinguish-01
                  :ARG0 (y / you)
                  :ARG1 (a / amr-unknown)
                  :ARG2 (b / benchmark-01
                        :ARG0 y
                        :ARG1 (f / fairness)
                        :ARG1-of (p2 / possible-01)
                        :ARG1-of (b2 / base-02
                              :ARG2 (o2 / or
                                    :op1 (p3 / policy-01)
                                    :op2 (c / consensus
                                          :mod (g / group)
                                          :mod (j / just)))))))
      :snt3 (e2 / equal-01
            :ARG3 (a2 / and
                  :op1 (p4 / person
                        :mod (y2 / young)
                        :ARG1-of (b3 / black-05))
                  :op2 (p5 / person
                        :ARG1-of (w / white-02)
                        :ARG1-of (h / have-degree-91
                              :ARG2 (o3 / old)
                              :ARG3 (m2 / more))))
            :ARG1-of (p6 / predict-01)
            :snt4-of m)
      :ARG3 (a3 / and
            :op1 (g2 / gender)
            :op2 (r / race)
            :op3 (e3 / ethnicity))
      :ARG4 e2
      :ARG3 (s / serve-01))

# ::snt Inadditiontothemorecommonconcernsaroundfairness,accountability ,andtranspar ency ,designer sanddeveloper sshouldconsiderhowacceler atingadecisiontodigit alspeedimpactsallthestakeholder sinthatprocess.Designingforslownessmaynotbepopular ,butitisnotanewidea(seeHallnäs&Redström2001)andisespeciallypertinen tintheageofAI.Theques tioneachAIdesignershouldaskthemselfthenis,howistheautoma tionofthistaskspeedingupthesocialrhythmofthatactivity?Andwha tarethepotentialbene fitsandharmsof tha t acceler ation t o all s takeholder s involved?
# File 125

(m / multi-sentence
      :snt1 (a / and
            :op2 (c / concern-01
                  :ARG0 (a2 / and
                        :op1 (f / fairness)
                        :op2 (a3 / accountable-02)
                        :op3 (t / transgender))
                  :mod (m2 / more)))
      :snt2 (r / recommend-01
            :ARG1 (c2 / consider-02
                  :ARG0 (p / person
                        :ARG0-of (d / design-01)
                        :ARG0-of (d2 / develop-02
                              :ARG1 (s / sand)))
                  :ARG1 (a4 / and
                        :op1 (a5 / accelerate-01
                              :ARG1 (a6 / accelerate-01
                                    :ARG1 (a7 / assemble-01)))
                        :op2 (d3 / distract-01
                              :ARG0 a6
                              :ARG1 (p2 / person
                                    :ARG0-of (h / hold-01
                                          :ARG1 (s2 / stake))
                                    :mod (a8 / all)
                                    :ARG1-of (ii / involve-01))))))
      :snt3 (a9 / and
            :op1 (p3 / possible-01
                  :ARG1 (f2 / fit-01))
            :op2 (h2 / harm-01)
            :domain (a10 / amr-unknown))
      :snt4 (s3 / see-01
            :ARG0 (y / you)
            :ARG1 (a11 / and
                  :op1 (p4 / person
                        :name (n / name
                              :op1 "Hallnäs"))
                  :op2 (p5 / person
                        :name (n2 / name
                              :op1 "Redström")))
            :ARG2 (a12 / and
                  :op1 (e / et-cetera)
                  :op2 (e2 / et-cetera))))

# ::snt Heather:Wha tIteachisveryfocusedonapplic ationandreal-w orldexamples.It’susuallynotsomuchthetechnic alaspectsofAIbuthowthetechnic alrelatestothebusinessandlargersocialandethicalimpacts.Sowetalkalotabouthowtochooseaprojectthatprovidesbusinessvalueandistechnic allyfeasible.Ontheethicsside,wetalkaboutethicalques tionsacrosstheentirelifecycle–fromselectinganappr opria teproject(thatis,onethatisn’tinher entlymean ttoharmpeople)todatacollection,datalabeling ,choosingproxiesandmetrics,oper ationalizingconcep tslikefairness,toworkingwithuser s,trainingthem,evalua ting,andwatchingforunexpect ed consequences.
# File 125

(s / say-01
      :ARG0 (p / person
            :name (n / name
                  :op1 "Heather"))
      :ARG1 (a / and
            :op1 (f / focus-01
                  :ARG1 (t / teach-01)
                  :ARG2 (a2 / and
                        :op1 (a3 / apply-02)
                        :op2 (r / real-04)
                        :op3 (t2 / thing
                              :ARG0-of (e / exemplify-01)))
                  :degree (v / very))
            :op2 (t3 / talk-01
                  :ARG0 t
                  :ARG1 (a4 / and
                        :op1 (o / organization
                              :name (n2 / name
                                    :op1 "Ontheethicsside"))
                        :op2 (o2 / organization
                              :name (n3 / name
                                    :op1 "Tionsacrosstheentirelifecycle"))
                        :op3 (s2 / select-01
                              :ARG0 t
                              :ARG1 (o3 / organization
                                    :name (n4 / name
                                          :op1 "Oriental"
                                          :op2 "Political"
                                          :op3 "Action"
                                          :op4 "Conference")))
                        :op4 (t4 / target-01
                              :ARG0 t
                              :ARG1 o3)
                        :op5 (c / choose-01
                              :ARG0 t
                              :ARG1 (a5 / and
                                    :op1 (o4 / organization
                                          :name (n5 / name
                                                :op1 "Proxies"
                                                :op2 "and"
                                                :op3 "Metrics"))
                                    :op2 (o5 / organization
                                          :name (n6 / name
                                                :op1 "Opera"))))
                        :op6 (t5 / train-01
                              :ARG0 t
                              :ARG2 o3)
                        :op7 (w / watch-01
                              :ARG0 t
                              :ARG1 (t6 / thing
                                    :ARG2-of (c2 / consequence-03)
                                    :ARG1-of (e2 / expect-01
                                          :polarity -)
                                    :mod (e3 / ethics)))))))

# ::snt Scholar shiponthedecoloniz ationanddevelopmen tofsociallyjusttechnologypoin tstowardstheimport antneedforthosecreatingourtechnologytodevelopanti-racistcritic alframe works.CathyO’Neil’ s2016WeaponsofMathDestructionclaimsthat“BigDataprocessescodifythepast.Theydonotinventthefutur e.Doingthatrequir esmoralimagina tion,andthat’ssome thingonlyhumanscanprovide.Wehavetoexplicitlyembedbettervaluesintoouralgorithms,creatingBigDatamodelsthatfollowourethicallead.Some timesthatwillmeanputtingfairnessaheadofprofit”(p.204).Somehavecalledthisdigit aljusticeorcodedequity(Benjamin,2019;Noble,2018).Regardlessofthename,aclearneedexistsfortoolsdesignedtosupportthedevelopmen toftechnologiesthatcontribut etoamoreequit able,liber atedplane tforallpeople.Thistoolhelp sfillthatneedbysupportingthedevelopmen tofthemindse tsnecessar y to code f or equity and jus tice.
# File 125

(m / multi-sentence
      :snt1 (c / claim-01
            :ARG0 (p / publication-91
                  :ARG0 (p2 / person
                        :name (n / name
                              :op1 "CathyO’Neil"))
                  :ARG1 (p3 / publication
                        :name (n2 / name
                              :op1 "BigDataprocessescodifythepast"))
                  :ARG4 (p4 / publication
                        :name (n3 / name
                              :op1 "Benjamin")
                        :time (d / date-entity
                              :year 2019))))
      :snt2 (a / and
            :op1 (n4 / need-01
                  :polarity -
                  :ARG0 (t / they)
                  :ARG1 (ii / invent-01
                        :ARG0 t
                        :ARG1 (t2 / thing
                              :ARG0-of (e / exemplify-01
                                    :ARG1 (n5 / need-01
                                          :ARG0 t
                                          :ARG1 (ii2 / invent-01
                                                :ARG0 t
                                                :ARG1 (t3 / thing
                                                      :ARG0-of e)
                                                :ARG1-of (m2 / moral-02))))))))
      :op2 (n6 / need-01
            :ARG0 (w / we)
            :ARG1 (e2 / embed-01
                  :ARG0 w
                  :ARG1 (t4 / thing
                        :ARG1-of (g / good-02
                              :ARG2-of (h / have-degree-91
                                    :ARG1 t4
                                    :ARG3 (m3 / more))))
                  :ARG2 (a2 / algorithm
                        :poss w)))
      :op3 (c2 / create-01
            :ARG0 w
            :ARG1 (t5 / thing
                  :name (n7 / name
                        :op1 "BigDatamodelsthatfollowourethicallead")))
      :op4 (n8 / need-01
            :ARG0 w
            :ARG1 (c3 / code-01
                  :ARG0 w
                  :ARG1 (a3 / and
                        :op1 (e3 / equity)
                        :op2 (e4 / et-cetera)))))

# ::snt InConf erenc eon fairness, ac countability and transparency(pp.
# File 125

(p / publication-91
      :ARG7 (a / and
            :op1 (f / fairness)
            :op2 (p2 / possible-01
                  :ARG1 (a2 / accurate))
            :op3 (t / transparency)))

# ::snt Consensus, Omission, and Disagr eemen t in AI E thics Thisfine-gr ainedappr oachconfirmsthatsometopicsareshar edprioritiesacrosssectors,includingtranspar ency ,fairness,privacy,andsafety.Notably,thereisalsoaconsensusinwhichtopicsareneglect edoromit ted,suchasconcernsaboutexistentialriskandcultur alsensitivity .Theseomissionsareworth yofattentionandhighligh tthefactthatpayingattentiontoconsensus alone c an mask import ant dimensions of AIethics.
# File 125

(m / multi-sentence
      :snt1 (ii / include-91
            :ARG1 (a / and
                  :op1 (c / consensus)
                  :op2 (e / exclude-01)
                  :op3 (d / disagr-eemen))
            :ARG2 (a2 / and
                  :op1 (t / thing
                        :name (n / name
                              :op1 "AI"))
                  :op2 (t2 / thing
                        :name (n2 / name
                              :op1 "E"
                              :op2 "Thics"))))
      :snt2 (h / have-concession-91
            :ARG1 (a3 / and
                  :op1 (a4 / acknowledge-01
                        :ARG0 (p / person)
                        :ARG1 (t3 / thing
                              :ARG0-of (e2 / exemplify-01
                                    :ARG1 (e3 / entitlement
                                          :ARG2-of (ii2 / include-91
                                                :ARG1 (a5 / and
                                                      :op1 (f / fairness)
                                                      :op2 (p2 / privilege-01)
                                                      :op3 (s / safe-01))))))
                        :ARG1-of (f2 / fine-04))
                  :op2 (c2 / confirm-01
                        :ARG0 p
                        :ARG1 (t4 / thing
                              :ARG0-of e2
                              :ARG1 e3))))
      :ARG2 (m2 / mask-01
            :ARG0 (p3 / pay-01
                  :ARG1 (a6 / attend-02
                        :ARG1 c)
                  :mod (a7 / alone)))
      :ARG1 (t5 / thing
            :ARG1-of (ii3 / important-01
                  :ARG2 (d2 / dimension
                        :mod (a8 / artificial))))
      :ARG1-of (n3 / notable-04))

# ::snt Betweenthelines:Asmoreself-helpgroupsemer geaddr essingthewoesofcontentcreators,suchasthoseonReddit,wemigh tstarttoleveltheplayingfieldbetweenthecorpor ationsandpeopleusingtheseplatforms.Untilthen,informalforaandtips&trick smigh tbethebestbetfor content creators to figh t against the un fairnessof the s ystem.
# File 125

(h / have-concession-91
      :ARG1 (s / start-01
            :ARG0 (p / person
                  :ARG0-of (c / create-01
                        :ARG1 (c2 / content))
                  :example (p2 / person
                        :location (p3 / publication
                              :name (n / name
                                    :op1 "Reddit")))
                  :mod (m / more)
                  :ARG0-of (h2 / help-01
                        :ARG1 c))
            :ARG1 (l / level-03
                  :ARG0 p
                  :ARG1 (f / field
                        :location-of (p4 / play-01))))
      :ARG2 (s2 / smigh-02
            :ARG0 (a / and
                  :op1 (o / organization
                        :name n
                        :op1 "Untilthen"))
            :op2 (ii / inform-01)
            :op3 (t / tip-05)
            :op4 (t2 / trick-01))
      :ARG1 (f2 / fight-01
            :ARG0 p
            :ARG1 (f3 / fairness
                  :polarity -
                  :poss (s3 / stem)))
      :ARG1-of (h3 / have-degree-91
            :ARG2 (g / good-02
                  :ARG1 f2)
            :ARG3 (m2 / most)))

# ::snt In Proceedings of the conference on fairness, accounta bility, and transparency , pp.
# File 31

(b / be-located-at-91
      :ARG2 (p / publication-91
            :ARG1 (c / conference
                  :topic (a / and
                        :op1 (f / fairness)
                        :op2 (a2 / accountable-02)
                        :op3 (t / transparency)))
            :ARG7 (v / value-interval
                  :op1 1
                  :op2 2)))

# ::snt Human rights impact assessments for AI: analysis an d recommendations AI GOVERNANCE AND HUMAN RIGHTS Over the last few years, at least 170 sets of ethic al or human-rights based AI principles, frameworks, and guidelines have been developed to s upport responsible AI development and deployment within the public and private sectors.11Research has shown that a growing consensus is forming around core principles, including the ne ed for accountability, privacy and security, transparency and explainability, fairness and non-d iscrimination, professional responsibility, human control, and the promotion of human values.12As these AI principles gain acceptance within the public and private sectors, the focus is  now shi ing to the development of appropriate strategies to operationalize the principles into re sponsible practices.
# File 31

(m / multi-sentence
      :snt1 (a / assess-01
            :ARG1 (ii / impact-01
                  :ARG0 (ii2 / intelligent-01
                        :mod (a2 / artificial))
                  :ARG1 (r / right-05
                        :ARG1 (h / human)))
            :ARG2 (a3 / analyze-01)
            :ARG0-of (r2 / recommend-01
                  :ARG1 (a4 / and
                        :op1 (g / government-organization
                              :ARG0-of (g2 / govern-01)
                              :mod (a5 / artificial))
                        :op2 (r3 / right-05
                              :ARG1 (h2 / human)))))
      :snt2 (d / develop-02
            :ARG1 (s / set
                  :quant (a6 / at-least
                        :op1 170)
                  :consist-of (a7 / and
                        :op1 (p / principle
                              :ARG1-of (b / base-02
                                    :ARG2 (e / ethic)))
                        :op2 (f / framework)
                        :op3 (g3 / guideline)))
            :purpose (s2 / support-01
                  :ARG0 s
                  :ARG1 (a8 / and
                        :op1 (d2 / develop-02
                              :ARG1 (ii3 / intelligent-01
                                    :mod (a9 / artificial))
                              :ARG1-of (r4 / responsible-02))
                        :op2 (d3 / deploy-01
                              :ARG1 ii3
                              :ARG2 (a10 / and
                                    :op1 (s3 / sector
                                          :ARG1-of (p2 / public-02))
                                    :op2 (s4 / sector
                                          :ARG1-of (p3 / private-03))))))
            :time (b2 / before
                  :op1 (n / now)
                  :duration (f2 / few
                        :op1 (t / temporal-quantity
                              :quant 1
                              :unit (y / year))))
            :snt3 (s5 / show-01
                  :ARG0 (r5 / research-01)
                  :ARG1 (f3 / form-01
                        :ARG1 (c / consensus
                              :ARG1-of (g4 / grow-01))
                        :ARG2 (p4 / principle
                              :ARG2-of (ii4 / include-01
                                    :ARG1 (a11 / and
                                          :op1 (a12 / accountability)
                                          :op2 (p5 / privacy)
                                          :op3 (s6 / security)
                                          :op4 (a13 / and
                                                :op1 (t2 / transparency)
                                                :op2 (e2 / explain-01))
                                          :op5 (f4 / fairness)
                                          :op6 (d4 / discriminate-02
                                                :polarity -)
                                          :op7 (c2 / control-01
                                                :ARG0 (h3 / human)))
                                    :op8 (p6 / promote-02
                                          :ARG1 (v / value
                                                :mod h3)))))))
      :snt4 (h4 / have-condition-91
            :li 12
            :ARG1 (f5 / focus-01
                  :ARG2 (d5 / develop-02
                        :ARG1 (s7 / strategy
                              :ARG1-of (a14 / appropriate-02)
                              :purpose (o / operateize-01
                                    :ARG1 p4
                                    :ARG2 (p7 / practice-01
                                          :ARG1-of (p8 / possible-01))))))
            :ARG2 (a15 / accept-01
                  :ARG1 (p9 / principle
                        :mod (t3 / this))
                  :ARG2 a8)))

# ::snt ”34Typical sources of risk to be identified include the  presence of bias in datasets used to train an AI system, as well as the  fairness and explainability of the model; identification of potential impacts can include con textual considerations related to equity and justice, as well as the economic interests, health,  and well-being of users or populations potentially aﬀected by the proposed system.
# File 31

(m / multi-sentence
      :snt1 (ii / include-01
            :li 34
            :ARG1 (a / and
                  :op1 (p / present-02
                        :ARG1 (b / bias-01)
                        :ARG2 (d / dataset
                              :ARG1-of (u / use-01
                                    :ARG2 (t / train-01
                                          :ARG1 (s / system
                                                :mod (ii2 / intelligent-01
                                                      :mod (a2 / artificial)))))))
                  :op2 (a3 / and
                        :op1 (f / fairness
                              :poss (m2 / model))
                        :op2 (e / explain-01
                              :ARG1 m2)))
            :ARG2 (s2 / source-02
                  :ARG1 (r / risk-01)
                  :ARG1-of (t2 / typical-02)
                  :ARG1-of (ii3 / identify-01)))
      :snt2 (p2 / possible-01
            :ARG1 (ii4 / include-01
                  :ARG1 (c / consider-02
                        :mod (t3 / text)
                        :ARG1-of (r2 / relate-01
                              :ARG2 (a4 / and
                                    :op1 (e2 / equity)
                                    :op2 (j / justice))))
                  :ARG2 (a5 / and
                        :op1 (ii5 / interest-01
                              :ARG1 (o / or
                                    :op1 (p3 / person
                                          :ARG0-of u))
                              :op2 (p4 / population))
                        :ARG2 (e3 / economy))
                  :op2 (h / healthy
                        :domain o)
                  :op3 (w / well-09
                        :ARG1 o)
                  :ARG1-of (p5 / protect-01
                        :ARG0 (s3 / system
                              :ARG1-of (p6 / propose-01))
                        :ARG1-of (p7 / possible-01)))
            :ARG3 (ii6 / identify-01
                  :ARG1 (ii7 / impact-01
                        :mod (p8 / potential)))))

# ::snt ” Harvard Journal of Law and Technology, 35( 10), 78, (2021), https://papers.ssrn.com/sol3/papers.cfm?abstract_id =3867634 .34Ibid ., 26.33Ibid ., 28.32Emanuel Moss et al., “Assembling Accountability: Alg orithmic Impact Assessment for the Public Interest, ”Data & Society, June 29, 2021, https://datasociety.net/library/assembling-accounta bility-algorithmic-impact-assessment-for-the-public -interest/31Jacob Metcalf et al.. "Algorithmic impact assessmen ts and accountability: The co-construction of impact s." In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Tra nsparency , pp.
# File 31

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Emanuel"
                        :op2 "Moss"))
            :op2 (p3 / person
                  :mod (o / other)))
      :ARG1 (p4 / publication
            :name (n2 / name
                  :op1 "Assembling"
                  :op2 "Accountability"
                  :op3 ":"
                  :op4 "Alg"
                  :op5 "orithmic"
                  :op6 "Impact"
                  :op7 "Assessment"
                  :op8 "for"
                  :op9 "the"
                  :op10 "Public"
                  :op11 "Interest"))
      :ARG4 (j / journal
            :name (n3 / name
                  :op1 "Harvard"
                  :op2 "Journal"
                  :op3 "of"
                  :op4 "Law"
                  :op5 "and"
                  :op6 "Technology"))
      :ARG7 (v / value-interval
            :op1 35
            :op2 78)
      :time (d / date-entity
            :year 2021
            :month 6
            :day 29)
      :medium (u / url-entity
            :value "https://www.ssrn.com/library/assembling-accounta bility-algorithmic-impact-assessment-for-the-public-interest/"))

# ::snt Canadaʼs Directive on Automated Decision-Making In 2019, the Canadian government released its Direc tive on Automated Decision-Making (the Directive).39The Directiveʼs principal objectives were to ensure the incorporation of ADS into external public service delivery respects “core adm inistrative law principles such as transparency, accountability, legality, and procedural fairness” and to ensure harmful eﬀects of algorithms on administrative decisions are assessed and reduced.40To this end, the Directive includes an accompanying impact assessment tool in the form of a questionnaire that must be completed prior to the development of any ADS.
# File 31

(m / multi-sentence
      :snt1 (r / release-01
            :li 39
            :ARG0 (g / government-organization
                  :ARG0-of (g2 / govern-01
                        :ARG1 (c / country
                              :name (n / name
                                    :op1 "Canada"))))
            :ARG1 (l / law
                  :name (n2 / name
                        :op1 "Directive"
                        :op2 "on"
                        :op3 "Automated"
                        :op4 "Decision-Making")
                  :poss g)
            :time (d / date-entity
                  :year 2019))
      :snt2 (ii / include-01
            :li 40
            :ARG0 (d2 / directive)
            :ARG1 (t / tool
                  :ARG0-of (a / assess-01
                        :ARG1 (ii2 / impact-01))
                  :ARG0-of (a2 / accompany-01)
                  :consist-of (q / questionnaire
                        :ARG1-of (c2 / complete-01
                              :ARG2-of (o / obligate-01)
                              :time (p / prior
                                    :op1 (d3 / develop-02
                                          :ARG1 (p2 / product
                                                :name (n3 / name
                                                      :op1 "ADS")
                                                :mod (a3 / any)))))))
            :purpose (a4 / and
                  :op1 (e / ensure-01
                        :ARG0 d2
                        :ARG1 (ii3 / incorporate-02
                              :ARG1 p2
                              :ARG2 (d4 / deliver-01
                                    :ARG1 (s / serve-01
                                          :ARG2 (p3 / public))
                                    :mod (e2 / external))))
                  :op2 (e3 / ensure-01
                        :ARG0 d2
                        :ARG1 (a5 / and
                              :op1 (a6 / assess-01
                                    :ARG1 (a7 / affect-01
                                          :ARG0 (a8 / algorithm)
                                          :ARG1 (d5 / decide-01
                                                :ARG3 (a9 / administrate-01))
                                          :ARG1-of (h / harmful-02)))
                              :op2 (r2 / reduce-01
                                    :ARG1 a7))))
            :mod (p4 / principal)))

# ::snt One of the current trends associated with AIAs is to focus on assessing the sociotechnical aspects (e.g., the potential for bias, fairness, or explainability of the system) and their immediately foreseeable and measurable risks or consequences.
# File 31

(f / focus-01
      :ARG1 (a / assess-01
            :ARG1 (a2 / aspect
                  :mod (s / sociology)
                  :example (p / potential
                        :domain (o / or
                              :op1 (b / bias-01
                                    :ARG1 (s2 / system))
                              :op2 (f2 / fairness
                                    :poss s2)
                              :op3 (e / explain-01
                                    :ARG1 s2))))
            :ARG2 (a3 / and
                  :op1 (p2 / possible-01
                        :ARG1 (f3 / foresee-01
                              :ARG1 (o2 / or
                                    :op1 (r / risk-01)
                                    :op2 (c / consequence-03)))
                        :time (ii / immediate))
                  :op2 (p3 / possible-01
                        :ARG1 (m / measure-01
                              :ARG1 o2))))
      :ARG1-of (ii2 / include-91
            :ARG2 (t / trend-01
                  :time (c2 / current)
                  :ARG1-of (a4 / associate-01
                        :ARG2 (p4 / product
                              :name (n / name
                                    :op1 "AIA"))))))

# ::snt "Algorithmic Impact Assessment s and Accountability: The Co-Construction of Impact s." In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Tra nsparency , pp.
# File 31

(p / publication-91
      :ARG1 (p2 / publication
            :name (n / name
                  :op1 "Algorithmic"
                  :op2 "Impact"
                  :op3 "Assessment"
                  :op4 "and"
                  :op5 "Accountability"
                  :op6 "The"
                  :op7 "Co-Construction"
                  :op8 "of"
                  :op9 "Impact"
                  :op10 "S"))
      :ARG4 (c / conference
            :name (n2 / name
                  :op1 "ACM"
                  :op2 "Conference"
                  :op3 "on"
                  :op4 "Fairness"
                  :op5 "and"
                  :op6 "Accountability"
                  :op7 "and"
                  :op8 "Tra"
                  :op9 "Nsparency")
            :time (d / date-entity
                  :year 2021)
            :ARG2-of (p3 / proceed-01))
      :ARG7 (v / value-interval
            :op1 "pp")
      :op2 "pp")

# ::snt If a developer implements the ECPAI S standards, it can add a quality assurance mark to its products and services with the intent t o raise consumer trust and market power.65 The ISO and the International Electrotechnical Comm ission (IEC) are advancing a conformity assessment standard for AI risk management through the work of a joint committee on artificial intelligence (ISO/IEC JTC1/SC 42).66The proposed ISO/EC 42001 - Artificial Intelligence Management System (AIMS) standard will enable organ izations to show they have implemented and continually work on improving processes to addr ess bias, fairness, inclusiveness, safety, security, privacy, accountability, applicability, a nd transparency in AI.
# File 31

(m / multi-sentence
      :snt1 (p / possible-01
            :ARG1 (a / add-02
                  :ARG0 (p2 / person
                        :ARG0-of (d / develop-02))
                  :ARG1 (m2 / mark
                        :mod (a2 / assure-01
                              :ARG2 (q / quality)))
                  :ARG2 (a3 / and
                        :op1 (p3 / product
                              :poss p2)
                        :op2 (s / serve-01
                              :ARG0 p2))
                  :purpose (ii / intend-01
                        :ARG0 p2
                        :ARG1 (r / raise-01
                              :ARG0 p2
                              :ARG1 (a4 / and
                                    :op1 (t / trust-01
                                          :ARG0 (p4 / person
                                                :ARG0-of (c / consume-01)))
                                    :op2 (p5 / power
                                          :mod (m3 / market)))))))
      :snt2 (a5 / advance-01
            :li 65
            :ARG0 (a6 / and
                  :op1 (o / organization
                        :name (n / name
                              :op1 "International"
                              :op2 "Scientific"
                              :op3 "Institute"))
                  :op2 (o2 / organization
                        :name (n2 / name
                              :op1 "International"
                              :op2 "Electrotechnical"
                              :op3 "Commission")))
            :ARG1 (s2 / standard
                  :mod (a7 / assess-01
                        :ARG1 (c2 / conform-01))
                  :topic (m4 / manage-01
                        :ARG1 (ii2 / intelligent-01
                              :mod (a8 / artificial)))
                  :ARG1-of (p6 / propose-01))
            :manner (w / work-01
                  :ARG0 (c3 / committee
                        :mod (j / joint)
                        :topic ii2
                        :ARG1-of (m5 / mean-01
                              :ARG2 (a9 / and
                                    :op1 (s3 / standard
                                          :mod (o3 / organization
                                                :name (n3 / name
                                                      :op1 "ISO"))
                                          :mod (o4 / organization
                                                :name (n4 / name
                                                      :op1 "JTC1")))
                                    :op2 (s4 / standard
                                          :mod (o5 / organization
                                                :name (n5 / name
                                                      :op1 "SC"
                                                      :op2 42)))))))))

# ::snt ”67Within two years, NIST is required to develop an AI risk management framework that enables the assessment of “trustworthy” AI and iden tification of appropriate risk mitigation strategies on a voluntary basis in the public and p rivate sectors.68NIST is to establish common definitions and characterizations for AI principles , such as explainability, transparency, and fairness.
# File 31

(r / require-01
      :li 67
      :ARG1 (d / develop-02
            :ARG0 (r2 / research-institute
                  :name (n / name
                        :op1 "NIST"))
            :ARG1 (f / framework
                  :ARG0-of (e / enable-01
                        :ARG1 (a / and
                              :op1 (a2 / assess-01
                                    :ARG1 (ii / intelligent-01
                                          :mod (a3 / artificial))
                                    :ARG2 (d2 / deserve-01
                                          :ARG0 ii))
                              :op2 (ii2 / identify-01
                                    :ARG1 (s / strategy
                                          :ARG0-of (m / mitigate-01
                                                :ARG1 (r3 / risk-01))
                                          :ARG1-of (a4 / appropriate-02))
                                    :ARG1-of (b / base-02
                                          :ARG2 (a5 / and
                                                :op1 (s2 / sector
                                                      :ARG1-of (p / public-02))
                                                :op2 (s3 / sector
                                                      :ARG1-of (p2 / private-03)))
                                          :ARG1-of (v / voluntary-02)))))
                  :purpose (m2 / manage-01
                        :ARG1 r3)))
      :ARG2 r2
      :time (a6 / after
            :op1 (n2 / now)
            :quant (u / up-to
                  :op1 (t / temporal-quantity
                        :quant 2
                        :unit (y / year))))
      :purpose (e2 / establish-01
            :ARG0 r2
            :ARG1 (a7 / and
                  :op1 (d3 / define-01
                        :ARG1 (p3 / principle
                              :mod ii)
                        :mod (c / common)
                        :example (a8 / and
                              :op1 (e3 / explain-01
                                    :ARG1-of (p4 / possible-01))
                              :op2 (t2 / transparency)
                              :op3 (f2 / fairness)))
                  :op2 (c2 / characterize-01
                        :ARG1 p3))))

# ::snt To facilitate rights-respecting AI governance at scale, policymakers should ensure appropriate coordination of research & development spending with AI standardization pilot programs, such as regulatory sandboxes, to ac celerate: a. the adoption of privacy-enhancing technologies, t echnical tools that enable bias and fairness detection and mitigation, or the conti nuous monitoring of AI system performance; and, b.
# File 31

(r / recommend-01
      :ARG1 (e / ensure-01
            :ARG0 (p / person
                  :ARG0-of (l / legislate-01))
            :ARG1 (c / coordinate-01
                  :ARG1 (s / spend-01
                        :ARG1 (a / and
                              :op1 (r2 / research-01)
                              :op2 (d / develop-02)))
                  :ARG3 (p2 / program
                        :ARG1-of (p3 / pilot-01)
                        :topic (s2 / standardize-01
                              :ARG1 (ii / intelligent-01
                                    :mod (a2 / artificial)))
                        :example (s3 / sandbox
                              :mod (r3 / regulate-01)))
                  :ARG1-of (a3 / appropriate-02)
                  :purpose (f / facilitate-01
                        :ARG0 p
                        :ARG1 (g / govern-01
                              :ARG0 ii
                              :ARG1-of (r4 / respect-01
                                    :ARG2 (r5 / right-05)))
                        :degree (a4 / at-scale))
                  :example (a5 / and
                        :op1 (a6 / adopt-01
                              :li "a"
                              :ARG1 (t / technology
                                    :ARG0-of (e2 / enhance-01
                                          :ARG1 (p4 / privacy))))
                        :op2 (a7 / adopt-01
                              :li "b"
                              :ARG1 (t2 / tool
                                    :mod (t3 / technical)
                                    :ARG0-of (e3 / enable-01
                                          :ARG1 (a8 / and
                                                :op1 (d2 / detect-01
                                                      :ARG1 (a9 / and
                                                            :op1 (b / bias-01)
                                                            :op2 (f2 / fair-01)))
                                                :op2 (m / mitigate-01
                                                      :ARG1 a9)))))
                        :op3 (m2 / monitor-01
                              :li "c"
                              :ARG1 (p5 / perform-02
                                    :ARG0 (s4 / system
                                          :mod ii))
                              :mod (c2 / conti-nuous))))))

# ::snt First, that  it’s ethically sound and complies with regulations  in all respects; second, that it’s underpinned by a  robust foundation of end-to-end governance; and  third, that it’s supported by strong performance  pillars addressing bias and fairness, interpretability  and explainability, and robustness and security.
# File 147

(a / and
      :op1 (a2 / and
            :li 1
            :op1 (s / sound
                  :mod (e / ethics)
                  :domain (ii / it))
            :op2 (c / comply-01
                  :ARG0 ii
                  :ARG1 (r / regulate-01)
                  :manner (r2 / respect
                        :mod (a3 / all))))
      :op2 (u / underpin-01
            :li 2
            :ARG0 (f / foundation
                  :mod (r3 / robust)
                  :mod (g / govern-01
                        :manner (e2 / end-to-end)))
            :ARG1 ii)
      :op3 (s2 / support-01
            :li 3
            :ARG0 (p / pillar
                  :ARG0-of (a4 / address-02
                        :ARG1 (a5 / and
                              :op1 (b / bias-01)
                              :op2 (f2 / fairness)
                              :op3 (ii2 / interpret-01
                                    :ARG1-of (p2 / possible-01))
                              :op4 (e3 / explain-01
                                    :ARG1-of (p3 / possible-01))
                              :op5 (r4 / robustness)
                              :op6 (s3 / security)))
                  :ARG1-of (s4 / strong-02)
                  :mod (p4 / perform-02))
            :ARG1 ii))

# ::snt PwC has developed a comprehensive Responsible AI Framework and  Toolkit to help companies focus on and address five key dimensions when  designing and deploying responsible AI applications: Governance Ethics and regulation Interpretability and  explainabilityRobustness and  security Bias and fairness1 2 3 54Governance serves as an   end-to-end foundation for all the  other dimensions.
# File 147

(m / multi-sentence
      :snt1 (d / develop-02
            :ARG0 (c / company
                  :name (n / name
                        :op1 "PwC"))
            :ARG1 (a / and
                  :op1 (f / framework
                        :name (n2 / name
                              :op1 "Responsible"
                              :op2 "AI"
                              :op3 "Framework"))
                  :op2 (t / toolkit)
                  :mod (c2 / comprehensive))
            :ARG4 (h / help-01
                  :ARG0 a
                  :ARG1 (a2 / and
                        :op1 (f2 / focus-01
                              :ARG0 (c3 / company)
                              :ARG2 (d2 / dimension
                                    :quant 5
                                    :ARG1-of (k / key-02)
                                    :ARG1-of (m2 / mean-01
                                          :ARG2 (a3 / and
                                                :op1 (e / ethics
                                                      :mod (g / govern-01))
                                                :op2 (ii / interpret-01
                                                      :ARG1 (r / regulate-01))
                                                :op3 (e2 / explain-01)
                                                :op4 (r2 / robustness)
                                                :op5 (b / bias-01
                                                      :mod (s / security))
                                                :op6 (f3 / fairness))))
                              :op2 (a4 / address-02
                                    :ARG0 c3
                                    :ARG1 d2)
                              :time (a5 / and
                                    :op1 (d3 / design-01
                                          :ARG0 c3
                                          :ARG1 (a6 / application
                                                :mod (ii2 / intelligent-01
                                                      :mod (a7 / artificial))
                                                :ARG1-of (r3 / responsible-01)))
                                    :op2 (d4 / deploy-01
                                          :ARG0 c3
                                          :ARG1 a6))))
                  :ARG2 c3))
      :snt2 (s2 / serve-01
            :ARG0 (g2 / govern-01)
            :ARG1 (f4 / foundation
                  :mod (e3 / end-to-end))
            :ARG2 (d5 / dimension
                  :mod (o / other)
                  :mod (a8 / all))))

# ::snt Addresses the issues of bias and fairness—recognising that while  there is no such thing as a decision that is fair to all parties, it is  possible for organisations to design AI systems to mitigate unwanted  bias and achieve decisions that are fair under a specific and clearlycommunicated definition.The core goal is to help  organisations develop AI that is  not only compliant with applicable  regulations, but is also ethical.
# File 147

(a / address-02
      :ARG1 (ii / issue-02
            :ARG0 (a2 / and
                  :op1 (b / bias-01)
                  :op2 (f / fair-01)))
      :ARG2 (r / recognize-02
            :ARG1 (c / contrast-01
                  :ARG1 (f2 / fair-01
                        :polarity -
                        :ARG1 (t / thing
                              :ARG1-of (d / decide-01))
                        :ARG2 (p / party
                              :mod (a3 / all)))
                  :ARG2 (p2 / possible-01
                        :ARG1 (d2 / design-01
                              :ARG0 (o / organization)
                              :ARG1 (s / system
                                    :mod (ii2 / intelligent-01
                                          :mod (a4 / artificial)))
                              :purpose (a5 / and
                                    :op1 (m / mitigate-01
                                          :ARG0 s
                                          :ARG1 (b2 / bias-01
                                                :ARG1-of (w / want-01
                                                      :polarity -)))
                                    :op2 (a6 / achieve-01
                                          :ARG0 s
                                          :ARG1 (t2 / thing
                                                :ARG1-of (d3 / decide-01)
                                                :ARG1-of (f3 / fair-01)
                                                :condition (d4 / define-01
                                                      :ARG1-of (c2 / clear-06)
                                                      :ARG1-of (s2 / specific-02)))))))))
      :mod (g / goal
            :ARG1-of (c3 / core-02))
      :purpose (h / help-01
            :ARG1 (d5 / develop-02
                  :ARG0 o
                  :ARG1 s
                  :ARG4 (c4 / comply-01
                        :ARG0 s
                        :ARG1 (a7 / and
                              :op1 (t3 / thing
                                    :ARG0-of (r2 / regulate-01)
                                    :ARG1-of (a8 / apply-01
                                          :ARG1-of p2)))
                        :op2 (e / ethics
                              :mod (a9 / also))))))

# ::snt And people  perceive bias through the subjective lens of fairness—a social construct with  strong local nuances and many different and even conflicting definitions.
# File 147

(a / and
      :op2 (p / perceive-01
            :ARG0 (p2 / person)
            :ARG1 (b / bias-01)
            :ARG2 (l / lens
                  :mod (f / fairness
                        :ARG1-of (c / construct-01
                              :mod (s / society)
                              :ARG0-of (h / have-03
                                    :ARG1 (a2 / and
                                          :op1 (n / nuances
                                                :ARG1-of (s2 / strong-02)
                                                :ARG1-of (l2 / local-02))
                                          :op2 (d / define-01
                                                :ARG1-of (d2 / differ-02)
                                                :ARG0-of (c2 / conflict-01
                                                      :mod (e / even))
                                                :quant (m / many))))))
                  :ARG1-of (s3 / subjective-03))))

# ::snt In each case,  establishing fairness requires businesses to choose their level of comfort in  the choices they make, and balance these against the associated costs and  wider impacts, which might be negative for some stakeholders.Bias and fairness 5 AI decisions are similar to those made by humans.
# File 147

(m / multi-sentence
      :snt1 (r / require-01
            :ARG0 (e / establish-01
                  :ARG1 (f / fairness))
            :ARG1 (a / and
                  :op1 (c / choose-01
                        :ARG0 (b / business)
                        :ARG1 (l / level
                              :degree-of (c2 / comfort-01
                                    :ARG0 (c3 / choose-01
                                          :ARG0 b)
                                    :ARG1 b)))
                  :op2 (b2 / balance-01
                        :ARG0 b
                        :ARG1 c3
                        :ARG2 (a2 / and
                              :op1 (c4 / cost-01
                                    :ARG1-of (a3 / associate-01))
                              :op2 (ii / impact-01
                                    :ARG0-of (n / negative-02
                                          :ARG2 (s / stake
                                                :quant (s2 / some))
                                          :ARG1-of (p / possible-01))
                                    :ARG1-of (h / have-degree-91
                                          :ARG2 (w / wide-02
                                                :ARG1 ii)
                                          :ARG3 (m2 / more))))))
            :prep-in (c5 / case-04
                  :mod (e2 / each)))
      :snt2 (r2 / resemble-01
            :ARG1 (t / thing
                  :ARG1-of (d / decide-01
                        :ARG3 (ii2 / intelligent-01
                              :mod (a4 / artificial))))
            :ARG2 (t2 / thing
                  :ARG1-of (d2 / decide-01)
                  :ARG1-of (m3 / make-01
                        :ARG0 (h2 / human)))))

# ::snt In each case, establishing fairness requires  businesses to choose their level of comfort in the  choices they make, and balance these against the  associated costs and wider impacts, which might  be negative for some stakeholders.
# File 147

(r / require-01
      :ARG0 (e / establish-01
            :ARG1 (f / fairness))
      :ARG1 (a / and
            :op1 (c / choose-01
                  :ARG0 (b / business)
                  :ARG1 (l / level
                        :degree-of (c2 / comfort-01
                              :ARG0 (c3 / choose-01
                                    :ARG0 b)
                              :ARG1 b)))
            :op2 (b2 / balance-01
                  :ARG0 b
                  :ARG1 c
                  :ARG2 (a2 / and
                        :op1 (c4 / cost-01
                              :ARG1-of (a3 / associate-01))
                        :op2 (ii / impact-01
                              :ARG0-of (n / negative-02
                                    :ARG2 (s / stake
                                          :quant (s2 / some))
                                    :ARG1-of (p / possible-01))
                              :ARG1-of (h / have-degree-91
                                    :ARG2 (w / wide-02
                                          :ARG1 ii)
                                    :ARG3 (m / more))))))
      :ARG2 b
      :mod (c5 / case-04
            :mod (e2 / each)))

# ::snt The data should be used in the appropriate context, and  the applicable techniques should be used to enable the trade-off between  accuracy, explainability, fairness, and security.
# File 147

(r / recommend-01
      :ARG1 (a / and
            :op1 (u / use-01
                  :ARG1 (d / data)
                  :location (c / context
                        :ARG1-of (a2 / appropriate-02)))
            :op2 (u2 / use-01
                  :ARG1 (t / technique
                        :ARG1-of (a3 / apply-02
                              :ARG1-of (p / possible-01)))
                  :ARG2 (e / enable-01
                        :ARG0 t
                        :ARG1 (t2 / trade-off-02
                              :ARG1 (a4 / accurate)
                              :ARG2 (a5 / and
                                    :op1 (e2 / explain-01
                                          :ARG1-of (p2 / possible-01))
                                    :op2 (f / fairness)
                                    :op3 (s / security)))))))

# ::snt While recognising  that fairness is an immensely complex concept with different, sometimes competing, definitions it  is nevertheless seen  as a fundamental component underpinning responsible systems and it is  suggested  that algorithmic processes should seek to minimise their potential to be unfair and  maximise their potential to be fair.
# File 78

(c / contrast-01
      :ARG1 (r / recognize-01
            :ARG1 (c2 / concept
                  :domain (f / fair-01)
                  :mod (c3 / complex
                        :degree (ii / immense))
                  :ARG0-of (h / have-03
                        :ARG1 (d / define-01
                              :ARG1-of (d2 / differ-02)
                              :ARG0-of (c4 / compete-01
                                    :frequency (s / sometimes))))))
      :ARG2 (a / and
            :op1 (s2 / see-01
                  :ARG1 f
                  :ARG2 (c5 / component
                        :mod (f2 / fundamental)
                        :ARG0-of (u / underpin-01
                              :ARG1 (s3 / system
                                    :ARG0-of (r2 / responsible-01)))))
            :op2 (s4 / suggest-01
                  :ARG1 (r3 / recommend-01
                        :ARG1 (a2 / and
                              :op1 (s5 / seek-01
                                    :ARG0 (p / process-02
                                          :mod (a3 / algorithm))
                                    :ARG1 (m / minimize-01
                                          :ARG0 p
                                          :ARG1 (p2 / potential
                                                :mod (f3 / fair-01
                                                      :polarity -
                                                      :ARG0 p))))
                              :op2 (m2 / maximize-01
                                    :ARG0 p
                                    :ARG1 (p3 / potential
                                          :mod (f4 / fair-01
                                                :ARG0 p))))))))

# ::snt A  series of real life case studies is used to illustrate how  this la ck of fairness can arise , before  explor ing the consequences that lack of fairness can have plus  the complexities inherent to trying to achieve fairness in any given societal context.
# File 78

(u / use-01
      :ARG1 (s / series
            :consist-of (s2 / study-01
                  :ARG1 (c / case-04
                        :ARG1 (l / life
                              :ARG1-of (r / real-04)))))
      :ARG2 (ii / illustrate-01
            :ARG0 s
            :ARG1 (p / possible-01
                  :ARG1 (a / arise-02
                        :ARG1 (l2 / law
                              :name (n / name
                                    :op1 "LA"
                                    :op2 "Ck")
                              :mod (t / this)
                              :topic (f / fairness))))
            :time (b / before
                  :op1 (e / explore-01
                        :ARG1 (a2 / and
                              :op1 (c2 / consequence-03
                                    :ARG1 (l3 / lack-01
                                          :ARG1 (f2 / fairness))
                                    :ARG1-of (p2 / possible-01))
                              :op2 (c3 / complexity
                                    :mod (ii2 / inherent)
                                    :domain (t2 / try-01
                                          :ARG1 (a3 / achieve-01
                                                :ARG1 (f3 / fairness)
                                                :location (c4 / context
                                                      :mod (s3 / society)
                                                      :ARG1-of (g / give-14)
                                                      :mod (a4 / any))))))))))

# ::snt The study  describes  ways in which lack of fairness in the outcomes of algorithmic systems might be caused by  developmental decision- making and design features embedded at different points in the lifecycle  of an algorithmic decision making model.
# File 78

(d / describe-01
      :ARG0 (s / study)
      :ARG1 (p / possible-01
            :ARG1 (c / cause-01
                  :ARG0 (a / and
                        :op1 (m / make-18
                              :ARG1 (d2 / decide-01)
                              :mod (d3 / develop-02))
                        :op2 (f / feature
                              :mod (d4 / design-01))
                        :ARG1-of (e / embed-01
                              :ARG2 (p2 / point
                                    :ARG1-of (d5 / differ-02)
                                    :part-of (l / lifecycle
                                          :poss (m2 / model
                                                :mod (d6 / decide-01)
                                                :mod (a2 / algorithm))))))
                  :ARG1 (l2 / lack-01
                        :ARG1 (f2 / fair-01
                              :ARG1 (o / outcome
                                    :poss (s2 / system
                                          :mod a2)))))))

# ::snt A connection is made between t he problem of fairness  and the tools of transparency and accountability, while highlighting  the value of responsible  research and innovation (RRI) approaches to pursuing fairness in algorithmic systems.
# File 78

(c / connect-01
      :ARG1 (p / problem
            :topic (f / fairness))
      :ARG2 (t / tool
            :purpose (a / and
                  :op1 (t2 / transparency)
                  :op2 (a2 / accountable-02)))
      :time (h / highlight-01
            :ARG1 (v / value-01
                  :ARG1 (a3 / approach-02
                        :ARG1 (p2 / pursue-01
                              :ARG1 (f2 / fairness
                                    :location (s / system
                                          :mod (a4 / algorithm))))
                        :ARG1-of (r / responsible-02)
                        :mod (r2 / research-01)
                        :mod (ii / innovate-01)))))

# ::snt Algorithmic Fairness: a guiding purpose for transparency and accountability  _________________ 10  3.4.1.
# File 78

(m / multi-sentence
      :snt1 (f / fairness
            :mod (a / algorithm)
            :ARG1-of (m2 / mean-01
                  :ARG2 (p / purpose
                        :ARG0-of (g / guide-01
                              :ARG2 (a2 / and
                                    :op1 (t / transparency)
                                    :op2 (a3 / accountable-02))))))
      :snt2 (h / have-li-91
            :ARG2 10
            :snt3-of m)
      :ARG2 "3.4.1")

# ::snt How can we understand algorithmic fairness?
# File 78

(p / possible-01
      :ARG1 (u / understand-01
            :ARG0 (w / we)
            :ARG1 (f / fairness
                  :mod (a / algorithm))
            :manner (a2 / amr-unknown)))

# ::snt Sources of unfairness  ____________________________________________________________ 20  3.4.3.
# File 78

(s / source-02
      :ARG1 (f / fairness
            :polarity -)
      :li 20
      :li 3.4)

# ::snt Opportunities and barriers towards achieving fairness in algorithmic systems  ______________ 21  3.4.4.
# File 78

(a / and
      :op1 (a2 / and
            :op1 (o / opportunity)
            :op2 (b / barrier)
            :direction (a3 / achieve-01
                  :ARG1 (f / fairness
                        :mod (s / system
                              :mod (a4 / algorithm)))))
      :op2 (a5 / and
            :op1 (p / publication
                  :ARG1-of (c / cite-01
                        :ARG2 21))
            :op2 (p2 / publication
                  :ARG1-of (c2 / cite-01
                        :ARG2 3.4))))

# ::snt Collateral implications of imposing Fairness, Accountability and/or Transparency requirements  __ 35  3.8.
# File 78

(ii / imply-01
      :ARG0 (ii2 / impose-01
            :ARG1 (r / require-01
                  :ARG1 (a / and-or
                        :op1 (f / fairness)
                        :op2 (a2 / accountable-02)
                        :op3 (t / transparency))))
      :mod (c / collateral)
      :ARG1-of (d / describe-01
            :ARG0 a
            :op1 (c2 / cite-01
                  :ARG2 35)
            :op2 (c3 / cite-01
                  :ARG2 3.8)))

# ::snt They require decisions  —  made by the appropriate stakeholders —  that involve  often difficult and particular questions of social goals and values, rights, models of fairness,  compensatory structures,  risk tolerance, etc.
# File 78

(r / require-01
      :ARG0 (t / they)
      :ARG1 (d / decide-01
            :ARG1-of (m / make-01
                  :ARG0 (s / stake
                        :ARG1-of (a / appropriate-02)))
            :ARG0-of (ii / involve-01
                  :ARG1 (q / question-01
                        :ARG1 (a2 / and
                              :op1 (a3 / and
                                    :op1 (g / goal)
                                    :op2 (v / value)
                                    :mod (s2 / society))
                              :op2 (r2 / right-05)
                              :op3 (m2 / model-01
                                    :ARG1 (f / fairness))
                              :op4 (s3 / structure-01
                                    :ARG3 (c / compensate-01))
                              :op5 (t2 / tolerate-01
                                    :ARG1 (r3 / risk-01))
                              :op6 (e / et-cetera))
                        :mod (d2 / difficult
                              :frequency (o / often))
                        :mod (p / particular)))))

# ::snt Objective  Beyond providing an up- to-date review of current and potential governance frameworks for  algorithmic accountability and transparency, the report aims to provide an understanding of the  technical challenges and solutions for algorithmic transparency, clarify the relationship between  accountability/transparency and fairness, and provide recommendations for an algorithmic impact  assessment metric for assessin g the degree of regulatory scrutiny of an algorithmic system that  would be appropri ate/necessary for a particular context of use.
# File 78

(a / aim-01
      :ARG0 (r / report)
      :ARG1 (a2 / and
            :op1 (p / provide-01
                  :ARG0 r
                  :ARG1 (u / understand-01
                        :ARG1 (a3 / and
                              :op1 (c / challenge-01
                                    :mod (t / technical))
                              :op2 (s / solve-01
                                    :ARG2 (t2 / transparency
                                          :mod (a4 / algorithm))))))
            :op2 (c2 / clarify-10
                  :ARG0 r
                  :ARG1 (r2 / relation-03
                        :ARG0 (a5 / accountability)
                        :ARG1 t2)
                  :ARG2 (f / fairness)))
      :op3 (p2 / provide-01
            :ARG0 r
            :ARG1 (t3 / thing
                  :ARG3-of (r3 / recommend-01)
                  :instrument-of (a6 / assess-01
                        :ARG1 (d / degree
                              :degree-of (s2 / scrutinize-01
                                    :ARG0 (r4 / regulate-01)
                                    :ARG1 (s3 / system
                                          :mod (a7 / algorithm))
                                    :ARG1-of (a8 / appropriate-02)
                                    :ARG1-of (n / need-01)
                                    :purpose (c3 / context
                                          :mod (p3 / particular)
                                          :mod (u2 / use-01)))))))
      :mod (b / beyond
            :op1 (p4 / provide-01
                  :ARG0 r
                  :ARG1 (r5 / review-01
                        :ARG1 (a9 / and
                              :op1 (f2 / framework
                                    :mod (g / govern-01)
                                    :time (c4 / current))
                              :op2 (f3 / framework
                                    :mod (g2 / govern-01)
                                    :mod (p5 / potential))
                              :purpose (a10 / and
                                    :op1 a5
                                    :op2 t2))
                        :ARG1-of (u3 / update-01))))
      :mod (o / objective))

# ::snt The underlying motivation  for a governance framework for algorithmic transparency and accountability is explored further  through a review of issues regarding algorithmic fairness.
# File 78

(e / explore-01
      :ARG1 (t / thing
            :ARG0-of (m / motivate-01
                  :ARG2 (f / framework
                        :mod (g / govern-01)
                        :purpose (a / and
                              :op1 (t2 / transparency
                                    :mod (a2 / algorithm))
                              :op2 (a3 / accountable-02
                                    :mod (a4 / algorithm)))))
            :ARG0-of (u / underlie-01))
      :degree (f2 / further)
      :manner (r / review-01
            :ARG1 (ii / issue-02
                  :ARG0 (f3 / fairness
                        :mod (a5 / algorithm)))))

# ::snt It can mean: access  upon  request to the public or authorised people; public posting of information; direct inspection of  internal processes; the results of the manufacturer’s or operator’s tests of the system for accuracy  and fairness; delivery of complete subsystems and their data for testing by authorised people, with  the results reported to the public or to regulatory bodies; access to computer scientists and  managers to explain algorithmic or operational processes.
# File 78

(p / possible-01
      :ARG1 (m / mean-01
            :ARG1 (ii / it)
            :ARG2 (a / and
                  :op1 (a2 / access-01
                        :time (u / upon
                              :op1 (r / request-01
                                    :ARG2 (o / or
                                          :op1 (p2 / public)
                                          :op2 (p3 / person
                                                :ARG1-of (a3 / authorize-01))))))
                  :op2 (p4 / post-01
                        :ARG1 (ii2 / information)
                        :ARG2 (p5 / public))
                  :op3 (ii3 / inspect-01
                        :ARG1 (p6 / process-02
                              :ARG1-of (ii4 / internal-02))
                        :ARG1-of (d / direct-02))
                  :op4 (r2 / result-01
                        :ARG1 (t / test-01
                              :ARG0 (o2 / or
                                    :op1 (p7 / person
                                          :ARG0-of (m2 / manufacture-01))
                                    :op2 (p8 / person
                                          :ARG0-of (o3 / operate-01)))
                              :ARG1 (s / system)
                              :ARG2 (a4 / and
                                    :op1 (a5 / accuracy)
                                    :op2 (f / fairness))))
                  :op5 (d2 / deliver-01
                        :ARG1 (a6 / and
                              :op1 (s2 / subsystem
                                    :ARG1-of (c / complete-02))
                              :op2 (d3 / data
                                    :poss s2))
                        :ARG2 (t2 / test-01
                              :ARG0 (p9 / person
                                    :ARG1-of (a7 / authorize-01))
                              :ARG1 a6))
                  :op6 (r3 / report-01
                        :ARG1 (r4 / result-01)
                        :ARG2 (o4 / or
                              :op1 (p10 / public)
                              :op2 (b / body
                                    :ARG0-of (r5 / regulate-01))))
                  :op7 (a8 / access-01
                        :ARG1 (a9 / and
                              :op1 (s3 / scientist
                                    :mod (c2 / computer))
                              :op2 (p11 / person
                                    :ARG0-of (m3 / manage-01)))
                        :purpose (e / explain-01
                              :ARG0 a9
                              :ARG1 (p12 / process-02
                                    :mod o3))))))

# ::snt A governance framework for algorithmic accountability and transparency      7 ● Check for bias in the data and algorithms that affect s the fairness of the system.
# File 78

(m / multi-sentence
      :snt1 (f / framework
            :purpose (g / govern-01)
            :purpose (a / and
                  :op1 (a2 / accountable-02
                        :ARG0 (a3 / algorithm))
                  :op2 (t / transparency
                        :mod a3)))
      :snt2 (c / check-01
            :mode imperative
            :ARG0 (y / you)
            :ARG1 (a4 / and
                  :op1 (d / data)
                  :op2 (a5 / algorithm)
                  :ARG0-of (a6 / affect-01
                        :ARG1 (f2 / fair-01
                              :ARG1 (s / system))))))

# ::snt Algorithmic Fairness: a guiding purpose for transparency and  accountability   Fairness is an immensely complex concept with different, sometimes competing, definitions.
# File 78

(m / multi-sentence
      :snt1 (h / have-purpose-91
            :ARG1 (f / fairness
                  :mod (a / algorithm))
            :ARG2 (a2 / and
                  :op1 (t / transparency)
                  :op2 (a3 / accountable-02))
            :ARG0-of (g / guide-01))
      :snt2 (c / concept
            :mod (c2 / complex
                  :degree (ii / immense))
            :domain (f2 / fairness)
            :ARG0-of (h2 / have-03
                  :ARG1 (d / define-01
                        :ARG1-of (d2 / differ-02)
                        :ARG0-of (c3 / compete-01
                              :frequency (s / sometimes))))))

# ::snt In  contrast to transparency and accountability, we do not suggest that fairness is to be considered as  a tool to facilitate best practice in algorithmic systems.
# File 78

(c / contrast-01
      :ARG1 (s / suggest-01
            :polarity -
            :ARG0 (w / we)
            :ARG1 (c2 / consider-02
                  :ARG1 (f / fairness)
                  :ARG2 (t / tool
                        :purpose (f2 / facilitate-01
                              :ARG0 f
                              :ARG1 (p / practice-01
                                    :ARG1 (s2 / system
                                          :mod (a / algorithm))
                                    :ARG1-of (h / have-degree-91
                                          :ARG2 (g / good-02
                                                :ARG1 p)
                                          :ARG3 (m / most)))))))
      :ARG2 (a2 / and
            :op1 (t2 / transparency)
            :op2 (a3 / accountable-02)))

# ::snt In this section we emphasise the importance of assessing and questioning the fairness of  algorithmic systems used for decision -making.
# File 78

(e / emphasize-01
      :ARG0 (w / we)
      :ARG1 (ii / important-01
            :ARG1 (a / and
                  :op1 (a2 / assess-01
                        :ARG1 (f / fair-01
                              :ARG1 (s / system
                                    :mod (a3 / algorithm)
                                    :ARG1-of (u / use-01
                                          :ARG2 (m / make-18
                                                :ARG1 (d / decide-01))))))
                  :op2 (q / question-03
                        :ARG1 f)))
      :location (s2 / section
            :mod (t / this)))

# ::snt We discuss fairness through the lens of social justice  and highlight the potential for algorithmic systems to systematically disadvantage, or even  discriminate against, different social groups and demographics.
# File 78

(a / and
      :op1 (d / discuss-01
            :ARG0 (w / we)
            :ARG1 (f / fairness)
            :manner (t / through
                  :op1 (j / justice
                        :mod (s / social))))
      :op2 (h / highlight-01
            :ARG0 w
            :ARG1 (p / potential
                  :domain (o / or
                        :op1 (d2 / disadvantage
                              :manner (s2 / systematic)
                              :domain (s3 / system
                                    :mod (a2 / algorithm)))
                        :op2 (d3 / discriminate-02
                              :ARG0 s3
                              :ARG1 (a3 / and
                                    :op1 (g / group
                                          :mod s)
                                    :op2 (d4 / demographics)
                                    :ARG1-of (d5 / differ-02))
                              :mod (e / even))))))

# ::snt We draw on a series o f real life case  studies to illustrate how this lack of fairness can arise and then go on to explore the consequences  lack of fairness can have plus the complexities inherent to trying to achieve fairness in any given  societal context.
# File 78

(a / and
      :op1 (d / draw-02
            :ARG0 (w / we)
            :ARG2 (s / series
                  :consist-of (s2 / study-01
                        :ARG1 (c / case-04
                              :ARG1 (l / life
                                    :ARG1-of (r / real-04)))))
            :purpose (ii / illustrate-01
                  :ARG0 w
                  :ARG1 (p / possible-01
                        :ARG1 (a2 / arise-02
                              :ARG1 (l2 / lack-01
                                    :ARG1 (f / fairness)
                                    :mod (t / this))))))
      :op2 (g / go-on-15
            :ARG0 w
            :ARG1 (e / explore-01
                  :ARG0 w
                  :ARG1 (a3 / and
                        :op1 (c2 / consequence-03
                              :ARG1 l2
                              :ARG1-of (p2 / possible-01))
                        :op2 (c3 / complexity
                              :mod (ii2 / inherent)
                              :domain (t2 / try-01
                                    :ARG1 (a4 / achieve-01
                                          :ARG1 (f2 / fairness)
                                          :location (c4 / context
                                                :mod (s3 / society)
                                                :ARG1-of (g2 / give-14)
                                                :mod (a5 / any)))))))
            :time (t3 / then)))

# ::snt We describe the ways  in which lack of fairness in the outcomes of algorithmic  systems might be caused by developmental decision- making and design features embedded at  different points in the lifecycle of an AI model.
# File 78

(d / describe-01
      :ARG0 (w / we)
      :ARG1 (p / possible-01
            :ARG1 (c / cause-01
                  :ARG0 (a / and
                        :op1 (m / make-18
                              :ARG1 (d2 / decide-01)
                              :mod (d3 / develop-02))
                        :op2 (f / feature
                              :mod (d4 / design-01))
                        :ARG1-of (e / embed-01
                              :ARG2 (p2 / point
                                    :ARG1-of (d5 / differ-02)
                                    :part-of (l / lifecycle
                                          :poss (m2 / model
                                                :mod (ii / intelligent-01
                                                      :mod (a2 / artificial)))))))
                  :ARG1 (l2 / lack-01
                        :ARG1 (f2 / fair-01
                              :ARG1 (o / outcome
                                    :poss (s / system
                                          :mod (a3 / algorithmic))))))))

# ::snt We connect the problem of fairness to the tools of  transpar ency and accountability and also highlight the value of responsible research and innovation  (RRI) [35] approaches to pursuing fairness in algorithmic systems.
# File 78

(a / and
      :op1 (c / connect-01
            :ARG0 (w / we)
            :ARG1 (p / problem
                  :topic (f / fair-01))
            :ARG2 (t / tool
                  :mod (a2 / and
                        :op1 (a3 / accountable-02)
                        :op2 (t2 / transparency))))
      :op2 (h / highlight-01
            :ARG0 w
            :ARG1 (v / value-01
                  :ARG1 (a4 / approach-02
                        :ARG1 (p2 / pursue-01
                              :ARG1 (f2 / fair-01
                                    :location (s / system
                                          :mod (a5 / algorithm))))
                        :ARG1-of (d / describe-01
                              :ARG0 (p3 / publication
                                    :ARG1-of (c2 / cite-01
                                          :ARG2 35)))
                        :mod (r / research-01
                              :ARG1-of (r2 / responsible-02))
                        :mod (ii / innovate-01)))
            :mod (a6 / also)))

# ::snt How can we understand algorithmic fairness?
# File 78

(p / possible-01
      :ARG1 (u / understand-01
            :ARG0 (w / we)
            :ARG1 (f / fairness
                  :mod (a / algorithm))
            :manner (a2 / amr-unknown)))

# ::snt Fairness is an everyday concept that all of us are a ble to understand at an intuitive level — at least,  we usually feel confident about recognizing unfair situations, which, does not mean we have or  share a coherent idea of fairness.
# File 78

(a / and
      :op1 (c / concept
            :domain (f / fairness)
            :frequency (r / rate-entity-91
                  :ARG3 (t / temporal-quantity
                        :quant 1
                        :unit (d / day)))
            :ARG1-of (u / understand-01
                  :ARG0 (w / we
                        :mod (a2 / all))
                  :manner (l / level
                        :mod (ii / intuitive))))
      :op2 (f2 / feel-01
            :ARG0 w
            :ARG1 (c2 / confident-01
                  :ARG1 w
                  :ARG2 (r2 / recognize-02
                        :ARG0 w
                        :ARG1 (s / situation
                              :ARG1-of (f3 / fair-01
                                    :polarity -))))
            :mod (u2 / usual)
            :mod (a3 / at-least)
            :ARG1-of (m / mean-01
                  :polarity -
                  :ARG2 (o / or
                        :op1 (h / have-03
                              :ARG0 w
                              :ARG1 (ii2 / idea
                                    :topic (f4 / fairness)
                                    :ARG1-of (c3 / cohere-01)))
                        :op2 (s2 / share-01
                              :ARG0 w
                              :ARG1 ii2)))))

# ::snt Fairness is an everyday concept that all of us are a ble to understand at an intuitive level — at least,  we usually feel confident about recognizing unfair situations, which, does not mean we have or  share a coherent idea of fairness.
# File 78

(a / and
      :op1 (c / concept
            :domain (f / fairness)
            :frequency (r / rate-entity-91
                  :ARG3 (t / temporal-quantity
                        :quant 1
                        :unit (d / day)))
            :ARG1-of (u / understand-01
                  :ARG0 (w / we
                        :mod (a2 / all))
                  :manner (l / level
                        :mod (ii / intuitive))))
      :op2 (f2 / feel-01
            :ARG0 w
            :ARG1 (c2 / confident-01
                  :ARG1 w
                  :ARG2 (r2 / recognize-02
                        :ARG0 w
                        :ARG1 (s / situation
                              :ARG1-of (f3 / fair-01
                                    :polarity -))))
            :mod (u2 / usual)
            :mod (a3 / at-least)
            :ARG1-of (m / mean-01
                  :polarity -
                  :ARG2 (o / or
                        :op1 (h / have-03
                              :ARG0 w
                              :ARG1 (ii2 / idea
                                    :topic (f4 / fairness)
                                    :ARG1-of (c3 / cohere-01)))
                        :op2 (s2 / share-01
                              :ARG0 w
                              :ARG1 ii2)))))

# ::snt Fairness turns out to be a multi -faceted, and inherently complex  concept.
# File 78

(t / turn-out-11
      :ARG1 (f / fairness)
      :ARG2 (c / concept
            :mod (c2 / complex
                  :mod (ii / inherent))
            :mod (f2 / facet
                  :quant (m / multiple))))

# ::snt Fairness reflects the appreciation of a situation based on a set of social  values, such as promoting equality in society [36].
# File 78

(r / reflect-01
      :ARG1 (f / fairness)
      :ARG2 (a / appreciate-02
            :ARG1 (s / situation
                  :ARG1-of (b / base-02
                        :ARG2 (s2 / set
                              :consist-of (v / value
                                    :mod (s3 / society)
                                    :example (p / promote-02
                                          :ARG1 (e / equal-01)
                                          :ARG2 (s4 / society)))))))
      :ARG1-of (d / describe-01
            :ARG0 (p2 / publication
                  :ARG1-of (c / cite-01
                        :ARG2 36))))

# ::snt The assessment of fairness depends on facts,  events, and goals, and therefore has to be understood as situation or task -specific and necessarily  addressed within the scope of a practice.
# File 78

(c / cause-01
      :ARG0 (d / depend-01
            :ARG0 (a / assess-01
                  :ARG1 (f / fair-01))
            :ARG1 (a2 / and
                  :op1 (f2 / fact)
                  :op2 (e / event)
                  :op3 (g / goal)))
      :ARG1 (o / obligate-01
            :ARG2 (u / understand-01
                  :ARG1 a
                  :ARG2 (a3 / and
                        :op1 (s / specific-02
                              :ARG1 (o2 / or
                                    :op1 (s2 / situation)
                                    :op2 (t / task)))
                        :op2 (a4 / address-02
                              :ARG1 o2
                              :ARG1-of (n / need-01)
                              :location (s3 / scope
                                    :poss (p / practice-01)))))))

# ::snt Therefore, for the purposes of this report ' fairness '  appreciates the social effect s of algorithms in sociotechnical structures, while considering how case specific actions and consequences fit into broad social values.
# File 78

(c / cause-01
      :ARG1 (a / appreciate-02
            :ARG1 (a2 / affect-01
                  :ARG0 (a3 / algorithm
                        :part-of (s / structure
                              :mod (s2 / society)))
                  :ARG1 (s3 / society))
            :time (c2 / consider-02
                  :ARG1 (f / fit-01
                        :ARG1 (a4 / and
                              :op1 (a5 / act-02)
                              :op2 (c3 / consequence-03)
                              :ARG1-of (s4 / specific-02))
                        :ARG2 (v / value
                              :ARG1-of (b / broad-02)
                              :mod (s5 / society))))
            :purpose (r / report-01
                  :mod (t / this))))

# ::snt Given the importance of  understanding fairness within context, we present a series of relevant case studies of recent  controversies regarding the ‘fair’ operation of algorithms in contemporary society.
# File 78

(p / present-01
      :ARG0 (w / we)
      :ARG1 (s / series
            :consist-of (s2 / study-01
                  :ARG1 (c / controversy
                        :time (r / recent)
                        :topic (o / operate-01
                              :ARG1 (a / algorithm)
                              :ARG1-of (f / fair-01)
                              :location (s3 / society
                                    :mod (c2 / contemporary))))
                  :ARG1-of (r2 / relevant-01)
                  :mod (c3 / case)))
      :ARG1-of (c4 / cause-01
            :ARG0 (ii / important-01
                  :ARG1 (u / understand-01
                        :ARG1 (f2 / fairness)
                        :location (c5 / context)))))

# ::snt We then use  these cases to highlight the core, general issues that require careful attention in discussions of  fairness in algorithmic systems.
# File 78

(u / use-01
      :ARG0 (w / we)
      :ARG1 (c / case-04
            :mod (t / this))
      :ARG2 (h / highlight-01
            :ARG0 w
            :ARG1 (ii / issue-02
                  :ARG1-of (c2 / core-02)
                  :ARG1-of (g / general-02)
                  :ARG0-of (r / require-01
                        :ARG1 (a / attend-02
                              :ARG1 ii
                              :manner (c3 / careful)
                              :subevent-of (d / discuss-01
                                    :ARG1 (f / fair-01
                                          :location (s / system
                                                :mod (a2 / algorithm))))))))
      :time (t2 / then))

# ::snt The concept of fairness in the context of algorithmic implementations appears as a balance between  the mutual interests, needs and values of different stakeholders affected by the algorithmic  decision.
# File 78

(a / appear-02
      :ARG1 (c / concept
            :topic (f / fair-01))
      :ARG2 (b / balance-01
            :ARG1 (a2 / and
                  :op1 (ii / interest-01
                        :ARG1 (s / stake
                              :ARG1-of (a3 / affect-01
                                    :ARG0 (d / decide-01
                                          :mod (a4 / algorithm)))
                              :ARG1-of (d2 / differ-02))
                        :mod (m / mutual))
                  :op2 (n / need-01
                        :ARG0 s
                        :mod m)
                  :op3 (v / value-02
                        :ARG0 s
                        :mod m)))
      :location (c2 / context
            :topic (ii2 / implement-01
                  :ARG1 a4)))

# ::snt Therefore, we also understand fairness within the lens  of social justice,  as opposed to individual cases in which there is a perceived imbalance of goods or penalties (' Why  did she get more cookies than me?
# File 78

(c / cause-01
      :ARG1 (u / understand-01
            :ARG0 (w / we)
            :ARG1 (f / fairness)
            :mod (a / also)
            :manner (l / lens
                  :mod (j / justice
                        :mod (s / social)))
            :ARG1-of (ii / instead-of-91
                  :ARG2 (c2 / case-04
                        :ARG1 (b / balance-01
                              :polarity -
                              :ARG1 (o / or
                                    :op1 (g / good)
                                    :op2 (p / penalty))
                              :ARG1-of (p2 / perceive-01))
                        :mod (ii2 / individual)
                        :example (g2 / get-01
                              :ARG0 (s2 / she)
                              :ARG1 (c3 / cookie
                                    :ARG1-of (h / have-quant-91
                                          :ARG3 (m / more)
                                          :ARG4 (ii3 / i)))
                              :ARG1-of (c4 / cause-01
                                    :ARG0 (a2 / amr-unknown)))))))

# ::snt Since then  much debate has occurred over what definitions of fairness can be applied to assess a lgorithms of  this kind (e.g.
# File 78

(d / debate-01
      :ARG1 (t / thing
            :ARG2-of (d2 / define-01
                  :ARG1 (f / fair-01))
            :ARG1-of (a / apply-02
                  :ARG2 (a2 / assess-01
                        :ARG1 (a3 / algorithm
                              :mod (k / kind
                                    :mod (t2 / this))
                              :example t)))
            :ARG1-of (p / possible-01))
      :time (s / since
            :op1 (t3 / then))
      :quant (m / much))

# ::snt (These i deas of fairness correspond roughly to ' Equal Oppor tunity '  algorithmic fairness [98 ] and 'Equal Accuracy ' fairness [99 ]).
# File 78

(c / correspond-02
      :ARG1 (t / thing
            :mod (t2 / this)
            :ARG2-of (e / estimate-01
                  :ARG1 (f / fairness)))
      :ARG2 (a / and
            :op1 (f2 / fairness
                  :mod (e2 / equal-01)
                  :mod (o / oppose-01)
                  :ARG1-of (d / describe-01
                        :ARG0 (p / publication
                              :ARG1-of (c2 / cite-01
                                    :ARG2 98)))
                  :mod (a2 / algorithm))
            :op2 (f3 / fairness
                  :mod (a3 / accurate
                        :ARG1-of (e3 / equal-01))
                  :ARG1-of (d2 / describe-01
                        :ARG0 (p2 / publication
                              :ARG1-of (c3 / cite-01
                                    :ARG2 99)))))
      :ARG1-of (r / rough-04))

# ::snt Commentary: understanding unfairness in algorithmic systems   The case studies provide a useful means to understand the social effects of algorithmic systems for  decision -making.
# File 78

(m / multi-sentence
      :snt1 (c / comment-01
            :topic (u / understand-01
                  :ARG1 (f / fairness
                        :polarity -
                        :source (s / system
                              :mod (a / algorithm)))))
      :snt2 (p / provide-01
            :ARG0 (s2 / study-01
                  :ARG1 (c2 / case))
            :ARG1 (m2 / means
                  :ARG1-of (u2 / useful-05
                        :ARG2 (u3 / understand-01
                              :ARG1 (a2 / affect-01
                                    :ARG0 (s3 / system
                                          :mod (a3 / algorithm)
                                          :purpose (m3 / make-01
                                                :ARG1 (d / decide-01)))
                                    :ARG1 (s4 / society)))))))

# ::snt Returning to the understanding of fairness outlined above, we can observe that these detrimental  consequences might be considered unfai r. The case studies illustrate that algorithmic processes can  sometimes have social effects that do not promote equality and do not align with fundamental  social values.
# File 78

(m / multi-sentence
      :snt1 (p / possible-01
            :ARG1 (o / observe-01
                  :ARG0 (w / we)
                  :ARG1 (p2 / possible-01
                        :ARG1 (c / consider-01
                              :ARG1 (n / negative-02
                                    :ARG1 (c2 / consequence-03
                                          :mod (t / this)
                                          :ARG0-of (h / harm-01)))))
                  :direction (r / return-01
                        :ARG4 (u / understand-01
                              :ARG1 (f / fairness)
                              :ARG1-of (o2 / outline-01
                                    :location (a / above))))))
      :snt2 (ii / illustrate-01
            :ARG0 (s / study-01
                  :ARG1 (c3 / case))
            :ARG1 (p3 / possible-01
                  :ARG1 (a2 / affect-01
                        :ARG0 (p4 / process-02
                              :mod (a3 / algorithm))
                        :ARG1 (s2 / society)
                        :ARG2 (a4 / and
                              :op1 (p5 / promote-02
                                    :polarity -
                                    :ARG0 p4
                                    :ARG1 (e / equal-01))
                              :op2 (a5 / align-01
                                    :polarity -
                                    :ARG1 p4
                                    :ARG2 (v / value
                                          :mod s2
                                          :mod (f2 / fundamental))))
                        :frequency (s3 / sometimes)))))

# ::snt Each of these values is closely entwined with understandings of fairness and social justice.
# File 78

(e / entwine-01
      :ARG1 (v / value
            :mod (t / this)
            :mod (e2 / each))
      :ARG2 (u / understand-01
            :ARG1 (a / and
                  :op1 (f / fairness)
                  :op2 (j / justice
                        :mod (s / social))))
      :ARG1-of (c / close-10))

# ::snt Sources of unfairness  Unfairness in algorithmic systems might result from a number of sources.
# File 78

(m / multi-sentence
      :snt1 (s / source-01
            :ARG1 (f / fairness
                  :polarity -))
      :snt2 (p / possible-01
            :ARG1 (r / result-01
                  :ARG1 (s2 / source-01
                        :quant (n / number))
                  :ARG2 (f2 / fairness
                        :polarity -
                        :mod (s3 / system
                              :mod (a / algorithm))))))

# ::snt In this case unfairness  results not from the design of the model itself but the way in which it is applied.
# File 78

(r / result-01
      :ARG1 (f / fair-01
            :polarity -)
      :ARG2 (c / contrast-01
            :ARG1 (d / design-01
                  :polarity -
                  :ARG1 (m / model))
            :ARG2 (w / way
                  :manner-of (a / apply-02
                        :ARG1 m)))
      :prep-in (c2 / case-04
            :ARG1 (t / this)))

# ::snt Similarly, sentencing AI might be used to definitively determine sentences, to recommend  sentences, or to check a judge’s independent decision for bias; the gravity of the unfairness is not  embedded in the AI but in its use and goals.
# File 78

(m / multi-sentence
      :snt1 (p / possible-01
            :ARG1 (u / use-01
                  :ARG1 (ii / intelligent-01
                        :mod (a / artificial))
                  :ARG2 (a2 / and
                        :op1 (d / determine-01
                              :ARG1 (s / sentence-01)
                              :manner (d2 / definitive))
                        :op2 (r / recommend-01
                              :ARG1 (s2 / sentence-01))
                        :op3 (c / check-01
                              :ARG1 (d3 / decide-01
                                    :ARG0 (p2 / person
                                          :ARG0-of (j / judge-01))
                                    :ARG0-of (d4 / depend-01
                                          :polarity -))
                              :ARG2 (b / bias-01))))
            :ARG1-of (r2 / resemble-01))
      :snt2 (c2 / contrast-01
            :ARG1 (e / embed-01
                  :polarity -
                  :ARG1 (g / gravity
                        :topic (f / fairness
                              :polarity -))
                  :ARG2 (ii2 / intelligent-01
                        :mod a))
            :ARG2 (e2 / embed-01
                  :ARG1 g
                  :ARG2 (a3 / and
                        :op1 (u2 / use-01
                              :ARG1 ii2)
                        :op2 (g2 / goal
                              :poss ii2)))))

# ::snt As we can see, the sources of unfairness identified can play a crucial part in reinforcing and  perpetuating exis ting discrimination in society, affecting access to available resources and  opportunities.
# File 78

(p / possible-01
      :ARG1 (s / see-01
            :ARG0 (w / we)
            :ARG1 (p2 / possible-01
                  :ARG1 (p3 / play-02
                        :ARG0 (s2 / source-02
                              :ARG1 (f / fairness
                                    :polarity -)
                              :ARG1-of (ii / identify-01))
                        :ARG1 (p4 / part
                              :mod (c / crucial)
                              :ARG0-of (r / reinforce-01
                                    :ARG1 (d / discriminate-02
                                          :ARG0-of (a / affect-01
                                                :ARG1 (a2 / access-01
                                                      :ARG1 (a3 / and
                                                            :op1 (r2 / resource)
                                                            :op2 (o / opportunity)
                                                            :ARG2-of (a4 / available-02))))))
                              :ARG0-of (p5 / perpetuate-01
                                    :ARG1 d))))))

# ::snt Opportunities and barriers towards achieving fairness in algorithmic  systems   Just as controversies over ‘unfair’ and ‘socially unjust’ algorithmic systems have been the focus of  much debate in academic, policy and public discourses, attention has also been given to potential  solutions.
# File 78

(m / multi-sentence
      :snt1 (a / and
            :op1 (o / opportunity)
            :op2 (b / barrier)
            :direction (a2 / achieve-01
                  :ARG1 (f / fair-01
                        :ARG1 (s / system
                              :mod (a3 / algorithm)))))
      :snt2 (a4 / attend-02
            :ARG1 (t / thing
                  :ARG2-of (s2 / solve-01)
                  :mod (p / potential))
            :mod (a5 / also)
            :ARG1-of (c / contrast-01
                  :ARG2 (f2 / focus-01
                        :ARG0 (d / debate-01
                              :ARG0 (a6 / and
                                    :op1 (a7 / academia)
                                    :op2 (p2 / policy-01)
                                    :op3 (d2 / discourse-01
                                          :ARG1-of (p3 / public-02)))
                              :mod (m2 / much))
                        :ARG1 (c2 / controversy
                              :topic (a8 / and
                                    :op1 (f3 / fair-01
                                          :polarity -
                                          :ARG1 (s3 / system
                                                :mod (a9 / algorithm)))
                                    :op2 (j / just-02
                                          :polarity -
                                          :ARG1 s3
                                          :manner (s4 / social))))))))

# ::snt Various means to achieve fairness and social justice in algorithms have been suggested.
# File 78

(s / suggest-01
      :ARG1 (m / means
            :mod (v / various)
            :instrument-of (a / achieve-01
                  :ARG1 (a2 / and
                        :op1 (f / fairness)
                        :op2 (j / justice
                              :mod (s2 / social)))
                  :instrument (a3 / algorithm))))

# ::snt How to understand fairness?
# File 78

(u / understand-01
      :ARG1 (f / fair-01)
      :manner (a / amr-unknown))

# ::snt As stated at the start of this section, fairness is a nuanced and  inconsistent concept open to different interpretations.
# File 78

(c / concept
      :ARG1-of (o / open-05
            :ARG2 (ii / interpret-01
                  :ARG1 c
                  :ARG1-of (d / differ-02)))
      :ARG1-of (n / nuance-01)
      :ARG1-of (c2 / consistent-02
            :polarity -)
      :domain (f / fairness)
      :ARG1-of (s / state-01
            :time (s2 / start-01
                  :ARG1 (s3 / section
                        :mod (t / this)))))

# ::snt This can make overall conclusions and  agreements about accomplishing fairness difficult to reach.
# File 78

(p / possible-01
      :ARG1 (m / make-02
            :ARG0 (t / this)
            :ARG1 (d / difficult
                  :domain (r / reach-01
                        :ARG1 (a / and
                              :op1 (c / conclude-01
                                    :mod (o / overall))
                              :op2 (a2 / agree-01
                                    :topic (a3 / accomplish-01
                                          :ARG1 (f / fairness))))))))

# ::snt However, selection differences occur because participants draw on different understandings of  what constitutes fairness in that instance.
# File 78

(c / contrast-01
      :ARG2 (c2 / cause-01
            :ARG0 (d / draw-02
                  :ARG0 (p / person
                        :ARG0-of (p2 / participate-01))
                  :ARG1 (u / understand-01
                        :ARG1 (c3 / constitute-01
                              :ARG0 (t / thing)
                              :ARG1 (f / fairness)
                              :time (ii / instance
                                    :mod (t2 / that)))
                        :ARG1-of (d2 / differ-02)))
            :ARG1 (d3 / differ-02
                  :ARG3 (s / select-01))))

# ::snt [111]  observe that it can be impossible to fully  accommodate different concepts of fairness  simultaneously because they are competing rather than compatible.
# File 78

(o / observe-01
      :ARG1 (p / possible-01
            :polarity -
            :ARG1 (a / accommodate-01
                  :ARG1 (c / concept
                        :topic (f / fair-01)
                        :ARG1-of (d / differ-02))
                  :extent (f2 / full)
                  :mod (s / simultaneous))
            :ARG1-of (c2 / cause-01
                  :ARG0 (c3 / compete-01
                        :ARG0 (t / they)
                        :ARG1-of (ii / instead-of-91
                              :ARG2 (c4 / compatible
                                    :domain t)))))
      :ARG1-of (c5 / cite-01
            :ARG2 111))

# ::snt They conclude that a way forward is  to consider trade -offs that  can be made between notions of fairness.
# File 78

(c / conclude-01
      :ARG0 (t / they)
      :ARG1 (w / way
            :direction (f / forward)
            :domain (c2 / consider-02
                  :ARG1 (t2 / tradeoff-01
                        :ARG2 (n / notion
                              :topic (f2 / fair-01))
                        :ARG1-of (p / possible-01)))))

# ::snt COMPAS provides a highly useful case study to consider the complexities around  what constitutes fairness.
# File 78

(p / provide-01
      :ARG0 (o / organization
            :name (n / name
                  :op1 "COMPAS"))
      :ARG1 (s / study
            :mod (c / case)
            :ARG1-of (u / useful-05
                  :ARG1-of (h / high-02)))
      :purpose (c2 / consider-02
            :ARG0 o
            :ARG1 (c3 / complexity
                  :topic (c4 / constitute-01
                        :ARG0 (t / thing)
                        :ARG1 (f / fair-01)))))

# ::snt Each  argument draws on different conceptualisations of fairness: unequally wrong vs equally right.
# File 78

(d / draw-02
      :ARG0 (t / thing
            :ARG1-of (a / argue-01)
            :mod (e / each))
      :ARG2 (c / conceptualize-01
            :ARG1 (f / fairness)
            :ARG1-of (d2 / differ-02)
            :ARG1-of (m / mean-01
                  :ARG2 (v / versus
                        :op1 (w / wrong-04
                              :ARG1-of (e2 / equal-01
                                    :polarity -))
                        :op2 (r / right-06
                              :ARG1-of (e3 / equal-01))))))

# ::snt In her work on recidivism prediction instruments (RPIs) Alexandra Chouldechova [ 112] also draws  on the COMPAS case and makes a distinction between the social and ethical conceptualisation of  fairness and the statistical concepts underpinning the operation of an algorithm.
# File 78

(a / and
      :op1 (d / draw-02
            :ARG0 (p / person
                  :name (n / name
                        :op1 "Alexandra"
                        :op2 "Chouldechova")
                  :ARG1-of (d2 / describe-01
                        :ARG0 (p2 / publication
                              :ARG1-of (c / cite-01
                                    :ARG2 112))))
            :ARG2 (c2 / case-04
                  :ARG1 (t / thing
                        :name (n2 / name
                              :op1 "Compass")))
            :mod (a2 / also))
      :op2 (d3 / distinguish-01
            :ARG0 p
            :ARG1 (c3 / conceptualize-01
                  :ARG1 (f / fairness)
                  :mod (s / society)
                  :mod (e / ethics))
            :ARG2 (c4 / concept
                  :mod (s2 / statistics)
                  :ARG0-of (u / underpin-01
                        :ARG1 (o / operate-01
                              :ARG1 (a3 / algorithm)))))
      :topic (w / work-01
            :ARG0 p
            :ARG1 (ii / instrument
                  :ARG3-of (p3 / predict-01
                        :ARG1 (r / recidivism))
                  :ARG1-of (c5 / call-01
                        :ARG2 (n3 / name
                              :op1 "RPI")))))

# ::snt This im pact is unintentional and may occur regardless of whether the RPI was designed to  fulfil  specific fairness criteria.
# File 78

(a / and
      :op1 (ii / intend-01
            :polarity -
            :ARG1 (p / pact
                  :mod (t / this)
                  :mod (ii2 / im)))
      :op2 (p2 / possible-01
            :ARG1 p
            :ARG1-of (r / regardless-91
                  :ARG2 (d / design-01
                        :ARG1 (t2 / thing
                              :name (n / name
                                    :op1 "RPI"))
                        :ARG3 (f / fulfill-01
                              :ARG0 t2
                              :ARG1 (c / criteria
                                    :topic (f2 / fair-01)
                                    :ARG1-of (s / specific-02)))))))

# ::snt So once again these  subjec tivities invoke different understandings of fairness.
# File 78

(ii / invoke-01
      :ARG0 (t / tactic
            :mod (s / subjec)
            :mod (t2 / this))
      :ARG1 (u / understand-01
            :ARG1 (f / fairness)
            :ARG1-of (d / differ-02))
      :mod (a / again
            :mod (o / once)))

# ::snt Given that algorithms have values  embedded in them, transparency about those values can help users interpret the results, guard  against biases, choose which systems to rely on, and engage in useful deba te about the fairness of  the outcomes.
# File 78

(p / possible-01
      :ARG1 (h / help-01
            :ARG0 (t / transparency
                  :topic (v / value
                        :ARG1-of (e / embed-01
                              :ARG2 (a / algorithm))))
            :ARG1 (a2 / and
                  :op1 (ii / interpret-01
                        :ARG0 (p2 / person
                              :ARG0-of (u / use-01))
                        :ARG1 (r / result))
                  :op2 (g / guard-01
                        :ARG0 p2
                        :ARG1 (b / bias-01))
                  :op3 (c / choose-01
                        :ARG0 p2
                        :ARG1 (s / system
                              :ARG2-of (r2 / rely-01
                                    :ARG0 p2)))
                  :op4 (e2 / engage-01
                        :ARG0 p2
                        :ARG2 (d / debate-01
                              :ARG0 p2
                              :ARG1 (f / fair-01
                                    :ARG1 (o / outcome))
                              :ARG1-of (u2 / useful-05))))
            :ARG2 p2)
      :ARG1-of (c2 / cause-01
            :ARG0 v))

# ::snt From a practical perspective therefore, it is important to understand that different concepts and  elements of fairness can conflict.
# File 78

(ii / important-01
      :ARG1 (u / understand-01
            :ARG1 (p / possible-01
                  :ARG1 (c / conflict-01
                        :ARG0 (c2 / concept
                              :ARG1-of (d / differ-02))
                        :ARG1 (e / element
                              :mod (f / fairness))))
            :manner (p2 / perspective
                  :ARG1-of (p3 / practical-02)))
      :ARG1-of (c3 / cause-01))

# ::snt In a  sense, defining the governing sense of ‘fairness’ is at the heart of many political disputes and is  required when we operationalise fairness by programming a computer.
# File 78

(a / and
      :op1 (d / define-01
            :ARG1 (s / sense-01
                  :ARG1 (f / fairness)
                  :ARG0-of (g / govern-01))
            :location (h / heart
                  :part-of (d2 / dispute-01
                        :ARG2 (p / politics)
                        :quant (m / many))))
      :op2 (r / require-01
            :ARG1 d
            :time (o / operate-01
                  :ARG0 (w / we)
                  :ARG1 (f2 / fairness)
                  :manner (p2 / program-01
                        :ARG0 w
                        :ARG1 (c / computer))))
      :mod (s2 / sense))

# ::snt As a first step toward addressing this issue however there needs  to be transparency regarding the fact that a choice of choice of fairness measure is taking place.
# File 78

(h / have-concession-91
      :ARG1 (n / need-01
            :ARG1 (t / transparency
                  :topic (f / fact
                        :topic (c / choose-01
                              :ARG1 (m / measure-02
                                    :ARG1 (f2 / fair-01)))))
            :purpose (s / step-01
                  :ARG2 (a / address-02
                        :ARG1 (ii / issue-02
                              :mod (t2 / this)))
                  :ord (o / ordinal-entity
                        :value 1))))

# ::snt A governance framework for algorithmic accountability and transparency      23 Who is responsible for ensuring fairness?
# File 78

(m / multi-sentence
      :snt1 (f / framework
            :mod (g / govern-01)
            :purpose (a / and
                  :op1 (a2 / accountable-02
                        :mod (a3 / algorithmic))
                  :op2 (t / transparency)))
      :snt2 (r / responsible-03
            :ARG0 (a4 / amr-unknown)
            :ARG1 (e / ensure-01
                  :ARG0 a4
                  :ARG1 (f2 / fair-01)))
      :li 23)

# ::snt Questions arise over where responsibility lies to resolve different forms of unfairness.
# File 78

(a / arise-02
      :ARG1 (q / question-01
            :ARG1 (l / location
                  :ARG2-of (l2 / lie-07
                        :ARG1 (r / responsible-03
                              :ARG1 (r2 / resolve-01
                                    :ARG1 (f / form
                                          :ARG1-of (d / differ-02)
                                          :mod (f2 / fairness
                                                :polarity -))))))))

# ::snt Multiple sources of unfairness, multiple solutions:  Because unfairness in algorithmic systems has  the potential to arise from a number of sources, there are multiple potential solutions to address it.
# File 78

(m / multi-sentence
      :snt1 (s / source-02
            :ARG1 (f / fairness
                  :polarity -)
            :quant (m2 / multiple))
      :snt2 (s2 / solve-01
            :quant (m3 / multiple))
      :snt3 (c / cause-01
            :ARG0 (p / potential
                  :domain (a / arise-02
                        :ARG1 (f2 / fairness
                              :polarity -
                              :mod (s3 / system
                                    :mod (a2 / algorithmic)))
                        :source (s4 / source-02
                              :quant (n / number))))
            :ARG1 (s5 / solve-01
                  :ARG2 (a3 / address-02
                        :ARG1 (ii / it))
                  :quant (m4 / multiple)
                  :mod (p2 / potential))))

# ::snt This multiplicity of sources and solutions creates a challenge for ethicists and regulators, because  there is no ‘one size fits all’ remedy and instead each type of unfairness invites different regulatory  responses from industry, academia, and policymakers.
# File 78

(c / create-01
      :ARG0 (m / multiply-01
            :ARG1 (a / and
                  :op1 (s / source-01)
                  :op2 (s2 / solution))
            :mod (t / this))
      :ARG1 (c2 / challenge-01
            :ARG1 (a2 / and
                  :op1 (e / ethicist)
                  :op2 (p / person
                        :ARG0-of (r / regulate-01))))
      :ARG1-of (c3 / cause-01
            :ARG0 (a3 / and
                  :op1 (r2 / remedy-01
                        :polarity -
                        :ARG2 (f / fit-06
                              :ARG1 (s3 / size-01)
                              :ARG2 (a4 / all)))
                  :op2 (ii / invite-01
                        :ARG0 (t2 / type-03
                              :ARG1 (f2 / fairness
                                    :polarity -)
                              :mod (e2 / each))
                        :ARG1 (r3 / respond-01
                              :ARG0 (a5 / and
                                    :op1 (ii2 / industry)
                                    :op2 (a6 / academia)
                                    :op3 (p2 / person
                                          :ARG0-of (l / legislate-01)))
                              :ARG1 t2
                              :ARG1-of (d / differ-02)
                              :ARG0-of (r4 / regulate-01))
                        :ARG2 (ii3 / instead-of-91)))))

# ::snt Where the source of unfairness (potentially) lies in the data algorithms work on, several  commentators have suggested the possibility of adjusting algorithms to accommodate for known  bias.
# File 78

(s / suggest-01
      :ARG0 (p / person
            :ARG0-of (c / comment-01)
            :quant (s2 / several))
      :ARG1 (p2 / possible-01
            :ARG1 (a / adjust-01
                  :ARG1 (a2 / algorithm)
                  :ARG2 (a3 / accommodate-01
                        :ARG0 a2
                        :ARG1 (b / bias-01
                              :ARG1-of (k / know-01)))))
      :location (w / work-01
            :ARG1 (a4 / algorithm
                  :mod (d / data))
            :ARG2-of (l / lie-07
                  :ARG1 (s3 / source-02
                        :ARG1 (f / fairness
                              :polarity -))
                  :mod (p3 / potential))))

# ::snt Finally,  addressing unfairness resulting from the application of algorithmic systems is often discussed in  terms of ex post facto laws, such as the use of anti -discrimination laws to seek redress against cases  of systematic unfairness against individuals or groups with protected characteristics [11 9] or the  expansion of the General Data Protection Regulation where it provides a ‘right to explanati on’ of  how data is processed [120 ].
# File 78

(d / discuss-01
      :li "-1"
      :ARG1 (a / address-02
            :ARG1 (t / thing
                  :ARG1-of (f / fair-01
                        :polarity -)
                  :ARG2-of (r / result-01
                        :ARG1 (a2 / apply-02
                              :ARG1 (s / system
                                    :mod (a3 / algorithmic))))))
      :manner (l / law
            :mod (e / ex-post-)
            :example (o / or
                  :op1 (u / use-01
                        :ARG1 (l2 / law
                              :ARG0-of (o2 / oppose-01
                                    :ARG1 (d2 / discriminate-02)))
                        :ARG2 (s2 / seek-01
                              :ARG1 (r2 / redress-01
                                    :ARG1 (c / case-03
                                          :ARG1 (f2 / fair-01
                                                :polarity -
                                                :ARG2 (o3 / or
                                                      :op1 (ii / individual)
                                                      :op2 (g / group)
                                                      :ARG0-of (h / have-03
                                                            :ARG1 (t2 / thing
                                                                  :ARG2-of (c2 / characteristic-02)
                                                                  :ARG1-of (p / protect-01))))
                                                :mod (s3 / systematic))))))
                  :op2 (e2 / expand-01
                        :ARG1 (l3 / law
                              :name (n / name
                                    :op1 "General"
                                    :op2 "Data"
                                    :op3 "Protection"
                                    :op4 "Regulation")
                              :location-of (p2 / provide-01
                                    :ARG1 (r3 / right-05
                                          :ARG2 (e3 / explain-01
                                                :ARG1 (t3 / thing
                                                      :manner-of (p3 / process-01
                                                            :ARG1 (d3 / data)))))
                                    :ARG1-of (d4 / describe-01
                                          :ARG0 (p4 / publication
                                                :ARG1-of (c3 / cite-01
                                                      :ARG2 11))))
                              :ARG0-of p2))))
      :frequency (o4 / often))

# ::snt Legislation could address algorithms in general, as an ' Internet Bill of  Rights' , adapting and re -affirming rights in the context of wide- scale algorithmic decision -making;  this should accommodate legitimate disagreements about the various forms of fairness to bring to  bear in any particular case.
# File 78

(m / multi-sentence
      :snt1 (p / possible-01
            :ARG1 (a / address-02
                  :ARG0 (l / legislate-01)
                  :ARG1 (a2 / algorithm)
                  :ARG2 (g / general-02)
                  :example (l2 / law
                        :name (n / name
                              :op1 "Internet"
                              :op2 "Bill"
                              :op3 "of"
                              :op4 "Rights"))))
      :snt2 (r / recommend-01
            :ARG1 (a3 / accommodate-01
                  :ARG0 (t / this)
                  :ARG1 (d / disagree-01
                        :ARG2 (f / fairness
                              :mod (f2 / form
                                    :mod (v / various))
                              :ARG1-of (b / bring-01
                                    :ARG2 (b2 / bear)
                                    :condition (c / case-04
                                          :mod (p2 / particular)
                                          :mod (a4 / any))))
                        :ARG1-of (l3 / legitimate-02))
                  :manner (a5 / and
                        :op1 (a6 / adapt-01
                              :ARG1 (r2 / right-05))
                        :op2 (r3 / reaffirm-01
                              :ARG1 r2)
                        :topic (m2 / make-01
                              :ARG1 (d2 / decide-01
                                    :mod (a7 / algorithm))
                              :mod (w / wide-scale))))))

# ::snt The current terms of the proposal seek to establish an agency responsibl e for fairness,  accountability and transparency of algorithms that are used by public authorities.
# File 78

(s / seek-01
      :ARG0 (t / term
            :time (c / current)
            :poss (t2 / thing
                  :ARG1-of (p / propose-01)))
      :ARG1 (e / establish-01
            :ARG0 t
            :ARG1 (r / responsible-03
                  :ARG0 (a / agency)
                  :ARG1 (a2 / and
                        :op1 (f / fairness)
                        :op2 (a3 / accountable-02
                              :ARG0 (a4 / algorithm
                                    :ARG1-of (u / use-01
                                          :ARG0 (a5 / authority
                                                :ARG1-of (p2 / public-02)))))
                        :op3 (t3 / transparency
                              :poss a4)))))

# ::snt One person’s fairness that minimises false positives may be another person’s unfairness  because it does not minimise false negatives.
# File 78

(p / possible-01
      :ARG1 (f / fair-01
            :ARG1 (p2 / person
                  :quant 1)
            :ARG0-of (m / minimize-01
                  :ARG1 (p3 / positive
                        :mod (f2 / false)))
            :domain (f3 / fair-01
                  :polarity -
                  :ARG1 (p4 / person
                        :mod (a / another))))
      :ARG1-of (c / cause-01
            :ARG0 (m2 / minimize-01
                  :polarity -
                  :ARG0 f
                  :ARG1 (n / negative-02
                        :mod f2))))

# ::snt Fairness is complex.
# File 78

(c / complex
      :domain (f / fairness))

# ::snt Industry standards and the risk of fairness as an escape from regulation   As a consequence of the various controversies arising from the application of algorithmic systems  for decision -making, there have been calls for industry to take the initiative to develop standards  and codes of conduct to ensure fair, ethical and socially  beneficial practice.
# File 78

(m / multi-sentence
      :snt1 (a / and
            :op1 (s / standard
                  :mod (ii / industry))
            :op2 (r / risk-01
                  :ARG2 (f / fairness)
                  :purpose (e / escape-01
                        :ARG1 (r2 / regulate-01))))
      :snt2 (c / call-03
            :ARG1 (ii2 / industry)
            :ARG2 (ii3 / initiate-01
                  :ARG0 ii2
                  :ARG1 (d / develop-02
                        :ARG0 ii2
                        :ARG1 (a2 / and
                              :op1 (s2 / standard)
                              :op2 (c2 / code
                                    :topic (c3 / conduct-02)))
                        :purpose (e2 / ensure-01
                              :ARG0 ii2
                              :ARG1 (a3 / and
                                    :op1 (f2 / fair-01)
                                    :op2 (e3 / ethics)
                                    :op3 (s3 / social-03)
                                    :ARG0-of (b / benefit-01)
                                    :ARG1-of (p / practice-01)))))
            :ARG2-of (c4 / consequence-03
                  :ARG1 (c5 / controversy
                        :mod (v / various)
                        :ARG1-of (a4 / arise-02
                              :ARG0 (a5 / apply-02
                                    :ARG1 (s4 / system
                                          :mod (a6 / algorithm))
                                    :ARG2 (m2 / make-01
                                          :ARG1 (d2 / decide-01))))))))

# ::snt This is an important first step for implementation and  institutionalisation of social values of fairness.
# File 78

(t / thing
      :ARG4-of (s / step-01)
      :ord (o / ordinal-entity
            :value 1)
      :ARG1-of (ii / important-01)
      :purpose (a / and
            :op1 (ii2 / implement-01
                  :ARG1 (v / value
                        :mod (s2 / society)
                        :topic (f / fairness)))
            :op2 (ii3 / institutionalize-01
                  :ARG1 v))
      :domain (t2 / this))

# ::snt One caveat though is that the provision  of concrete  guidance on fairness in algorithmic systems is of course also made difficult by the complexities  around the various types of fairness.
# File 78

(h / have-concession-91
      :ARG2 (m / make-02
            :ARG0 (c / complexity
                  :topic (f / fairness
                        :mod (t / type
                              :mod (v / various))))
            :ARG1 (d / difficult
                  :domain (p / provide-01
                        :ARG1 (g / guide-01
                              :ARG1-of (c2 / concrete-02)
                              :topic (f2 / fairness))
                        :ARG2 (s / system
                              :mod (a / algorithm))))
            :mod (o / of-course)
            :mod (a2 / also))
      :quant (o2 / one))

# ::snt The notions of responsibility and fairness are core  aspects of the field, and so could be seen a potential solutions in relation to the design and use of  algorithms.
# File 78

(a / aspect
      :ARG1-of (c / core-02)
      :poss (f / field)
      :domain (n / notion
            :topic (a2 / and
                  :op1 (r / responsible-02)
                  :op2 (f2 / fairness)))
      :ARG0-of (c2 / cause-01
            :ARG1 (p / possible-01
                  :ARG1 (s / see-01
                        :ARG1 (t / thing
                              :ARG2-of (s2 / solve-01)
                              :mod (p2 / potential)
                              :ARG1-of (r2 / relate-01
                                    :ARG2 (a3 / and
                                          :op1 (d / design-01
                                                :ARG1 (a4 / algorithm))
                                          :op2 (u / use-01
                                                :ARG1 a4))))))))

# ::snt Political and Legal   The discussion around fairness should not be set in isolation of other social systems.
# File 78

(m / multi-sentence
      :snt1 (a / and
            :op1 (p / politics)
            :op2 (l / legal-02))
      :snt2 (r / recommend-01
            :polarity -
            :ARG1 (s / set-01
                  :ARG1 (d / discuss-01
                        :ARG1 (f / fairness))
                  :ARG2 (ii / isolate-01
                        :ARG1 d
                        :ARG2 (s2 / system
                              :mod (s3 / society)
                              :mod (o / other))))))

# ::snt It is important  to understand that fairness is being defined within a set of existing legal and social norms and  political deliberati on.
# File 78

(ii / important-01
      :ARG1 (u / understand-01
            :ARG1 (d / define-01
                  :ARG1 (f / fair-01)
                  :ARG2 (s / set
                        :consist-of (a / and
                              :op1 (n / norm
                                    :ARG1-of (l / legal-02))
                              :op2 (n2 / norm
                                    :mod (s2 / society))
                              :ARG1-of (e / exist-01))
                        :op2 (d2 / deliberate-01
                              :ARG1 f)
                        :mod (p / politics)))))

# ::snt Therefore, the comprehension of fairness is the simultaneous inquiry of what  should  be the appropriate outcomes of algorithmic decision -making, but also a political debate  which seeks the establishment of rules of conduct, producing higher order rules  which detach  themselves from the fairness debate.
# File 78

(c / cause-01
      :ARG1 (c2 / contrast-01
            :ARG1 (ii / inquire-01
                  :ARG1 (r / recommend-01
                        :ARG1 (o / outcome
                              :ARG1-of (a / appropriate-02)
                              :poss (m / make-01
                                    :ARG1 (d / decide-01
                                          :manner (a2 / algorithm)))))
                  :mod (s / simultaneous))
            :ARG2 (d2 / debate-01
                  :ARG1 (p / politics)
                  :ARG0-of (s2 / seek-01
                        :ARG1 (e / establish-01
                              :ARG1 (r2 / rule
                                    :topic (c3 / conduct-02)
                                    :ARG0-of (p2 / produce-01
                                          :ARG1 (r3 / rule
                                                :topic (o2 / order
                                                      :ARG1-of (h / have-degree-91
                                                            :ARG2 (h2 / high-02)
                                                            :ARG3 (m2 / more)))
                                                :ARG0-of (d3 / detach-01
                                                      :ARG2 d2
                                                      :ARG1 (f / fairness))
                                                :ARG1-of d3))))))
            :mod (a3 / also))
      :domain (c4 / comprehend-01
            :ARG1 f))

# ::snt In this regard, the first caveat to the discussion of fairness should be its relation with institutionalised  norms.
# File 78

(r / recommend-01
      :ARG1 (c / caveat
            :ord (o / ordinal-entity
                  :value 1)
            :part-of (d / discuss-01
                  :ARG1 (f / fair-01))
            :domain (r2 / relate-01
                  :ARG1 f
                  :ARG2 (n / norm
                        :ARG1-of (ii / institutionalize-02))))
      :topic (t / this))

# ::snt Fairness orients action towards just  outcomes, but it has to respect existing social constraints.
# File 78

(o / orient-01
      :ARG0 (f / fairness)
      :ARG1 (a / act-02)
      :ARG2 (o2 / outcome
            :mod (j / just))
      :concession-of (o3 / obligate-01
            :ARG1 f
            :ARG2 (r / respect-01
                  :ARG0 f
                  :ARG1 (c / constrain-01
                        :ARG1 (s / society)
                        :ARG1-of (e / exist-01)))))

# ::snt If a constraint is deemed unfair, it can be  changed though political discussion, but fairness, as a low -level institution, cannot override higher  level instit utions indiscriminately.
# File 78

(c / contrast-01
      :ARG1 (p / possible-01
            :ARG1 (c2 / change-01
                  :ARG1 (c3 / constraint)
                  :manner (d / discuss-01
                        :ARG1 (p2 / politics)))
            :condition (d2 / deem-01
                  :ARG1 (f / fair-01
                        :polarity -
                        :ARG1 c3)))
      :ARG2 (p3 / possible-01
            :polarity -
            :ARG1 (o / override-01
                  :ARG0 (f2 / fairness
                        :ARG1-of (c4 / cause-01
                              :ARG0 (ii / institution
                                    :mod (l / level
                                          :ARG1-of (l2 / low-04)))))
                  :ARG1 (ii2 / institution
                        :mod (l3 / level
                              :ARG1-of (h / have-degree-91
                                    :ARG2 (h2 / high-02)
                                    :ARG3 (m / more))))
                  :manner (d3 / discriminate-01
                        :polarity -))))

# ::snt A second caveat to fairness should be the political effects of algorithmic decision- making.
# File 78

(r / recommend-01
      :ARG1 (c / caveat
            :li 2
            :prep-to (f / fairness)
            :domain (a / affect-01
                  :ARG0 (m / make-01
                        :ARG1 (d / decide-01
                              :manner (a2 / algorithm)))
                  :ARG1 (p / politics))))

# ::snt Fairness  shouldn’t be concerned exclusively with how algorithms are transforming society, for example by  reinforcing discrimination, but al so how these tools can shape social understanding and views.
# File 78

(r / recommend-01
      :ARG1 (c / contrast-01
            :ARG1 (c2 / concern-02
                  :polarity -
                  :ARG0 (f / fairness)
                  :ARG1 (t / thing
                        :manner-of (t2 / transform-01
                              :ARG0 (a / algorithm)
                              :ARG1 (s / society)
                              :example (r2 / reinforce-01
                                    :ARG0 a
                                    :ARG1 (d / discriminate-02))))
                  :ARG1-of (e / exclusive-02))
            :ARG2 (c3 / concern-02
                  :ARG0 f
                  :ARG1 (t3 / thing
                        :manner-of (p / possible-01
                              :ARG1 (s2 / shape-01
                                    :ARG0 (t4 / tool
                                          :mod (t5 / this))
                                    :ARG1 (a2 / and
                                          :op1 (u / understand-01
                                                :ARG1 s)
                                          :op2 (v / view-02
                                                :ARG1 s))))
                        :mod (a3 / al-so)))))

# ::snt Therefore, fairness
# File 78

(c / cause-01
      :ARG1 (f / fairness))

# ::snt In this reg ard, elements such as transparency and accountability are not solely tools for identifying  and contesting biased decisions, but they are also mechanisms that enable people to ensure the  absence of threats of unfairness to society.
# File 78

(c / contrast-01
      :ARG1 (t / tool
            :domain (e / element
                  :example (a / and
                        :op1 (t2 / transparency)
                        :op2 (a2 / accountable-02)))
            :purpose (a3 / and
                  :op1 (ii / identify-01
                        :ARG1 (d / decide-01
                              :ARG1-of (b / bias-01)))
                  :op2 (c2 / contest-01
                        :ARG1 d))
            :mod (s / sole
                  :polarity -))
      :ARG2 (m / mechanism
            :ARG0-of (e2 / enable-01
                  :ARG1 (e3 / ensure-01
                        :ARG0 (p / person)
                        :ARG1 (a4 / absent-01
                              :ARG1 (t3 / threaten-01
                                    :ARG1 (f / fairness
                                          :polarity -
                                          :beneficiary (s2 / society)))))
                  :ARG2 p)
            :mod (a5 / also)
            :domain e)
      :prep-in (r / regrieve-01
            :mod (t4 / this)))

# ::snt Therefore, mechanisms that promote awareness, recognition and protection of soc ial  values are an essential part of fairness, since they enable people to participate, trust and ensure the  reliability of algorithmic decision -making.
# File 78

(ii / infer-01
      :ARG1 (h / have-part-91
            :ARG1 (f / fairness)
            :ARG2 (m / mechanism
                  :ARG0-of (p / promote-02
                        :ARG1 (a / and
                              :op1 (r / realize-01
                                    :ARG1 (v / value
                                          :mod (s / society)))
                              :op2 (r2 / recognize-01
                                    :ARG1 v)
                              :op3 (p2 / protect-01
                                    :ARG1 v))))
            :mod (e / essential)
            :ARG1-of (c / cause-01
                  :ARG0 (e2 / enable-01
                        :ARG0 m
                        :ARG1 (a2 / and
                              :op1 (p3 / participate-01
                                    :ARG0 (p4 / person))
                              :op2 (t / trust-02
                                    :ARG0 p4)
                              :op3 (e3 / ensure-01
                                    :ARG0 p4
                                    :ARG1 (r3 / rely-01
                                          :ARG1 (m2 / make-01
                                                :ARG1 (d / decide-01
                                                      :manner (a3 / algorithm)))
                                          :ARG1-of (p5 / possible-01))))
                        :ARG2 p4))))

# ::snt Human vs machine bias   It is also important not to consider algorithmic (un)fairness in isolation from issues surrounding  human (un)fairness: more specifically human bias versus machine bias.
# File 78

(m / multi-sentence
      :snt1 (v / versus
            :op1 (b / bias
                  :mod (h / human))
            :op2 (b2 / bias
                  :mod (m2 / machine)))
      :snt2 (ii / important-01
            :ARG1 (c / consider-02
                  :polarity -
                  :ARG1 (f / fairness
                        :mod (a / algorithm)
                        :ARG1-of (c2 / contrast-01
                              :ARG2 (f2 / fairness
                                    :polarity -
                                    :mod (h2 / human))))
                  :manner (ii2 / isolate-01
                        :ARG1 f
                        :ARG2 (ii3 / issue-02
                              :ARG0 (v2 / versus
                                    :op1 (b3 / bias
                                          :mod (h3 / human))
                                    :op2 (b4 / bias
                                          :mod (m3 / machine))
                                    :ARG1-of (s / specific-02
                                          :mod (m4 / more))))))
            :mod (a2 / also)))

# ::snt However,  an important question remains: should we evaluate algorithmic systems against an ideal of perfect  fairness, or is it enough for them just to  be less ‘unfair’ than humans?
# File 78

(c / contrast-01
      :ARG2 (r / remain-01
            :ARG1 (q / question-01
                  :ARG1 (a / amr-choice
                        :op1 (r2 / recommend-01
                              :ARG1 (e / evaluate-01
                                    :ARG0 (w / we)
                                    :ARG1 (s / system
                                          :mod (a2 / algorithm))
                                    :ARG3 (ii / ideal
                                          :topic (f / fair-01
                                                :ARG1-of (p / perfect-02)))))
                        :op2 (h / have-quant-91
                              :ARG1 s
                              :ARG3 (e2 / enough)
                              :ARG6 (f2 / fair-01
                                    :polarity -
                                    :ARG1 s
                                    :mod (j / just)
                                    :ARG2-of (h2 / have-degree-91
                                          :ARG1 s
                                          :ARG3 (l / less)
                                          :ARG4 (h3 / human)))))
                  :ARG1-of (ii2 / important-01))))

# ::snt As noted throughout, lack of  transparency is a complicating factor in being able to assess the fairness of algorithms and also a  barrier to ensuring their fairness.
# File 78

(a / and
      :op1 (f / factor
            :ARG0-of (c / complicate-01)
            :domain (l / lack-01
                  :ARG1 (t / transparency))
            :topic (p / possible-01
                  :ARG1 (a2 / assess-01
                        :ARG1 (f2 / fair-01
                              :ARG1 (a3 / algorithm)))))
      :op2 (b / barrier
            :mod (a4 / also)
            :domain l
            :purpose (e / ensure-01
                  :ARG1 (f3 / fair-01
                        :ARG1 a3)))
      :ARG1-of (n / note-01
            :location (t2 / throughout)))

# ::snt For example, standard statistical evaluation techniques could be used to determine if  outcomes or accuracy are different f or specific subgroups of individuals, suggesting fairness  problems.
# File 78

(e / exemplify-01
      :ARG0 (p / possible-01
            :ARG1 (u / use-01
                  :ARG1 (t / technique
                        :instrument-of (e2 / evaluate-01
                              :ARG2 (s / statistics))
                        :ARG1-of (s2 / standard-02))
                  :ARG2 (d / determine-01
                        :ARG0 t
                        :ARG1 (d2 / differ-02
                              :ARG1 (o / or
                                    :op1 (o2 / outcome)
                                    :op2 (a / accuracy))
                              :ARG2 (s3 / subgroup
                                    :ARG1-of (s4 / specific-02)
                                    :part-of (ii / individual))
                              :ARG0-of (s5 / suggest-01
                                    :ARG1 (p2 / problem
                                          :topic (f / fairness))))))))

# ::snt There have been many definitions for fairness proposed, and it has been shown that  it can be impossible to simultaneously satisfy multiple definitions [37]; any hard requirement on  fairness may have unintended impac ts.
# File 78

(m / multi-sentence
      :snt1 (a / and
            :op1 (p / propose-01
                  :ARG1 (t / thing
                        :ARG2-of (d / define-01
                              :ARG1 (f / fairness))
                        :quant (m2 / many)))
            :op2 (s / show-01
                  :ARG1 (p2 / possible-01
                        :ARG1 (p3 / possible-01
                              :polarity -
                              :ARG1 (s2 / satisfy-01
                                    :ARG1 (t2 / thing
                                          :ARG2-of (d2 / define-01
                                                :ARG1 (f2 / fairness))
                                          :quant (m3 / multiple))
                                    :mod (s3 / simultaneous))))
                  :ARG1-of (d3 / describe-01
                        :ARG0 (p4 / publication
                              :ARG1-of (c / cite-01
                                    :ARG2 37)))))
      :snt2 (p5 / possible-01
            :ARG1 (t3 / thing
                  :ARG1-of (r / require-01
                        :ARG1-of (h / hard-02)
                        :topic (f3 / fairness))
                  :mod (a2 / any)
                  :ARG0-of (ii / impacute-01
                        :ARG1-of (ii2 / intend-01
                              :polarity -)))))

# ::snt Input data analysis   Understanding what data is used to determine an outcome can be useful in establishing confidence  in the fairness of an individual outcome.
# File 78

(m / multi-sentence
      :snt1 (a / analyze-01
            :ARG1 (d / data
                  :mod (ii / input)))
      :snt2 (p / possible-01
            :ARG1 (u / useful-05
                  :ARG1 (u2 / understand-01
                        :ARG1 (d2 / data
                              :ARG1-of (u3 / use-01
                                    :ARG2 (d3 / determine-01
                                          :ARG1 (o / outcome)))))
                  :ARG2 (e / establish-01
                        :ARG1 (c / confident-01
                              :ARG2 (f / fairness
                                    :poss (o2 / outcome
                                          :mod (ii2 / individual))))))))

# ::snt Such ' what if '  analyses can provide useful information to individuals, as well as identify fairness issues that require  further investigation.
# File 78

(p / possible-01
      :ARG1 (a / and
            :op1 (p2 / provide-01
                  :ARG0 (a2 / analyze-01
                        :mod (s / such)
                        :mod (s2 / suppose-01))
                  :ARG1 (ii / information
                        :ARG1-of (u / useful-05))
                  :ARG2 (ii2 / individual))
            :op2 (ii3 / identify-01
                  :ARG0 a2
                  :ARG1 (ii4 / issue-02
                        :ARG0 (f / fair-01)
                        :ARG0-of (r / require-01
                              :ARG1 (ii5 / investigate-01
                                    :ARG1 ii4
                                    :degree (f2 / further)))))))

# ::snt Fairness, Accountability and Transparency/Explainability are some of the fastest growing research  areas for algorithmic decision -making systems, and especially machine learning.
# File 78

(ii / include-91
      :ARG1 (a / and
            :op1 (f / fairness)
            :op2 (a2 / accountable-02)
            :op3 (s / slash
                  :op1 (t / transparency)
                  :op2 (e / explain-01)))
      :ARG2 (a3 / area
            :mod (r / research-01)
            :ARG1-of (g / grow-01
                  :ARG1-of (h / have-degree-91
                        :ARG2 (f2 / fast-02)
                        :ARG3 (m / most)))
            :beneficiary (a4 / and
                  :op1 (s2 / system
                        :mod (d / decide-01
                              :manner (a5 / algorithm)))
                  :op2 (l / learn-01
                        :manner (m2 / machine)
                        :mod (e2 / especially)))))

# ::snt Not only academic  funding bodies, but also industry is increasing its investment in this domai n. This has resulted in the  production of an increasing number of open source libraries and tools to help developers address  Fairness, Accountability and Transparency requirements [e.g.
# File 78

(m / multi-sentence
      :snt1 (c / contrast-01
            :ARG1 (ii / increase-01
                  :ARG0 (b / body
                        :ARG0-of (f / fund-01)
                        :mod (a / academia)
                        :mod (o / only
                              :polarity -))
                  :ARG1 (ii2 / invest-01
                        :ARG0 b
                        :ARG2 (d / domai
                              :mod (t / this))))
            :ARG2 (ii3 / increase-01
                  :ARG0 (ii4 / industry
                        :mod (a2 / also))
                  :ARG1 ii2
                  :ARG0 ii4
                  :ARG2 (d2 / domai)))
      :snt2 (r / result-01
            :ARG1 (t2 / this)
            :ARG2 (p / produce-01
                  :ARG1 (n / number
                        :ARG1-of (ii5 / increase-01)
                        :quant-of (a3 / and
                              :op1 (l / library)
                              :op2 (t3 / tool)
                              :mod (s / source
                                    :ARG1-of (o2 / open-04)))
                        :purpose (h / help-01
                              :ARG0 a3
                              :ARG1 (a4 / address-02
                                    :ARG0 (p2 / person
                                          :ARG0-of (d3 / develop-02))
                                    :ARG1 (r2 / require-01
                                          :ARG1 (a5 / and
                                                :op1 (f2 / fairness)
                                                :op2 (a6 / accountable-02)
                                                :op3 (t4 / transparency))
                                          :example (e / exemplify-01)))
                              :ARG2 p2)))))

# ::snt Collateral implications of imposing Fairness, Accountability  and/or Transparency requirement s  Here we provide a brief overview of some of the collateral implications (i.e.
# File 78

(m / multi-sentence
      :snt1 (ii / implicate-01
            :mod (c / collateral)
            :ARG1-of (c2 / cause-01
                  :ARG0 (ii2 / impose-01
                        :ARG1 (a / and-or
                              :op1 (f / fairness)
                              :op2 (a2 / accountable-02)
                              :op3 (t / transparency)
                              :ARG1-of (r / require-01)))))
      :snt2 (p / provide-01
            :ARG0 (w / we)
            :ARG1 (o / overview
                  :mod (b / brief)
                  :topic (ii3 / implicate-01
                        :mod (c3 / collateral)
                        :quant (s / some)
                        :example (ii4 / implicate-01)))
            :location (h / here)))

# ::snt indirect/secondary  effects) that may occur when Fairness, Accountability and/or Transparency (FAT) requirements are  imposed on algorithmic  decision -making systems.
# File 78

(p / possible-01
      :ARG1 (s / slash
            :op1 (a / affect-01
                  :ARG1-of (d / direct-02
                        :polarity -))
            :op2 (a2 / affect-01
                  :mod (s2 / secondary)))
      :time (ii / impose-01
            :ARG1 (r / require-01
                  :ARG1 (o / or
                        :op1 (f / fairness)
                        :op2 (a3 / accountable-02)
                        :op3 (t / transparency)
                        :ARG1-of (m / mean-01
                              :ARG2 (t2 / thing
                                    :name (n / name
                                          :op1 "FAT")))))
            :ARG2 (s3 / system
                  :ARG0-of (m2 / make-01
                        :ARG1 (d2 / decide-01)
                        :manner (a4 / algorithm)))))

# ::snt Fairness and accountability requirements more indirectly support  trustworthiness due to the increased rigor of system behaviour  inspection that is needed to control  for fairness and establish accountability.
# File 78

(s / support-01
      :ARG0 (r / require-01
            :ARG1 (a / and
                  :op1 (f / fairness)
                  :op2 (a2 / accountable-02)))
      :ARG1 (d / deserve-01
            :ARG1 (t / trust-01))
      :ARG1-of (c / cause-01
            :ARG0 (r2 / rigor
                  :ARG1-of (ii / increase-01)
                  :topic (ii2 / inspect-01
                        :ARG1 (b / behave-01
                              :ARG1 (s2 / system)))
                  :ARG1-of (n / need-01
                        :purpose (a3 / and
                              :op1 (c2 / control-01
                                    :ARG0 ii2
                                    :ARG1 f)
                              :op2 (e / establish-01
                                    :ARG0 ii2
                                    :ARG1 a2)))))
      :ARG1-of (h / have-degree-91
            :ARG2 (d2 / direct-02
                  :polarity -
                  :ARG1 s)
            :ARG3 (m / more)))

# ::snt Fairness and accountability requirements more indirectly support  trustworthiness due to the increased rigor of system behaviour  inspection that is needed to control  for fairness and establish accountability.
# File 78

(s / support-01
      :ARG0 (r / require-01
            :ARG1 (a / and
                  :op1 (f / fairness)
                  :op2 (a2 / accountable-02)))
      :ARG1 (d / deserve-01
            :ARG1 (t / trust-01))
      :ARG1-of (c / cause-01
            :ARG0 (r2 / rigor
                  :ARG1-of (ii / increase-01)
                  :topic (ii2 / inspect-01
                        :ARG1 (b / behave-01
                              :ARG1 (s2 / system)))
                  :ARG1-of (n / need-01
                        :purpose (a3 / and
                              :op1 (c2 / control-01
                                    :ARG0 ii2
                                    :ARG1 f)
                              :op2 (e / establish-01
                                    :ARG0 ii2
                                    :ARG1 a2)))))
      :ARG1-of (h / have-degree-91
            :ARG2 (d2 / direct-02
                  :polarity -
                  :ARG1 s)
            :ARG3 (m / more)))

# ::snt STOA  | Panel for the Future of Science and Technology      36 such as: the ' reasonableness ' of the algorithmic outcomes, which is facilitated by algorithmic  transparency/explainability; or the perceived ethical values that the service provider built into the  system, which  are expressed through fairness and accountability requirement.
# File 78

(m / multi-sentence
      :snt1 (o / organization
            :name (n / name
                  :op1 "STOA"))
      :snt2 (o2 / organization
            :name (n2 / name
                  :op1 "Panel"
                  :op2 "for"
                  :op3 "the"
                  :op4 "Future"
                  :op5 "of"
                  :op6 "Science"
                  :op7 "and"
                  :op8 "Technology"))
      :snt3 (e / exemplify-01
            :ARG0 (o3 / or
                  :op1 (r / reasonableness
                        :domain (o4 / outcome
                              :mod (a / algorithm))
                        :ARG1-of (f / facilitate-01
                              :ARG0 (s / slash
                                    :op1 (t / transparency
                                          :mod a)
                                    :op2 (e2 / explain-01
                                          :ARG1 o4))))
                  :op2 (v / value
                        :mod (e3 / ethics)
                        :ARG1-of (p / perceive-01)
                        :ARG1-of (b / build-01
                              :ARG0 (c / company
                                    :ARG0-of (p2 / provide-01
                                          :ARG1 (s2 / serve-01)))
                              :ARG2 (s3 / system))
                        :ARG1-of (e4 / express-01
                              :ARG0 (r2 / require-01
                                    :ARG1 (a2 / and
                                          :op1 (f2 / fairness)
                                          :op2 (a3 / accountable-02))))))))

# ::snt Primarily  these solutions are taking the form of algorithm auditing support services such as an ' AI fairness  toolkit ' [227, 228], 'Audit -AI' by Pymetrics [2 29], Facebook’s ' Fairness Flow ' [230] and ' ORCAA ' [231]  an Algorithms Auditing company set up by Cathy O’Neil, acclaimed author of ' Weapons of Math  Destruction: How Big Data Increases Inequality And Threatens Democracy ' [53].
# File 78

(f / form-01
      :ARG1 (t / thing
            :ARG2-of (s / solve-01)
            :mod (t2 / this))
      :ARG2 (s2 / service
            :ARG0-of (s3 / support-01
                  :ARG1 (a / audit-01
                        :ARG1 (a2 / algorithm)))
            :example (a3 / and
                  :op1 (t3 / toolkit
                        :mod (f2 / fairness
                              :mod (a4 / artificial))
                        :ARG1-of (d / describe-01
                              :ARG0 (p / publication
                                    :ARG1-of (c / cite-01
                                          :ARG2 (a5 / and
                                                :op1 225
                                                :op2 228)))))
                  :op2 (p2 / publication
                        :name (n / name
                              :op1 "Audit-AI")
                        :ARG1-of (d2 / describe-01
                              :ARG0 (p3 / publication
                                    :name (n2 / name
                                          :op1 "Pymetrics")
                                    :ARG1-of (c2 / cite-01
                                          :ARG2 29))))
                  :op3 (f3 / flow-01
                        :ARG1 (f4 / fairness)
                        :mod (p4 / publication
                              :name (n3 / name
                                    :op1 "Facebook's"))
                        :ARG1-of (d3 / describe-01
                              :ARG0 (p5 / publication
                                    :name (n4 / name
                                          :op1 "Weapons"
                                          :op2 "of"
                                          :op3 "Math"
                                          :op4 "Destruction:"
                                          :op5 "How"
                                          :op6 "Big"
                                          :op7 "Data"
                                          :op8 "Increase"
                                          :op9 "Inequality"
                                          :op10 "and"
                                          :op11 "Threatens"
                                          :op12 "Democracy"))))
                  :op4 (o / organization
                        :name (n5 / name
                              :op1 "ORCAA")
                        :ARG1-of (d4 / describe-01
                              :ARG0 (p6 / publication
                                    :ARG1-of (s4 / set-up-03
                                          :ARG0 (p7 / person
                                                :name (n6 / name
                                                      :op1 "Cathy"
                                                      :op2 "O'Neil")
                                                :ARG0-of (a6 / author-01
                                                      :ARG1 (b / book
                                                            :name (n7 / name
                                                                  :op1 "Algorithms"
                                                                  :op2 "Audit"
                                                                  :op3 "Company")))
                                                :ARG1-of (a7 / award-01)
                                                :ARG2-of a7)))
                              :ARG1-of (d5 / describe-01
                                    :ARG0 (p8 / publication
                                          :ARG1-of (c3 / cite-01
                                                :ARG2 53)))))))
      :mod (p9 / primary))

# ::snt Primarily  these solutions are taking the form of algorithm auditing support services such as an ' AI fairness  toolkit ' [227, 228], 'Audit -AI' by Pymetrics [2 29], Facebook’s ' Fairness Flow ' [230] and ' ORCAA ' [231]  an Algorithms Auditing company set up by Cathy O’Neil, acclaimed author of ' Weapons of Math  Destruction: How Big Data Increases Inequality And Threatens Democracy ' [53].
# File 78

(f / form-01
      :ARG1 (t / thing
            :ARG2-of (s / solve-01)
            :mod (t2 / this))
      :ARG2 (s2 / service
            :ARG0-of (s3 / support-01
                  :ARG1 (a / audit-01
                        :ARG1 (a2 / algorithm)))
            :example (a3 / and
                  :op1 (t3 / toolkit
                        :mod (f2 / fairness
                              :mod (a4 / artificial))
                        :ARG1-of (d / describe-01
                              :ARG0 (p / publication
                                    :ARG1-of (c / cite-01
                                          :ARG2 (a5 / and
                                                :op1 225
                                                :op2 228)))))
                  :op2 (p2 / publication
                        :name (n / name
                              :op1 "Audit-AI")
                        :ARG1-of (d2 / describe-01
                              :ARG0 (p3 / publication
                                    :name (n2 / name
                                          :op1 "Pymetrics")
                                    :ARG1-of (c2 / cite-01
                                          :ARG2 29))))
                  :op3 (f3 / flow-01
                        :ARG1 (f4 / fairness)
                        :mod (p4 / publication
                              :name (n3 / name
                                    :op1 "Facebook's"))
                        :ARG1-of (d3 / describe-01
                              :ARG0 (p5 / publication
                                    :name (n4 / name
                                          :op1 "Weapons"
                                          :op2 "of"
                                          :op3 "Math"
                                          :op4 "Destruction:"
                                          :op5 "How"
                                          :op6 "Big"
                                          :op7 "Data"
                                          :op8 "Increase"
                                          :op9 "Inequality"
                                          :op10 "and"
                                          :op11 "Threatens"
                                          :op12 "Democracy"))))
                  :op4 (o / organization
                        :name (n5 / name
                              :op1 "ORCAA")
                        :ARG1-of (d4 / describe-01
                              :ARG0 (p6 / publication
                                    :ARG1-of (s4 / set-up-03
                                          :ARG0 (p7 / person
                                                :name (n6 / name
                                                      :op1 "Cathy"
                                                      :op2 "O'Neil")
                                                :ARG0-of (a6 / author-01
                                                      :ARG1 (b / book
                                                            :name (n7 / name
                                                                  :op1 "Algorithms"
                                                                  :op2 "Audit"
                                                                  :op3 "Company")))
                                                :ARG1-of (a7 / award-01)
                                                :ARG2-of a7)))
                              :ARG1-of (d5 / describe-01
                                    :ARG0 (p8 / publication
                                          :ARG1-of (c3 / cite-01
                                                :ARG2 53)))))))
      :mod (p9 / primary))

# ::snt FAT* (Fairness, Accountability and Transparency)[2 32]; AIES (Artificial Intelligence, Ethics and  Society)[2 33].
# File 78

(a / and
      :op1 (p / publication
            :ARG1-of (c / cite-01
                  :ARG2 32)
            :ARG1-of (m / mean-01
                  :ARG2 (a2 / and
                        :op1 (f / fairness)
                        :op2 (a3 / accountable-02)
                        :op3 (t / transparency))))
      :op2 (p2 / publication
            :ARG1-of (c2 / cite-01
                  :ARG2 33)
            :ARG1-of (m2 / mean-01
                  :ARG2 (a4 / and
                        :op1 (ii / intelligent-01
                              :mod (a5 / artificial))
                        :op2 (e / ethics)
                        :op3 (s / society)))))

# ::snt Perhaps due to internal pressure, increasing public awareness, the threat of government regulation,  and/or a genuine recognition of the issues machine learning poses to social fairness, major  companies, including Amazon, Facebook, Google [2 54], IBM [2 55], and Microsoft, have introduced  or announced open source tools for detecting systems for bias or unfairness in systems [2 56].
# File 78

(o / or
      :op1 (ii / introduce-02
            :ARG0 (c / company
                  :ARG1-of (m / major-02)
                  :ARG2-of (ii2 / include-01
                        :ARG1 (a / and
                              :op1 (c2 / company
                                    :name (n / name
                                          :op1 "Amazon"))
                              :op2 (c3 / company
                                    :name (n2 / name
                                          :op1 "Facebook"))
                              :op3 (c4 / company
                                    :name (n3 / name
                                          :op1 "Google"))
                              :op4 (c5 / company
                                    :name (n4 / name
                                          :op1 "IBM")
                                    :ARG1-of (d / describe-01
                                          :ARG0 (p / publication
                                                :ARG1-of (c6 / cite-01
                                                      :ARG2 54))))
                              :op5 (c7 / company
                                    :name (n5 / name
                                          :op1 "Microsoft")
                                    :ARG1-of (d2 / describe-01
                                          :ARG0 (p2 / publication
                                                :ARG1-of (c8 / cite-01
                                                      :ARG2 55)))))))
            :ARG1 (t / tool
                  :ARG0-of (d3 / detect-01
                        :ARG1 (o2 / or
                              :op1 (b / bias-01
                                    :ARG1 (s / system))
                              :op2 (f / fair-01
                                    :polarity -
                                    :location (s2 / system))))
                  :mod (s3 / source
                        :ARG1-of (o3 / open-04))))
      :op2 (a2 / announce-01
            :ARG0 c
            :ARG1 t)
      :ARG1-of (c9 / cause-01
            :ARG0 (a3 / and
                  :op1 (p3 / pressure-01
                        :ARG1 c
                        :ARG1-of (ii3 / internal-02))
                  :op2 (ii4 / increase-01
                        :ARG1 (r / realize-01
                              :ARG0 (p4 / public)))
                  :op3 (t2 / threaten-01
                        :ARG1 (r2 / regulate-01
                              :ARG0 (g / government-organization
                                    :ARG0-of (g2 / govern-01))))
                  :op4 (r3 / recognize-02
                        :ARG0 c
                        :ARG1 (p5 / pose-02
                              :ARG0 (l / learn-01
                                    :ARG1 (m2 / machine))
                              :ARG1 (ii5 / issue-02
                                    :ARG0 l)
                              :ARG2 (f2 / fair-01
                                    :mod (s4 / society))))
                  :mod (g3 / genuine))))

# ::snt Cathy O’Neil’s  'ORCAA ' Algorithmic  Auditing Company has recently started to offer ' algorithmic accuracy, bias & fairness ' certification  [258], but certification of algorithmic systems has not yet acquired significant mainstream support.
# File 78

(h / have-concession-91
      :ARG1 (s / start-01
            :ARG0 (c / company
                  :name (n / name
                        :op1 "Cathy"
                        :op2 "O'Neil's"
                        :op3 "ORCAA"
                        :op4 "Algorithmic"
                        :op5 "Auditing"
                        :op6 "Company"))
            :ARG1 (o / offer-01
                  :ARG0 c
                  :ARG1 (c2 / certify-01
                        :ARG1 (s2 / system
                              :mod (a / algorithm))
                        :ARG2 (a2 / and
                              :op1 (a3 / accuracy
                                    :mod a)
                              :op2 (b / bias-01
                                    :ARG0 s2)
                              :op3 (f / fair-01
                                    :ARG0 s2))))
            :time (r / recent))
      :ARG2 (a4 / acquire-01
            :polarity -
            :ARG0 (c3 / certify-01
                  :ARG1 s2)
            :ARG1 (s3 / support-01
                  :ARG1 c3
                  :ARG1-of (s4 / significant-02)
                  :ARG1-of (m / mainstream-02))
            :time (y / yet))
      :ARG1-of (d / describe-01
            :ARG0 (p / publication
                  :ARG1-of (c4 / cite-01
                        :ARG2 258))))

# ::snt Several experts have proposed the use of counterfactuals as a way to assess the fairness of machine  learning systems without requiring explanations.
# File 78

(p / propose-01
      :ARG0 (p2 / person
            :ARG1-of (e / expert-01)
            :quant (s / several))
      :ARG1 (u / use-01
            :ARG1 (c / counterfactual)
            :ARG2 (a / assess-01
                  :ARG1 (f / fair-01
                        :ARG1 (s2 / system
                              :instrument-of (l / learn-01
                                    :mod (m / machine))))
                  :manner (r / require-01
                        :polarity -
                        :ARG1 (e2 / explain-01)))))

# ::snt This is in fact the default for AI that is not making classifications or predictions that  have an immediate impact on fairness.
# File 78

(d / default-01
      :ARG1 (ii / intelligent-01
            :mod (a / artificial)
            :ARG0-of (m / make-01
                  :polarity -
                  :ARG1 (o / or
                        :op1 (c / classify-01)
                        :op2 (p / predict-01)
                        :ARG0-of (ii2 / impact-01
                              :ARG1 (f / fair-01)
                              :time (ii3 / immediate)))))
      :ARG2 (t / this)
      :mod (ii4 / in-fact))

# ::snt Optimisations always also ne ed to support critical societal values, such as fairness.
# File 78

(e / efficient-01
      :polarity -
      :ARG1 (o / optimize-01)
      :ARG2 (s / support-01
            :ARG0 o
            :ARG1 (v / value
                  :mod (s2 / society)
                  :ARG1-of (c / critical-02)
                  :example (f / fairness)))
      :time (a / always)
      :mod (a2 / also))

# ::snt Benefits to Vendors   AIAs would also benefit vendors that prioritise fairness, accountability, and transparency in their  offerings.
# File 78

(m / multi-sentence
      :snt1 (b / benefit-01
            :ARG1 (p / person
                  :ARG0-of (v / vend-01)))
      :snt2 (b2 / benefit-01
            :ARG0 (a / artificial-physical-03)
            :ARG1 (c / company
                  :ARG0-of (v2 / vend-01)
                  :ARG0-of (p2 / prioritize-01
                        :ARG1 (a2 / and
                              :op1 (f / fairness)
                              :op2 (a3 / accountable-02)
                              :op3 (t / transparency))
                        :ARG2 (o / offer-01
                              :ARG0 c)))
            :mod (a4 / also)))

# ::snt Datasheets requirement   The technical research community studying fairness, accountability, and transparency in machine  learning has begun to consider standard ways to acc ount for data and its history, biases, and skews.
# File 78

(m / multi-sentence
      :snt1 (r / require-01
            :ARG1 (d / dataset))
      :snt2 (b / begin-01
            :ARG0 (c / community
                  :ARG0-of (r2 / research-01
                        :mod (t / technical))
                  :ARG0-of (s / study-01
                        :ARG1 (a / and
                              :op1 (f / fairness)
                              :op2 (a2 / accountable-02)
                              :op3 (t2 / transparency)
                              :topic (l / learn-01
                                    :mod (m2 / machine)))))
            :ARG1 (c2 / consider-02
                  :ARG0 c
                  :ARG1 (w / way
                        :ARG1-of (s2 / standard-02)
                        :manner-of (a3 / accolor-01
                              :ARG1 (a4 / and
                                    :op1 (d2 / data)
                                    :op2 (h / history
                                          :poss d2)
                                    :op3 (b2 / bias
                                          :poss d2)
                                    :op4 (s3 / skewer
                                          :poss d2)))))))

# ::snt [25] Lawrence Lessig, ' Against Transparency ,' The New Republic, Oct. 9, 2009   https://newrepublic.com/article/70097/against -transparency   [26] Michael Kearns, Seth Neel, Aaron Roth, Zhiwei Steven Wu, ' Preventing Fairness Gerrymandering: Auditing  and Learning for Subgroup Fairness,'  Arxiv.org, Nov. 14, 2017 https://arxiv.org/abs/1711.05144   [27] Brent Mittelstadt, Sandra Wachter, ' Could Counterfactuals Explain Algorithmic Dec isions Without  Opening the Black Box? '
# File 78

(p / publication-91
      :ARG0 (p2 / person
            :name (n / name
                  :op1 "Lawrence"
                  :op2 "Lessig"))
      :ARG1 (p3 / publication
            :name (n2 / name
                  :op1 "Against"
                  :op2 "Transparency"))
      :ARG4 (n3 / newspaper
            :name (n4 / name
                  :op1 "The"
                  :op2 "New"
                  :op3 "Republic"))
      :time (d / date-entity
            :day 9
            :month 10
            :year 2009)
      :medium (u / url-entity
            :value "https://newrepublic.com/article/70097/against-transparency")
      :ARG1-of (c / cite-01
            :ARG2 (p4 / publication
                  :ARG0 (a / and
                        :op1 (p5 / person
                              :name (n5 / name
                                    :op1 "Michael"
                                    :op2 "Kearns"))
                        :op2 (p6 / person
                              :name (n6 / name
                                    :op1 "Seth"
                                    :op2 "Neel"))
                        :op3 (p7 / person
                              :name (n7 / name
                                    :op1 "Aaron"
                                    :op2 "Roth"))
                        :op4 (p8 / person
                              :name (n8 / name
                                    :op1 "Zhiwei"
                                    :op2 "Steven"
                                    :op3 "Wu")))
                  :ARG1 (p9 / publication
                        :name (n9 / name
                              :op1 "Preventing"
                              :op2 "Fairness"
                              :op3 "Gerrymandering"
                              :op4 ":"
                              :op5 ":"
                              :op6 "Audit"
                              :op7 "and"
                              :op8 "Learning"
                              :op9 "for"
                              :op10 "Subgroup"
                              :op11 "Fairness"))
                  :ARG4 (p10 / publication
                        :name (n10 / name
                              :op1 "Arxiv.org"))
                  :ARG1-of (c2 / cite-01
                        :ARG2 (a2 / and
                              :op1 (p11 / person
                                    :name (n11 / name
                                          :op1 "Brent"
                                          :op2 "Mittelstadt"))
                              :op2 (p12 / person
                                    :name (n12 / name
                                          :op1 "Sandra"
                                          :op2 "Wachter"))))))
      :ARG4 p10
      :ARG1-of (c3 / cite-01
            :ARG2 (p13 / publication
                  :ARG0-of (d2 / describe-01
                        :ARG1 (p14 / possible-01
                              :ARG1 (e / explain-01
                                    :ARG0 (c4 / counterfactual)
                                    :ARG1 (f / fallacy
                                          :mod (a3 / algorithm))
                                    :manner (o / open-01
                                          :polarity -
                                          :ARG1 (b / box
                                                :ARG1-of (b2 / black-04))))
                              :polarity (a4 / amr-unknown))))))

# ::snt On the (im)possibility of fairness.
# File 78

(p / possible-01
      :ARG1 (f / fairness)
      :polarity (a / amr-unknown))

# ::snt Justice as fairness: A restatement.
# File 78

(r / restat-01
      :ARG1 (j / justice
            :prep-as (f / fairness)))

# ::snt In Proceedings of the 1st Conference on Fairness, Accountability and Transparency:  PMLR 81 ( pp.
# File 78

(p / publication-91
      :ARG7 81
      :ARG1 (p2 / Proceedings
            :mod (c / conference
                  :name (n / name
                        :op1 "Conference"
                        :op2 "on"
                        :op3 "Fairness"
                        :op4 "Accountability"
                        :op5 "and"
                        :op6 "Transparency")
                  :ord (o / ordinal-entity
                        :value 1)))
      :ARG4 (j / journal
            :name (n2 / name
                  :op1 "MPLR")))

# ::snt A  unified approach to quantifying algorith mic unfairness: Measuring individual & group unfairness via  inequality indices.
# File 78

(a / approach-02
      :ARG1 (q / quantify-01
            :ARG1 (f / fair-01
                  :polarity -
                  :mod (p / product
                        :name (n / name
                              :op1 "Algorithmic"
                              :op2 "Mic"))))
      :ARG1-of (m / mean-01
            :ARG2 (m2 / measure-01
                  :ARG1 (f2 / fair-01
                        :polarity -
                        :ARG1 (ii / individual)
                        :ARG1-of (g / group-01))
                  :instrument (ii2 / index
                        :mod (e / equal-01
                              :polarity -))))
      :ARG1-of (u / unify-01))

# ::snt 'Fairness through  awareness. '
# File 78

(f / fairness
      :manner (r / realize-01))

# ::snt Fairness in criminal justice  risk assessments: the state of the art. '
# File 78

(s / state
      :mod (a / art)
      :domain (a2 / and
            :op1 (f / fairness
                  :topic (j / justice
                        :ARG0-of (c / criminal-03)))
            :op2 (a3 / assess-01
                  :ARG1 (r / risk-01))))

# ::snt Beyond distributive fairness in  algorithm ic decision -making: Feature selection for procedurally fair learning.
# File 78

(a / and
      :op1 (b / beyond
            :op1 (f / fairness
                  :mod (d / distributive)
                  :prep-in (m / make-18
                        :ARG1 (d2 / decide-01)
                        :mod (a2 / algorithm))))
      :op2 (s / select-01
            :ARG1 (f2 / feature)
            :purpose (l / learn-01
                  :ARG1-of (f3 / fair-01
                        :manner (p / procedure)))))

# ::snt The accuracy, fairness, and limits of predicting recidivism.
# File 78

(a / and
      :op1 (a2 / accurate)
      :op2 (f / fair-01)
      :op3 (l / limit-01
            :ARG1 (p / predict-01
                  :ARG1 (r / recidivism))))

# ::snt Fairness in Decision -Making– The Causal Explanation Formula. '
# File 78

(m / multi-sentence
      :snt1 (f / fairness
            :topic (m2 / make-18
                  :ARG1 (d / decide-01)))
      :snt2 (t / thing
            :name (n / name
                  :op1 "The"
                  :op2 "Causal"
                  :op3 "Explaining"
                  :op4 "Formula")))

# ::snt A governance framework for algorithmic accountability and transparency      87 [174]  'Awesom -machine -learning -interpretability ', list of open source tools for machine learning  interpretability hosted on GitHub https://github.com/jphall663/awesome- machine -learning -interpretability    [175]  IBM Research Trusted AI, ' AI Fairness 360 Open Source Toolkit ', http://aif360.mybluemix.net/    [176]  Chiandussi, G., Codegone, M., Ferrero, S. and Varesio, F.E., 2012.
# File 78

(f / framework
      :purpose (g / govern-01)
      :purpose (a / and
            :op1 (a2 / accountable-02
                  :mod (a3 / algorithmic))
            :op2 (t / transparency))
      :ARG1-of (d / describe-01
            :ARG0 (p / publication
                  :ARG0-of (c / cite-01
                        :ARG2 87)
                  :ARG1-of (c2 / cite-01
                        :ARG2 174)
                  :ARG1-of (t2 / title-01
                        :ARG2 (a4 / and
                              :op1 (p2 / publication
                                    :name (n / name
                                          :op1 "Awesom -machine -learning -interpretability"))
                              :op2 (p3 / publication
                                    :name (n2 / name
                                          :op1 "Codegone"))
                              :op3 (p4 / publication
                                    :name (n3 / name
                                          :op1 "Ferrero"))
                              :op4 (p5 / publication
                                    :name (n4 / name
                                          :op1 "Varesio")
                                    :ARG1-of (t3 / title-01
                                          :ARG2 "F.E."))
                              :time (d2 / date-entity
                                    :year 2012))
                        :op5 (p6 / publication
                              :name (n5 / name
                                    :op1 "IBM"
                                    :op2 "Research"
                                    :op3 "Trusted"
                                    :op4 "AI"))
                        :op6 (p7 / publication
                              :name (n6 / name
                                    :op1 "Open"
                                    :op2 "Source"
                                    :op3 "Toolkit")
                              :ARG1-of (t4 / title-01
                                    :ARG2 360)))))
      :ARG1-of (h / host-01
            :location (u / url-entity
                  :value "https://github.com/jphall663/awesome- machine-learning-interpretability")))

# ::snt CNE T. Accessed on: 28 September  2018. https://www.cnet.com/news/facebook -starts -building- ai-with -an-ethical -compass/   [231] O’Neil Risk Consulting & Algorithmic A uditing, Accessed on: 28 September 2018.  http://www.oneilrisk.com/   [232] ACM Conference on Fairness, Accountability, and Transparency (ACM FAT*), Accessed on: 28 September  2018, http://fatconference.org/
# File 78

(m / multi-sentence
      :snt1 (p / publication
            :name (n / name
                  :op1 "CNE"
                  :op2 "T.")
            :ARG1-of (a / access-01
                  :time (d / date-entity
                        :day 28
                        :month 9
                        :year 2018)))
      :snt2 (p2 / publication
            :name (n2 / name
                  :op1 "ACM"
                  :op2 "Conference"
                  :op3 "on"
                  :op4 "Fairness"
                  :op5 "and"
                  :op6 "Accountability"
                  :op7 "and"
                  :op8 "Transparency")
            :ARG1-of (a2 / access-01
                  :time d
                  :location (u / url-entity
                        :value "http://fatconference.cnet.com/")))
      :snt3 (p3 / publication
            :name (n3 / name
                  :op1 "O'Neil"
                  :op2 "Risk"
                  :op3 "Consulting"
                  :op4 "&"
                  :op5 "Algorithmic"
                  :op6 "A"
                  :op7 "Uditing")
            :ARG1-of (a3 / access-01
                  :time (d2 / date-entity
                        :day 28
                        :month 9
                        :year 2018))
            :ARG1-of (c / cite-01
                  :ARG2 231)))

# ::snt Access, fairness and accountability in the  law of search ', Cornell Law Review, Vol.
# File 78

(p / publication-91
      :ARG4 (j / journal
            :name (n / name
                  :op1 "Cornell"
                  :op2 "Law"
                  :op3 "Review")
            :mod (v / vol))
      :ARG7 (a / and
            :op1 (a2 / access-01)
            :op2 (f / fairness)
            :op3 (a3 / accountable-02)
            :topic (l / law
                  :topic (s / search-01))))

# ::snt 11  Sept. 2018.  https://ai.googleblog.com/2018/09/the -what -if-tool- code -free -probing -of.html   [255] AI Fairness 360 Open Source Toolkit, IBM, Accessed on: 28 Septemb er 2018.  https://aif360.mybluemix.net/    [256] Teich, Paul.
# File 78

(m / multi-sentence
      :snt1 (d / date-entity
            :month 9
            :day 11
            :year 2018)
      :snt2 (u / url-entity
            :value "https://ai.googleblog.com/2018/09/the-what-if-tool- code-free -probing -of.html")
      :snt3 (p / publication
            :name (n / name
                  :op1 "IBM"
                  :op2 "Fairness"
                  :op3 360
                  :op4 "Open"
                  :op5 "Source"
                  :op6 "Toolkit")
            :ARG1-of (c / cite-01
                  :ARG2 255)
            :ARG1-of (a / access-01
                  :time (d2 / date-entity
                        :day 28
                        :month 9
                        :year 2018)))
      :snt4 (u2 / url-entity
            :value "https://aif360.mybluemix.net/"
            :ARG1-of (c2 / cite-01
                  :ARG2 (p2 / person
                        :name (n2 / name
                              :op1 "Teich")))))

# ::snt 'Artificial Intelligence Can Reinforce Bias, Cloud Giants Announce Tools For AI Fairness. '
# File 78

(a / and
      :op1 (p / possible-01
            :ARG1 (r / Reinforce-01
                  :ARG0 (ii / intelligent-01
                        :mod (a2 / artificial))
                  :ARG1 (b / bias-01)))
      :op2 (a3 / announce-01
            :ARG0 (c / company
                  :name (n / name
                        :op1 "Cloud"
                        :op2 "Giant"))
            :ARG1 (t / tool
                  :purpose (f / fairness
                        :mod ii))))

# ::snt Forbes, 24 Sept. 2018.  https://www.forbes.com/sites/paulteich/2018/09/24/artificial -intelligence -canrein force -bias -cloud -giants -announce -tools -for-ai-fairness/#362f66cc9d21   [257] Anderson, Ronald E. 'ACM code of ethics and professional conduct. '
# File 78

(p / publication-91
      :ARG0 (p2 / person
            :name (n / name
                  :op1 "Ronald"
                  :op2 "E."
                  :op3 "Anderson"))
      :ARG1 (c / code
            :mod (e / ethics)
            :mod (c2 / conduct-02
                  :ARG1 (p3 / professional))
            :mod (o / organization
                  :name (n2 / name
                        :op1 "ACM")))
      :ARG4 (m / magazine
            :name (n3 / name
                  :op1 "Forbes"))
      :time (d / date-entity
            :day 24
            :month 9
            :year 2018)
      :medium (u / url-entity
            :value "https://www.forbes.com/sites/paulteich/2018/09/24/artificial-intelligence-canrein-force-bias-cloud-giants-announce-tools-for-ai-fairness/#362f66cc9d21"))

# ::snt A governance framework for algorithmic accountability and transparency      95 [334] Elvira Perez Vallejos, Ansgar Koene, Virginia Portillo, Liz Dowthwai te and Monica Cano, ' Young people’s  policy recommendations on algorithm fairness ', in Proceedings of the 2017 ACM on Web Science Conference,  Pages 247- 251 ISBN: 978- 1-4503- 4896- 6 DOI: 10.1145/3091478.3091512   [335] Eslami, M., Rickman, A., Vaccaro, K., Aley asen, A., Vuong, A., Karahalios, K., .
# File 78

(f / framework
      :purpose (g / govern-01)
      :beneficiary (a / and
            :op1 (a2 / accountable-02
                  :mod (a3 / algorithmic))
            :op2 (t / transparency))
      :ARG1-of (d / describe-01
            :ARG0 (p / publication-91
                  :ARG0 (a4 / and
                        :op1 (p2 / person
                              :name (n / name
                                    :op1 "Elvira"
                                    :op2 "Perez"
                                    :op3 "Vallejos"))
                        :op2 (p3 / person
                              :name (n2 / name
                                    :op1 "Ansgar"
                                    :op2 "Koene"))
                        :op3 (p4 / person
                              :name (n3 / name
                                    :op1 "Virginia"
                                    :op2 "Portillo"))
                        :op4 (p5 / person
                              :name (n4 / name
                                    :op1 "Liz"
                                    :op2 "Dowthwai"
                                    :op3 "Te"))
                        :op5 (p6 / person
                              :name (n5 / name
                                    :op1 "Monica"
                                    :op2 "Cano")))
                  :ARG1 (p7 / publication
                        :name (n6 / name
                              :op1 "Young"
                              :op2 "People's"
                              :op3 "Policy"
                              :op4 "Advices"
                              :op5 "on"
                              :op6 "Algorithm"
                              :op7 "Fairt"))
                  :ARG4 (c / conference
                        :name (n7 / name
                              :op1 "ACM"
                              :op2 "on"
                              :op3 "Web"
                              :op4 "Science"
                              :op5 "Conference")
                        :time (d2 / date-entity
                              :year 2017))
                  :ARG7 (p8 / page
                        :mod (v / value-interval
                              :op1 247
                              :op2 251))
                  :ARG1-of (c2 / cite-01
                        :ARG2 (a5 / and
                              :op1 (p9 / person
                                    :name (n8 / name
                                          :op1 "Eslami"))
                              :op2 (p10 / person
                                    :name (n9 / name
                                          :op1 "Rickman"))
                              :op3 (p11 / person
                                    :name (n10 / name
                                          :op1 "Vaccaro"))
                              :op4 (p12 / person
                                    :name (n11 / name
                                          :op1 "Aley"
                                          :op2 "Asen"))
                              :op5 (p13 / person
                                    :name (n12 / name
                                          :op1 "Vuong"))
                              :op6 (p14 / person
                                    :name (n13 / name
                                          :op1 "Karahalios"))))
                  :ARG4 (j / journal
                        :name (n14 / name
                              :op1 "The"
                              :op2 "Student"
                              :op3 "Room"))
                  :ARG7 v
                  :op1 9
                  :op2 1145)))

# ::snt 5 (2016): 14- 19.  http://onlinelibrary.wiley.com/doi/10.1111/j.1740- 9713.2016.00960.x/full    [468] Conference on Fairness, Accountability, and Transparency, https://fatconference.org  .
# File 78

(c / conference
      :mod 484
      :topic (a / and
            :op1 (f / fairness)
            :op2 (a2 / accountable-02)
            :op3 (t / transparency))
      :time (d / date-entity
            :year 2016)
      :ARG1-of (c2 / cite-01
            :ARG2 (b / between
                  :op1 14
                  :op2 19.5))
      :medium (u / url-entity
            :value "http://onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.00960.x/full"))

# ::snt Big  Data & Society 3(1)  [559] Elvira Perez Vallejos, Ansgar Koene, Virginia Portillo, Liz Dowthwaite and Monica Cano, ' Young people’s  policy recommendations on algorithm fairness ', in Proceedings of the 2017 ACM on Web Science Conference,  Pages 247- 251 ISBN: 978- 1-4503- 4896- 6 DOI: 10.1145/3091478.3091512   [560] Eslami, M., Rickman, A., Vaccaro, K., Aleyasen, A., Vuong, A., Karahalios, K., .
# File 78

(p / publication-91
      :ARG5 559
      :ARG1 (p2 / publication
            :name (n / name
                  :op1 "Big"
                  :op2 "Data"
                  :op3 "&"
                  :op4 "Society")
            :ARG1-of (d / describe-01
                  :ARG0 (a / and
                        :op1 (p3 / person
                              :name (n2 / name
                                    :op1 "Elvira"
                                    :op2 "Vallejos"))
                        :op2 (p4 / person
                              :name (n3 / name
                                    :op1 "Ansgar"
                                    :op2 "Koene"))
                        :op3 (p5 / person
                              :name (n4 / name
                                    :op1 "Virginia"
                                    :op2 "Portillo"))
                        :op4 (p6 / person
                              :name (n5 / name
                                    :op1 "Liz"
                                    :op2 "Dowthwaite"))
                        :op5 (p7 / person
                              :name (n6 / name
                                    :op1 "Monica"
                                    :op2 "Cano")))
                  :ARG1 (r / recommend-01
                        :ARG0 (p8 / person
                              :mod (y / young))
                        :ARG1 (p9 / policy-01
                              :ARG2 (f / fair-01
                                    :ARG1 (a2 / algorithm)))))
            :ARG1-of d
            :ARG0 p2
            :name (n7 / name
                  :op1 "ACM"
                  :op2 "on"
                  :op3 "Web"
                  :op4 "Science"
                  :op5 "Conference")
            :time (d2 / date-entity
                  :year 2017))
      :ARG7 a
      :op1 (p10 / page
            :mod (v / value-interval
                  :op1 247
                  :op2 251))
      :op2 (p11 / page
            :mod v
            :ARG1-of (v2 / value-interval
                  :op1 "978-1-4503-"))
      :op3 (p12 / page
            :mod v2
            :ARG1-of (v3 / value-interval
                  :op1 10.1145)))

# ::snt Achieving Fairness through Adversarial Learning:  an Application to Recidivism Prediction. '
# File 78

(a / achieve-01
      :ARG1 (f / fairness)
      :manner (l / learn-01
            :manner (a2 / adversary)
            :ARG1-of (m / mean-01
                  :ARG2 (a3 / apply-01
                        :ARG1 l
                        :ARG2 (p / predict-01
                              :ARG1 (r / recidivism))))))

# ::snt Fairness  beyond disparate treatment & disparate impact: Learning classification without disparate mistreatment. '
# File 78

(b / beyond
      :op1 (a / and
            :op1 (t / treat-01
                  :mod (d / disparate))
            :op2 (ii / impact-01
                  :mod (d2 / disparate)))
      :domain (f / fair-01
            :ARG1-of (m / mean-01
                  :ARG2 (l / learn-01
                        :ARG1 (c / classify-01)
                        :manner (m2 / mistreat-01
                              :polarity -
                              :mod (d3 / disparate))))))

# ::snt PE650.508v02-00 6/130 RR\1215422EN.docx ENto increase businesses' productivity levels and contribute to efficiency gains; whereas  innovation programs in this area can enable regional clusters to thrive;  G. whereas the Union and its Member States have a particular responsibility to harness,  promote and enhance the added value of artificial intelligence and make sure that AI  technologies are safe and contribute to the well-being and general interest of their  citizens as they can make a huge contribution to reaching the common goal of  improving the lives of citizens and fostering prosperity within the Union by contributing  to the development of better strategies and innovation in a number of areas and sectors;  whereas, in order to exploit the full potential of artificial intelligence and make users  aware of the benefits and challenges that AI technologies bring,  it is necessary to  include AI or digital literacy in education and training, including in terms of promoting  digital inclusion, and to conduct information campaigns at Union level that give an  accurate representation of all aspects of AI development; H. whereas a common Union regulatory framework for the development, deployment and  use of artificial intelligence, robotics and related technologies (‘regulatory framework  for AI’) should allow citizens to share the benefits drawn from their potential, while  protecting citizens from the potential risks of such technologies and promoting the  trustworthiness of such technologies in the Union and elsewhere; whereas that  framework should be based on Union law and values and guided by the principles of  transparency and explainability, fairness, accountability and responsibility; I. whereas such a regulatory framework is of key importance in avoiding the  fragmentation of the Internal Market, resulting from differing national legislation and  will help foster much needed investment, develop data infrastructure and support  research; whereas it should consist of common legal obligations and ethical principles  as set out in the proposal for a Regulation requested in the annex to this resolution;  whereas it should be established according to the better regulation guidelines; J. whereas the Union has a strict legal framework in place to ensure, inter alia, the  protection of personal data and privacy and non-discrimination, to promote gender  equality, environmental protection and consumers’ rights; whereas such a legal  framework consisting of an extensive body of horizontal and sectoral legislation ,  including the existing rules on product safety and liability, will continue to apply in  relation to artificial intelligence, robotics and related technologies, although certain  adjustments of specific legal instruments may be necessary to reflect the digital  transformation and address new challenges posed by the use of artificial intelligence; K. whereas there are concerns that the current Union legal framework, including the  consumer law and employment and social acquis, data protection legislation, product  safety and market surveillance legislation, as well as antidiscrimination legislation may  no longer be fit for purpose to effectively tackle the risks created by artificial  intelligence, robotics and related technologies; L. whereas in addition to adjustments to existing legislation, legal and ethical questions  relating to AI technologies should be addressed through an effective, comprehensive  and future-proof regulatory framework of Union law reflecting the Union’s principles  and values as enshrined in the Treaties and the Charter of Fundamental Rights that
# File 87

(m / multi-sentence
      :snt1 (a / and
            :op1 (c / concern-01
                  :ARG0 (p / possible-01
                        :ARG1 (f / fit-06
                              :ARG1 (f2 / framework
                                    :ARG1-of (s / share-01
                                          :ARG0 (c2 / citizen)
                                          :ARG2 (p2 / potential
                                                :mod (a2 / artificial))))
                              :ARG2 (a3 / and
                                    :op1 (p3 / protect-01
                                          :ARG1 c2
                                          :ARG2 (r / risk-01
                                                :ARG0 (t / technology
                                                      :mod (a4 / artificial))))
                                    :op2 (p4 / promote-02
                                          :ARG1 (w / worth-02
                                                :ARG1 (t2 / technology
                                                      :mod (a5 / artificial)))))
                              :location (a6 / and
                                    :op1 (o / organization
                                          :name (n / name
                                                :op1 "European"
                                                :op2 "Union"))
                                    :op2 (o2 / organization
                                          :name (n2 / name
                                                :op1 "European"
                                                :op2 "Union"))))
                        :time (n3 / no-longer)))
            :op2 (r2 / recommend-01
                  :ARG1 (a7 / and
                        :op1 (b / base-02
                              :ARG1 f2
                              :ARG2 (a8 / and
                                    :op1 (l / law
                                          :mod o)
                                    :op2 (v / value
                                          :poss o)))
                        :op2 (g / guide-01
                              :ARG0 (p5 / principle
                                    :topic (a9 / and
                                          :op1 (t3 / transparency)
                                          :op2 (f3 / fairness)
                                          :op3 (a10 / accountable-02)
                                          :op4 (r3 / responsible-02)))
                              :ARG1 f2))))
      :snt2 (c3 / contrast-01
            :ARG2 (a11 / and
                  :op1 (p6 / possible-01
                        :ARG1 (e / enable-01
                              :ARG0 (p7 / program
                                    :mod (ii / innovate-01)
                                    :mod (a12 / area))
                              :ARG1 (t4 / thrive-01
                                    :ARG1 (c4 / cluster
                                          :mod (r4 / region))))
                        :op2 (h / help-01
                              :ARG0 p7
                              :ARG1 (a13 / and
                                    :op1 (ii2 / invest-01)
                                    :op2 (d / develop-02
                                          :ARG1 (ii3 / infrastructure
                                                :mod (d2 / data)))
                                    :op3 (s2 / support-01
                                          :ARG1 (r5 / research-01)))))))
      :snt3 (c5 / contrast-01
            :ARG2 (h2 / have-03
                  :ARG1 (f4 / framework
                        :mod (s3 / strict)
                        :mod (l2 / law)
                        :ARG1-of (r6 / reflect-01
                              :ARG2 (a14 / and
                                    :op1 (p8 / principle)
                                    :op2 v)
                              :poss (t5 / treaty
                                    :name (n4 / name
                                          :op1 "Charter"
                                          :op2 "of"
                                          :op3 " Fundamental"
                                          :op4 "Rights")))))))

# ::snt Believes that any new regulatory framework for AI consisting of legal obligations and  ethical principles for the development, deployment and use of artificial intelligence,  robotics and related technologies should fully respect the Charter and thereby respect  human dignity, autonomy and self-determination of the individual, prevent harm,  promote fairness, inclusion and transparency, eliminate biases and discrimination,  including as regards minority groups, and respect and comply with the principles of  limiting the negative externalities of technology used, of ensuring explainability of  technologies, and of guaranteeing that the technologies are there to serve people and not  replace or decide for them, with the ultimate aim of increasing every human being’s  well-being; 3.
# File 87

(b / believe-01
      :li 3
      :ARG1 (r / recommend-01
            :ARG1 (a / and
                  :op1 (r2 / respect-01
                        :ARG0 (f / framework
                              :mod (a2 / any)
                              :ARG1-of (n / new-01)
                              :ARG0-of (r3 / regulate-01
                                    :ARG1 (ii / intelligent-01
                                          :mod (a3 / artificial)))
                              :ARG1-of (c / consist-01
                                    :ARG2 (a4 / and
                                          :op1 (o / obligate-01
                                                :ARG1-of (l / legal-02))
                                          :op2 (p / principle
                                                :mod (e / ethics))
                                          :purpose (a5 / and
                                                :op1 (d / develop-02
                                                      :ARG1 ii)
                                                :op2 (d2 / deploy-01
                                                      :ARG1 ii)
                                                :op3 (u / use-01
                                                      :ARG1 ii)))))
                        :ARG1 (a6 / and
                              :op1 (d3 / dignity
                                    :mod (h / human))
                              :op2 (a7 / autonomy
                                    :poss (ii2 / individual))
                              :op3 (d4 / determine-01
                                    :ARG0 ii2
                                    :ARG1 ii2))
                        :degree (f2 / full))
                  :op2 (p2 / prevent-01
                        :ARG1 (h2 / harm-01))
                  :op3 (p3 / promote-02
                        :ARG1 (a8 / and
                              :op1 (f3 / fairness)
                              :op2 (ii3 / include-01)
                              :op3 (t / transparency)))
                  :op4 (e2 / eliminate-01
                        :ARG1 (a9 / and
                              :op1 (b2 / bias-01)
                              :op2 (d5 / discriminate-02))
                        :ARG2-of (ii4 / include-91
                              :ARG1 (g / group
                                    :mod (m / minority))))
                  :op5 (a10 / and
                        :op1 (r4 / respect-01
                              :ARG0 f
                              :ARG1 (p4 / principle
                                    :topic (a11 / and
                                          :op1 (l2 / limit-01
                                                :ARG1 (e3 / externality
                                                      :ARG1-of (n2 / negative-02)
                                                      :poss (t2 / technology
                                                            :ARG1-of (u2 / use-01))))
                                          :op2 (e4 / ensure-01
                                                :ARG1 (e5 / explain-01
                                                      :ARG1 t2))))
                              :op2 (g2 / guarantee-01
                                    :ARG1 (b3 / be-located-at-91
                                          :ARG1 t2
                                          :ARG2 (t3 / there)
                                          :purpose (s / serve-01
                                                :ARG0 t2
                                                :ARG2 (p5 / person)
                                                :ARG1-of (ii5 / instead-of-91
                                                      :ARG2 (o2 / or
                                                            :op1 (r5 / replace-01
                                                                  :ARG1 p5)
                                                            :op2 (d6 / decide-01
                                                                  :ARG0 t2
                                                                  :ARG3 p5))))))))
                  :ARG1-of (c2 / cause-01
                        :ARG0 (a12 / aim-01
                              :ARG1 (ii6 / increase-01
                                    :ARG1 (w / well-09
                                          :ARG1 (b4 / being
                                                :mod (h3 / human
                                                      :mod (e6 / every)))))
                              :mod (u3 / ultimate))))))

# ::snt Maintains that ethical values of fairness, accuracy, confidentiality and transparency should  be the basis of these technologies, which in this context entails that their operations should  be such that they do not generate biased outputs; 33.
# File 87

(a / and
      :li 33
      :op1 (m / maintain-01
            :ARG1 (r / recommend-01
                  :ARG1 (b / base-02
                        :ARG1 (t / technology
                              :mod (t2 / this))
                        :ARG2 (v / value
                              :mod (e / ethics)
                              :example (a2 / and
                                    :op1 (f / fairness)
                                    :op2 (a3 / accuracy)
                                    :op3 (c / confidentiality)
                                    :op4 (t3 / transparency))))
                  :ARG0-of (e2 / entail-01
                        :ARG1 (r2 / recommend-01
                              :ARG1 (g / generate-01
                                    :polarity -
                                    :ARG0 (o / operate-01
                                          :ARG0 (t4 / they))
                                    :ARG1 (o2 / output
                                          :ARG1-of (b2 / bias-01))))
                        :location (c2 / context
                              :mod (t5 / this))))))

# ::snt Is of the opinion that effective cross-border cooperation and ethical standards can be  achieved only if all stakeholders commit to ensure human agency and oversight,  technical robustness and safety, transparency and accountability, diversity, nondiscrimination and fairness, societal and environmental well-being, and respect the  established principles of privacy, data governance and data protection, specifically those  enshrined in Regulation (EU) 2016/679 of the European Parliament and of the Council; 138.
# File 87

(o / opine-01
      :ARG1 (p / possible-01
            :ARG1 (a / achieve-01
                  :ARG1 (a2 / and
                        :op1 (c / cooperate-01
                              :ARG0-of (e / effective-04)
                              :ARG0-of (c2 / cross-02
                                    :ARG1 (b / border)))
                        :op2 (s / standard
                              :mod (e2 / ethics))))
            :condition (c3 / commit-01
                  :ARG0 (s2 / stake-01
                        :mod (a3 / all))
                  :ARG1 (e3 / ensure-01
                        :ARG0 s2
                        :ARG1 (a4 / and
                              :op1 (a5 / agency
                                    :mod (h / human))
                              :op2 (o2 / oversee-01
                                    :ARG0 h)
                              :op3 (a6 / and
                                    :op1 (r / robustness
                                          :mod (t / technical))
                                    :op2 (s3 / safe-01))
                              :op4 (a7 / and
                                    :op1 (t2 / transparency)
                                    :op2 (a8 / accountable-02))
                              :op5 (d / diversity)
                              :op6 (a9 / and
                                    :op1 (d2 / discriminate-02
                                          :polarity -)
                                    :op2 (f / fairness))
                              :op7 (a10 / and
                                    :op1 (w / well-05
                                          :ARG1 (s4 / society))
                                    :op2 (w2 / well-05
                                          :ARG1 (e4 / environment)))
                              :op8 (r2 / respect-01
                                    :ARG0 s2
                                    :ARG1 (p2 / principle
                                          :ARG1-of (e5 / establish-01)
                                          :topic (a11 / and
                                                :op1 (p3 / privacy)
                                                :op2 (g / govern-01
                                                      :ARG1 (d3 / data))
                                                :op3 (p4 / protect-01
                                                      :ARG1 d3))
                                          :ARG1-of (e6 / enshrine-01
                                                :ARG0 (a12 / and
                                                      :op1 (o3 / organization
                                                            :name (n / name
                                                                  :op1 "European"
                                                                  :op2 "Parliament"))
                                                      :op2 (o4 / organization
                                                            :name (n2 / name
                                                                  :op1 "Council")))
                                                :ARG1-of (s5 / specific-02))))))
                  :mod (o5 / only)))
      :ARG1-of (c4 / cite-01
            :ARG2 (l / law
                  :name (n3 / name
                        :op1 "Regulation"
                        :op2 "( organization_2 :name ( name_3 :op1 "))))

# ::snt (31) Artificial intelligence, robotics and related technologies should also be developed,  deployed and used with a view to supporting social inclusion, democracy, plurality,  solidarity, fairness, equality and cooperation and their potential in that context should  be maximized and explored through research and innovation projects.
# File 87

(r / recommend-01
      :li 31
      :ARG1 (a / and
            :op1 (d / develop-02
                  :ARG1 (a2 / and
                        :op1 (ii / intelligent-01
                              :mod (a3 / artificial))
                        :op2 (r2 / robot)
                        :op3 (t / technology
                              :ARG1-of (r3 / relate-01))))
            :op2 (d2 / deploy-01
                  :ARG1 a2)
            :op3 (u / use-01
                  :ARG1 a2)
            :mod (a4 / also)
            :purpose (s / support-01
                  :ARG1 (a5 / and
                        :op1 (ii2 / include-01
                              :ARG2 (s2 / society))
                        :op2 (d3 / democracy)
                        :op3 (p / plurality)
                        :op4 (s3 / solidarity)
                        :op5 (f / fairness)
                        :op6 (e / equal-01)
                        :op7 (c / cooperate-01))))
      :op2 (r4 / recommend-01
            :ARG1 (a6 / and
                  :op1 (m / maximize-01
                        :ARG1 (p2 / potential
                              :poss a2
                              :location (c2 / context
                                    :mod (t2 / that))))
                  :op2 (e2 / explore-01
                        :ARG1 p2
                        :manner (p3 / project
                              :mod (r5 / research-01)
                              :mod (ii3 / innovate-01))))))

# ::snt The Union and its Member States shall encourage research projects intended to provide  solutions, based on artificial intelligence, robotics and related technologies, that seek to  promote social inclusion, democracy, plurality, solidarity, fairness, equality and cooperation.
# File 87

(e / encourage-01
      :ARG0 (a / and
            :op1 (o / organization
                  :name (n / name
                        :op1 "Union"))
            :op2 (s / state
                  :ARG0-of (h / have-org-role-91
                        :ARG1 o
                        :ARG2 (m / member))))
      :ARG1 (p / project
            :mod (r / research)
            :ARG0-of (p2 / provide-01
                  :ARG1 (s2 / solution
                        :ARG1-of (b / base-02
                              :ARG2 (a2 / and
                                    :op1 (ii / intelligent-01
                                          :mod (a3 / artificial))
                                    :op2 (r2 / robot)
                                    :op3 (t / technology
                                          :ARG1-of (r3 / relate-01))))
                        :ARG0-of (s3 / seek-01
                              :ARG1 (p3 / promote-02
                                    :ARG0 s2
                                    :ARG1 (a4 / and
                                          :op1 (ii2 / include-01
                                                :ARG2 (s4 / society))
                                          :op2 (d / democracy)
                                          :op3 (p4 / plurality)
                                          :op4 (s5 / solidarity)
                                          :op5 (f / fairness)
                                          :op6 (e2 / equal-01)
                                          :op7 (c / cooperate-01)))))
                  :ARG1-of (ii3 / intend-01))))

# ::snt Considers that a value-sensitive design approach is strongly needed to create the conditions  for widespread social acceptance of AI for consumers; considers that ethical values of  fairness, accuracy, confidentiality and transparency should be the basis of AI, which in this  context entails that the system’s operations should be such that they do not generate unfairly  biased outputs; 11.
# File 87

(a / and
      :li 11
      :op1 (c / consider-01
            :ARG1 (n / need-01
                  :ARG1 (a2 / approach-02
                        :ARG1 (d / design-01
                              :ARG0-of (s / sensitive-03
                                    :ARG1 (v / value))))
                  :ARG1-of (s2 / strong-02)
                  :purpose (c2 / create-01
                        :ARG0 a2
                        :ARG1 (c3 / condition-01
                              :ARG1 (a3 / accept-01
                                    :ARG0 (p / person
                                          :ARG0-of (c4 / consume-01))
                                    :ARG1 (ii / intelligent-01
                                          :mod (a4 / artificial))
                                    :mod (s3 / society)
                                    :ARG1-of (s4 / spread-02
                                          :ARG1-of (w / wide-02)))))))
      :op2 (c5 / consider-01
            :ARG1 (r / recommend-01
                  :ARG1 (b / base-02
                        :ARG1 ii
                        :ARG2 (v2 / value
                              :mod (e / ethics)
                              :example (a5 / and
                                    :op1 (f / fairness)
                                    :op2 (a6 / accuracy)
                                    :op3 (c6 / confidentiality)
                                    :op4 (t / transparency)))
                        :ARG0-of (e2 / entail-01
                              :ARG1 (r2 / recommend-01
                                    :ARG1 (g / generate-01
                                          :polarity -
                                          :ARG0 (o / operate-01
                                                :ARG1 (s5 / system))
                                          :ARG1 (o2 / output
                                                :ARG1-of (b2 / bias-01
                                                      :ARG1-of (f2 / fair-01
                                                            :polarity -)))))
                              :location (c7 / context
                                    :mod (t2 / this)))))))

# ::snt RR\1215422EN.docx 85/130 PE650.508v02-00 ENautonomy, prevention of harm, fairness and explainability; whereas the respect of those ethical  principles necessitates adopting specific rules for the Union’s transport sector; E. whereas human error is still involved in about 95% of all road traffic accidents in the  Union; whereas the Union aimed to reduce annual road fatalities in the Union by 50% by 2020  compared to 2010, but, in view of stagnating progress, renewed its efforts in its Road Safety  Policy Framework 2021 - 2030 - Next steps towards "Vision Zero"; whereas in this regard, AI,  automation and other new technologies have great potential and vital importance for increasing  road safety by reducing the possibilities for human error; F. whereas AI, automation and other new technologies can also contribute to reducing  traffic congestion and emissions of greenhouse gases and air pollutants;  G. whereas the production of ethically responsible, human-centred and technologically  robust AI, robotics and related technologies in the transport sector present Union businesses,  including SMEs, with a business opportunity to become global leaders in this area;  H. whereas such new business opportunities can contribute to the recovery of Union  industry after the current health and economic crisis and to making greater use of AI technology  in the transport industry; whereas such opportunities will create new jobs, as the uptake of AI  and related technologies has the potential to increase businesses' productivity levels and  contribute to efficiency gains; whereas innovation programs in this area can enable regional  clusters to thrive;  I. whereas a European approach to the development of AI, robotics and related  technologies in transport has the potential to increase the global competitiveness and strategic  autonomy of the Union economy; J. whereas for sectors like public transport, AI systems for intelligent transport systems  can be used to minimise queuing, optimise routing, enable persons with disabilities to be more  independent, and increase energy efficiency thereby enhancing decarbonisation efforts and  reducing the environmental footprint;  1.
# File 87

(m / multi-sentence
      :snt1 (c / contrast-01
            :ARG2 (c2 / create-01
                  :ARG0 (o / opportunity
                        :mod (b / business)
                        :ARG1-of (n / new-01))
                  :ARG1 (j / job
                        :ARG1-of (n2 / new-01))
                  :ARG1-of (c3 / cause-01
                        :ARG0 (p / possible-01
                              :ARG1 (a / and
                                    :op1 (ii / increase-01
                                          :ARG0 (t / take-01
                                                :ARG1 (a2 / and
                                                      :op1 (ii2 / intelligent-01
                                                            :mod (a3 / artificial))
                                                      :op2 (a4 / automate-01)
                                                      :op3 (t2 / technology
                                                            :ARG1-of (r / relate-01
                                                                  :ARG2 ii2))))
                                          :ARG1 (l / level
                                                :mod (p2 / productive-03
                                                      :ARG0 (b2 / business))))
                                    :op2 (p3 / prevent-01
                                          :ARG1 (h / harm-01))
                                    :op3 (f / fairness)
                                    :op4 (e / explain-01))))))
      :snt2 (c4 / contrast-01
            :ARG2 (n3 / necessitate-01
                  :ARG0 (r2 / respect-01
                        :ARG1 (p4 / principle
                              :mod (e2 / ethics)))
                  :ARG1 (a5 / adopt-01
                        :ARG1 (r3 / rule
                              :ARG1-of (s / specific-02))
                        :ARG2 (s2 / sector
                              :mod (t3 / transport-01)
                              :poss (o2 / organization
                                    :name (n4 / name
                                          :op1 "Union"))))
                  :ARG1-of (c5 / cause-01
                        :ARG0 (a6 / and
                              :op1 (a7 / aim-01
                                    :ARG0 o2
                                    :ARG1 (r4 / reduce-01
                                          :ARG0 o2
                                          :ARG1 (f2 / fatality
                                                :mod (r5 / road)
                                                :ARG1-of (ii3 / include-91
                                                      :ARG2 (a8 / accident
                                                            :mod (t4 / traffic)
                                                            :mod (a9 / all)
                                                            :location o2)))
                                          :ARG2 (p5 / percentage-entity
                                                :value 50)
                                          :time (b3 / by
                                                :op1 (d / date-entity
                                                      :year 2020))))
                              :op2 (r6 / renew-01
                                    :ARG0 o2
                                    :ARG1 (e3 / effort-01
                                          :ARG0 o2
                                          :ARG1 (f3 / framework
                                                :name (n5 / name
                                                      :op1 "Road"
                                                      :op2 "Safety"
                                                      :op3 "Policy"
                                                      :op4 "Framework"))
                                          :time (d2 / date-interval
                                                :op1 (d3 / date-entity
                                                      :year 2021)
                                                :op2 (d4 / date-entity
                                                      :year 2030))))))))
      :snt3 (c6 / contrast-01
            :ARG2 (p6 / possible-01
                  :ARG1 (u / use-01
                        :ARG1 (s3 / system
                              :mod (ii4 / intelligent-01
                                    :mod a3))
                        :mod (r7 / robot))
                  :ARG2 (a10 / and
                        :op1 (e4 / efficient-01)
                        :op2 (e5 / efficient-01)))
            :ARG2 (a11 / and
                  :op1 (m2 / minimize-01
                        :ARG1 (q / queue-01))
                  :op2 (o3 / optimize-01
                        :ARG1 (r8 / route-01))))
      :snt4 (e6 / et-cetera))

# ::snt Believes that any framework of ethical principles for the development, deployment and  use of AI, robotics and related technologies should fully respect the EU Charter of  fundamental rights and thereby respect human dignity, autonomy and self-determination  of the individual, prevent harm, promote fairness, inclusion and transparency, eliminate  biases and discrimination, also of minority groups, and respect and comply with the  principles of limiting the negative externalities of technology used, explainability of  technologies, and the guarantee that the technologies are there to serve people and not  replace or decide for them, with the ultimate aim of increasingly human well-being for  everybody; 4.
# File 87

(b / believe-01
      :li 4
      :ARG1 (r / recommend-01
            :ARG1 (a / and
                  :op1 (r2 / respect-01
                        :ARG0 (f / framework
                              :mod (a2 / any)
                              :consist-of (p / principle
                                    :mod (e / ethics))
                              :purpose (a3 / and
                                    :op1 (d / develop-02
                                          :ARG1 (a4 / and
                                                :op1 (a5 / artificial-physical-intelligence)
                                                :op2 (r3 / robot)
                                                :op3 (t / technology
                                                      :ARG1-of (r4 / relate-01))))
                                    :op2 (d2 / deploy-01
                                          :ARG1 a4)
                                    :op3 (u / use-01
                                          :ARG1 a4)))
                        :ARG1 (a6 / and
                              :op1 (c / charter
                                    :mod (o / organization
                                          :name (n / name
                                                :op1 "EU"))
                                    :topic (r5 / right-05
                                          :mod (f2 / fundamental)))
                              :op2 (r6 / respect-01
                                    :ARG0 f
                                    :ARG1 (a7 / and
                                          :op1 (d3 / dignity
                                                :mod (h / human))
                                          :op2 (a8 / autonomy
                                                :poss (ii / individual))
                                          :op3 (d4 / determine-01
                                                :ARG0 ii
                                                :ARG1 ii))
                                    :mod (f3 / full)
                                    :mod (t2 / thereby))
                              :op3 (p2 / prevent-01
                                    :ARG0 f
                                    :ARG1 (h2 / harm-01))
                              :op4 (p3 / promote-02
                                    :ARG0 f
                                    :ARG1 (a9 / and
                                          :op1 (f4 / fairness)
                                          :op2 (ii2 / include-01)
                                          :op3 (t3 / transparency)))
                              :op5 (e2 / eliminate-01
                                    :ARG0 f
                                    :ARG1 (a10 / and
                                          :op1 (b2 / bias-01)
                                          :op2 (d5 / discriminate-02)
                                          :poss (g / group
                                                :mod (m / minority))
                                          :mod (a11 / also)))
                              :op6 (a12 / and
                                    :op1 (r7 / respect-01
                                          :ARG0 f
                                          :ARG1 (p4 / principle
                                                :topic (l / limit-01
                                                      :ARG1 (e3 / externality
                                                            :ARG1-of (n2 / negative-02)
                                                            :poss (t4 / technology
                                                                  :ARG1-of (u2 / use-01))))))
                                    :op2 (e4 / explain-01
                                          :ARG1 t4))
                              :op3 (g2 / guarantee-01
                                    :ARG1 (b3 / be-located-at-91
                                          :ARG1 t4
                                          :ARG2 (t5 / there)
                                          :purpose (s / serve-01
                                                :ARG0 t4
                                                :ARG2 (p5 / person))
                                          :ARG1-of (ii3 / instead-of-91
                                                :ARG2 (o2 / or
                                                      :op1 (r8 / replace-01
                                                            :ARG1 t4
                                                            :ARG2 p5)
                                                      :op2 (d6 / decide-01
                                                            :ARG0 t4
                                                            :ARG3 p5)))))))
                  :ARG1-of (c2 / cause-01
                        :ARG0 (a13 / aim-01
                              :ARG1 (w / well-09
                                    :ARG1 (e5 / everybody)
                                    :mod (h3 / human)
                                    :ARG1-of (ii4 / increase-01))
                              :mod (u3 / ultimate))))))

# ::snt Is of the opinion that effective cross- border cooperation and ethical standards can be  achieved only if all stakeholders commit to ensure human agency and oversight,  technical robustness and safety, transparency and accountability, diversity, nondiscrimination and fairness, societal and environmental well-being and respect the  established principles of privacy, and data governance and data protection - specifically  those enshrined in Regulation (EU) 2016/679 (GDPR); 11.
# File 87

(o / opine-01
      :li 11
      :ARG1 (p / possible-01
            :ARG1 (a / achieve-01
                  :ARG1 (a2 / and
                        :op1 (c / cooperate-01
                              :ARG0-of (e / effective-04
                                    :ARG1 (c2 / cross-02
                                          :ARG1 (b / border))))
                        :op2 (s / standard
                              :mod (e2 / ethics))))
            :condition (c3 / commit-01
                  :ARG0 (s2 / stake-01
                        :mod (a3 / all))
                  :ARG1 (e3 / ensure-01
                        :ARG0 s2
                        :ARG1 (a4 / and
                              :op1 (a5 / agency
                                    :mod (h / human))
                              :op2 (o2 / oversee-01
                                    :ARG0 h)
                              :op3 (a6 / and
                                    :op1 (r / robustness
                                          :mod (t / technical))
                                    :op2 (s3 / safe-01))
                              :op4 (a7 / and
                                    :op1 (t2 / transparency)
                                    :op2 (a8 / accountable-02))
                              :op5 (d / diversity)
                              :op6 (a9 / and
                                    :op1 (d2 / discriminate-02
                                          :polarity -)
                                    :op2 (f / fairness))
                              :op7 (a10 / and
                                    :op1 (w / well-09
                                          :ARG1 (s4 / society))
                                    :op2 (w2 / well-09
                                          :ARG1 (e4 / environment)))
                              :op8 (r2 / respect-01
                                    :ARG0 s2
                                    :ARG1 (p2 / principle
                                          :ARG1-of (e5 / establish-01)
                                          :topic (a11 / and
                                                :op1 (p3 / privacy)
                                                :op2 (g / govern-01
                                                      :ARG1 (d3 / data))
                                                :op3 (p4 / protect-01
                                                      :ARG1 d3))
                                          :ARG2-of (e6 / enshrine-01
                                                :ARG1 (l / law
                                                      :name (n / name
                                                            :op1 "Regulation"
                                                            :op2 "EU"
                                                            :op3 "2016/679")))
                                          :ARG1-of (s5 / specific-02)))))
                  :mod (o3 / only))))

# ::snt We also find that  there are overarching ethical themes, namely  consent , fairness  and rights , that cut across the  challenges we identify.
# File 96

(f / find-01
      :ARG0 (w / we)
      :ARG1 (t / theme
            :mod (e / ethics)
            :ARG0-of (o / overrule-01)
            :ARG1-of (m / mean-01
                  :ARG2 (a / and
                        :op1 (c / consent-01)
                        :op2 (f2 / fairness)
                        :op3 (r / right-05)))
            :ARG0-of (c2 / cut-01
                  :ARG2 (a2 / across
                        :op1 (c3 / challenge-01
                              :ARG1-of (ii / identify-01
                                    :ARG0 w)))))
      :mod (a3 / also))

# ::snt Ensuring fairness through  preventing and eliminating health inequality,  and providing value to stakeholders is another  critical issue.
# File 96

(ii / issue-02
      :ARG0 (e / ensure-01
            :ARG1 (f / fairness)
            :manner (a / and
                  :op1 (a2 / and
                        :op1 (p / prevent-01
                              :ARG1 (e2 / equal-01
                                    :polarity -
                                    :ARG3 (h / health)))
                        :op2 (e3 / eliminate-01
                              :ARG1 e2))
                  :op2 (p2 / provide-01
                        :ARG1 (v / value-01)
                        :ARG2 (s / stake-01))))
      :ARG1-of (c / critical-02)
      :mod (a3 / another))

# ::snt A  high-level question that can be asked is “how do we  give meaningful consent to the use of AI to deliver  services, where there may be an element of auton omy in the AI’s decisions, or where we do not fully  understand these decisions?”  Another major theme that the challenges we iden tify touch upon is that of fairness .
# File 96

(m / multi-sentence
      :snt1 (p / possible-01
            :ARG1 (a / ask-01
                  :ARG1 (c / consent-01
                        :ARG0 (w / we)
                        :ARG1 (u / use-01
                              :ARG1 (ii / intelligent-01
                                    :mod (a2 / artificial))
                              :ARG2 (d / deliver-01
                                    :ARG0 ii
                                    :ARG1 (s / serve-01)))
                        :manner (m2 / meaningful)
                        :condition (o / or
                              :op1 (p2 / possible-01
                                    :ARG1 (e / element
                                          :mod (a3 / autonomy)
                                          :location (d2 / decide-01
                                                :ARG0 ii)))
                              :op2 (u2 / understand-01
                                    :polarity -
                                    :ARG0 (w2 / we)
                                    :ARG1 d2
                                    :degree (f / full))))
                  :mod (l / level
                        :ARG1-of (h / high-02))))
      :snt2 (t / theme
            :ARG1-of (m3 / major-02)
            :mod (a4 / another)
            :ARG1-of (t2 / touch-on-04
                  :ARG0 (c2 / challenge-01
                        :ARG1-of (ii2 / identify-01
                              :ARG0 (w3 / we))))
            :domain (f2 / fairness)))

# ::snt Are the three  general principles of distributive fairness (respon sibilities, capabilities, and needs) a useful guide  to help address these issues?
# File 96

(g / guide-01
      :ARG0 (p / principle
            :quant 3
            :ARG1-of (g2 / general-02)
            :topic (f / fairness
                  :mod (d / distribute-01))
            :ARG1-of (m / mean-01
                  :ARG2 (a / and
                        :op1 (r / responsible-03)
                        :op2 (c / capable-01)
                        :op3 (n / need-01))))
      :ARG1-of (u / useful-05
            :ARG2 (h / help-01
                  :ARG1 (a2 / address-02
                        :ARG1 (ii / issue-02
                              :mod (t / this)))))
      :polarity (a3 / amr-unknown))

# ::snt These principles are  highly open to interpretation, meaning that new  approaches to fairness may need to be considered,  particularly given the rapidly-changing nature of  these technologies.180Closely related to the concept of fairness is that  of rights .
# File 96

(m / multi-sentence
      :li 180
      :snt1 (m2 / mean-01
            :ARG1 (o / open-08
                  :ARG1 (p / principle
                        :mod (t / this))
                  :ARG2 (ii / interpret-01
                        :ARG1 p)
                  :degree (h / high-02))
            :ARG2 (p2 / possible-01
                  :ARG1 (o2 / obligate-01
                        :ARG2 (c / consider-02
                              :ARG1 (a / approach-02
                                    :ARG1 (f / fairness)
                                    :ARG1-of (n / new-01))))
                  :ARG1-of (c2 / cause-01
                        :ARG0 (n2 / nature
                              :ARG1-of (c3 / change-01
                                    :manner (r / rapid))
                              :poss (t2 / technology
                                    :mod (t3 / this))
                              :mod (p3 / particular)))))
      :snt2 (r2 / relate-01
            :ARG1 (r3 / right-05)
            :ARG2 (c4 / concept
                  :mod (f2 / fairness))
            :ARG1-of (c5 / close-10)))

# ::snt Underdal, A., and Wei, T. (2015) “Distributive fairness: A mutual recognition approach” Environmental Science & Policy, 51:35-44.
# File 96

(p / publication-91
      :ARG0 (a / and
            :op1 (p2 / person
                  :name (n / name
                        :op1 "Underdal")
                  :ARG0-of (h / have-rel-role-91
                        :ARG2 (h2 / husband)))
            :op2 (p3 / person
                  :name (n2 / name
                        :op1 "Wei")
                  :ARG0-of (h3 / have-rel-role-91
                        :ARG2 (h4 / husband))))
      :ARG1 (p4 / publication
            :name (n3 / name
                  :op1 "Distributive"
                  :op2 "Fairfair"
                  :op3 "A"
                  :op4 "Mellowship")
            :ARG1-of (a2 / approach-02
                  :ARG2 (r / recognize-01
                        :manner (m / mutual))))
      :ARG4 (j / journal
            :name (n4 / name
                  :op1 "Environmental"
                  :op2 "Science"
                  :op3 "&"
                  :op4 "Policy"))
      :ARG7 (v / value-interval
            :op1 51
            :op2 35
            :op3 44)
      :time (d / date-entity
            :year 2015))

# ::snt In many cases, experts in fairness,  human rights and ethics, rather than in technical aspects of  AI, do not feel welcome in technical standards organizations.
# File 182

(f / feel-01
      :polarity -
      :ARG0 (p / person
            :ARG1-of (e / expert-01
                  :ARG2 (a / and
                        :op1 (f2 / fairness)
                        :op2 (r / right-05
                              :ARG1 (h / human))
                        :op3 (e2 / ethics)
                        :ARG1-of (ii / instead-of-91
                              :ARG2 (a2 / aspect
                                    :mod (t / technical)
                                    :topic (ii2 / intelligent-01
                                          :mod (a3 / artificial)))))))
      :ARG1 (w / welcome-01
            :ARG1 p
            :ARG2 (o / organization
                  :mod (s / standard
                        :mod (t2 / technical))))
      :ARG1-of (c / case-04
            :quant (m / many)))

# ::snt As a result, those who have an interest in using the EU AI  regulation to ensure fairness, transparency, ethics,  and rights  protection, ha ve no specific training or education available.
# File 182

(r / result-01
      :ARG2 (a / available-02
            :polarity -
            :ARG1 (p / person
                  :mod (t / that)
                  :ARG0-of (ii / interest-01
                        :ARG2 (u / use-01
                              :ARG0 p
                              :ARG1 (r2 / regulate-01
                                    :ARG0 (o / organization
                                          :name (n / name
                                                :op1 "EU"))
                                    :ARG1 (ii2 / intelligent-01
                                          :mod (a2 / artificial)))
                              :ARG2 (e / ensure-01
                                    :ARG0 p
                                    :ARG1 (a3 / and
                                          :op1 (f / fairness)
                                          :op2 (t2 / transparency)
                                          :op3 (e2 / ethics)
                                          :op4 (p2 / protect-01
                                                :ARG1 (r3 / right-05)))))))
            :ARG2 (o2 / or
                  :op1 (t3 / train-01
                        :ARG2 p
                        :ARG1-of (s / specific-02))
                  :op2 (e3 / educate-01
                        :ARG1 p))))

# ::snt The AI HLEG has published two documents:  n Ethics Guidelines on Artificial Intelligence: The Guidelines put forward a human-centric approach on AI and list seven  key requirements that AI systems should meet in order to be considered trustworthy: 1) Human agency and oversight,  2) Technical robustness and safety, 3) Privacy and Data Governance, 4) Transparency, 5) Diversity, non-discrimination  and fairness, 6) Societal and environmental well-being, and 7) Accountability.
# File 69

(m / multi-sentence
      :snt1 (p / publish-01
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "AI"
                        :op2 "HLEG"))
            :ARG1 (d / document
                  :quant 2
                  :name (n2 / name
                        :op1 "Ethics"
                        :op2 "Guidelines"
                        :op3 "on"
                        :op4 "Artificial"
                        :op5 "Intelligence")))
      :snt2 (a / and
            :op1 (p2 / put-01
                  :ARG0 (g / guideline)
                  :ARG1 (a2 / approach-02
                        :ARG1 (ii / intelligent-01
                              :mod (a3 / artificial))
                        :ARG1-of (c / center-01
                              :ARG2 (h / human)))
                  :ARG2 (f / forward))
            :op2 (l / list-01
                  :ARG0 g
                  :ARG1 (r / require-01
                        :quant 7
                        :ARG1 (a4 / and
                              :op1 (a5 / and
                                    :li 1
                                    :op1 (a6 / agency
                                          :mod (h2 / human))
                                    :op2 (o2 / oversee-01
                                          :ARG0 h2))
                              :op2 (a7 / and
                                    :li 2
                                    :op1 (r2 / robustness
                                          :mod (t / technical))
                                    :op2 (s / safe-01))
                              :op3 (a8 / and
                                    :li 3
                                    :op1 (p3 / privacy)
                                    :op2 (g2 / govern-01
                                          :ARG1 (d2 / data)))
                              :op4 (t2 / transparency)
                              :op5 (a9 / and
                                    :li 5
                                    :op1 (d3 / discriminate-02
                                          :polarity -)
                                    :op2 (f2 / fairness))
                              :op6 (a10 / and
                                    :li 6
                                    :op1 (w / well-05
                                          :mod (s2 / society))
                                    :op2 (w2 / well-05
                                          :mod (e / environment)))
                              :op7 (a11 / accountable-02
                                    :li 7))
                        :ARG1-of (k / key-02)
                        :ARG1-of (m2 / meet-01
                              :ARG0 (s3 / system
                                    :mod ii)
                              :ARG1-of (r3 / recommend-01)
                              :purpose (c2 / consider-01
                                    :ARG1 (t3 / trustworthy
                                          :domain s3)))))))

# ::snt In addition to explainability and interpretability, among other AI system characteristics proposed to support system trustworthiness are accuracy, privacy, reliability, robustness, safety, security (resilience), mitigation of harmful bias, transparency, fairness, and accountability.
# File 128

(ii / include-91
      :ARG1 (a / and
            :op1 (a2 / accurate)
            :op2 (p / privacy)
            :op3 (r / reliability)
            :op4 (r2 / robustness)
            :op5 (s / safe-01)
            :op6 (s2 / security
                  :ARG1-of (m / mean-01
                        :ARG2 (r3 / resilience)))
            :op7 (m2 / mitigate-01
                  :ARG1 (b / bias-01
                        :ARG0-of (h / harmful-02)))
            :op8 (t / transparency)
            :op9 (f / fairness)
            :op10 (a3 / accountable-02))
      :ARG2 (t2 / thing
            :ARG2-of (c / characteristic-02
                  :ARG1 (s3 / system
                        :mod (ii2 / intelligent-01
                              :mod (a4 / artificial))))
            :mod (o / other)
            :ARG1-of (p2 / propose-01
                  :purpose (s4 / support-01
                        :ARG0 t2
                        :ARG1 (w / worth-02
                              :ARG1 s3
                              :ARG2 (t3 / trust-02
                                    :ARG1 s3)))))
      :ARG3 (a5 / and
            :op1 (p3 / possible-01
                  :ARG1 (e / explain-01))
            :op2 (p4 / possible-01
                  :ARG1 (ii3 / interpret-01))))

# ::snt In addition to discussing principles, they discuss different things that go into an explanation, including process-based explanations vs. outcome-based explanations, the rationale, the responsibility of who made what decisions, an explanation of the data, and design steps that maximize fairness, safety, and impact of the use of the system.
# File 128

(d / discuss-01
      :ARG0 (t / they)
      :ARG1 (t2 / thing
            :ARG1-of (d2 / differ-02)
            :ARG0-of (g / go-06
                  :ARG2 (e / explain-01))
            :ARG2-of (ii / include-01
                  :ARG1 (a / and
                        :op1 (c / contrast-01
                              :ARG1 (e2 / explain-01
                                    :ARG1-of (b / base-02
                                          :ARG2 (p / process-02)))
                              :ARG2 (e3 / explain-01
                                    :ARG1-of (b2 / base-02
                                          :ARG2 (o / outcome))))
                        :op2 (r / rationale)
                        :op3 (r2 / responsible-03
                              :ARG0 (p2 / person
                                    :ARG0-of (d3 / decide-01
                                          :ARG1 t2))))
                  :op4 (e4 / explain-01
                        :ARG1 (d4 / data))
                  :op5 (s / step-01
                        :ARG2 (d5 / design-01)
                        :ARG0-of (m / maximize-01
                              :ARG1 (a2 / and
                                    :op1 (f / fairness)
                                    :op2 (s2 / safe-01)
                                    :op3 (ii2 / impact-01
                                          :ARG0 (u / use-01
                                                :ARG1 (s3 / system))))))))
      :ARG1-of (a3 / add-02
            :ARG2 (d6 / discuss-01
                  :ARG0 t
                  :ARG1 (p3 / principle))))

# ::snt They fairwash a model by taking a closed-box model and produce an ensemble of interpretable models that approximate the original model but are much fairer, which then hide the unfairness of the original model.
# File 128

(f / fairwash-01
      :ARG0 (t / they)
      :ARG1 (m / model)
      :manner (a / and
            :op1 (t2 / take-01
                  :ARG0 t
                  :ARG1 (m2 / model
                        :mod (b / box
                              :ARG1-of (c / close-01))))
            :op2 (p / produce-01
                  :ARG0 t
                  :ARG1 (e / ensemble
                        :consist-of (m3 / model
                              :ARG1-of (ii / interpret-01
                                    :ARG1-of (p2 / possible-01))
                              :ARG1-of (a2 / approximate-01
                                    :ARG2 (m4 / model
                                          :mod (o / original))
                                    :ARG1-of (c2 / contrast-01
                                          :ARG2 (f2 / fair-01
                                                :polarity -
                                                :ARG1 m3)))
                              :ARG1-of (h / have-degree-91
                                    :ARG2 f2
                                    :ARG3 (m5 / more
                                          :quant (m6 / much)))
                              :ARG0-of (h2 / hide-01
                                    :ARG1 (f3 / fair-01
                                          :polarity -
                                          :ARG1 m4)
                                    :time (t3 / then)))))))

# ::snt The ability for developers to cover up unfairness in closed-box models is one of the several vulnerabilities of explainable AI discussed in Hall et al.
# File 128

(ii / include-91
      :ARG1 (p / possible-01
            :ARG1 (c / cover-up-04
                  :ARG0 (p2 / person
                        :ARG0-of (d / develop-02))
                  :ARG1 (f / fair-01
                        :polarity -
                        :ARG1 (m / model
                              :mod (b / box
                                    :ARG1-of (c2 / close-01))))))
      :ARG2 (v / vulnerable-01
            :ARG1 (ii2 / intelligent-01
                  :mod (a / artificial)
                  :ARG1-of (e / explain-01
                        :ARG1-of (p3 / possible-01)))
            :quant (s / several)
            :ARG1-of (d2 / discuss-01
                  :ARG0 (a2 / and
                        :op1 (p4 / person
                              :name (n / name
                                    :op1 "Hall"))
                        :op2 (p5 / person
                              :mod (o / other))))))

# ::snt In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, pages 648–657, 2020.
# File 128

(b / be-located-at-91
      :ARG2 (p / publication
            :name (n / name
                  :op1 "Proceeds"
                  :op2 "of"
                  :op3 "the"
                  :op4 "2020"
                  :op5 "Conference"
                  :op6 "on"
                  :op7 "Fairness,"
                  :op8 "Accountability"
                  :op9 "and"
                  :op10 "Transparency")
            :ARG7 (p2 / page
                  :mod (b2 / between
                        :op1 648
                        :op2 655))
            :time (d / date-entity
                  :year 2020)))

# ::snt You shouldn’t trust me: Learning models which conceal unfairness from multiple explanation methods.
# File 128

(r / recommend-01
      :polarity -
      :ARG1 (t / trust-01
            :ARG0 (y / you)
            :ARG1 (ii / i))
      :ARG1-of (c / cause-01
            :ARG0 (m / model-01
                  :ARG1 (l / learn-01)
                  :ARG0-of (c2 / conceal-01
                        :ARG1 (f / fair-01
                              :polarity -)
                        :ARG2 (m2 / method
                              :instrument-of (e / explain-01)
                              :quant (m3 / multiple))))))

# ::snt In Proceedings of the Conference on Fairness, Accountability, and Transparency, FAT* ’19, pages 220–229, New York, NY , USA, January 2019.
# File 128

(b / be-located-at-91
      :ARG2 (p / publication
            :name (n / name
                  :op1 "FAT"
                  :op2 "19")
            :ARG1-of (d / describe-01
                  :ARG0 (c / conference
                        :name (n2 / name
                              :op1 "Conference"
                              :op2 "on"
                              :op3 "Fairness"
                              :op4 "Accountability"
                              :op5 "and"
                              :op6 "Transparency")))
            :ARG1-of (c2 / cite-01
                  :ARG2 (a / and
                        :op1 (p2 / page
                              :mod 220)
                        :op2 (p3 / page
                              :mod 229))))
      :location (c3 / city
            :name (n3 / name
                  :op1 "New"
                  :op2 "York")
            :location (s / state
                  :name (n4 / name
                        :op1 "NY")
                  :location (c4 / country
                        :name (n5 / name
                              :op1 "USA"))))
      :time (d2 / date-entity
            :month 1
            :year 2019))

# ::snt In Conference on Fairness, Accountability, and Transparency (FAT* ’20), Barcelona, Spain, 2020. doi: 10.1145/3351095.3372834.
# File 128

(c / conference
      :name (n / name
            :op1 "Conference"
            :op2 "on"
            :op3 "Fairness"
            :op4 "Accountability"
            :op5 "and"
            :op6 "Transparency")
      :time (d / date-entity
            :year 2020)
      :location (c2 / city
            :name (n2 / name
                  :op1 "Barcelona")
            :location (c3 / country
                  :name (n3 / name
                        :op1 "Spain")))
      :ARG1-of (c4 / cite-01
            :ARG2 (p / publication-91
                  :ARG4 10.1145
                  :op1 "10.3372834")))

# ::snt In Proceedings of the Conference on Fairness, Accountability, and Transparency, FAT* ’19, pages 10–19, New York, NY , USA, 2019.
# File 128

(b / be-located-at-91
      :ARG1 (p / publication
            :name (n / name
                  :op1 "FAT")
            :time (d / date-entity
                  :year 2019)
            :subevent-of (p2 / Proceedings
                  :mod (c / conference
                        :name (n2 / name
                              :op1 "Conference"
                              :op2 "on"
                              :op3 "Fairness"
                              :op4 "Accountability"
                              :op5 "and"
                              :op6 "Transparency")))
            :ARG1-of (c2 / cite-01
                  :ARG2 (a / and
                        :op1 (p3 / page
                              :mod 10)
                        :op2 (p4 / page
                              :mod 19))))
      :ARG2 (c3 / city
            :name (n3 / name
                  :op1 "New"
                  :op2 "York")
            :location (s / state
                  :name (n4 / name
                        :op1 "NY")
                  :location (c4 / country
                        :name (n5 / name
                              :op1 "USA"))))
      :time (d2 / date-entity
            :year 2019))

# ::snt A qualitative exploration of perceptions of algorithmic fairness.
# File 128

(e / explore-01
      :ARG1 (p / perceive-01
            :ARG1 (f / fairness
                  :mod (a / algorithm)))
      :mod (q / qualitative))

# ::snt Did you consult with the impacted communities about  your definition of fairness?
# File 75

(c / consult-01
      :ARG0 (y / you)
      :ARG1 (c2 / community
            :ARG1-of (ii / impact-01))
      :ARG2 (d / define-01
            :ARG0 y
            :ARG1 (f / fair-01))
      :polarity (a / amr-unknown))

# ::snt Does the system potentially negatively  discriminate against people on the basis of any  of the following grounds (non-exhaustively):  sex, gender, race, colour, ethnic or social origin,  genetic features, language, religion or belief,  political or any other opinion, membership of  a national minority, property, place of birth,  disability, age or sexual orientation?44 12.1 Did you consider diversity and  representativeness of persons concerned in the  data?45 12.2 Did you test for specific target groups or  problematic use cases?46  12.3 Do you have a definition of fairness?
# File 75

(m / multi-sentence
      :snt1 (d / discriminate-02
            :ARG0 (s / system)
            :ARG1 (p / person)
            :polarity (a / amr-unknown)
            :manner (n / negative-02)
            :ARG1-of (b / base-02
                  :ARG2 (g / ground-02
                        :ARG2 (o / or
                              :op1 (s2 / sex)
                              :op2 (g2 / gender)
                              :op3 (r / race)
                              :op4 (c / color)
                              :op5 (o2 / originate-01
                                    :ARG2 (o3 / or
                                          :op1 (e / ethnic-group)
                                          :op2 (s3 / society)))
                              :op6 (f / feature
                                    :mod (g3 / genetics))
                              :op7 (o4 / or
                                    :op1 (l / language)
                                    :op2 (r2 / religion)
                                    :op3 (b2 / believe-01)
                                    :op4 (o5 / or
                                          :op1 (p2 / politics)
                                          :op2 (t / thing
                                                :ARG1-of (o6 / opine-01)
                                                :mod (o7 / other)))
                                    :op9 (m2 / membership
                                          :poss (m3 / minority
                                                :mod (n2 / nation)))
                                    :op10 (p3 / property)
                                    :op11 (p4 / place
                                          :location-of (b3 / bear-02))
                                    :op12 (d2 / disability)
                                    :op13 (o8 / or
                                          :op1 (a2 / age-01)
                                          :op2 (o9 / orient-01
                                                :ARG3 s2))))
                        :mod (a3 / any))
                  :ARG1-of (e2 / exhaust-01
                        :polarity -)))
      :snt2 (t2 / test-01
            :ARG0 (y / you)
            :ARG2 (o10 / or
                  :op1 (g4 / group
                        :ARG1-of (t3 / target-01))
                  :op2 (c2 / case-04
                        :ARG1 (u / use-01)
                        :ARG1-of (p5 / problematic-02)))
            :polarity (a4 / amr-unknown))
      :snt3 (h / have-03
            :ARG0 y
            :ARG1 t
            :ARG2-of (d3 / define-01
                  :ARG1 (f2 / fair-01)))
      :snt4 (a5 / and
            :op1 (h2 / have-li-91
                  :ARG2 12.45)
            :op2 (h3 / have-li-91
                  :ARG2 12.2)))

# ::snt Is  your definition of fairness commonly used and  implemented in any phase of the process of  setting up the system?
# File 75

(a / and
      :polarity (a2 / amr-unknown)
      :op1 (u / use-01
            :ARG1 (t / thing
                  :ARG2-of (d / define-01
                        :ARG0 (y / you)
                        :ARG1 (f / fair-01)))
            :mod (c / common))
      :op2 (ii / implement-01
            :ARG1 t
            :time (p / phase
                  :mod (a3 / any)
                  :subevent-of (p2 / process-02
                        :ARG1 (s / set-up-03
                              :ARG1 (s2 / system))))))

# ::snt 12.4 Did you establish mechanisms to ensure  fairness in your system?
# File 75

(e / establish-01
      :li 12.4
      :ARG0 (y / you)
      :ARG1 (m / mechanism
            :ARG0-of (e2 / ensure-01
                  :ARG1 (f / fairness)
                  :location (s / system
                        :poss y)))
      :polarity (a / amr-unknown))

# ::snt However, the core  interest in   fairness remains  critical to  any discussion of basic rights.
# File 161

(h / have-concession-91
      :ARG2 (r / remain-01
            :ARG1 (ii / interest-01
                  :ARG2 (f / fairness)
                  :ARG1-of (c / core-02))
            :ARG3 (c2 / critical-02
                  :ARG1 ii
                  :ARG2 (d / discuss-01
                        :ARG1 (r2 / right-05
                              :mod (b / basic))
                        :mod (a / any)))))

# ::snt Fair  Fairness relates to the insights and applications that are a product of big data, while  respectful speaks to the conditions related to , and the processing of , the data.
# File 161

(c / contrast-01
      :ARG1 (r / relate-01
            :ARG1 (f / fairness)
            :ARG2 (a / and
                  :op1 (ii / insight)
                  :op2 (a2 / application)
                  :ARG1-of (p / produce-01
                        :ARG0 (d / data
                              :mod (b / big)))))
      :ARG2 (s / speak-01
            :ARG0 (f2 / fairness
                  :ARG1-of (r2 / respect-01))
            :ARG1 (c2 / condition
                  :ARG1-of (r3 / relate-01
                        :ARG2 (a3 / and
                              :op1 (d2 / data)
                              :op2 (p2 / process-01
                                    :ARG1 d2))))))

# ::snt Section 5 of the  United States Federa l Trade Commission Act prohibits unfair practices  in commerce that  are harmful to individuals  not outweighed by countervailing benefits .15  European  guidance  on application of the data protection directive continually references fairness  as a component of determining whether a use of data is incompatible or a legal basis to  process is appropriate.
# File 161

(r / refer-01
      :li 15
      :ARG0 (g / guide-01
            :ARG1 (a / apply-02
                  :ARG1 (d / directive
                        :topic (p / protect-01
                              :ARG1 (d2 / data))))
            :mod (c / continent
                  :name (n / name
                        :op1 "Europe")))
      :ARG1 (f / fair-01)
      :ARG2 (c2 / component
            :part-of (d3 / determine-01
                  :ARG1 (o / or
                        :op1 (c3 / compatible
                              :polarity -
                              :domain (u / use-01
                                    :ARG1 (d4 / data)))
                        :op2 (a2 / appropriate-02
                              :ARG1 (b / base-02
                                    :ARG1 (p2 / process-02)
                                    :ARG1-of (l / legal-02))))))
      :ARG1-of (c4 / continue-01)
      :manner c4
      :ARG1-of (c5 / cause-01
            :ARG0 (p3 / prohibit-01
                  :ARG0 (s / section
                        :mod 5
                        :part-of (l2 / law
                              :name (n2 / name
                                    :op1 "Federa"
                                    :op2 "L"
                                    :op3 "Trade"
                                    :op4 "Commission"
                                    :op5 "Act")
                              :mod (c6 / country
                                    :name (n3 / name
                                          :op1 "United"
                                          :op2 "States"))))
                  :ARG1 (p4 / practice-01
                        :ARG1-of (f2 / fair-01
                              :polarity -)
                        :location (c7 / commerce)
                        :ARG0-of (h / harm-01
                              :ARG1 (ii / individual))
                        :ARG1-of (o2 / outweigh-01
                              :polarity -
                              :ARG0 (b2 / benefit-01
                                    :ARG0-of (c8 / countervail-01)))))))

# ::snt The analysis of fairness needs to look not only at protecting against unseemly or risky  actions but also at enhancing beneficial opportunities.
# File 161

(n / need-01
      :ARG1 (l / look-01
            :ARG0 (a / analyze-01
                  :ARG1 (f / fairness))
            :ARG1 (c / contrast-01
                  :ARG1 (p / protect-01
                        :ARG1 (o / or
                              :op1 (a2 / act-02
                                    :mod (u / unseemly))
                              :op2 (a3 / act-02
                                    :ARG1-of (r / risky-02))))
                  :ARG2 (e / enhance-01
                        :ARG1 (o2 / opportunity
                              :ARG0-of (b / benefit-01))
                        :mod (a4 / also)))))

# ::snt Interfering with  such opportunities is also a fairness issue.
# File 161

(ii / issue-02
      :ARG0 (ii2 / interfere-01
            :ARG1 (o / opportunity
                  :mod (s / such)))
      :ARG1 (f / fair-01)
      :mod (a / also))

# ::snt In conducting this fairness assessment, organ isations should take steps to b alanc e  individual interests with  integrity.
# File 161

(r / recommend-01
      :ARG1 (t / take-01
            :ARG0 (o / organization)
            :ARG1 (s / step-01
                  :ARG1 o
                  :ARG2 (a / align-01
                        :ARG0 o
                        :ARG1 (ii / interest
                              :mod (ii2 / individual))
                        :manner (ii3 / integrity))))
      :time (c / conduct-01
            :ARG0 o
            :ARG1 (a2 / assess-01
                  :ARG1 (f / fair-01)
                  :mod (t2 / this))))

# ::snt 15 FTC Policy Statement  on 17  December  1980 states:  (1) whether the practice, without necessarily having been  previously considered unlawful, offends public policy as it has been established by statutes, the common law, or  otherwise -whether, in other words, i t is within at least the penumbra of some common law, statutory or other  established concept of unfairness; (2) whether it is immoral, unethical, oppressive or unscrupulous; (3) whether it  causes substantial injury to consumers (or competitors or other bus inessmen).
# File 161

(s / state-01
      :li 15
      :ARG0 (o / organization
            :name (n / name
                  :op1 "FTC"))
      :ARG1 (o2 / or
            :op1 (o3 / offend-01
                  :li 1
                  :ARG0 (p / practice-01)
                  :ARG1 (p2 / policy-01
                        :ARG2 (p3 / public))
                  :ARG1-of (c / cause-01
                        :ARG0 (o4 / or
                              :op1 (e / establish-01
                                    :ARG0 (o5 / or
                                          :op1 (s2 / statute)
                                          :op2 (l / law
                                                :mod (c2 / common)))
                                    :ARG1 o3)
                              :op2 (e2 / establish-01
                                    :polarity -
                                    :ARG0 o5
                                    :ARG1 o3))))
            :op2 (o6 / or
                  :li 2
                  :op1 (m / moral-02
                        :polarity -
                        :ARG1 p)
                  :op2 (e3 / ethical
                        :polarity -
                        :domain p)
                  :op3 (o7 / oppress-01
                        :ARG0 p)
                  :op4 (u / unscrupulous
                        :domain p))
            :op5 (c3 / cause-01
                  :li 3
                  :ARG0 p
                  :ARG1 (ii / injure-01
                        :ARG0 p
                        :ARG1 (o8 / or
                              :op1 (p4 / person
                                    :ARG0-of (c4 / consume-01))
                              :op2 (p5 / person
                                    :ARG0-of (c5 / compete-02))
                              :op3 (p6 / person
                                    :mod (o9 / other)
                                    :ARG0-of (h / have-org-role-91
                                          :ARG1 (b / bus))))
                        :degree (s3 / substantial))))
      :op6 (b2 / be-located-at-91
            :ARG1 p
            :ARG2 (p7 / penumbra
                  :part-of (o10 / or
                        :op1 (l2 / law
                              :mod c2)
                        :mod (s4 / some))
                  :op2 s2)
            :op3 (c6 / concept
                  :ARG1-of (e4 / establish-01)
                  :mod (o11 / other)
                  :topic (f / fairness
                        :polarity -)))
      :mod (a / at-least)
      :time (d / date-entity
            :year 1980
            :month 12
            :day 17))

# ::snt U.S. Federal Trade Commission  (1980), "FTC Policy Statement on Unfairness", http://www.ftc.gov/public -statements/1980/12/ftc -policy statement -unfairnes s.
# File 161

(p / publication-91
      :ARG0 (g / government-organization
            :name (n / name
                  :op1 "U.S."
                  :op2 "Federal"
                  :op3 "Trade"
                  :op4 "Commission"))
      :ARG1 (p2 / publication
            :name (n2 / name
                  :op1 "FTC"
                  :op2 "Policy"
                  :op3 "Statement"
                  :op4 "on"
                  :op5 "Fairness"))
      :time (d / date-entity
            :year 1980)
      :medium (u / url-entity
            :value "http://www.ftc.gov/public-statements/1980/12/ftc -policy statement -unfairnes s"))

# ::snt ................................ ................................ ................................ ............................  6  The Current State of AI  ................................ ................................ ................................ ................................ ........  7  Public Outreach and Development of this Report  ................................ ................................ ................................ .. 12  Applications of AI for Public Good  ................................ ................................ ................................ ..........................  13  AI in the Federal G overnment  ................................ ................................ ................................ ................................ .. 15  AI and Regulation  ................................ ................................ ................................ ................................ ......................  17  Case Study: Autonomous Vehicles and Aircraft  ................................ ................................ ................................  18  Research and Workforce  ................................ ................................ ................................ ................................ ..........  23  Monitoring Progress in AI ................................ ................................ ................................ ................................ .. 23  Federal Support for AI Research  ................................ ................................ ................................ ........................  25  Workforce Development and Diversity  ................................ ................................ ................................ .............  26  AI, Automation, and the Economy  ................................ ................................ ................................ .......................  29  Fairness, Safety, and  Governance  ................................ ................................ ................................ ............................  30  Justice, Fairness, and Accountability  ................................ ................................ ................................ .................  30  Safety and Control ................................ ................................ ................................ ................................ ..............  32  Global Considerations and Security  ................................ ................................ ................................ ........................  35  International Coope ration  ................................ ................................ ................................ ................................ ... 35  AI and Cybersecurity  ................................ ................................ ................................ ................................ .........  36  AI in Weapon Systems  ................................ ................................ ................................ ................................ .......  37  Conclusion  ................................ ................................ ................................ ................................ ................................ .. 39  Recommendations in this Report  ................................ ................................ ................................ .............................  40  Acronyms ................................ ................................ ................................ ................................ ................................ .... 43  References  ................................ ................................ ................................ ................................ ................................ .. 45
# File 20

(m / multi-sentence
      :snt1 (s / state
            :mod (c / current)
            :mod (ii / intelligent-01
                  :mod (a / artificial))
            :example (a2 / and
                  :op1 (a3 / automate-01)
                  :op2 (e / economy)))
      :snt2 (a4 / and
            :op1 (f / fair-01)
            :op2 (s2 / safe-01)
            :op3 (g / govern-01))
      :snt3 (r / refer-01
            :ARG1 (r2 / report-01
                  :mod (t / this)))
      :snt4 (a5 / and
            :op1 (p / publication
                  :name (n / name
                        :op1 "Global"
                        :op2 "Considerations"))
            :op2 (p2 / publication
                  :name (n2 / name
                        :op1 "International"
                        :op2 "Coope"
                        :op3 "Rice"))
            :op3 (p3 / publication
                  :name (n3 / name
                        :op1 "Advanced"
                        :op2 "Integrated"
                        :op3 "Automated"
                        :op4 "Vehicle"))
            :op4 (p4 / publication
                  :name (n4 / name
                        :op1 "Advanced"
                        :op2 "Vehicle"
                        :op3 "and"
                        :op4 "Aerospace"
                        :op5 "Development"))
            :op5 (p5 / publication
                  :name (n5 / name
                        :op1 "Advanced"
                        :op2 "Vehicle"
                        :op3 "and"
                        :op4 "Aerospace"
                        :op5 "Development"))
            :op6 (p6 / publication
                  :name (n6 / name
                        :op1 "Advanced"
                        :op2 "Vehicle"
                        :op3 "and"
                        :op4 "Aerospace"
                        :op5 "Development"))
            :op7 (p7 / publication
                  :name (n7 / name
                        :op1 "Public"
                        :op2 "Outreach"))
            :op8 (p8 / publication
                  :name (n8 / name
                        :op1 "Public"
                        :op2 "Good"))
            :op9 (p9 / publication
                  :name (n9 / name
                        :op1 "Advanced"
                        :op2 "Vehicle"
                        :op3 "and"
                        :op4 "Aerospace"
                        :op5 "Development"))
            :op10 (p10 / publication
                  :name (n10 / name
                        :op1 "Public"
                        :op2 "Good"))
            :op11 (p11 / publication
                  :name (n11 / name
                        :op1 "Aeronomic"
                        :op2 "Vehicle"
                        :op3 "and"
                        :op4 "Aerospace"))
            :op12 (p12 / publication
                  :name (n12 / name
                        :op1 "Aeronomic"
                        :op2 "Vehicle"
                        :op3 "and"
                        :op4 "Control"))
            :op13 "and"
            :op14 "Aeronomic"
            :op15 "Vehicle"
            :op16 "and"
            :op17 "Aerospace"
            :op18 "Development"
            :op19 "and"
            :op20 "Aerospace"
            :op21 "and"
            :op21 "Regulations"))

# ::snt AI and Regulation   AI has applications in many products, such as cars and air craft, which  are subject to regulation designed  to protect the public from harm  and ensure fairness in economic competition .
# File 20

(m / multi-sentence
      :snt1 (a / and
            :op1 (ii / intelligent-01
                  :mod (a2 / artificial))
            :op2 (r / regulate-01))
      :snt2 (a3 / apply-02
            :ARG1 (ii2 / intelligent-01
                  :mod a2))
      :ARG2 (p / product
            :quant (m2 / many)
            :example (a4 / and
                  :op1 (c / car)
                  :op2 (c2 / craft
                        :mod (a5 / air))
                  :ARG1-of (s / subject-02
                        :ARG2 (r2 / regulate-01
                              :ARG1-of (d / design-01
                                    :ARG3 (a6 / and
                                          :op1 (p2 / protect-01
                                                :ARG0 r2
                                                :ARG1 (p3 / public)
                                                :ARG2 (h / harm-01
                                                      :ARG1 p3))
                                          :op2 (e / ensure-01
                                                :ARG0 r2
                                                :ARG1 (f / fair-01
                                                      :ARG1 (c3 / compete-01
                                                            :mod (e2 / economy)))))))))))

# ::snt Also , where regulatory responses to the ad dition of AI threaten to increase the cost  of compliance , or slow the development or adoption of beneficial innovations, policymakers should  consider how those responses could be adjusted to lower costs and barriers to innovation  without  adversely impactin g safety  or market fairness .
# File 20

(r / recommend-01
      :ARG1 (c / consider-02
            :ARG0 (p / person
                  :ARG0-of (l / legislate-01))
            :ARG1 (t / thing
                  :manner-of (a / adjust-01
                        :ARG1 (r2 / respond-01
                              :ARG0 (r3 / regulate-01)
                              :ARG1 (a2 / administer-01
                                    :ARG1 (a3 / artificial)))
                        :ARG2 (a4 / and
                              :op1 (c2 / cost-01)
                              :op2 (b / barrier
                                    :prep-to (ii / innovate-01))
                              :ARG1-of (h / have-degree-91
                                    :ARG2 (l2 / low-04
                                          :ARG1 a4)
                                    :ARG3 (m / more)))
                        :manner (ii2 / impact-01
                              :polarity -
                              :ARG1 (o / or
                                    :op1 (s / safe-01)
                                    :op2 (f / fair-01
                                          :ARG1 (m2 / market)))
                              :manner (a5 / adverse)))))
      :mod (a6 / also)
      :condition (t2 / threaten-01
            :ARG0 r2
            :ARG1 (o2 / or
                  :op1 (ii3 / increase-01
                        :ARG0 r2
                        :ARG1 (c3 / cost-01
                              :ARG1 (c4 / comply-01)))
                  :op2 (s2 / slow-01
                        :ARG0 r2
                        :ARG1 (o3 / or
                              :op1 (d / develop-02
                                    :ARG1 (ii4 / innovate-01
                                          :ARG1-of (b2 / benefit-01)))
                              :op2 (a7 / adopt-01
                                    :ARG1 ii4))))))

# ::snt Fairness, Safety, and Governance   As AI technologies move toward broader deployment, technical experts , policy analysts , and ethicists   have raised concerns about unintended consequences  of widespread adoption .
# File 20

(c / concern-01
      :ARG0 (c2 / consequence-03
            :ARG1 (a / adopt-01
                  :ARG1-of (s / spread-03
                        :ARG1-of (w / wide-02)))
            :ARG1-of (ii / intend-01
                  :polarity -))
      :ARG1 (a2 / and
            :op1 (f / fairness)
            :op2 (s2 / safe-01)
            :op3 (g / govern-01))
      :time (m / move-01
            :ARG0 (t / technology
                  :mod (a3 / artificial))
            :ARG2 (d / deploy-01
                  :ARG1 t
                  :ARG1-of (h / have-degree-91
                        :ARG2 (b / broad-02
                              :ARG1 d)
                        :ARG3 (m2 / more))))
      :ARG1-of (c3 / cause-01
            :ARG0 a2
            :op1 (p / person
                  :ARG1-of (e / expert-01
                        :ARG2 (t2 / technical)))
            :op2 (p2 / person
                  :ARG0-of (a4 / analyze-01
                        :ARG1 (p3 / policy-01)))
            :op3 (e2 / ethicist)))

# ::snt Use of AI to make  consequential decisions about people, often replacing decisions made by human -driven  bureaucra tic  processes , leads to concerns about how to ensure justice, fairness, and accountability —the same concerns  voiced previously in the Administration’s Big Data: Seizing Opportunities, Preserving Values  report of  2014,1 as well as the Report to the President on Big Data  and Privacy: A Technological Perspective  published by the President’s Council of Advisors on Science and Technology in 2014 .2 Transparency  concerns focus not only on the data and algorithms involved, but also on the potential to have some form  of explanat ion for any AI -based determination.
# File 20

(l / lead-03
      :ARG0 (u / use-01
            :ARG1 (ii / intelligent-01
                  :mod (a / artificial))
            :ARG2 (d / decide-01
                  :ARG3 (p / person)
                  :ARG1-of (c / consequential-01)
                  :ARG1-of (r / replace-01
                        :ARG2 (d2 / decide-01
                              :ARG0 (p2 / process-02
                                    :ARG0 (b / bureaucracy)
                                    :ARG1-of (d3 / drive-02
                                          :ARG0 (h / human))))
                        :frequency (o / often))))
      :ARG2 (c2 / concern-01
            :ARG0 (e / ensure-01
                  :ARG1 (a2 / and
                        :op1 (j / justice)
                        :op2 (f / fairness)
                        :op3 (a3 / accountable-02)))
            :ARG1-of (s / same-01
                  :ARG2 (c3 / concern-01
                        :ARG1-of (v / voice-01
                              :ARG0 (a4 / and
                                    :op1 (p3 / publication
                                          :name (n / name
                                                :op1 "Big"
                                                :op2 "Data"
                                                :op3 "Seizing"
                                                :op4 "Opportunities"
                                                :op5 ","
                                                :op6 "Preserving"
                                                :op7 "Value")
                                          :ARG1-of (r2 / report-01
                                                :ARG0 (g / government-organization
                                                      :ARG0-of (a5 / administrate-01))
                                                :time (d4 / date-entity
                                                      :year 2014)))
                                    :op2 (p4 / publication
                                          :name (n2 / name
                                                :op1 "Report"
                                                :op2 "to"
                                                :op3 "the"
                                                :op4 "President")
                                          :topic (a6 / and
                                                :op1 (d5 / data
                                                      :mod (b2 / big))
                                                :op2 (p5 / privacy)
                                                :op3 (p6 / perspective
                                                      :mod (t / technology)))
                                          :ARG1-of (p7 / publish-01
                                                :ARG0 (g2 / government-organization
                                                      :name (n3 / name
                                                            :op1 "Council"
                                                            :op2 "of"
                                                            :op3 "Advisors"
                                                            :op4 "on"
                                                            :op5 "Science"
                                                            :op6 "and"
                                                            :op7 "Technology"))
                                                :time (d6 / date-entity
                                                      :year 2014))))
                              :time (p8 / previous)))))
      :ARG2 (c4 / concern-01
            :ARG0 (t2 / transparency)
            :ARG1 (p9 / potential
                  :domain (h2 / have-03
                        :ARG1 (e2 / explain-01
                              :ARG1 (t3 / thing
                                    :ARG1-of (b3 / base-02
                                          :ARG2 ii)))
                        :mod (f2 / form
                              :mod (s2 / some))))))

# ::snt At a technical level, the challenges of fairness and safety are related.
# File 20

(r / relate-01
      :ARG1 (c / challenge-01
            :ARG0 (a / and
                  :op1 (f / fairness)
                  :op2 (s / safe-01)))
      :mod (l / level
            :mod (t / technical)))

# ::snt It can monitor the safety and fairness of applications as they  develop, and adapt regulatory frameworks to encourage innovation while protecting the public.
# File 20

(p / possible-01
      :ARG1 (m / monitor-01
            :ARG0 (ii / it)
            :ARG1 (a / and
                  :op1 (s / safe-01
                        :ARG1 (a2 / application))
                  :op2 (f / fair-01
                        :ARG1 a2))
            :time (a3 / and
                  :op1 (d / develop-02
                        :ARG0 a2
                        :ARG1 (f2 / framework
                              :ARG0-of (r / regulate-01)))
                  :op2 (a4 / adapt-01
                        :ARG0 a2
                        :ARG1 f2
                        :ARG3 (e / encourage-01
                              :ARG0 f2
                              :ARG1 (ii2 / innovate-01)
                              :time (p2 / protect-01
                                    :ARG0 f2
                                    :ARG1 (p3 / public)))))))

# ::snt PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE     17   AI and Regulation   AI has applications in many products, such as cars and aircraft, which  are subject to regulation designed  to protect the public from harm  and ensure fairness in economic competition .
# File 20

(m / multi-sentence
      :snt1 (p / prepare-02
            :ARG2 (f / future
                  :mod (a / artificial_instrument)))
      :snt2 (a2 / and
            :op1 (ii / intelligent-01
                  :mod (a3 / artificial))
            :op2 (r / regulate-01))
      :snt3 (a4 / apply-02
            :ARG1 (ii2 / intelligent-01
                  :mod (a5 / artificial))
            :ARG2 (p2 / product
                  :quant (m2 / many)
                  :example (a6 / and
                        :op1 (c / car)
                        :op2 (a7 / aircraft)
                        :ARG1-of (s / subject-02
                              :ARG2 (r2 / regulate-01
                                    :ARG1-of (d / design-01
                                          :ARG3 (a8 / and
                                                :op1 (p3 / protect-01
                                                      :ARG0 r2
                                                      :ARG1 (p4 / public)
                                                      :ARG2 (h / harm-01
                                                            :ARG1 p4))
                                                :op2 (e / ensure-01
                                                      :ARG0 r2
                                                      :ARG1 (f2 / fair-01
                                                            :ARG1 (c2 / compete-01
                                                                  :mod (e2 / economy))))))))))))

# ::snt Also, where regulatory responses to the addition of AI t hreaten to increase the cost  of compliance or slow the development or adoption of beneficial innovations, policymakers should  consider how those responses could be adjusted to lower costs and barriers to innovation without  adversely impacting safety  or mar ket fairness .
# File 20

(r / recommend-01
      :ARG1 (c / consider-02
            :ARG0 (p / person
                  :ARG0-of (l / legislate-01))
            :ARG1 (t / thing
                  :manner-of (a / adjust-01
                        :ARG1 (r2 / respond-01
                              :ARG1 (a2 / add-02
                                    :ARG1 (ii / intelligent-01
                                          :mod (a3 / artificial)))
                              :ARG0-of (r3 / regulate-01))
                        :ARG2 (a4 / and
                              :op1 (c2 / cost-01
                                    :ARG1 (c3 / comply-01))
                              :op2 (s / slow-01
                                    :ARG1 (o / or
                                          :op1 (d / develop-02
                                                :ARG1 (ii2 / innovate-01
                                                      :ARG1-of (b / benefit-01)))
                                          :op2 (a5 / adopt-01
                                                :ARG1 ii2))))
                        :ARG3 (a6 / and
                              :op1 (c4 / cost-01
                                    :ARG1-of (h / have-degree-91
                                          :ARG2 (l2 / low-04
                                                :ARG1 c4)
                                          :ARG3 (m / more)))
                              :op2 (b2 / barrier
                                    :prep-to (ii3 / innovate-01)))
                        :manner (o2 / or
                              :op1 (ii4 / impact-01
                                    :polarity -
                                    :ARG0 r2
                                    :ARG1 (s2 / safe-01)
                                    :manner (a7 / adverse))
                              :op2 (m2 / mar-02
                                    :polarity -
                                    :ARG0 r2
                                    :ARG1 (f / fairness))))))
      :mod (a8 / also))

# ::snt PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE     30   Fairness, Saf ety, and Governance   As AI technologies gain broader deployment, technical experts and policy analysts have raised concerns  about unintended consequences.
# File 20

(m / multi-sentence
      :snt1 (p / prepare-02
            :ARG2 (f / future
                  :mod (a / artificial)))
      :snt2 (c / concern-01
            :ARG0 (c2 / consequence-03
                  :ARG1-of (ii / intend-01
                        :polarity -))
            :ARG1 (a2 / and
                  :op1 (p2 / person
                        :ARG1-of (e / expert-01
                              :ARG2 (t / technical)))
                  :op2 (p3 / person
                        :ARG0-of (a3 / analyze-01
                              :ARG1 (p4 / policy-01))))
            :time (g / gain-02
                  :ARG0 (t2 / technology
                        :mod a))
            :ARG1 (d / deploy-01
                  :ARG1 t2
                  :ARG1-of (h / have-degree-91
                        :ARG2 (b / broad-02
                              :ARG1 d)
                        :ARG3 (m2 / more))))
      :snt3 (a4 / and
            :op1 (f2 / fairness)
            :op2 (s / safe-01)
            :op3 (e2 / ethics)
            :op4 (g2 / govern-01)))

# ::snt The u se of AI to make consequential decisions about people, often  replacing decisions made by human actors and institutions , leads to concerns about how to ensure justice,  fairness, and accountability —the same concerns voice d previously in the “ Big Data” context.62 The u se of  AI to control physical -world equipment leads to concerns about safety, especially as systems are exposed  to the full complexity of the human environment.
# File 20

(m / multi-sentence
      :li 62
      :snt1 (l / lead-03
            :ARG0 (ii / intelligent-01
                  :mod (a / artificial)
                  :ARG0-of (m2 / make-01
                        :ARG1 (d / decide-01
                              :ARG3 (p / person)
                              :ARG1-of (c / consequential-01))
                        :ARG1-of (r / replace-01
                              :ARG2 (d2 / decide-01
                                    :ARG0 (a2 / and
                                          :op1 p
                                          :ARG0-of (a3 / act-01))
                                    :op2 (ii2 / institution)
                                    :mod (h / human)))
                        :frequency (o / often))))
      :ARG2 (c2 / concern-01
            :ARG0 (e / ensure-01
                  :ARG1 (a4 / and
                        :op1 (j / justice)
                        :op2 (f / fairness)
                        :op3 (a5 / accountable-02)))
            :ARG1-of (s / same-01
                  :ARG2 (c3 / concern-01
                        :ARG1-of (v / voice-01
                              :location (c4 / context
                                    :mod (d3 / data
                                          :mod (b / big)))
                              :time (p2 / previous)))))
      :snt2 (l2 / lead-03
            :ARG0 (ii3 / intelligent-01
                  :mod a)
            :ARG0-of (c5 / control-01
                  :ARG1 (e2 / equipment
                        :mod (w / world
                              :mod (p3 / physical)))))
      :ARG2 (c6 / concern-01
            :ARG0 (s2 / safe-01)
            :ARG1-of (c7 / cause-01
                  :ARG0 (e3 / expose-01
                        :ARG1 (s3 / system)
                        :ARG2 (c8 / complexity
                              :mod (f2 / full)
                              :poss (e4 / environment
                                    :mod (h2 / human)))
                        :mod (e5 / especially)))))

# ::snt At a technical level, the challenges of fairness and safety are related.
# File 20

(r / relate-01
      :ARG1 (c / challenge-01
            :ARG0 (a / and
                  :op1 (f / fairness)
                  :op2 (s / safe-01)))
      :mod (l / level
            :mod (t / technical)))

# ::snt Justice, Fairness, and Accountability   A common theme in the Law and Governance, AI for Social Good, and Social and Economic Impac ts  workshops was the need to ensure that AI promotes justice  and fairness, and that AI -based processes are  accountab le to stakeholders .
# File 20

(n / need-01
      :ARG1 (e / ensure-01
            :ARG1 (a / and
                  :op1 (p / promote-02
                        :ARG0 (ii / intelligent-01
                              :mod (a2 / artificial))
                        :ARG1 (a3 / and
                              :op1 (j / justice)
                              :op2 (f / fairness)))
                  :op2 (a4 / account-01
                        :ARG0 (p2 / process-02
                              :ARG1-of (b / base-02
                                    :ARG2 ii))
                        :ARG1-of (p3 / possible-01)
                        :beneficiary (s / stake-01))))
      :mod (t / theme
            :mod (c / common)
            :location (a5 / and
                  :op1 (a6 / and
                        :op1 (l / law)
                        :op2 (g / govern-01))
                  :op2 (c2 / conference
                        :name (n2 / name
                              :op1 "AI"
                              :op2 "for"
                              :op3 "Social"
                              :op4 "Good"))
                  :op3 (c3 / conference
                        :name (n3 / name
                              :op1 "Social"
                              :op2 "Economic"
                              :op3 "Impac"
                              :op4 "TS"))
                  :op4 (w / workshop)))
      :example (a7 / and
            :op1 j
            :op2 f
            :op3 (a8 / accountable-02)))

# ::snt Justice, Fairness, and Accountability   A common theme in the Law and Governance, AI for Social Good, and Social and Economic Impac ts  workshops was the need to ensure that AI promotes justice  and fairness, and that AI -based processes are  accountab le to stakeholders .
# File 20

(n / need-01
      :ARG1 (e / ensure-01
            :ARG1 (a / and
                  :op1 (p / promote-02
                        :ARG0 (ii / intelligent-01
                              :mod (a2 / artificial))
                        :ARG1 (a3 / and
                              :op1 (j / justice)
                              :op2 (f / fairness)))
                  :op2 (a4 / account-01
                        :ARG0 (p2 / process-02
                              :ARG1-of (b / base-02
                                    :ARG2 ii))
                        :ARG1-of (p3 / possible-01)
                        :beneficiary (s / stake-01))))
      :mod (t / theme
            :mod (c / common)
            :location (a5 / and
                  :op1 (a6 / and
                        :op1 (l / law)
                        :op2 (g / govern-01))
                  :op2 (c2 / conference
                        :name (n2 / name
                              :op1 "AI"
                              :op2 "for"
                              :op3 "Social"
                              :op4 "Good"))
                  :op3 (c3 / conference
                        :name (n3 / name
                              :op1 "Social"
                              :op2 "Economic"
                              :op3 "Impac"
                              :op4 "TS"))
                  :op4 (w / workshop)))
      :example (a7 / and
            :op1 j
            :op2 f
            :op3 (a8 / accountable-02)))

# ::snt A separate report from Upturn question ed the fairness and efficacy of some  predictive  policing tools.67                                                               62 The White House, “Big Data: Seizing Opportunities, Preserving Values,” May 2014,  https://www.whitehouse.gov/sites/de fault/files/docs/big_data_privacy_report_may_1_2014.pdf; and The White  House, “Big Data: A Report on Algorithmic Systems, Opportunity, and Civil Rights,” May 2016,  https://www.whitehouse.gov/sites/default/files/microsites/ostp/2016_0504_data_discrimination .pdf.
# File 20

(a / and
      :op1 (p / publication
            :name (n / name
                  :op1 "Big"
                  :op2 "Data"
                  :op3 "A"
                  :op4 "Report"
                  :op5 "on"
                  :op6 "Algorithmic"
                  :op7 "Systems"
                  :op8 "Opportunities"
                  :op9 "and"
                  :op10 "Civil"
                  :op11 "Rights")
            :ARG1-of (s / separate-02)
            :time (d / date-entity
                  :month 5
                  :year 2016))
      :op2 (p2 / publication
            :name (n2 / name
                  :op1 "The"
                  :op2 "White"
                  :op3 "House")
            :ARG1-of (t / title-01
                  :ARG2 (a2 / and
                        :op1 (s2 / seize-01
                              :ARG1 (o / opportunity))
                        :op2 (p3 / preserve-01
                              :ARG1 (v / value))))
            :time (d2 / date-entity
                  :month 5
                  :year 2014)
            :medium (u / url-entity
                  :value "https://www.whitehouse.gov/sites/default/files/microsites/ostp/2016_0504_data_discrimination.pdf")))

# ::snt Recommendation 16: Federal agencies that use AI -based systems to make or provide decision  support for consequential decisions about individuals should take extra care to ensure the eff icacy  and fairness of those systems, based on evidence -based verification and validation.
# File 20

(r / recommend-01
      :ARG1 (c / care-03
            :ARG0 (a / agency
                  :mod (f / federal)
                  :ARG0-of (u / use-01
                        :ARG1 (s / system
                              :ARG1-of (b / base-02
                                    :ARG2 (ii / intelligent-01
                                          :mod (a2 / artificial))))
                        :ARG2 (o / or
                              :op1 (m / make-01
                                    :ARG0 a
                                    :ARG1 (d / decide-01
                                          :ARG3 (ii2 / individual)
                                          :ARG1-of (c2 / consequential-01)))
                              :op2 (p / provide-01
                                    :ARG0 a
                                    :ARG1 (s2 / support-01
                                          :ARG0 a
                                          :ARG1 (d2 / decide-01
                                                :ARG3 ii2))))))
            :ARG1 (e / ensure-01
                  :ARG0 a
                  :ARG1 (a3 / and
                        :op1 (ii3 / integrity
                              :polarity -
                              :poss (s3 / system
                                    :mod (t / that)))
                        :op2 (f2 / fair-01
                              :ARG1 s3)
                        :ARG1-of (b2 / base-02
                              :ARG2 (a4 / and
                                    :op1 (v / verify-01)
                                    :op2 (v2 / validate-01)
                                    :ARG1-of (b3 / base-02
                                          :ARG2 (e2 / evidence))))))
            :degree (e3 / extra))
      :ARG3 16)

# ::snt Recommendation 17: Federal agencies that make grants to state and local governments in support  of the use of AI -based systems to make consequential decisions about individuals should review the  terms of grants to ensure that AI -based products or services purchased with Federal grant funds  produce results in a sufficiently transparent fashion and are supported by evidence of efficacy and  fairness.
# File 20

(r / recommend-01
      :ARG1 (r2 / review-01
            :ARG0 (a / agency
                  :mod (f / federal)
                  :ARG0-of (g / grant-01
                        :ARG2 (a2 / and
                              :op1 (g2 / government-organization
                                    :ARG0-of (g3 / govern-01)
                                    :mod (s / state))
                              :op2 (g4 / government-organization
                                    :ARG0-of (g5 / govern-01)
                                    :ARG1-of (l / local-02)))
                        :purpose (s2 / support-01
                              :ARG0 a
                              :ARG1 (u / use-01
                                    :ARG1 (s3 / system
                                          :ARG1-of (b / base-02
                                                :ARG2 (ii / intelligent-01
                                                      :mod (a3 / artificial))))
                                    :ARG2 (d / decide-01
                                          :ARG3 (ii2 / individual)
                                          :ARG1-of (c / consequential-01))))))
            :ARG1 (t / term
                  :mod (g6 / grant-01))
            :purpose (e / ensure-01
                  :ARG0 a
                  :ARG1 (a4 / and
                        :op1 (p / produce-01
                              :ARG0 (o / or
                                    :op1 (p2 / product)
                                    :op2 (s4 / serve-01)
                                    :ARG1-of (b2 / base-02
                                          :ARG2 ii)
                                    :ARG1-of (p3 / purchase-01
                                          :ARG3 (f2 / fund
                                                :mod g6)))
                              :ARG1 (r3 / result-01
                                    :manner (t2 / transparent
                                          :ARG0-of (s5 / suffice-01))))
                        :op2 (s6 / support-01
                              :ARG0 (e2 / evidence-01
                                    :ARG1 (a5 / and
                                          :op1 (e3 / effective-04)
                                          :op2 (f3 / fair-01)))
                              :ARG1 o))))
      :ARG2 (p4 / publication
            :mod 17))

# ::snt PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE     35   Global Considerations and Security   In addition to the long -term challenges of AI and the specific issues relating to fairness and safety, AI  poses consequential policy questions in international relations, cybersecurity, and defense.
# File 20

(m / multi-sentence
      :snt1 (p / prepare-02
            :ARG2 (f / future
                  :mod (a / artificial_instrument)))
      :snt2 (a2 / and
            :li 35
            :op1 (c / consider-02
                  :ARG1 (g / globe))
            :op2 (s / security))
      :snt3 (p2 / pose-02
            :ARG0 (ii / intelligent-01
                  :mod (a3 / artificial))
            :ARG1 (q / question-01
                  :ARG1 (p3 / policy-01)
                  :ARG2 (a4 / and
                        :op1 (r / relation-03
                              :ARG1 (ii2 / international))
                        :op2 (c2 / cybersecurity)
                        :op3 (d / defend-01))
                  :ARG1-of (c3 / consequential-01))
            :ARG1-of (a5 / add-02
                  :ARG2 (a6 / and
                        :op1 (c4 / challenge-01
                              :ARG0 ii
                              :ARG1-of (l / long-03))
                        :op2 (ii3 / issue-02
                              :ARG1-of (s2 / specific-02)
                              :ARG1-of (r2 / relate-01
                                    :ARG2 (a7 / and
                                          :op1 (f2 / fairness)
                                          :op2 (s3 / safe-01))))))))

# ::snt It should monitor the safety and fairness of applications as they develop,  and adapt regulatory frameworks to encourage innovation while protecting the public.
# File 20

(r / recommend-01
      :ARG1 (m / monitor-01
            :ARG0 (ii / it)
            :ARG1 (a / and
                  :op1 (s / safe-01
                        :ARG1 (a2 / application))
                  :op2 (f / fair-01
                        :ARG1 a2))
            :time (a3 / and
                  :op1 (d / develop-02
                        :ARG0 a2
                        :ARG1 (f2 / framework
                              :ARG0-of (r2 / regulate-01)))
                  :op2 (a4 / adapt-01
                        :ARG0 a2
                        :ARG1 f2
                        :ARG3 (e / encourage-01
                              :ARG0 f2
                              :ARG1 (ii2 / innovate-01)
                              :time (p / protect-01
                                    :ARG0 f2
                                    :ARG1 (p2 / public)))))))

# ::snt Recommendation  16: Federal ag encies that use AI -based systems to make or provide decision support  for consequential decisions about individuals should take extra care to ensure the efficacy and fairness  of those systems, based on evidence -based verification and validation.
# File 20

(r / recommend-01
      :li 16
      :ARG1 (c / care-03
            :ARG0 (g / government-organization
                  :mod (f / federal)
                  :ARG0-of (a / administer-01)
                  :ARG0-of (u / use-01
                        :ARG1 (s / system
                              :ARG1-of (b / base-02
                                    :ARG2 (ii / intelligent-01
                                          :mod (a2 / artificial))))
                        :ARG2 (o / or
                              :op1 (m / make-01
                                    :ARG0 g
                                    :ARG1 (d / decide-01
                                          :ARG3 (ii2 / individual)
                                          :ARG1-of (c2 / consequential-01)))
                              :op2 (p / provide-01
                                    :ARG0 g
                                    :ARG1 (s2 / support-01
                                          :ARG0 g
                                          :ARG1 (d2 / decide-01
                                                :ARG3 ii2))))))
            :ARG1 (e / ensure-01
                  :ARG0 g
                  :ARG1 (a3 / and
                        :op1 (e2 / effective-04
                              :ARG0 (s3 / system
                                    :mod (t / that)))
                        :op2 (f2 / fair-01
                              :ARG1 s3)
                        :ARG1-of (b2 / base-02
                              :ARG2 (a4 / and
                                    :op1 (v / verify-01)
                                    :op2 (v2 / validate-01)
                                    :ARG1-of (b3 / base-02
                                          :ARG2 (e3 / evidence))))))
            :degree (e4 / extra)))

# ::snt Recommend ation  17: Federal agencies that make grants to state and local governments in support of  the use of AI -based systems to make consequential decisions about individuals should review the terms  of grants to ensure that AI -based products or services purchased with Federal grant funds produce  results in a sufficiently transparent fashion and are supported by evidence of efficacy and fairness.
# File 20

(r / recommend-01
      :ARG1 (r2 / review-01
            :ARG0 (a / agency
                  :mod (f / federal)
                  :ARG0-of (g / grant-01
                        :ARG2 (a2 / and
                              :op1 (g2 / government-organization
                                    :ARG0-of (g3 / govern-01)
                                    :mod (s / state))
                              :op2 (g4 / government-organization
                                    :ARG0-of (g5 / govern-01)
                                    :ARG1-of (l / local-02)))
                        :purpose (s2 / support-01
                              :ARG0 a
                              :ARG1 (u / use-01
                                    :ARG1 (s3 / system
                                          :ARG1-of (b / base-02
                                                :ARG2 (ii / intelligent-01
                                                      :mod (a3 / artificial))))
                                    :ARG2 (d / decide-01
                                          :ARG3 (ii2 / individual)
                                          :ARG1-of (c / consequential-01))))))
            :ARG1 (t / term-01
                  :ARG1 (g6 / grant-01))
            :purpose (e / ensure-01
                  :ARG0 a
                  :ARG1 (a4 / and
                        :op1 (p / produce-01
                              :ARG0 (o / or
                                    :op1 (p2 / product)
                                    :op2 (s4 / serve-01)
                                    :ARG1-of (b2 / base-02
                                          :ARG2 ii)
                                    :ARG1-of (p3 / purchase-01
                                          :ARG3 (f2 / fund-01
                                                :ARG0 g6)))
                              :ARG1 (r3 / result-01
                                    :manner (t2 / transparent
                                          :ARG0-of (s5 / suffice-01))))
                        :op2 (s6 / support-01
                              :ARG0 (e2 / evidence-01
                                    :ARG1 (a5 / and
                                          :op1 (e3 / effective-04)
                                          :op2 (f3 / fair-01)))
                              :ARG1 o))))
      :ARG2 (p4 / publication
            :name (n / name
                  :op1 "Ation"
                  :op2 17)))

# ::snt 21"**P5 .PCJMF $MPVE#JH %BUB 21Strengths Weaknesses ■ Topnotch ICT infrastructure ■ Tech-savvy people ■ Aggressive government investment in R&D ■ World-class manufacturing infrastructure ■ Zeal for education■ Reluctance to invest in startups with innovative      technologies or potential for M&A deals ■ Lack of entrepreneurial spirit and will to rise to      challenges and take risks ■ Lack of quality data infrastructure ■ Monolithic education and hiring-centered     employment policy ■ Rigid, vertical regulatory system Opportunities Threats ■ Using Intelligent IT to solve social problems ■ Using Intelligent IT to strengthen competitiveness of      major industries and pioneer new markets ■ Using knowledge and data to achieve greater growth      in the global market■ Encroachment by global corporations into Korean      industries ■ Rapidly changing structure of employment and      socioeconomic polarization ■ Fairness-related controversies over platform      monopolization and other such issues ■ Increased risks of hacking and threats to privacyMid-to Long-Term Master Plan in Preparation for the Intelligent Information Society:  Managing the Fourth Industrial Revolution ⅠBackground  Ⅱ Engine of the Fourth  Industrial Revolution: Intelligent ITⅤVision and Strategy Ⅶ Tasks ⅥMid- to Long-Term Policy Aims  for Intelligent Information SocietyⅢForecasts of Possible Changes  Brought about by Intelligent IT ⅣFuture Prospects  and Core Factors of Success2.
# File 103

(m / multi-sentence
      :snt1 (a / and
            :op1 (p / publication
                  :name (n / name
                        :op1 "PCJMF"))
            :op2 (p2 / publication
                  :name (n2 / name
                        :op1 "MPVE#JH"))
            :op3 (p3 / publication
                  :name (n3 / name
                        :op1 "BUB"))
            :op4 (p4 / publication
                  :name (n4 / name
                        :op1 "Intelligent"
                        :op2 "Information"
                        :op3 "Society"))
            :op5 (p5 / publication
                  :name (n5 / name
                        :op1 "The"
                        :op2 "Fourth"
                        :op3 "Industrial"
                        :op4 "Revolution"))
            :op6 (p6 / publication
                  :name (n6 / name
                        :op1 "Vision"
                        :op2 "and"
                        :op3 "Data"))
            :op7 (p7 / publication
                  :name (n7 / name
                        :op1 "Mid-to"
                        :op2 "Long-"
                        :op3 "Term"
                        :op4 "Policy"
                        :op5 "Aims"
                        :op6 "for"
                        :op7 "Intelligent"
                        :op8 "Information"
                        :op9 "Society"))
            :op8 (p8 / publication
                  :name (n8 / name
                        :op1 "Future"
                        :op2 "Prospects"))
            :op9 (p9 / publication
                  :name (n9 / name
                        :op1 "Core"
                        :op2 "Factor"))
            :op10 (p10 / publication
                  :name (n10 / name
                        :op1 "The"
                        :op2 "Fourth"
                        :op3 "Industrial"
                        :op4 "Revolution"))
            :op11 (p11 / publication
                  :name (n11 / name
                        :op1 "21"
                        :op2 "P5"))
            :op12 (r / reluctant-01
                  :ARG1 (ii / invest-01
                        :ARG2 (s / startup
                              :ARG0-of (h / have-03
                                    :ARG1 (o / or
                                          :op1 (t / technology
                                                :ARG1-of (ii2 / innovate-01))
                                          :op2 (p12 / potential
                                                :purpose (d / deal-01
                                                      :ARG2 (a2 / and
                                                            :op1 (m2 / manufacture-01)
                                                            :op2 (o2 / operate-01)))))))))
            :op13 (a3 / and
                  :op1 (l / lack-01
                        :ARG1 (s2 / spirit
                              :mod (e / entrepreneurial)))
                  :op2 (w / will-02
                        :ARG1 (r2 / rise-01
                              :ARG1 (a4 / and
                                    :op1 (c / challenge-01)
                                    :op2 (t2 / take-01
                                          :ARG1 (r3 / risk-01))))))
            :op14 (c2 / change-01
                  :ARG1 (s3 / structure-01
                        :ARG1 (a5 / and
                              :op1 (e2 / employ-01)
                              :op2 (e3 / employ-01)))
                  :ARG1-of (r4 / rapid-02)))
      :op15 (c3 / controversy
            :ARG1-of (r5 / relate-01
                  :ARG2 (f / fairness)))
      :op16 (a6 / and
            :op1 (m3 / monopolize-01)
            :op2 (ii3 / issue-02
                  :mod (o3 / other)))
      :op17 (e4 / et-cetera)
      :op18 (t3 / threaten-01
            :ARG1 (a7 / and
                  :op1 (h2 / hack-04)
                  :op2 (p13 / privacy)))
      :op19 (u / use-01
            :ARG1 t)
      :ARG2 (s4 / solve-01
            :ARG1 (p14 / problem
                  :mod (s5 / society))))

# ::snt * As the massive quantities of data involved and high complexity of AI algorithms will make it nearly impossible for  humans to rid these systems of biases once they begin operating and evolving, policymakers may well need to develop and establish refined methods for applying and testing ethical standards for their development at every stage (e.g., requirements for testing the fairness and reliability of data, enforcing the fiduciary duty of developers, preventing reverse choices, etc.).
# File 103

(p / possible-01
      :ARG1 (n / need-01
            :ARG0 (p2 / person
                  :ARG0-of (l / legislate-01))
            :ARG1 (a / and
                  :op1 (d / develop-02
                        :ARG0 p2
                        :ARG1 (m / method
                              :ARG1-of (r / refine-01)
                              :instrument-of (a2 / and
                                    :op1 (a3 / apply-02
                                          :ARG0 p2
                                          :ARG1 (s / standard
                                                :mod (e / ethics))
                                          :ARG2 (d2 / develop-02
                                                :ARG1 (s2 / system
                                                      :mod (t / this))))
                                    :op2 (t2 / test-01
                                          :ARG0 p2
                                          :ARG1 s)
                                    :time (s3 / stage
                                          :mod (e2 / every)))
                              :example (r2 / require-01
                                    :ARG1 (a4 / and
                                          :op1 (t3 / test-01
                                                :ARG1 (a5 / and
                                                      :op1 (f / fairness
                                                            :poss (d3 / data))
                                                      :op2 (r3 / reliability
                                                            :poss d3)))
                                          :op2 (e3 / enforce-01
                                                :ARG1 (d4 / duty
                                                      :mod (f2 / fiduciary)
                                                      :poss (p3 / person
                                                            :ARG0-of (d5 / develop-02))))
                                          :op3 (p4 / prevent-01
                                                :ARG1 (c / choose-01
                                                      :ARG1-of (r4 / reverse-01)))
                                          :op4 (e4 / et-cetera)))))
                  :op2 (e5 / establish-01
                        :ARG0 p2
                        :ARG1 m)))
      :ARG1-of (c2 / cause-01
            :ARG0 (m2 / make-02
                  :ARG0 (a6 / and
                        :op1 (q / quantity
                              :quant-of (d6 / data
                                    :ARG1-of (ii / involve-01))
                              :mod (m3 / massive))
                        :op2 (c3 / complexity
                              :ARG1-of (h / high-02)
                              :poss (a7 / algorithm
                                    :mod (ii2 / intelligent-01
                                          :mod (a8 / artificial)))))
                  :ARG1 (p5 / possible-01
                        :polarity -
                        :ARG1 (r5 / rid-01
                              :ARG0 (h2 / human)
                              :ARG1 (b / bias-01
                                    :ARG1 s2)
                              :time (b2 / begin-01
                                    :ARG0 s2
                                    :ARG1 (a9 / and
                                          :op1 (o / operate-01
                                                :ARG0 s2)
                                          :op2 (e6 / evolve-01
                                                :ARG1 s2))))
                        :degree (n2 / near))))
      :mod (w / well))

# ::snt Government Forum Judiciary Administration Legislature ■ Accumulate responsible decisions       and precedents with the aim of       establishing AI ethics.■ Reinforce the social security net       to produce better workforces and      enhance quality of life for all.■ Build a society-wide consensus on       the expected revolutionary changes.■ Mitigate the winner-takes-all       tendency and ensure fairness in       distribution.■ Provide strategic support       for the rapid development of      competitiveness in technologies       and industries.■ Update the paradigm for, and       specific measures of, regulation.■ Find new models for dispute       settlement in consideration of the      changes in society at large.■ Build public-private partnership.■ Discuss issues concerning       democratic values, such as ethics      and privacy.
# File 103

(m / multi-sentence
      :snt1 (o / organization
            :name (n / name
                  :op1 "Government"
                  :op2 "Forum"
                  :op3 "Judiciary"
                  :op4 "Administration"))
      :snt2 (a / and
            :op1 (a2 / accumulate-01
                  :ARG1 (a3 / and
                        :op1 (t / thing
                              :ARG1-of (d / decide-01)
                              :ARG1-of (r / responsible-02))
                        :op2 (p / precedent))
                  :purpose (e / establish-01
                        :ARG1 (e2 / ethics
                              :mod (a4 / artificial))))
            :op2 (e3 / ensure-01
                  :ARG1 (f / fair-01
                        :ARG1 (d2 / distribute-01)))
            :snt3 (p2 / provide-01
                  :ARG1 (s / support-01
                        :ARG1 (d3 / develop-02
                              :ARG1 (a5 / and
                                    :op1 (w / workforce
                                          :ARG1-of (h / have-degree-91
                                                :ARG2 (g / good-02
                                                      :ARG1 w)
                                                :ARG3 (m2 / more)))
                                    :op2 (c / competitiveness
                                          :topic (a6 / and
                                                :op1 (t2 / technology)
                                                :op2 (ii / industry))))
                              :manner (r2 / rapid))))
            :snt4 (u / update-01
                  :ARG1 (p3 / paradigm)
                  :purpose (a7 / and
                        :op1 (d4 / dispute-01)
                        :op2 (s2 / settle-02)
                        :ARG1-of (s3 / specific-02))
                  :ARG1-of (c2 / consider-02
                        :ARG2 (c3 / change-01
                              :location (s4 / society
                                    :mod (a8 / at-large))
                              :ARG1-of (e4 / expect-01))))
            :snt5 (b / build-01
                  :ARG1 (p4 / partnership
                        :ARG1-of (p5 / public-02)
                        :ARG1-of (p6 / private-03)))))

# ::snt Availability (supply)   People (skills, training, diversity)   Innovation (R&D)   Access (access rights)   Security and sovereignty (location)     ISO/IEC TR 24030:2021   (ISO and IEC, 2021 [76])  Provides a selection of submitted AI use cases,  focusing on trustworthiness ( e.g., fairness and bias).
# File 134

(m / multi-sentence
      :snt1 (a / and
            :op1 (a2 / availability
                  :ARG1-of (m2 / mean-01
                        :ARG2 (s / supply-01)))
            :op2 (p / person
                  :ARG1-of (m3 / mean-01
                        :ARG2 (a3 / and
                              :op1 (s2 / skill)
                              :op2 (t / train-01)
                              :op3 (d / diversity))))
            :op3 (ii / innovate-01
                  :ARG1-of (m4 / mean-01
                        :ARG2 (r / research-01)))
            :op4 (a4 / access-01
                  :ARG1-of (m5 / mean-01
                        :ARG2 (r2 / right-05
                              :ARG2 (a5 / access-01))))
            :op5 (a6 / and
                  :op1 (s3 / security)
                  :op2 (s4 / sovereignty)
                  :ARG1-of (m6 / mean-01
                        :ARG2 (l / location)))
            :op6 (p2 / provide-01
                  :ARG1 (s5 / select-01
                        :ARG1 (c / case-04
                              :ARG1 (u / use-01
                                    :ARG1 (ii2 / intelligent-01
                                          :mod (a7 / artificial)))
                              :ARG1-of (s6 / submit-01))
                        :ARG0-of (f / focus-01
                              :ARG2 (d2 / deserve-01
                                    :ARG1 (t2 / trust-01)
                                    :example (a8 / and
                                          :op1 (f2 / fairness)
                                          :op2 (b / bias-01))))))
            :ARG1-of (d3 / describe-01
                  :ARG0 (p3 / publication
                        :name (n / name
                              :op1 "ISO/IEC"
                              :op2 "TR")
                        :time (d4 / date-entity
                              :year 2021)
                        :ARG1-of d3
                        :ARG0 p3
                        :ARG1-of (c2 / cite-01
                              :ARG2 76)))))

# ::snt The Communication explicitly addresses the risk posed by automated decision-making: “Some AI applications may raise new ethical and legal questions, related to liability or fairness of decision-making” .
# File 39

(a / address-02
      :ARG0 (c / communicate-01)
      :ARG1 (r / risk-01
            :ARG1 (m / make-01
                  :ARG1 (d / decide-01)
                  :ARG1-of (a2 / automate-01)))
      :ARG2 (p / possible-01
            :ARG1 (r2 / raise-01
                  :ARG0 (a3 / application
                        :mod (ii / intelligent-01
                              :mod (a4 / artificial))
                        :mod (s / some))
                  :ARG1 (q / question-01
                        :ARG1 (a5 / and
                              :op1 (e / ethics)
                              :op2 (l / legal-02))
                        :ARG1-of (n / new-01)
                        :ARG1-of (r3 / relate-01
                              :ARG2 (o / or
                                    :op1 (l2 / liable-01
                                          :ARG1 (m2 / make-01
                                                :ARG1 (d2 / decide-01)))
                                    :op2 (f / fair-01
                                          :ARG1 m2))))))
      :ARG1-of (e2 / explicit-03))

# ::snt By the summer of 2019, the Communication foresees the creation of a framework for all  relevant stakeholders and experts—see European AI Alliance and High-Level Expert Group in this chapter—who will draft the guidelines, addressing issues such as future of work, fairness, safety, security, social inclusion and algorithmic transparency.
# File 39

(m / multi-sentence
      :snt1 (f / foresee-01
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "Communication"))
            :ARG1 (c / create-01
                  :ARG1 (f2 / framework
                        :beneficiary (a / and
                              :op1 (s / stake-01
                                    :ARG1-of (r / relevant-01))
                              :op2 (p / person
                                    :ARG1-of (e / expert-01))
                              :mod (a2 / all))
                        :ARG0-of (d / draft-01
                              :ARG1 (g / guideline
                                    :ARG0-of (a3 / address-02
                                          :ARG1 (ii / issue-02
                                                :example (a4 / and
                                                      :op1 (f3 / future
                                                            :poss (w / work-01))
                                                      :op2 (f4 / fairness)
                                                      :op3 (s2 / safe-01)
                                                      :op4 (s3 / security)
                                                      :op5 (ii2 / include-01
                                                            :ARG2 (s4 / society))
                                                      :op6 (t / transparency
                                                            :mod (a5 / algorithm))))))))
                  :time (b / by
                        :op1 (d2 / date-entity
                              :year 2019
                              :season (s5 / summer)))))
      :snt2 (s6 / see-01
            :mode imperative
            :ARG0 (y / you)
            :ARG1 (a6 / and
                  :op1 (o2 / organization
                        :name (n2 / name
                              :op1 "European"
                              :op2 "AI"
                              :op3 "Alliance"))
                  :op2 (o3 / organization
                        :name (n3 / name
                              :op1 "High-Level"
                              :op2 "Expert"
                              :op3 "Group")))
            :location (c2 / chapter
                  :mod (t2 / this))))

# ::snt The guidelines will cover issues such as fairness, safety, transparency, the future of work, democracy and more broadly the impact of AI and automated decision-making on the application of the Charter of Fundamental Rights, including: privacy and personal data protection, dignity, consumer protection and non-discrimination.
# File 39

(c / cover-01
      :ARG0 (g / guideline)
      :ARG1 (ii / issue-02
            :ARG0 (a / and
                  :op1 (f / fairness)
                  :op2 (s / safe-01)
                  :op3 (t / transparency)
                  :op4 (f2 / future
                        :poss (w / work-01))
                  :op5 (d / democracy)
                  :op6 (ii2 / impact-01
                        :ARG0 (a2 / and
                              :op1 (ii3 / intelligent-01
                                    :mod (a3 / artificial))
                              :op2 (m / make-01
                                    :ARG1 (d2 / decide-01)
                                    :ARG1-of (a4 / automate-01)))
                        :ARG1 (a5 / apply-02
                              :ARG1 (l / law
                                    :name (n / name
                                          :op1 "Charter"
                                          :op2 "of"
                                          :op3 "Fundamental"
                                          :op4 "Rights")
                                    :ARG2-of (ii4 / include-01
                                          :ARG1 (a6 / and
                                                :op1 (p / privacy)
                                                :op2 (p2 / protect-01
                                                      :ARG1 (d3 / data
                                                            :ARG1-of (p3 / personal-02)))
                                                :op3 (d4 / dignity)
                                                :op4 (p4 / protect-01
                                                      :ARG1 (p5 / person
                                                            :ARG0-of (c2 / consume-01)))
                                                :op5 (d5 / discriminate-01
                                                      :polarity -)))))
                        :ARG1-of (h / have-degree-91
                              :ARG2 (b / broad-02
                                    :ARG1 ii2)
                              :ARG3 (m2 / more))))))

# ::snt And how can the benefits brought about by new digital technologies be equitably shared among all?”  external [eU 54]   W The Declar ation on Ethics and Data Protection in Artificial Intelligence, adopted at  the 2018 International Conference of Data  p rotection and  p rivacy Commissioners,  endorses guiding principles in regard to AI—including elaborations on fairness, accountability, systems transparency and intelligibility, ethics and privacy by design, empowerment and public engagement and the reduction and mitigation of unlawful bias and discrimination  external [eU 55]  W An early opinion b y the ED p S from 2014 analyses the EU Commission's proposal for a  Regulation of the European  parliament and of the Council on a European network of  Emplo yment Services, workers’ access to mobility services and the further integration  of labour markets, among others, on the use of ADM in job matching at the EURES portal  external [eU 56]page 32 a utomating s ociety european Union
# File 39

(m / multi-sentence
      :snt1 (a / and
            :op2 (p / possible-01
                  :ARG1 (s / share-01
                        :ARG0 (a2 / all)
                        :ARG1 (b / benefit
                              :ARG1-of (b2 / bring-about-05
                                    :ARG0 (t / technology
                                          :mod (d / digital)
                                          :ARG1-of (n / new-01))))
                        :manner (e / equitable))
                  :manner (a3 / amr-unknown)))
      :snt2 (a4 / and
            :op1 (e2 / external
                  :mod 54)
            :op2 (e3 / external
                  :mod 56))
      :snt3 (a5 / analyze-01
            :ARG0 (t2 / thing
                  :ARG1-of (o / opine-01
                        :ARG0 (o2 / organization
                              :name (n2 / name
                                    :op1 "ED")))
                  :time (d2 / date-entity
                        :year 2014))
            :ARG1 (p2 / propose-01
                  :ARG0 (a6 / and
                        :op1 (o3 / organization
                              :name (n3 / name
                                    :op1 "European"
                                    :op2 "Commission"))
                        :op2 (o4 / organization
                              :name (n4 / name
                                    :op1 "Council"
                                    :op2 "on"
                                    :op3 "a"
                                    :op4 "European"
                                    :op5 "Network")))
                  :ARG1 (a7 / and
                        :op1 (f / fairness)
                        :op2 (a8 / accountable-02)
                        :op3 (t3 / transparency)
                        :op4 (ii / intelligibility)
                        :op5 (e4 / ethics)
                        :op6 (p3 / privacy
                              :manner (d3 / design-01))
                        :op7 (e5 / empower-01)
                        :op8 (e6 / engage-01
                              :ARG1 (p4 / public))
                        :op9 (r / reduce-01
                              :ARG1 (a9 / and
                                    :op1 (b3 / bias-01
                                          :mod (l / law
                                                :polarity -))
                                    :op2 (d4 / discriminate-02)))))))

# ::snt Implications of particular relevance to the participatory and fairness aspects of automated  decision-making—which also have strong effects on the regulatory and policy framework for the application of ADM—can be found in the following paragraphs: Section 3.1, focusing on Strengthening Research in Germany and Europe and section 3.8, Making data available and facilitating (re-)use introduce a “systematic approach to technology” that promotes research on methods for “monitoring and traceability of algorithmic predic-tion and decision-making systems” , as well as research on pseudonymisation and anonymi-sation methods, and on the compilation of synthetic training data.
# File 39

(p / possible-01
      :ARG1 (f / find-01
            :ARG1 (ii / implicate-01
                  :ARG0-of (a / affect-01
                        :ARG1 (a2 / and
                              :op1 (f2 / framework
                                    :ARG0-of (r / regulate-01))
                              :op2 (f3 / framework
                                    :mod (p2 / policy-01)))
                        :ARG2 (a3 / apply-02
                              :ARG1 (p3 / product
                                    :name (n / name
                                          :op1 "ADM")))
                        :ARG1-of (s / strong-02)
                        :mod (a4 / also))
                  :ARG1-of (r2 / relevant-01
                        :ARG2 (a5 / aspect
                              :mod (p4 / particular)
                              :mod (p5 / participate-01)
                              :mod (m / make-01
                                    :ARG1 (d / decide-01)
                                    :ARG1-of (a6 / automate-01)))))
            :location (p6 / paragraph
                  :ARG1-of (f4 / follow-04)
                  :ARG2-of (ii2 / include-91
                        :ARG1 (a7 / and
                              :op1 (s2 / section
                                    :mod 3.1
                                    :ARG0-of (f5 / focus-01
                                          :ARG1 (s3 / strengthen-01
                                                :ARG1 (r3 / research-01
                                                      :location (a8 / and
                                                            :op1 (c / country
                                                                  :name (n2 / name
                                                                        :op1 "Germany"))
                                                            :op2 (c2 / continent
                                                                  :name (n3 / name
                                                                        :op1 "Europe")))))))
                              :op2 (s4 / section
                                    :mod 3.8
                                    :topic (m2 / make-02
                                          :ARG1 (a9 / available-02
                                                :ARG2 (d2 / data)))
                                    :op3 (f6 / facilitate-01
                                          :ARG1 (u / use-01
                                                :ARG1 d2
                                                :mod (a10 / again)))
                                    :ARG0-of (ii3 / introduce-02
                                          :ARG1 (a11 / approach-02
                                                :ARG1 (t / technology)
                                                :mod (s5 / systematic)
                                                :ARG0-of (p7 / promote-02
                                                      :ARG1 (r4 / research-01
                                                            :ARG1 (a12 / and
                                                                  :op1 (m3 / method
                                                                        :purpose (m4 / monitor-01
                                                                              :ARG1 (a13 / and
                                                                                    :op1 (s6 / system
                                                                                          :mod (p8 / predict-01
                                                                                                :manner (a14 / algorithm)))
                                                                                    :op2 (s7 / system
                                                                                          :mod (m5 / make-01
                                                                                                :ARG1 (d3 / decide-01)))))))
                                                            :op2 (m6 / method
                                                                  :purpose (a15 / and
                                                                        :op1 (p9 / pseudonymize-00)
                                                                        :op2 (m7 / method
                                                                              :mod (a16 / anonymity)))))
                                                      :op3 (c3 / compile-01
                                                            :ARG1 (d4 / data
                                                                  :mod (t2 / train-01)
                                                                  :mod (s8 / synthetic))))))))))))

# ::snt external [NL 20] Notable recent research includes a report external [NL 21]  that is part of a research collaboration  between the Universities of Amsterdam, Tilburg, Radboud, Utrecht and Eindhoven (TU/e) on automated decision-making, and which forms part of the groups’ research on fairness in automated decision-making.
# File 39

(ii / include-01
      :ARG1 (r / report-01
            :ARG1 (c / collaborate-01
                  :ARG0 (a / and
                        :op1 (u / university
                              :name (n / name
                                    :op1 "University"
                                    :op2 "of"
                                    :op3 "Amsterdam"))
                        :op2 (u2 / university
                              :name (n2 / name
                                    :op1 "Tilburg"))
                        :op3 (u3 / university
                              :name (n3 / name
                                    :op1 "Radboud"))
                        :op4 (u4 / university
                              :name (n4 / name
                                    :op1 "Utrecht"))
                        :op5 (u5 / university
                              :name (n5 / name
                                    :op1 "Eindhoven")))
                  :ARG1 (r2 / research-01
                        :ARG1 (m / make-01
                              :ARG1 (d / decide-01)
                              :ARG1-of (a2 / automate-01))))
            :part-of (r3 / research-01
                  :ARG0 a))
      :ARG2 (r4 / research-01
            :time (r5 / recent)
            :ARG1-of (n6 / notable-04))
      :ARG1-of (d2 / describe-01
            :ARG0 (p / publication
                  :name (n7 / name
                        :op1 "NL"
                        :op2 20))))

# ::snt barcelona spainT aking Stock of   Automated DecisionMaking in the EUautomating Society – The Fairness Measures  Project is an international group of data scientists who develop fairness-aware algorithms and systems and provide relevant software and data sets to the research community.
# File 39

(m / multi-sentence
      :snt2 (g / group
            :mod (ii / international)
            :consist-of (s / scientist
                  :mod (d / data))
            :ARG0-of (d2 / develop-02
                  :ARG1 (a / and
                        :op1 (a2 / algorithm)
                        :op2 (s2 / system)
                        :ARG0-of (r / realize-01
                              :ARG1 (f / fairness))))
            :ARG0-of (p / provide-01
                  :ARG1 (a3 / and
                        :op1 (s3 / software)
                        :op2 (s4 / set
                              :consist-of (d3 / data))
                        :ARG1-of (r2 / relevant-01))
                  :ARG2 (c / community
                        :mod (r3 / research-01)))
            :domain (o / organization
                  :name (n / name
                        :op1 "The"
                        :op2 "Fairness"
                        :op3 "Measures"
                        :op4 "Project")))
      :snt1 (s5 / sell-01
            :ARG0 (c2 / city
                  :name (n2 / name
                        :op1 "Barcelona"))
            :ARG1 (s6 / stock
                  :mod (o2 / organization
                        :name (n3 / name
                              :op1 "Automated"
                              :op2 "Decision"
                              :op3 "Making"
                              :op4 "in"
                              :op5 "the"
                              :op6 "EUautomating"
                              :op7 "Society")))))

# ::snt barcelona spainT aking Stock of   Automated DecisionMaking in the EUautomating Society – The Fairness Measures  Project is an international group of data scientists who develop fairness-aware algorithms and systems and provide relevant software and data sets to the research community.
# File 39

(m / multi-sentence
      :snt2 (g / group
            :mod (ii / international)
            :consist-of (s / scientist
                  :mod (d / data))
            :ARG0-of (d2 / develop-02
                  :ARG1 (a / and
                        :op1 (a2 / algorithm)
                        :op2 (s2 / system)
                        :ARG0-of (r / realize-01
                              :ARG1 (f / fairness))))
            :ARG0-of (p / provide-01
                  :ARG1 (a3 / and
                        :op1 (s3 / software)
                        :op2 (s4 / set
                              :consist-of (d3 / data))
                        :ARG1-of (r2 / relevant-01))
                  :ARG2 (c / community
                        :mod (r3 / research-01)))
            :domain (o / organization
                  :name (n / name
                        :op1 "The"
                        :op2 "Fairness"
                        :op3 "Measures"
                        :op4 "Project")))
      :snt1 (s5 / sell-01
            :ARG0 (c2 / city
                  :name (n2 / name
                        :op1 "Barcelona"))
            :ARG1 (s6 / stock
                  :mod (o2 / organization
                        :name (n3 / name
                              :op1 "Automated"
                              :op2 "Decision"
                              :op3 "Making"
                              :op4 "in"
                              :op5 "the"
                              :op6 "EUautomating"
                              :op7 "Society")))))

# ::snt Political de Bate S on a SPect S of automation -  civil  S ociety and academia / The Fairness Measures Project   The growing use of automated decision-making has the potential to increase the risk of discrimination against disadvantaged groups.
# File 39

(p / potential
      :domain (ii / increase-01
            :ARG0 (u / use-01
                  :ARG1 (m / make-01
                        :ARG1 (d / decide-01)
                        :ARG1-of (a / automate-01))
                  :ARG1-of (g / grow-01))
            :ARG1 (r / risk-01
                  :ARG1 (d2 / discriminate-02
                        :ARG1 (g2 / group
                              :ARG1-of (a2 / advantage-01
                                    :polarity -)))))
      :prep-on (t / topic
            :name (n / name
                  :op1 "Political"
                  :op2 "de"
                  :op3 "Bate")
            :topic (a3 / automate-01)
            :mod (c / civil)
            :mod (e / economy)
            :mod (a4 / academia)
            :mod (t2 / thing
                  :name (n2 / name
                        :op1 "The"
                        :op2 "Fairness"
                        :op3 "Measures"
                        :op4 "Project"))))

# ::snt The Fairness Measures Project is a group of data scientists from Chile, Germany and Spain, led by Carlos Castillo (Pompeu Fabra Uni-versity, Barcelona).
# File 39

(g / group-01
      :ARG1 (s / scientist
            :mod (d / data)
            :source (a / and
                  :op1 (c / country
                        :name (n / name
                              :op1 "Chile"))
                  :op2 (c2 / country
                        :name (n2 / name
                              :op1 "Germany"))
                  :op3 (c3 / country
                        :name (n3 / name
                              :op1 "Spain"))))
      :ARG2 (p / project
            :name (n4 / name
                  :op1 "Fairness"
                  :op2 "Measures"
                  :op3 "Project"))
      :ARG1-of (l / lead-02
            :ARG0 (p2 / person
                  :name (n5 / name
                        :op1 "Carlos"
                        :op2 "Castillo")
                  :ARG0-of (h / have-org-role-91
                        :ARG1 (u / university
                              :name (n6 / name
                                    :op1 "Pompeu"
                                    :op2 "Fabra"
                                    :op3 "Univerra"
                                    :op4 "versity")
                              :location (c4 / city
                                    :name (n7 / name
                                          :op1 "Barcelona")))))))

# ::snt The main goal of this group is to develop fairness-aware algorithms and systems  external [SP 8] , and to provide relevant software and datasets to the research community  through the website fairness-measures.org.
# File 39

(h / have-purpose-91
      :ARG1 (g / group
            :mod (t / this))
      :ARG2 (a / and
            :op1 (d / develop-02
                  :ARG0 g
                  :ARG1 (a2 / and
                        :op1 (a3 / algorithm
                              :ARG0-of (r / realize-01
                                    :ARG1 (f / fairness)))
                        :op2 (s / system
                              :mod (e / external)
                              :ARG1-of (d2 / describe-01
                                    :ARG0 (p / publication
                                          :name (n / name
                                                :op1 "SP"
                                                :op2 8))))))
            :op2 (p2 / provide-01
                  :ARG0 g
                  :ARG1 (a4 / and
                        :op1 (s2 / software
                              :ARG1-of (r2 / relevant-01))
                        :op2 (d3 / dataset
                              :ARG1-of (r3 / relevant-01)))
                  :ARG2 (c / community
                        :mod (r4 / research-01))
                  :medium (w / website
                        :name n
                        :op1 "fair-measures.org")))
      :mod (m / main))

# ::snt The data sets cover several fields and applica-tions such as finance, law and human resources, and provide common fairness definitions for machine learning.
# File 39

(a / and
      :op1 (c / cover-01
            :ARG0 (s / set
                  :consist-of (d / data))
            :ARG1 (a2 / and
                  :op1 (f / field)
                  :op2 (a3 / apply-02
                        :ARG1 f)
                  :example (a4 / and
                        :op1 (f2 / finance)
                        :op2 (l / law)
                        :op3 (r / resource
                              :mod (h / human)))
                  :quant (s2 / several)))
      :op2 (p / provide-01
            :ARG0 s
            :ARG1 (d2 / define-01
                  :ARG1 (f3 / fair-01)
                  :ARG1-of (s3 / share-01)
                  :topic (l2 / learn-01
                        :ARG1 (m / machine)))))

# ::snt / Predictive evaluation by SAVRY  The goal of this investigation is to evaluate the predictive power and fairness of an expert  assessment instrument called the Structured Assessment of Violence in Youth (SAVRY) and to compare it against standard machine learning (ML) algorithms.
# File 39

(m / multi-sentence
      :snt1 (e / evaluate-01
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "SAVRY"))
            :ARG1-of (p / predict-01))
      :snt2 (h / have-purpose-91
            :ARG1 (ii / investigate-01
                  :mod (t / this))
            :ARG2 (a / and
                  :op1 (e2 / evaluate-01
                        :ARG1 (a2 / and
                              :op1 (p2 / power
                                    :ARG1-of (p3 / predict-01)
                                    :poss (ii2 / instrument
                                          :ARG1-of (c / call-01
                                                :ARG2 (n2 / name
                                                      :op1 "Structured"
                                                      :op2 "Assessment"
                                                      :op3 "of"
                                                      :op4 "Violence"
                                                      :op5 "in"
                                                      :op6 "Youth"))
                                          :instrument-of (a3 / assess-01
                                                :ARG1 (p4 / person
                                                      :ARG1-of (e3 / expert-01)))))
                              :op2 (f / fair-01
                                    :ARG1 ii2)))
                  :op2 (c2 / compare-01
                        :ARG1 ii2
                        :ARG2 (a4 / algorithm
                              :instrument-of (l / learn-01
                                    :manner (m2 / machine))
                              :ARG1-of (s / standard-02))))))

# ::snt The HUMA in T (HUmanity vs MAchine  in T elligence) external [SP 18]  is an interdisciplinary  research project that proposes evaluating fairness, taking into account the uncertainty  of some predictions.
# File 39

(p / project
      :mod (r / research-01
            :mod (ii / interdisciplinary))
      :ARG0-of (p2 / propose-01
            :ARG1 (e / evaluate-01
                  :ARG1 (f / fairness)
                  :manner (t / take-into-account-04
                        :ARG1 (c / certain
                              :polarity -
                              :domain (p3 / predict-01
                                    :mod (s / some))))))
      :domain (p4 / publication
            :name (n / name
                  :op1 "HUMA"
                  :op2 "in"
                  :op3 "T"
                  :op4 "Elligence")
            :ARG1-of (d / describe-01
                  :ARG0 (p5 / publication
                        :name (n2 / name
                              :op1 "SP"
                              :op2 18)))
            :mod (e2 / external)))

# ::snt In addition, it discusses the implications of different sources of bias for fairness and performance analysis.
# File 39

(a / and
      :op2 (d / discuss-01
            :ARG0 (ii / it)
            :ARG1 (ii2 / implicate-01
                  :ARG1 (s / source-02
                        :ARG1 (b / bias-01
                              :ARG1 (a2 / and
                                    :op1 (f / fairness)
                                    :op2 (a3 / analyze-01
                                          :ARG1 (p / perform-02))))
                        :ARG1-of (d2 / differ-02)))))

# ::snt –Select data that fits criteria of fairness.
# File 187

(s / select-01
      :ARG1 (d / data
            :ARG1-of (f / fit-06
                  :ARG2 (c / criteria
                        :topic (f2 / fair-01)))))

# ::snt 15 Guidelines for AI Procurementwhich variables have contributed most to a result, and  the types of audit and assurance the model went through  in relation to systemic issues such as discrimination  and fairness.
# File 187

(a / and
      :op1 (g / guideline
            :quant 15
            :topic (p / procure-01
                  :ARG1 (ii / intelligent-01
                        :mod (a2 / artificial))))
      :op2 (c / contribute-01
            :ARG0 (v / variable)
            :ARG2 (r / result-01)
            :ARG2-of (h / have-degree-91
                  :ARG1 v
                  :ARG3 (m / most)))
      :op3 (g2 / go-12
            :ARG1 (m2 / model)
            :ARG2 (a3 / and
                  :op1 (a4 / audit-01)
                  :op2 (a5 / assure-01)
                  :mod (t / type))
            :ARG1-of (r2 / relate-01
                  :ARG2 (ii2 / issue-02
                        :mod (s / systemic)
                        :example (a6 / and
                              :op1 (d / discriminate-02)
                              :op2 (f / fair-01))))))

# ::snt For more information on fairness during data selection, refer to: “Understanding artificial intelligence ethics and safety.
# File 187

(r / refer-01
      :mode imperative
      :ARG0 (y / you)
      :ARG1 (p / publication
            :name (n / name
                  :op1 "Understanding"
                  :op2 "of"
                  :op3 "Artificial"
                  :op4 "Intelligence"
                  :op5 "and"
                  :op6 "Safety"))
      :purpose (ii / information
            :topic (f / fairness
                  :time (s / select-01
                        :ARG1 (d / data)))
            :mod (m / more)))

# ::snt A  guide for the responsible design and implementation of AI systems in the public sector”, section “Data fairness”, David  Leslie, the Alan Turing Institute.
# File 187

(p / publication-91
      :ARG0 (p2 / person
            :name (n / name
                  :op1 "David"
                  :op2 "Leslie")
            :ARG0-of (h / have-org-role-91
                  :ARG1 (r / research-institute
                        :name (n2 / name
                              :op1 "Alan"
                              :op2 "Turing"
                              :op3 "Institute"))))
      :ARG1 (g / guide
            :topic (a / and
                  :op1 (d / design-01
                        :ARG1 (s / system
                              :mod (ii / intelligent-01
                                    :mod (a2 / artificial))))
                  :op2 (ii2 / implement-01
                        :ARG1 s)
                  :ARG1-of (r2 / responsible-02)
                  :location (s2 / sector
                        :ARG1-of (p3 / public-02)))
            :part (s3 / section
                  :topic (f / fair-01
                        :ARG1 (d2 / data)))))

# ::snt A guide  for the responsible design and implementation of AI systems in the public sector”, section “Data fairness”, David Leslie,  the Alan Turing Institute.
# File 187

(g / guide-01
      :ARG0 (p / publication-91
            :ARG0 (p2 / person
                  :name (n / name
                        :op1 "David"
                        :op2 "Leslie")
                  :ARG0-of (h / have-org-role-91
                        :ARG1 (r / research-institute
                              :name (n2 / name
                                    :op1 "Alan"
                                    :op2 "Turing"
                                    :op3 "Institute"))))
            :ARG1 (a / and
                  :op1 (d / design-01
                        :ARG1 (s / system
                              :mod (ii / intelligent-01
                                    :mod (a2 / artificial))))
                  :op2 (ii2 / implement-01
                        :ARG1 s)
                  :location (s2 / sector
                        :ARG1-of (p3 / public-02))
                  :ARG1-of (r2 / responsible-02))
            :ARG7 (s3 / section
                  :topic (f / fair-01
                        :ARG1 (d2 / data)))))

# ::snt A guide for the responsible design and implementation of AI  systems in the public sector”, section “Data fairness”, David Leslie, the Alan Turing Institute.
# File 187

(p / publication-91
      :ARG0 (p2 / person
            :name (n / name
                  :op1 "David"
                  :op2 "Leslie")
            :ARG0-of (h / have-org-role-91
                  :ARG1 (r / research-institute
                        :name (n2 / name
                              :op1 "Alan"
                              :op2 "Turing"
                              :op3 "Institute"))))
      :ARG1 (g / guide
            :topic (a / and
                  :op1 (d / design-01
                        :ARG1 (s / system
                              :mod (ii / intelligent-01
                                    :mod (a2 / artificial)))
                        :ARG1-of (r2 / responsible-02)
                        :location (s2 / sector
                              :ARG1-of (p3 / public-02)))
                  :op2 (ii2 / implement-01
                        :ARG1 s
                        :location s2))
            :part (s3 / section
                  :topic (f / fair-01
                        :ARG1 (d2 / data)))))

# ::snt Data on populations can be seen through multiple frames: the frame of the uncounted (those who ‘don’t exist’ because they are not included in any sort of database), the unaccounted (portrayals of people and groups with less inclusion into the digital world, who are, therefore not adequately represented, possibly due to reasons of economic or social exclusion) and the discounted (those who exist and are in the system,  23 Yasodara Cordova, 'Artificial Intelligence and the need for data fairness in the global south', Medium, 21 March 2018, https://thelivinglib.org/artificial-intelligence-and-the-need-for-data-fairness-in-the-global-south/ 24 Franklin Foer, F, World Without Mind: The Existential Threat of Big Tech, Penguin, 2017.
# File 153

(m / multi-sentence
      :snt1 (p / possible-01
            :ARG1 (s / see-01
                  :ARG1 (d / data
                        :topic (p2 / population))
                  :manner (f / frame
                        :quant (m2 / multiple)
                        :ARG1-of (m3 / mean-01
                              :ARG2 (a / and
                                    :op1 (c / count-01
                                          :polarity -
                                          :ARG1 p2
                                          :ARG1-of (m4 / mean-01
                                                :ARG2 (e / exist-01
                                                      :polarity -
                                                      :ARG1 p2
                                                      :ARG1-of (c2 / cause-01
                                                            :ARG0 (ii / include-01
                                                                  :polarity -
                                                                  :ARG1 p2
                                                                  :ARG2 (d2 / database
                                                                        :mod (s2 / sort
                                                                              :mod (a2 / any))))))))
                                    :op2 (p3 / portray-01
                                          :ARG1 (a3 / and
                                                :op1 (p4 / person)
                                                :op2 (g / group)
                                                :ARG1-of (h / have-degree-91
                                                      :ARG2 (ii2 / include-01
                                                            :ARG1 a3
                                                            :ARG2 (w / world
                                                                  :mod (d3 / digital)))
                                                      :ARG3 (l / less)
                                                      :ARG0-of (c3 / cause-01
                                                            :ARG1 (r / represent-01
                                                                  :polarity -
                                                                  :ARG1 a3
                                                                  :mod (a4 / adequate))
                                                            :ARG1-of (p5 / possible-01)
                                                            :ARG1-of (c4 / cause-01
                                                                  :ARG0 (r2 / reason
                                                                        :topic (o / or
                                                                              :op1 (e2 / exclude-01
                                                                                    :ARG1 a3
                                                                                    :ARG2 (e3 / economy))
                                                                              :op2 (e4 / exclude-01
                                                                                    :ARG1 a3
                                                                                    :ARG2 (s3 / society))))))))))))))
      :snt2 (p6 / publication-91
            :ARG0 (p7 / person
                  :name (n / name
                        :op1 "Franklin"
                        :op2 "Foster"))
            :ARG1 (p8 / publication
                  :name (n2 / name
                        :op1 "World"
                        :op2 "Without"
                        :op3 "Mind"
                        :op4 "The"
                        :op5 "Existential"
                        :op6 "Threat"
                        :op7 "of"
                        :op8 "Big"
                        :op9 "Tech"))
            :ARG4 p8
            :name (n3 / name
                  :op1 "Penguin"))
      :time (d4 / date-entity
            :year 2017
            :month 3
            :day 23)
      :medium p8
      :name (n4 / name
            :op1 "The"
            :op2 "Living"
            :op3 "Lib")
      :time (d5 / date-entity
            :month 3
            :day 21
            :year 2018))

# ::snt 25 Yasodara Cordova, 'Artificial Intelligence and the need for data fairness in the global south'  26 Ryan Calo, 'Artificial Intelligence Policy: A Primer and Roadmap', University of California, Davis Law 51(399), 2017.
# File 153

(p / publication-91
      :li 25
      :ARG0 (p2 / person
            :name (n / name
                  :op1 "Yasodara"
                  :op2 "Cordova"))
      :ARG1 (p3 / publication
            :name (n2 / name
                  :op1 "Artificial"
                  :op2 "Intelligence"
                  :op3 "and"
                  :op4 "the"
                  :op5 "Need"
                  :op6 "for"
                  :op7 "Data"
                  :op8 "Fairfair"
                  :op9 "in"
                  :op10 "the"
                  :op11 "South"))
      :ARG4 (p4 / publication
            :name (n3 / name
                  :op1 "Artificial"
                  :op2 "Intelligence"
                  :op3 "Policy"
                  :op4 "A"
                  :op5 "Primer"
                  :op6 "and"
                  :op7 "Roadmap"))
      :ARG6 (p5 / publication
            :name (n4 / name
                  :op1 "Ryan"
                  :op2 "Calo"))
      :ARG7 (p6 / publication
            :name (n5 / name
                  :op1 "Law"
                  :op2 51
                  :op3 399)
            :part-of (u / university
                  :name (n6 / name
                        :op1 "University"
                        :op2 "of"
                        :op3 "California")))
      :time (d / date-entity
            :year 2017))

# ::snt Open data can be useful for many purposes, such as diversified data sets, content innovation,45 and benchmarking fairness.
# File 153

(p / possible-01
      :ARG1 (u / useful-05
            :ARG1 (d / data
                  :ARG1-of (o / open-04))
            :ARG2 (p2 / purpose
                  :quant (m / many)
                  :example (a / and
                        :op1 (s / set
                              :mod (d2 / data)
                              :ARG1-of (d3 / diversify-01))
                        :op2 (ii / innovate-01
                              :ARG1 (c / content))
                        :op3 (b / benchmark-01
                              :ARG1 (f / fairness))))))

# ::snt Use open data sets for benchmarking fairness.
# File 153

(u / use-01
      :mode imperative
      :ARG0 (y / you)
      :ARG1 (s / set
            :consist-of (d / data
                  :ARG1-of (o / open-04)))
      :ARG2 (b / benchmark-01
            :ARG0 y
            :ARG1 (f / fairness)))

# ::snt The use of open data sets - with safeguards - offers the benefits of benchmarking fairness.
# File 153

(o / offer-01
      :ARG0 (u / use-01
            :ARG1 (s / set
                  :consist-of (d / data
                        :ARG1-of (o2 / open-04))
                  :ARG0-of (s2 / safeguard-01)))
      :ARG1 (b / benefit-01
            :ARG0 (b2 / benchmark-01
                  :ARG1 (f / fairness))))

# ::snt However, as important as algorithmic fairness is, it is crucial to avoid reducing ethics to a fairness problem alone.
# File 153

(c / contrast-01
      :ARG2 (c2 / crucial
            :domain (a / avoid-01
                  :ARG1 (r / reduce-01
                        :ARG1 (e / ethics)
                        :ARG4 (p / problem
                              :topic (f / fairness)
                              :mod (a2 / alone))))
            :concession (ii / important-01
                  :ARG1 (f2 / fairness
                        :mod (a3 / algorithm)))))

# ::snt ................................ ................................ ................................ ...................  11  The Black Box  ................................ ................................ ................................ ................................ ....................  12  ARTIFICIAL INTELLIGEN CE MEETS THE GDPR  ................................ ................................ ................................ ..........  15  Fundamental principles of data protection  ................................ ................................ ................................ ..... 15  Algorithmic bias meets the fairness principle  ................................ ................................ ................................ .
# File 164

(m / multi-sentence
      :snt1 (a / and
            :op1 (t / thing
                  :li 11)
            :op2 (t2 / thing
                  :name (n / name
                        :op1 "The"
                        :op2 "Black"
                        :op3 "Box"))
            :op3 (t3 / thing
                  :li 12)
            :op4 (m2 / meet-01
                  :ARG0 (o / organization
                        :name (n2 / name
                              :op1 "Academy"
                              :op2 "of"
                              :op3 "Engineers")
                        :mod (a2 / artificial))
                  :ARG1 (l / law
                        :name (n3 / name
                              :op1 "GDPR")))
            :op5 (p / principle
                  :mod (f / fundamental)
                  :topic (p2 / protect-01
                        :ARG1 (d / data)))
            :op6 (p3 / principle
                  :mod (f2 / fairness)
                  :quant 15)
            :op7 (m3 / meet-01
                  :ARG0 (b / bias-01
                        :mod (a3 / algorithm))
                  :ARG1 (p4 / principle
                        :mod f2))))

# ::snt In this  report we will provide greater technical detail in  describing artificial intelligence (AI), while also ta king a  closer look at four relevant AI challenges associated with  the data protection principles embodied in the GDPR:    Fairness and discrimination    Purpose limitation    Data minimisation    Transparency and the right to information   The above list is not exhaustive, but represents a  selection of data protection concerns that in our opinion  are most relevance for the use of AI today.
# File 164

(m / multi-sentence
      :snt1 (c / contrast-01
            :ARG1 (d / detail-01
                  :ARG0 (w / we)
                  :ARG1 (d2 / describe-01
                        :ARG0 w
                        :ARG1 (ii / intelligent-01
                              :mod (a / artificial)))
                  :mod (t / technical)
                  :ARG1-of (h / have-degree-91
                        :ARG2 (g / great)
                        :ARG3 (m2 / more)))
            :ARG2 (l / look-01
                  :ARG0 w
                  :ARG1 (c2 / challenge-01
                        :quant 4
                        :ARG0 ii
                        :ARG1-of (r / relevant-01
                              :ARG2 (u / use-01
                                    :ARG1 ii
                                    :time (t2 / today))
                              :ARG1-of (o / opine-01
                                    :ARG0 w))
                        :ARG1-of (a2 / associate-01
                              :ARG2 (p / principle
                                    :ARG0-of (p2 / protect-01
                                          :ARG1 (d3 / data))
                                    :ARG1-of (e / embody-01
                                          :ARG2 (l2 / law
                                                :name (n / name
                                                      :op1 "GDPR"))))))
                  :mod (a3 / also)
                  :ARG1-of (h2 / have-degree-91
                        :ARG2 (c3 / close-10
                              :ARG1 l)
                        :ARG3 (m3 / more))))
      :snt2 (h3 / have-concession-91
            :ARG1 (r2 / represent-01
                  :ARG0 (l3 / list
                        :location (a4 / above))
                  :ARG1 (c4 / concern-01
                        :ARG0 p2
                        :ARG1 (d4 / data))
                  :ARG1-of (s / select-01)
                  :example (a5 / and
                        :op1 (a6 / and
                              :op1 (f / fairness)
                              :op2 (d5 / discriminate-02))
                        :op2 (l4 / limit-01
                              :ARG1 (p3 / purpose))
                        :op3 (m4 / minimize-01
                              :ARG1 (d6 / data))
                        :op4 (a7 / and
                              :op1 (t3 / transparency)
                              :op2 (r3 / right-05
                                    :ARG2 (ii2 / information))))))
      :ARG2 (e2 / exhaustive
            :polarity -
            :domain l3))

# ::snt In summary, these principles require that personal data  is:   processed in a lawful, fair and transparent  manner (principle of legality, fairness and  transparency)    collected for specific, expressly stated and  justified purposes and not treated in a new way  that is incompatible with these purposes  (principle of purpos e limitation)    adequate, relevant and limited to what is  necessary for fulfilling the purposes for which it  is being processed (principle of data  minimisation)    correct and, if necessary, updated (accuracy  principle)    not stored in identifiable form for longer  periods than i s necessary for the purposes  (principle relating to data retention periods)    processed in a way that ensures adequate  personal data protection (principle of integrity  and confidentiality)   Personal data   Personal data means any information relating  to an identified or identifiable natural person.
# File 164

(m / multi-sentence
      :snt1 (r / require-01
            :ARG0 (p / principle
                  :mod (t / this))
            :ARG1 (p2 / process-01
                  :ARG1 (d / data
                        :ARG1-of (p3 / personal-02))
                  :manner (a / and
                        :op1 (l / lawful)
                        :op2 (f / fair-01)
                        :op3 (t2 / transparent)
                        :example (p4 / principle
                              :topic (a2 / and
                                    :op1 (l2 / legal-02)
                                    :op2 (f2 / fairness)
                                    :op3 (t3 / transparency))))
                  :op2 (a3 / and
                        :op1 (c / collect-01
                              :ARG1 d
                              :purpose (p5 / purpose
                                    :ARG1-of (s / specific-02)
                                    :ARG1-of (s2 / state-01
                                          :manner (e / express))
                                    :ARG1-of (j / justify-01)))
                        :op2 (a4 / and
                              :op1 (r2 / relevant-01
                                    :ARG1 d)
                              :op2 (l3 / limit-01
                                    :ARG1 d
                                    :ARG2 (t4 / thing
                                          :ARG1-of (n / need-01
                                                :purpose (f3 / fulfill-01
                                                      :ARG1 (p6 / purpose
                                                            :ARG1-of (p7 / process-01
                                                                  :ARG1 d)))))))
                        :op3 (c2 / correct-02
                              :ARG1 d)
                        :op4 (u / update-01
                              :ARG1 d
                              :condition (n2 / need-01))
                        :op5 (s3 / store-01
                              :polarity -
                              :ARG1 d
                              :ARG2 (f4 / form
                                    :ARG1-of (ii / identify-01
                                          :ARG1-of (p8 / possible-01)))
                              :duration (p9 / period
                                    :ARG1-of (h / have-degree-91
                                          :ARG2 (l4 / long-03
                                                :ARG1 p9)
                                          :ARG3 (m2 / more)
                                          :ARG4 (p10 / period
                                                :ARG1-of (n3 / need-01
                                                      :purpose (r3 / retain-01
                                                            :ARG1 (d2 / data))))))))
                  :manner (w / way
                        :ARG1-of (n4 / new-01)
                        :ARG1-of (c3 / compatible-01
                              :polarity -
                              :ARG2 p6)
                        :example (p11 / principle
                              :topic l3))))
      :snt2 (m3 / mean-01
            :ARG1 (d3 / data
                  :ARG1-of p3))
      :ARG2 (ii2 / information
            :mod (a5 / any)))

# ::snt We look at these challenges  in the light of the data protection principles that are  most relevant to artificial intelligence – namely th e  principles of fairness, purpose limitation, data  minimisation and transparency.
# File 164

(l / look-01
      :ARG0 (w / we)
      :ARG1 (c / challenge-01
            :mod (t / this))
      :ARG2 (p / principle
            :topic (p2 / protect-01
                  :ARG1 (d / data))
            :ARG1-of (r / relevant-01
                  :ARG2 (ii / intelligent-01
                        :mod (a / artificial))
                  :ARG2-of (h / have-degree-91
                        :ARG1 p
                        :ARG3 (m / most)))
            :ARG1-of (m2 / mean-01
                  :ARG2 (p3 / principle
                        :topic (a2 / and
                              :op1 (f / fairness)
                              :op2 (l2 / limit-01
                                    :ARG1 (p4 / purpose))
                              :op3 (m3 / minimize-01
                                    :ARG1 (d2 / data))
                              :op4 (t2 / transparency))))))

# ::snt Algorithmic bias meets the  fairness principle   It is easy to think that artificial intelligence will be able  to perform more objective analyses and therefore reach  better deci sions than human beings.
# File 164

(m / multi-sentence
      :snt1 (m2 / meet-01
            :ARG0 (b / bias-01
                  :mod (a / algorithm))
            :ARG1 (p / principle
                  :topic (f / fairness)))
      :snt2 (e / easy-05
            :ARG1 (t / think-01
                  :ARG1 (p2 / possible-01
                        :ARG1 (p3 / perform-02
                              :ARG0 (ii / intelligent-01
                                    :mod (a2 / artificial))
                              :ARG1 (a3 / analyze-01
                                    :ARG0 ii
                                    :manner (o / objective
                                          :ARG2-of (h / have-degree-91
                                                :ARG1 a3
                                                :ARG3 (m3 / more))))
                              :ARG0-of (c / cause-01
                                    :ARG1 (r / reach-01
                                          :ARG0 ii
                                          :ARG1 (t2 / thing
                                                :ARG1-of (d / decide-01)
                                                :ARG1-of (h2 / have-degree-91
                                                      :ARG2 (g / good-02
                                                            :ARG1 t2)
                                                      :ARG3 (m4 / more)
                                                      :ARG4 (b2 / being
                                                            :mod (h3 / human)))))))))))

# ::snt Such use of personal  data would be in contraventio n of the fairness principle.
# File 164

(c / contravent-01
      :ARG0 (u / use-01
            :ARG1 (d / data
                  :ARG1-of (p / personal-02))
            :mod (s / such))
      :ARG1 (p2 / principle
            :topic (f / fairness)))

# ::snt If it is suspected, or claimed, that use of a model will  entail unfair or discriminatory results, the Data  Protection Authority can investigate whether the principle of fairness has been safeguarded in the  processing of personal data .
# File 164

(p / possible-01
      :ARG1 (ii / investigate-01
            :ARG0 (o / organization
                  :name (n / name
                        :op1 "Data"
                        :op2 "Protection"
                        :op3 "Authority"))
            :ARG1 (t / truth-value
                  :polarity-of (s / safeguard-01
                        :ARG1 (p2 / principle
                              :topic (f / fairness))
                        :manner (p3 / process-01
                              :ARG1 (d / data
                                    :ARG1-of (p4 / personal-02))))))
      :condition (o2 / or
            :op1 (s2 / suspect-01
                  :ARG1 (e / entail-01
                        :ARG0 (u / use-01
                              :ARG1 (m / model))
                        :ARG1 (r / result
                              :ARG1-of (f2 / fair-01
                                    :polarity -)
                              :ARG0-of (d2 / discriminate-01))))
            :op2 (c / claim-01
                  :ARG1 e)))

# ::snt Civil rights and privacy advocates have expressed concern that this erodes accountability and fairness.
# File 47

(e / express-01
      :ARG0 (p / person
            :ARG0-of (a / advocate-01
                  :ARG1 (a2 / and
                        :op1 (r / right-05
                              :mod (c / civil))
                        :op2 (p2 / privacy))))
      :ARG1 (c2 / concern-01
            :ARG0 (e2 / erode-01
                  :ARG0 (t / this)
                  :ARG1 (a3 / and
                        :op1 (a4 / accountable-02)
                        :op2 (f / fair-01)))
            :ARG1 p))

# ::snt The question of how to ensure fairness in automated systems is complicated and will require thoughtful and candid  debate.
# File 47

(a / and
      :op1 (c / complicate-01
            :ARG1 (q / question-01
                  :ARG1 (e / ensure-01
                        :ARG1 (f / fairness
                              :location (s / system
                                    :ARG1-of (a2 / automate-01))))))
      :op2 (r / require-01
            :ARG0 q
            :ARG1 (d / debate-01
                  :manner (t / thoughtful)
                  :manner (c2 / candid))))

# ::snt ..........26  What do we need to do to ensure lawfulness, fairness, and transparency  in AI systems?
# File 106

(n / need-01
      :li 26
      :ARG0 (w / we)
      :ARG1 (d / do-02
            :ARG0 w
            :ARG1 (a / amr-unknown)
            :purpose (e / ensure-01
                  :ARG0 w
                  :ARG1 (a2 / and
                        :op1 (l / lawfulness)
                        :op2 (f / fairness)
                        :op3 (t / transparency))
                  :ARG2 (s / system
                        :mod (ii / intelligent-01
                              :mod (a3 / artificial))))))

# ::snt ......................................................................................... 36  How does the principle of lawfulness, fairness and transparency apply to  AI?
# File 106

(a / apply-02
      :li 36
      :ARG1 (p / principle
            :topic (a2 / and
                  :op1 (l / law)
                  :op2 (f / fairness)
                  :op3 (t / transparency)))
      :ARG2 (ii / intelligent-01
            :mod (a3 / artificial))
      :manner (a4 / amr-unknown))

# ::snt Part two covers the lawfulness, fairness, and transparency of processing personal data in AI systems, with sections covering lawful bases for  processing personal data in AI systems, assessing and improving AI system  performance and mitigating potential discrimination to ensure fair  processing.
# File 106

(a / and
      :op1 (c / cover-01
            :ARG0 (p / part
                  :ord (o / ordinal-entity
                        :value 2))
            :ARG1 (a2 / and
                  :op1 (l / lawful
                        :domain (p2 / process-01
                              :ARG1 (d / data
                                    :ARG1-of (p3 / personal-02))
                              :ARG2 (s / system
                                    :mod (a3 / artificial))))
                  :op2 (f / fairness
                        :domain p2)
                  :op3 (t / transparency
                        :domain p2)))
      :op2 (c2 / cover-01
            :ARG0 (s2 / section)
            :ARG1 (a4 / and
                  :op1 (b / base-02
                        :ARG1 (p4 / process-01
                              :ARG1 d
                              :ARG2 s)
                        :mod (l2 / lawful))
                  :op2 (a5 / and
                        :op1 (a6 / assess-01
                              :ARG1 (p5 / perform-02
                                    :ARG0 s))
                        :op2 (ii / improve-01
                              :ARG1 p5))
                  :op3 (m / mitigate-01
                        :ARG1 (d2 / discriminate-02
                              :mod (p6 / potential))
                        :purpose (e / ensure-01
                              :ARG1 (p7 / process-01
                                    :ARG1-of (f2 / fair-01)))))))

# ::snt Your DPIA should include:  • a systematic description of the processing activity, including data flows  and the stages when AI processes and automated decisions m ay  produce effects on individuals;  • an explanation of any relevant variation or margins of error in the  performance of the system which may affect the fairness of the  personal data processing (see ‘Statistical Accuracy’ ); and  • a description of the scope and context of the processing, including:  o what data you will process;  o the number of data subjects involved;  o the source of the data; and  o how far individuals are likely to expect the processing.
# File 106

(r / recommend-01
      :ARG1 (ii / include-01
            :ARG1 (a / and
                  :op1 (d / describe-01
                        :ARG1 (a2 / activity-06
                              :ARG1 (p / process-01)
                              :ARG2-of (ii2 / include-01
                                    :ARG1 (a3 / and
                                          :op1 (f / flow-01
                                                :ARG1 (d2 / data))
                                          :op2 (s / stage
                                                :time-of (p2 / produce-01
                                                      :ARG0 (a4 / and
                                                            :op1 (p3 / process-01
                                                                  :ARG1 (ii3 / intelligent-01
                                                                        :mod (a5 / artificial)))
                                                            :op2 (d3 / decide-01
                                                                  :ARG1-of (a6 / automate-01)))
                                                      :ARG1 (a7 / affect-01
                                                            :ARG0 a4
                                                            :ARG1 (ii4 / individual))))))
                              :mod (s2 / systematic))
                        :op2 (e / explain-01
                              :ARG1 (o / or
                                    :op1 (v / vary-01
                                          :ARG1 (p4 / perform-02
                                                :ARG0 (s3 / system))
                                          :ARG1-of (r2 / relevant-01))
                                    :op2 (m / margin
                                          :mod (e2 / error))
                                    :ARG0-of (a8 / affect-01
                                          :ARG1 (f2 / fair-01
                                                :ARG1 (p5 / process-01
                                                      :ARG1 (d4 / data
                                                            :ARG1-of (p6 / personal-02))))
                                          :ARG1-of (p7 / possible-01)))))
                  :op3 (d5 / describe-01
                        :ARG1 (a9 / and
                              :op1 (s4 / scope
                                    :poss p)
                              :op2 (c / context
                                    :poss p))
                        :ARG2-of (ii5 / include-01
                              :ARG1 (a10 / and
                                    :op1 (d6 / data
                                          :ARG1-of (p8 / process-01
                                                :ARG0 (y / you)))
                                    :op2 (n / number
                                          :quant-of (s5 / subject
                                                :mod (d7 / data)
                                                :ARG1-of (ii6 / involve-01)))
                                    :op3 (s6 / source
                                          :mod d7)
                                    :op4 (l / likely-01
                                          :ARG1 (e3 / expect-01
                                                :ARG0 (ii7 / individual)
                                                :ARG1 p8))))))
            :ARG2 (t / thing
                  :name (n2 / name
                        :op1 "DPIA")
                  :poss y)))

# ::snt You may also want to read the relevant sections of the Guide on:  • lawfulness, fairness and transparency ;  • lawful basis for processing ;  • data minimisation ; and  • accuracy .
# File 106

(p / possible-01
      :ARG1 (w / want-01
            :ARG0 (y / you)
            :ARG1 (r / read-01
                  :ARG0 y
                  :ARG1 (s / section
                        :ARG1-of (r2 / relevant-01)
                        :part-of (g / guide)
                        :topic (a / and
                              :op1 (a2 / and
                                    :op1 (l / lawfulness)
                                    :op2 (f / fairness)
                                    :op3 (t / transparency))
                              :op2 (t2 / thing
                                    :ARG2-of (b / base-02
                                          :ARG1 (p2 / process-01))
                                    :mod (l2 / lawful))
                              :op3 (m / minimize-01
                                    :ARG1 (d / data))
                              :op4 (a3 / accurate))))
            :mod (a4 / also)))

# ::snt Privacy vs statistical accuracy  Fairness, in a data protection context, generally means that you should  handle personal data in ways that people would reasonably expect and not  use it in ways that have unjustified adverse effects on them.
# File 106

(m / multi-sentence
      :snt1 (v / versus
            :op1 (p / privacy)
            :op2 (a / accurate
                  :mod (s / statistics)))
      :snt2 (m2 / mean-01
            :ARG1 (f / fairness)
            :ARG2 (r / recommend-01
                  :ARG1 (h / handle-01
                        :ARG0 (y / you)
                        :ARG1 (d / data
                              :ARG1-of (p2 / personal-02))
                        :manner (a2 / and
                              :op1 (e / expect-01
                                    :ARG0 (p3 / person)
                                    :ARG1 h
                                    :ARG1-of (r2 / reasonable-02))
                              :op2 (u / use-01
                                    :polarity -
                                    :ARG0 y
                                    :ARG1 d
                                    :ARG2 (t / thing
                                          :ARG0-of (a3 / affect-01
                                                :ARG1 p3
                                                :manner (a4 / adverse)
                                                :ARG1-of (j / justify-01
                                                      :polarity -)))))))
            :location (c / context
                  :topic (p4 / protect-01
                        :ARG1 (d2 / data)))
            :ARG1-of (g / general-02)))

# ::snt Improving the  ‘statistical accuracy’ of your AI system’s outputs is one of your considerations to ensure compliance with the fairness principle.
# File 106

(ii / include-91
      :ARG1 (ii2 / improve-01
            :ARG1 (a / accurate
                  :mod (s / statistics)
                  :domain (o / output
                        :poss (s2 / system
                              :mod (ii3 / intelligent-01
                                    :mod (a2 / artificial))
                              :poss (y / you)))))
      :ARG2 (c / consider-02
            :ARG0 y
            :ARG1 ii2
            :purpose (e / ensure-01
                  :ARG0 y
                  :ARG1 (c2 / comply-01
                        :ARG0 ii2
                        :ARG1 (p / principle
                              :topic (f / fairness))))))

# ::snt                                                                                                                                                                                                                                                                                                                                    AI auditing framework -draft guidance for consultation  system is, the more likely that your processing will be in line with the  fairness principle.
# File 106

(c / correlate-91
      :ARG1 (m / more
            :ARG3-of (h / have-degree-91
                  :ARG1 (p / process-01
                        :ARG0 (y / you))
                  :ARG2 (l / likely-01
                        :ARG1 (ii / in-line-04
                              :ARG1 p
                              :ARG2 (p2 / principle
                                    :mod (f / fairness))))))
      :ARG2 (a / and
            :op1 (x :op1 (x2))
            :op2 (x3)
            :op3 (x4)
            :op4 (x5 :op1 (x6)
                  :op2 (x7)
                  :op3 (x8)
                  :op4 (x9))))

# ::snt These may in turn pose compliance risks in terms of the fairness princip le.
# File 106

(p / possible-01
      :ARG1 (p2 / pose-02
            :ARG0 (t / this)
            :ARG1 (r / risk-01
                  :ARG2 (c / comply-01
                        :ARG1 (p3 / principle
                              :topic (f / fairness)
                              :mod (l / le))))
            :mod (ii / in-turn)))

# ::snt Explainability and statistical accuracy  Part of your fairness considerations also include a trade -off between the  explainability and statistical accuracy of AI systems.
# File 106

(ii / include-01
      :ARG1 (t / trade-off-02
            :ARG1 (p / possible-01
                  :ARG1 (e / explain-01))
            :ARG2 (p2 / possible-01
                  :ARG1 (a / accurate
                        :mod (s / statistical)))
            :ARG3 (a2 / accurate
                  :mod (s2 / statistical)
                  :domain (s3 / system
                        :mod (ii2 / intelligent-01
                              :mod (a3 / artificial)))))
      :ARG2 (c / consider-02
            :ARG0 (y / you)
            :ARG1 (f / fair-01)
            :part-of (p3 / part))
      :mod (a4 / also))

# ::snt In many cases, values like privacy and fairness are difficult to meaningfully quantify.
# File 106

(d / difficult
      :domain (q / quantify-01
            :ARG1 (v / value
                  :example (a / and
                        :op1 (p / private-02)
                        :op2 (f / fairness)))
            :ARG0-of (m / meaningful-05))
      :frequency (c / case-04
            :quant (m2 / many)))

# ::snt                                                                                                                                                                                                                                          AI auditing framework -draft guidance for consultation  What do we need to do to ensure  lawfulness, fairness, and transparency in AI systems?
# File 106

(m / multi-sentence
      :snt1 (n / need-01
            :ARG0 (w / we)
            :ARG1 (d / do-02
                  :ARG0 w
                  :ARG1 (e / ensure-01
                        :ARG0 w
                        :ARG1 (a / and
                              :op1 (l / lawfulness)
                              :op2 (f / fairness)
                              :op3 (t / transparency))
                        :location (s / system
                              :mod (ii / intelligent-01
                                    :mod (a2 / artificial))))))
      :snt2 (g / guide-01
            :ARG1-of (d2 / draft-01)))

# ::snt In detail  • How do the principles of lawfulness, fairness and transparency apply to  AI  • How do we identify our purposes and lawful basis when using AI??
# File 106

(m / multi-sentence
      :snt1 (a / apply-02
            :ARG1 (p / principle
                  :example (a2 / and
                        :op1 (l / law)
                        :op2 (f / fairness)
                        :op3 (t / transparency)))
            :ARG2 (ii / intelligent-01
                  :mod (a3 / artificial))
            :manner (a4 / amr-unknown)
            :ARG1-of (d / detail-01))
      :snt2 (ii2 / identify-01
            :ARG0 (w / we)
            :ARG1 (a5 / and
                  :op1 (p2 / purpose
                        :poss w)
                  :op2 (t2 / thing
                        :ARG2-of (b / base-02
                              :ARG1 w)
                        :mod (l2 / lawful)))
            :manner (a6 / amr-unknown)
            :time (u / use-01
                  :ARG0 w
                  :ARG1 ii)))

# ::snt How does the principle of lawfulness, fairness and transparency  apply to AI?
# File 106

(a / apply-02
      :ARG1 (p / principle
            :topic (a2 / and
                  :op1 (l / lawfulness)
                  :op2 (f / fairness)
                  :op3 (t / transparency)))
      :ARG2 (a3 / artificial-intelligence)
      :manner (a4 / amr-unknown))

# ::snt This section explains the controls you can implement to ensure that your AI  systems are sufficiently statistically accurate to ensure the personal data  they process complies with the fairness principle.
# File 106

(e / explain-01
      :ARG0 (s / section
            :mod (t / this))
      :ARG1 (c / control-01
            :ARG1-of (ii / implement-01
                  :ARG0 (y / you)
                  :ARG1-of (p / possible-01)
                  :purpose (e2 / ensure-01
                        :ARG0 y
                        :ARG1 (a / accurate
                              :ARG0-of (s2 / suffice-01
                                    :ARG1 (e3 / ensure-01
                                          :ARG0 (s3 / system
                                                :ARG1 (c2 / comply-01
                                                      :ARG0 (d / data
                                                            :ARG1-of (p2 / personal-02)
                                                            :ARG1-of (p3 / process-01
                                                                  :ARG0 s3))
                                                      :ARG1 (p4 / principle
                                                            :topic (f / fairness)))))
                                    :domain s3
                                    :mod (s4 / statistics)))))))

# ::snt Failure to do  this could mean that your processing is not compliant with the fairness  principle.
# File 106

(p / possible-01
      :ARG1 (m / mean-01
            :ARG1 (f / fail-01
                  :ARG2 (d / do-02
                        :ARG1 (t / this)))
            :ARG2 (c / comply-01
                  :polarity -
                  :ARG0 (p2 / process-01
                        :ARG0 (y / you))
                  :ARG1 (p3 / principle
                        :topic (f2 / fairness)))))

# ::snt Example of controls  Risk Statement  Inaccurate output or decisions made by AI systems could lead to unfair /  negative outcomes for individuals and a failure to meet the fairness principle.
# File 106

(m / multi-sentence
      :snt1 (e / exemplify-01
            :ARG1 (c / control-01))
      :snt2 (s / state-01
            :ARG1 (r / risk-01))
      :snt3 (p / possible-01
            :ARG1 (l / lead-03
                  :ARG0 (o / or
                        :op1 (o2 / output
                              :ARG1-of (a / accurate
                                    :polarity -))
                        :op2 (d / decide-01
                              :ARG0 (s2 / system
                                    :ARG0-of (ii / intelligent-01
                                          :mod (a2 / artificial)))))
                  :ARG2 (a3 / and
                        :op1 (o3 / outcome
                              :ARG1-of (f / fair-01
                                    :polarity -))
                        :op2 (o4 / outcome
                              :ARG0-of (n / negative-02))
                        :beneficiary (ii2 / individual))
                  :op2 (f2 / fail-01
                        :ARG2 (m2 / meet-01
                              :ARG1 (p2 / principle
                                    :topic (f3 / fair-01)))))))

# ::snt This poses compliance issues with the fairness principle as wel l as risks to  individuals’ rights and freedoms – including the right to non-d iscrimination.
# File 106

(p / pose-02
      :ARG0 (t / this)
      :ARG1 (ii / issue-02
            :ARG0 (c / comply-01
                  :ARG1 (p2 / principle
                        :topic (f / fairness))))
      :prep-as (r / risk-01
            :ARG2 (a / and
                  :op1 (r2 / right-05
                        :ARG1 (ii2 / individual))
                  :op2 (f2 / free-04
                        :ARG1 ii2)
                  :ARG2-of (ii3 / include-01
                        :ARG1 (r3 / right-05
                              :ARG1 ii2
                              :ARG2 (d / discriminate-02
                                    :polarity -))))))

# ::snt This field  is often referred to as algorithmic ‘fairness’.
# File 106

(r / refer-01
      :ARG1 (f / field
            :mod (t / this))
      :ARG2 (f2 / fairness
            :mod (a / algorithm))
      :frequency (o / often))

# ::snt In order for these techniques to be effective, you need to choose one or  more mathematical ‘fairness’ measures against which you can measure the results.
# File 106

(n / need-01
      :ARG0 (y / you)
      :ARG1 (c / choose-01
            :ARG0 y
            :ARG1 (o / or
                  :op1 (m / measure-01
                        :quant 1
                        :ARG1 (f / fairness)
                        :mod (m2 / mathematics))
                  :op2 (m3 / measure-01
                        :ARG1 f
                        :ARG1-of (h / have-quant-91
                              :ARG3 (m4 / more)))
                  :ARG0-of (m5 / measure-01
                        :ARG1 (r / result)
                        :ARG1-of (p / possible-01))))
      :purpose (e / effective-04
            :ARG0 (t / technique
                  :mod (t2 / this))))

# ::snt You  will still need to consider:  • the broader questions of lawfulness, fairness and the risks the  processing poses as a whole; and  • the possibility for the data to either be special category data anyway,  or becoming so during the processing (ie, if the processing involves  analysing or inferring any data to do with health or genetic status).
# File 106

(n / need-01
      :ARG0 (y / you)
      :ARG1 (c / consider-02
            :ARG0 y
            :ARG1 (a / and
                  :op1 (q / question-01
                        :ARG1 (a2 / and
                              :op1 (l / law)
                              :op2 (f / fairness)
                              :op3 (r / risk-01
                                    :ARG1-of (p / pose-02
                                          :ARG0 (p2 / process-01)
                                          :prep-as (w / whole))))
                        :ARG1-of (h / have-degree-91
                              :ARG2 (b / broad-02
                                    :ARG1 q)
                              :ARG3 (m / more)))
                  :op2 (p3 / possible-01
                        :ARG1 (o / or
                              :op1 (d / data
                                    :mod (c2 / category
                                          :ARG1-of (s / special-02))
                                    :mod (a3 / anyway)
                                    :domain (d2 / data))
                              :op2 (b2 / become-01
                                    :ARG1 d2
                                    :ARG2 d
                                    :time (p4 / process-01)
                                    :condition (ii / involve-01
                                          :ARG1 (o2 / or
                                                :op1 (a4 / analyze-01
                                                      :ARG1 d2)
                                                :op2 (ii2 / infer-01
                                                      :ARG1 d2)
                                                :topic (o3 / or
                                                      :op1 (h2 / health)
                                                      :op2 (s2 / status
                                                            :mod (g / genetics))))))))))
      :mod (s3 / still))

# ::snt Whether procured internally or externally, you should satisfy yourself that the data is representative of the  population you apply the ML system to (although for reasons stated above, this will not be sufficient to ensure fairness).
# File 106

(h / have-concession-91
      :ARG1 (r / recommend-01
            :ARG1 (s / satisfy-01
                  :ARG0 (y / you)
                  :ARG1 y
                  :ARG2 (r2 / represent-01
                        :ARG0 (d / data)
                        :ARG1 (p / population
                              :ARG2-of (a / apply-02
                                    :ARG0 y
                                    :ARG1 (s2 / system
                                          :mod (t / thing
                                                :name (n / name
                                                      :op1 "ML"))))))
                  :ARG1-of (r3 / regardless-91
                        :ARG2 (p2 / procure-01
                              :ARG1 d
                              :manner (o / or
                                    :op1 (ii / internal-02)
                                    :op2 (e / external))))))
      :ARG2 (s3 / suffice-01
            :polarity -
            :ARG0 s
            :ARG1 (e2 / ensure-01
                  :ARG0 s
                  :ARG1 (f / fairness))
            :ARG1-of (c / cause-01
                  :ARG0 (r4 / reason
                        :ARG1-of (s4 / state-01
                              :location (a2 / above))))))

# ::snt Your technical leads should also be proactive in seeking domain -specific knowledge, including known  proxies for protected characteristics, to inform algorithmic ‘fairness’  approaches.
# File 106

(r / recommend-01
      :ARG1 (p / proactive
            :domain (l / lead-02
                  :ARG0 (y / you)
                  :mod (t / technical))
            :mod (a / also)
            :topic (s / seek-01
                  :ARG0 l
                  :ARG1 (k / know-01
                        :ARG1-of (s2 / specific-02
                              :ARG2 (d / domain))
                        :ARG2-of (ii / include-01
                              :ARG1 (p2 / proxy
                                    :ARG1-of (k2 / know-01)
                                    :purpose (t2 / thing
                                          :ARG2-of (c / characteristic-02)
                                          :ARG1-of (p3 / protect-01)))))
                  :purpose (ii2 / inform-01
                        :ARG0 l
                        :ARG2 (a2 / approach-02
                              :ARG1 (f / fairness
                                    :mod (a3 / algorithm)))))))

# ::snt Detective  • Regularly monitor for algorithmic fairness using appropriate measures.
# File 106

(m / monitor-01
      :ARG0 (p / person
            :ARG0-of (h / have-org-role-91
                  :ARG2 (d / detective)))
      :ARG1 (f / fair-01
            :mod (a / algorithm))
      :ARG1-of (r / regular-02)
      :manner (u / use-01
            :ARG0 p
            :ARG1 (m2 / measure-02
                  :ARG1-of (a2 / appropriate-02))))

# ::snt • Retrain the model with fairness constraints.
# File 106

(r / retrain-01
      :mode imperative
      :ARG0 (y / you)
      :ARG1 (m / model)
      :manner (c / constraint
            :mod (f / fairness)))

# ::snt Most discussions on ethical considerations of AI are a derivation of the FAT  framework (Fairness, Accountability and Transparency).
# File 25

(d / derive-01
      :ARG1 (d2 / discuss-01
            :ARG1 (c / consider-02
                  :ARG1 (e / ethics)
                  :ARG2 (ii / intelligent-01
                        :mod (a / artificial)))
            :quant (m / most))
      :ARG2 (f / framework
            :name (n / name
                  :op1 "FAT")
            :ARG1-of (m2 / mean-01
                  :ARG2 (a2 / and
                        :op1 (f2 / fairness)
                        :op2 (a3 / accountable-02)
                        :op3 (t / transparency)))))

# ::snt Ethics and AI   Fairness / tackling the biases AI  Based on the premise that  a large set of well -diversified data may be an accurate description of the world,  most of the developer community takes a technocratic attitude that data -driven decision making is good  and algorithms are neutral.
# File 25

(m / multi-sentence
      :snt1 (a / and
            :op1 (e / ethics)
            :op2 (ii / intelligent-01
                  :mod (a2 / artificial)))
      :snt2 (s / slash
            :op1 (f / fairness)
            :op2 (t / tackle-01
                  :ARG1 (b / bias-01))
            :topic (ii2 / intelligent-01
                  :mod (a3 / artificial)))
      :snt3 (b2 / base-02
            :ARG1 (a4 / attitude
                  :mod (t2 / technocratic)
                  :poss (c / community
                        :mod (p / person
                              :ARG0-of (d / develop-02))
                        :quant (m2 / most))
                  :topic (a5 / and
                        :op1 (g / good-02
                              :ARG1 (m3 / make-01
                                    :ARG1 (d2 / decide-01)
                                    :ARG1-of (d3 / drive-02
                                          :ARG0 (d4 / data))))
                        :op2 (n / neutral-02
                              :ARG0 (a6 / algorithm))))
            :ARG2 (p2 / premise-01
                  :ARG1 (p3 / possible-01
                        :ARG1 (d5 / describe-01
                              :ARG0 (s2 / set
                                    :consist-of (d6 / data)
                                    :mod (l / large)
                                    :ARG1-of (d7 / diversify-01
                                          :ARG1-of (w / well-09)))
                              :ARG1 (w2 / world)
                              :mod (a7 / accurate))))))

# ::snt The issue of fairness is at the forefront of  discussion in academic, research and policy fora, and definitely merits a combined dialogue and  sustained research to com e to an acceptable resolution.
# File 25

(a / and
      :op1 (b / be-located-at-91
            :ARG1 (ii / issue-02
                  :ARG0 (f / fairness))
            :ARG2 (f2 / forefront
                  :part-of (d / discuss-01
                        :ARG1 (a2 / and
                              :op1 (a3 / academia)
                              :op2 (r / research-01)
                              :op3 (p / policy-01)))))
      :op2 (m / merit-01
            :ARG0 ii
            :ARG1 (a4 / and
                  :op1 (d2 / dialogue-01)
                  :op2 (r2 / research-01
                        :ARG1-of (s / sustain-01)))
            :mod (d3 / definite)
            :purpose (c / come-04
                  :ARG1 ii
                  :ARG2 (r3 / resolve-01
                        :ARG1 ii
                        :ARG1-of (a5 / accept-01
                              :ARG1-of (p2 / possible-01))))))

# ::snt Almost all  citizens (95%) expect AI systems to  meet high standards of:    –performance and accuracy    –data privacy    –security and governance    –transparency and explainability    –accountability    –risk and impact mitigation    –fairness    –human oversight Most citizens (more than 57%)  would be more willing to use AI  systems if assurance mechanisms  were in place, such as independent  AI ethics reviews, AI ethics  certifications, national standards  for transparency, and AI codes of  conduct.
# File 117

(m / multi-sentence
      :snt1 (e / expect-01
            :ARG0 (c / citizen
                  :mod (a / all
                        :mod (a2 / almost))
                  :ARG2-of (ii / include-91
                        :ARG1 (c2 / citizen)
                        :ARG3 (p / percentage-entity
                              :value 95)))
            :ARG1 (m2 / meet-01
                  :ARG0 (s / system
                        :mod (ii2 / intelligent-01
                              :mod (a3 / artificial)))
                  :ARG1 (s2 / standard
                        :ARG1-of (h / high-02)
                        :example (a4 / and
                              :op1 (a5 / and
                                    :op1 (p2 / perform-02)
                                    :op2 (a6 / accurate))
                              :op2 (p3 / privacy
                                    :mod (d / data))
                              :op3 (a7 / and
                                    :op1 (s3 / security)
                                    :op2 (g / govern-01))
                              :op4 (t / transparent)
                              :op5 (e2 / explain-01)
                              :op6 (a8 / accountable-02)
                              :op7 (a9 / and
                                    :op1 (r / risk-01)
                                    :op2 (m3 / mitigate-01
                                          :ARG1 (ii3 / impact-01)))
                              :op8 (f / fairness)
                              :op9 (o / oversee-01
                                    :ARG0 (h2 / human))))))
      :snt2 (h3 / have-condition-91
            :ARG1 (w / will-02
                  :ARG0 (c3 / citizen
                        :ARG2-of (ii4 / include-91
                              :ARG1 (c4 / citizen
                                    :quant (m4 / more-than
                                          :op1 (p4 / percentage-entity
                                                :value 57)))
                              :ARG3 (m5 / most)))
                  :ARG1 (u / use-01
                        :ARG0 c3
                        :ARG1 s))
            :ARG2 (ii5 / in-place
                  :domain (m6 / mechanism
                        :ARG0-of (a10 / assure-01)
                        :example (a11 / and
                              :op1 (r2 / review-01
                                    :ARG1 (e3 / ethics
                                          :ARG0-of (d2 / depend-01
                                                :polarity -))
                                    :op2 (c5 / certify-01
                                          :ARG1 e3)
                                    :op3 (s4 / standard
                                          :mod (n / nation)
                                          :topic (t2 / transparency))
                                    :op4 (c6 / code-01
                                          :ARG1 e3)))))))

# ::snt fairness), is transparent about  the data it collects and how it is used, and upholds the rights  of users and societal interests.
# File 117

(a / and
      :op1 (t / transparency
            :domain (f / fairness))
      :op2 (a2 / and
            :op1 (c / collect-01
                  :ARG0 f
                  :ARG1 (d / data))
            :op2 (u / use-01
                  :ARG0 f
                  :ARG1 d))
      :op3 (u2 / uphold-01
            :ARG0 f
            :ARG1 (r / right-05
                  :ARG1 (a3 / and
                        :op1 (p / person
                              :ARG0-of (u3 / use-01))
                        :op2 (ii / interest
                              :mod (s / society))))))

# ::snt Fairness and   non-discrimination The outcomes of AI systems  are assessed regularly to  ensure they are fair, free of  unfair bias, and designed to  be inclusive to a diversity of  users.
# File 117

(a / assess-01
      :ARG1 (o / outcome
            :poss (s / system
                  :mod (ii / intelligent-01
                        :mod (a2 / artificial))))
      :ARG3 (e / ensure-01
            :ARG0 o
            :ARG1 (a3 / and
                  :op1 (f / fair-01
                        :ARG1 s)
                  :op2 (f2 / free-04
                        :ARG1 s
                        :ARG2 (b / bias-01
                              :ARG1-of (f3 / fair-01
                                    :polarity -)))
                  :op3 (d / design-01
                        :ARG1 s
                        :ARG3 (ii2 / include-01
                              :ARG1 (p / person
                                    :ARG0-of (u / use-01)
                                    :mod (d2 / diversity))
                              :ARG2 s))))
      :ARG1-of (r / regular-02)
      :ARG0-of (m / mean-01
            :ARG1 (a4 / and
                  :op1 (f4 / fairness)
                  :op2 (d3 / discriminate-01
                        :polarity -))))

# ::snt % Low Importance % Moderate Importance % High Importance Data Privacy, Security & Governance Technical Robustness & Safety Transparency & Explainability Human Agency & Oversight Accountability & Contestability Fairness, Inclusion & Non-discrimination AI Literacy Risk & Impact Mitigation6 14 80 5 16 79 5 17 78 5 19 76 5 19 76 5 19 76 5 22 73 6 21 73 Low importance = 'Not at all important', 'Very low importance', or 'Low importance' Moderate importance = 'Moderately important' High importance = 'High importance', 'Very high importance', or 'Extr emely important' ©2021 The University of Queensland  ©2021 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company  limited by guarantee.
# File 117

(m / multi-sentence
      :snt1 (a / and
            :op1 (ii / important-01
                  :ARG1 (d / data)
                  :ARG1-of (l / low-04))
            :op2 (ii2 / important-01
                  :ARG1 d
                  :ARG1-of (m2 / moderate-01))
            :op3 (a2 / and
                  :op1 (s / secure-02)
                  :op2 (g / govern-01)
                  :op3 (t / transparency)
                  :op4 (e / explain-01)
                  :op5 (a3 / audit-01)
                  :op6 (o / organization
                        :mod (h / human)
                        :ARG0-of (o2 / oversee-01))
                  :op7 (a4 / accountable-02)
                  :op8 (f / fairness)
                  :op9 (d2 / discriminate-02
                        :polarity -)
                  :op10 (r / risk-01
                        :mod (ii3 / intelligent-01
                              :mod (a5 / artificial)))
                  :op11 (m3 / mitigate-01
                        :ARG1 (ii4 / impact-01)))
            :ARG1-of (m4 / mean-01
                  :ARG2 (o3 / or
                        :op1 (ii5 / important-01
                              :polarity -
                              :degree (a6 / at-all))
                        :op2 (ii6 / important-01
                              :degree (v / very))
                        :op3 (ii7 / important-01
                              :degree (m5 / moderate-01))
                        :op4 (ii8 / important-01
                              :degree (v2 / very)))))
      :snt2 (o4 / organization
            :name (n / name
                  :op1 "KPMG"
                  :op2 "International"
                  :op3 "Limited")
            :domain (f2 / firm
                  :mod (c / country
                        :name (n2 / name
                              :op1 "Australia"))
                  :ARG1-of (a7 / affiliate-01
                        :ARG2 (f3 / firm
                              :ARG0-of (h2 / have-org-role-91
                                    :ARG1 (o5 / organization
                                          :name (n3 / name
                                                :op1 "KPMG")
                                          :mod (g2 / globe)
                                          :consist-of (f4 / firm
                                                :ARG0-of (d3 / depend-01
                                                      :polarity -))))))
                  :ARG1-of (p / private-03)
                  :mod (c2 / country
                        :name (n4 / name
                              :op1 "England")))
            :time (d4 / date-entity
                  :year 2002
                  :month 7
                  :day 21)))

# ::snt They expect organisations to maintain high standards  of AI systems in terms of:    –performance and accuracy   –data privacy   –security and governance   –transparency and explainability   –accountability   –risk and impact mitigation   –fairness   –human oversight   –These principles and practices reflect those identified in  numerous recent government reports on trustworthy,  ethical AI 28, and our findings provide clear public  endorsement for them, as well as underscoring their  importance for public trust.
# File 117

(a / and
      :op1 (e / expect-01
            :ARG0 (t / they)
            :ARG1 (m / maintain-01
                  :ARG0 (o / organization)
                  :ARG1 (s / standard
                        :ARG1-of (h / high-02)
                        :topic (a2 / and
                              :op1 (p / perform-02)
                              :op2 (a3 / accurate)
                              :op3 (p2 / privacy
                                    :mod (d / data))
                              :op4 (s2 / security)
                              :op5 (g / govern-01)
                              :op6 (a4 / and
                                    :op1 (t2 / transparency)
                                    :op2 (e2 / explain-01))
                              :op7 (a5 / accountable-02)
                              :op8 (a6 / and
                                    :op1 (r / risk-01)
                                    :op2 (m2 / mitigate-01
                                          :ARG1 (ii / impact-01)))
                              :op9 (f / fairness)
                              :op10 (o2 / oversee-01
                                    :ARG0 (h2 / human))))))
      :op2 (p3 / provide-01
            :ARG0 (t3 / thing
                  :ARG1-of (f2 / find-01
                        :ARG0 (w / we)))
            :ARG1 (e3 / endorse-01
                  :ARG0 (p4 / public)
                  :ARG1 t)
            :ARG1-of (c / clear-06)
            :ARG0-of (u / underscore-01
                  :ARG1 (ii2 / important-01
                        :ARG1 t
                        :ARG2 (t4 / trust-01
                              :ARG0 p4))))
      :ARG2 t
      :op3 (r2 / reflect-01
            :ARG1 (t5 / thing
                  :ARG1-of (p5 / practice-01)
                  :mod (t6 / this))
            :ARG2 (t7 / thing
                  :ARG1-of (ii3 / identify-01
                        :ARG0 (r3 / report-01
                              :ARG0 (g2 / government-organization
                                    :ARG0-of g))
                        :ARG1 (t8 / thing
                              :name (n / name
                                    :op1 "Artificial"
                                    :op2 28)
                              :mod (t9 / trustworthy)
                              :mod (e4 / ethics))
                        :time (r4 / recent)
                        :quant (n2 / numerous)))))

# ::snt A primer for cliniciansPatient safety The doctor and patient relationshipPublic acceptance and trust Accountability for decisionsBias, inequality and unfairnessData quality, consent and information governanceTraining and educationMedical researchThe regulatory environmentIntellectual property and the financial impact  on the healthcare system Impact on doctors’ working livesImpact on the wider healthcare systemGlossaryFurther readingThanks346811141618202224262830 32 34363839 Contents
# File 28

(m / multi-sentence
      :snt1 (p / primer
            :beneficiary (p2 / person
                  :ARG0-of (h / have-org-role-91
                        :ARG2 (c / clinician))))
      :snt2 (a / and
            :op1 (s / safe-01
                  :ARG1 (p3 / patient))
            :op2 (r / relation-03
                  :ARG0 (d / doctor)
                  :ARG2 (p4 / patient))
            :op3 (a2 / and
                  :op1 (a3 / accept-01
                        :ARG1 (t / thing
                              :ARG1-of (d2 / decide-01))
                        :ARG1-of (p5 / public-02))
                  :op2 (a4 / accountable-02
                        :ARG1 t
                        :mod (t2 / trust)))
            :op4 (a5 / and
                  :op1 (b / bias-01)
                  :op2 (e / equal-01
                        :polarity -)
                  :op3 (f / fair-01
                        :polarity -))
            :op5 (a6 / and
                  :op1 (q / quality
                        :mod (d3 / data))
                  :op2 (c2 / consent-01)
                  :op3 (g / govern-01
                        :ARG1 (ii / information)))
            :op6 (a7 / and
                  :op1 (t3 / train-01)
                  :op2 (e2 / educate-01))
            :op7 (r2 / research-01
                  :ARG1 (m2 / medicine))
            :op8 (e3 / environment
                  :ARG0-of (r3 / regulate-01))
            :op9 (a8 / and
                  :op1 (p6 / property
                        :mod (ii2 / intellectual))
                  :op2 (ii3 / impact-01
                        :ARG1 (s2 / system
                              :mod (h2 / healthcare)
                              :ARG1-of (h3 / have-degree-91
                                    :ARG2 (w / wide-02
                                          :ARG1 s2)
                                    :ARG3 (m3 / more)))
                        :mod (f2 / financial))
                  :op10 (ii4 / impact-01
                        :ARG1 (l / live-01
                              :ARG0 (p7 / person
                                    :ARG0-of (w2 / work-01
                                          :ARG2 d))))))
      :snt3 (r4 / read-01
            :mod (f3 / further)))

# ::snt These are: — Patient safety  — The doctor an d patient r elati onship — Public a cceptance an d trust — Accountability f or de cisions — Bias, i nequality an d unfairness — Data qu ality, c onsent an d information go vernance — Training an d education — Medical r esearch — The regulatory en vironment — Intellectual pr operty an d the financial i mpact on t he h ealthcare s ystem  — Impact o n do ctors’ w orking l ives — Impact o n the w ider h ealthcare s ystem.
# File 28

(e / exemplify-01
      :ARG0 (t / this)
      :ARG1 (a / and
            :op1 (s / safe-01
                  :ARG1 (p / patient))
            :op2 (p2 / person
                  :ARG0-of (h / have-rel-role-91
                        :ARG1 p
                        :ARG2 (p3 / patient)))
            :op3 (c / corporation
                  :ARG0-of (o / operate-01))
            :op4 (c2 / corporation
                  :ARG0-of (o2 / operate-01)
                  :ARG1-of (p4 / public-02))
            :op5 (a2 / accountable-02
                  :mod (o3 / or
                        :op1 (a3 / accountable-02)
                        :op2 (a4 / accountable-02
                              :polarity -)))
            :op6 a
            :op1 (b / bias-01)
            :op2 (q / quality
                  :polarity -)
            :op3 (f / fair-01
                  :polarity -))
      :op7 q
      :mod (d / data)
      :op8 (c3 / come-01
            :ARG1 (ii / information))
      :op9 (t2 / train-01)
      :op10 (e2 / educate-01)
      :op11 (r / research-01
            :ARG1 (m / medicine))
      :op12 (m2 / mandate-01
            :ARG1 (r2 / regulate-01))
      :op13 (p5 / perform-02
            :ARG0 (p6 / person
                  :ARG0-of h
                  :ARG1 p
                  :ARG2 (p7 / patient)))
      :ARG1 (b2 / business)
      :ARG2 (f2 / finance)
      :op14 (ii2 / impact-01
            :ARG0 (p8 / person
                  :ARG0-of (w / work-01
                        :ARG1 (c4 / company
                              :name (n / name
                                    :op1 "Ctors"))))
            :ARG1 b2))

# ::snt Bias, inequality and unfairness
# File 28

(a / and
      :op1 (b / bias-01)
      :op2 (e / equal-01
            :polarity -)
      :op3 (f / fair-01
            :polarity -))

# ::snt Will this type of technology therefore promote bias and unfairness?
# File 28

(ii / infer-01
      :polarity (a / amr-unknown)
      :ARG1 (p / promote-02
            :ARG0 (t / type
                  :mod (t2 / technology)
                  :mod (t3 / this))
            :ARG1 (a2 / and
                  :op1 (b / bias-01)
                  :op2 (f / fairness
                        :polarity -))))

# ::snt The conceptual complexities surrounding what “values” are (e.g., Hitlin and Piliavin, 2004;  Malle and Dickert, 2007; Rohan, 2000; Sommer, 2016) make it currently difficult to envision  A/IS that have computational structures directly corresponding to social or cultural values  (such as “security,” “autonomy,” or “fairness”).
# File 3

(m / make-02
      :ARG0 (c / complexity
            :mod (c2 / conceptual)
            :ARG0-of (s / surround-01
                  :ARG1 (v / value))
            :example (a / and
                  :op1 (a2 / and
                        :op1 (p / person
                              :name (n / name
                                    :op1 "Hitlin"))
                        :op2 (p2 / person
                              :name (n2 / name
                                    :op1 "Pilus"))
                        :time (d / date-entity
                              :year 2004))
                  :op2 (a3 / and
                        :op1 (p3 / person
                              :name (n3 / name
                                    :op1 "Malle"))
                        :op2 (p4 / person
                              :name (n4 / name
                                    :op1 "Dickert"))
                        :time (d2 / date-entity
                              :year 2007))
                  :op3 (p5 / person
                        :name (n5 / name
                              :op1 "Rohan")
                        :time (d3 / date-entity
                              :year 2000))
                  :op4 (p6 / person
                        :name (n6 / name
                              :op1 "Sommer")
                        :time (d4 / date-entity
                              :year 2016))))
      :ARG1 (d5 / difficult
            :domain (e / envision-01
                  :ARG1 (s2 / slash
                        :op1 (a4 / analyze-01)
                        :op2 (s3 / science
                              :mod (ii / information))
                        :ARG0-of (h / have-03
                              :ARG1 (s4 / structure
                                    :mod (c3 / computational)
                                    :ARG1-of (c4 / correspond-02
                                          :ARG2 (o / or
                                                :op1 (v2 / value
                                                      :mod (s5 / society))
                                                :op2 (v3 / value
                                                      :mod (c5 / culture))
                                                :example o
                                                :op1 (s6 / security)
                                                :op2 (a5 / autonomy)
                                                :op3 (f / fairness)))
                                    :ARG1-of (d6 / direct-02))))))
      :time (c6 / current))

# ::snt For instance, an organization can refer to the “trade-offs” (or “value trade-offs”) involved in the examination of the fairness of an algorithm to a specific end user population.
# File 3

(e / exemplify-01
      :ARG0 (p / possible-01
            :ARG1 (r / refer-01
                  :ARG0 (o / organization)
                  :ARG1 (t / trade-off-02
                        :ARG1-of (ii / involve-01
                              :ARG2 (e2 / examine-01
                                    :ARG1 (f / fair-01
                                          :ARG1 f
                                          :ARG1 (a / algorithm)
                                          :ARG2 (p2 / population
                                                :ARG2-of (ii2 / include-91
                                                      :ARG1 (p3 / person
                                                            :ARG0-of (u / use-01
                                                                  :mod (e3 / end)))
                                                      :ARG1-of (s / specific-02)))))))
                  :ARG1-of (m / mean-01
                        :ARG2 (t2 / trade-off-02
                              :ARG1 (v / value))))))

# ::snt Organizational members must ensure that the technologies they create enhance meaningful human control over increasingly sophisticated systems and do not undermine or eliminate the values of respect, humanity, fairness, and dignity.
# File 3

(o / obligate-01
      :ARG2 (e / ensure-01
            :ARG0 (p / person
                  :ARG0-of (h / have-org-role-91
                        :ARG1 (o2 / organization)
                        :ARG2 (m / member)))
            :ARG1 (a / and
                  :op1 (e2 / enhance-01
                        :ARG0 (t / technology
                              :ARG1-of (c / create-01
                                    :ARG0 p))
                        :ARG1 (c2 / control-01
                              :ARG0 (h2 / human)
                              :ARG1 (s / system
                                    :mod (s2 / sophisticated
                                          :ARG1-of (ii / increase-01)))
                              :ARG0-of (m2 / meaningful-05)))
                  :op2 (o3 / or
                        :op1 (u / undermine-01
                              :polarity -
                              :ARG0 t
                              :ARG1 (v / value
                                    :example (a2 / and
                                          :op1 (r / respect-01)
                                          :op2 (h3 / humanity)
                                          :op3 (f / fairness)
                                          :op4 (d / dignity))))
                        :op2 (e3 / eliminate-01
                              :polarity -
                              :ARG0 t
                              :ARG1 v)))))

# ::snt • Zarsky, T. “ The Trouble with Algorithmic  Decisions: an Analytic Roadmap to Examine Efficiency and Fairness in Automated and Opaque Decision Making .” Science,  Technology & Human Values  41, no.
# File 3

(p / publication-91
      :ARG0 (p2 / person
            :name (n / name
                  :op1 "Zarsky"))
      :ARG1 (p3 / publication
            :name (n2 / name
                  :op1 "The"
                  :op2 "Trouble"
                  :op3 "with"
                  :op4 "Algorithmic"
                  :op5 "Decisions:"
                  :op6 "An"
                  :op7 "Analysis"
                  :op8 "Roadmap"
                  :op9 "to"
                  :op10 "Examine"
                  :op11 "and"
                  :op12 "Efficiency"
                  :op13 "and"
                  :op14 "Fairness"
                  :op15 "in"
                  :op16 "Automated"
                  :op17 "and"
                  :op18 "Op19 "
                  :op22 "Decision"))
      :ARG4 (j / journal
            :name (n3 / name
                  :op1 "Science,"
                  :op2 "Technology"
                  :op3 "and"
                  :op4 "Human"
                  :op5 "Values")
            :ord (o / ordinal-entity
                  :value 41)
            :ARG6 "No."))

# ::snt We recommend the following: • Enable a cross-disciplinary research  environment that encourages research on the fairness, security, transparency, understandability, privacy, and societal impacts of A/IS and that incorporates   independent means to properly vet, audit, and assign accountability to the A/IS applications.
# File 3

(r / recommend-01
      :ARG0 (w / we)
      :ARG1 (a / and
            :op1 (e / enable-01
                  :ARG1 (e2 / environment
                        :mod (r2 / research-01)
                        :mod (c / cross-disciplinary)
                        :ARG0-of (e3 / encourage-01
                              :ARG2 (r3 / research-01
                                    :ARG1 (a2 / and
                                          :op1 (f / fairness)
                                          :op2 (s / security)
                                          :op3 (t / transparency)
                                          :op4 (p / possible-01
                                                :ARG1 (u / understand-01))
                                          :op5 (p2 / privacy)
                                          :op6 (ii / impact-01
                                                :ARG0 (p3 / product
                                                      :name (n / name
                                                            :op1 "A/IS"))
                                                :ARG1 (s2 / society)))))
                        :ARG0-of (ii2 / incorporate-01
                              :ARG1 (m / means
                                    :ARG0-of (d / depend-01
                                          :polarity -)
                                    :instrument-of (a3 / and
                                          :op1 (v / vet-01
                                                :ARG1 (a4 / application
                                                      :mod p3)
                                                :manner (p4 / proper))
                                          :op2 (a5 / audit-01
                                                :ARG1 a4)
                                          :op3 (a6 / assign-01
                                                :ARG1 (a7 / accountable-02)
                                                :ARG2 a4))))))
            :ARG1-of (f2 / follow-04)))

# ::snt To better understand the societal implications of A/IS, we recommend that funding be increased for interdisciplinary research on topics ranging from basic research into intelligence to principles on ethics, safety, privacy, fairness, liability, and trustworthiness of A/IS technology.
# File 3

(r / recommend-01
      :ARG0 (w / we)
      :ARG1 (ii / increase-01
            :ARG1 (f / fund-01
                  :ARG1 (r2 / research-01
                        :ARG1 (t / topic
                              :ARG1-of (r3 / range-01
                                    :ARG3 (r4 / research-01
                                          :ARG1 (ii2 / intelligence)
                                          :mod (b / basic))
                                    :ARG4 (p / principle
                                          :topic (a / and
                                                :op1 (e / ethics)
                                                :op2 (s / safe-01)
                                                :op3 (p2 / privacy)
                                                :op4 (f2 / fairness)
                                                :op5 (l / liable-01)
                                                :op6 (d / deserve-01
                                                      :ARG0 (t2 / technology
                                                            :mod (s2 / slash
                                                                  :op1 (a2 / accident)
                                                                  :op2 (s3 / security)))
                                                      :ARG1 (t3 / trust-01))))))
                        :mod (ii3 / interdisciplinary))))
      :purpose (u / understand-01
            :ARG1 (ii4 / implicate-01
                  :ARG0 t2
                  :ARG1 (s4 / society))
            :ARG1-of (h / have-degree-91
                  :ARG2 (g / good-02
                        :ARG1 u)
                  :ARG3 (m / more))))

